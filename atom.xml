<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ESY</title>
  
  <subtitle>miao</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://esyyes.github.io/"/>
  <updated>2020-07-22T04:39:11.000Z</updated>
  <id>https://esyyes.github.io/</id>
  
  <author>
    <name>esy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>chatbot_sorry篇</title>
    <link href="https://esyyes.github.io/2020/07/22/chatbot/chatbot-sorry%E7%AF%87/"/>
    <id>https://esyyes.github.io/2020/07/22/chatbot/chatbot-sorry%E7%AF%87/</id>
    <published>2020-07-22T04:39:11.000Z</published>
    <updated>2020-07-22T04:39:11.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="chatbot-sorry篇"><a href="#chatbot-sorry篇" class="headerlink" title="chatbot_sorry篇"></a>chatbot_sorry篇</h1><p>直接循环输入语句。判断哪些句子无法被检测</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"># @Time     : 2020/7/22</span><br><span class="line"># @Author   : esy</span><br><span class="line"></span><br><span class="line">from chatbot_21 import *</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data = pd.read_csv(&apos;Q&amp;A pairs.csv&apos;)</span><br><span class="line">print(&quot;Hello, I&apos;m a question-and-answer chatbot for the tourism domain based on retrieval mode.&quot;</span><br><span class="line">      &quot;If you want to exit, input &apos;Bye&apos;!&quot;)</span><br><span class="line">greeting_output = [&quot;hi&quot;, &quot;hey&quot;, &quot;hello&quot;, &quot;I&apos;m glad! You are talking to me&quot;]</span><br><span class="line"></span><br><span class="line">for i in range(len(data)):</span><br><span class="line">    question = np.array(data[&apos;Question&apos;]).tolist()</span><br><span class="line">    text2 = question[i]</span><br><span class="line">    # 将词还原到最基础模式</span><br><span class="line">    text1 = &quot; &quot;.join([token.lemma_ for token in nlp(text2)])</span><br><span class="line">    # 进行简单回复</span><br><span class="line">    if text1 == &apos;hey&apos; or text1 == &apos;hi&apos; or text1 == &apos;hello&apos; or text1 == &apos;HI&apos;:</span><br><span class="line">        print(random.choice(greeting_output))</span><br><span class="line">    elif text1 == &apos;thank&apos; or text1 == &apos;thank -PRON-&apos; or text1 == &apos;THANK&apos;:</span><br><span class="line">        print(&apos;You are welcome.&apos;)</span><br><span class="line">    elif text1 == &apos;bye&apos; or text1 == &apos;BYE&apos;:</span><br><span class="line">        print(&apos;Bye!&apos;)</span><br><span class="line">    elif len(text1.split()) &lt; 3:</span><br><span class="line">        print(f&quot;I&apos;m sorry. I don&apos;t understand you&quot;)</span><br><span class="line">        print(f&apos;第&#123;i+1&#125;个由于n&lt;3&apos;)</span><br><span class="line">    else:</span><br><span class="line">        if QA_tf_idf(data, del_stop(text1)) == 0:</span><br><span class="line">            print(f&quot;I&apos;m sorry. I don&apos;t understand you&quot;)</span><br><span class="line">            print(f&apos;第&#123;i+1&#125;个由于return=0&apos;)</span><br><span class="line">        else:</span><br><span class="line">            tf_idf1, quet_tfidf1, scores1 = QA_tf_idf(data, del_stop(text1))</span><br><span class="line">            recall_ques1, recall_answ1, recall_tf_idf_1 = recall_5(scores1, data, tf_idf1)</span><br><span class="line">            # print(f&apos;召回的5个问题&apos;)</span><br><span class="line">            # for j in range(5):</span><br><span class="line">                # print(f&apos;第&#123;j + 1&#125;问题：&#123;recall_ques1[j]&#125;&apos;, end=&apos;\t&apos;)</span><br><span class="line">                # print(f&apos;相似度：&#123;similar_list(quet_tfidf1, recall_tf_idf_1)[j]&#125;&apos;)</span><br><span class="line">            # print(f&apos;最佳答案：&#123;best_answer(similar_list(quet_tfidf1, recall_tf_idf_1), recall_answ1)&#125;&apos;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">I<span class="string">'m sorry. I don'</span>t understand you</span><br><span class="line">第<span class="number">4</span>个由于<span class="keyword">return</span>=<span class="number">0</span></span><br><span class="line">I<span class="string">'m sorry. I don'</span>t understand you</span><br><span class="line">第<span class="number">5</span>个由于<span class="keyword">return</span>=<span class="number">0</span></span><br><span class="line">I<span class="string">'m sorry. I don'</span>t understand you</span><br><span class="line">第<span class="number">9</span>个由于<span class="keyword">return</span>=<span class="number">0</span></span><br><span class="line">I<span class="string">'m sorry. I don'</span>t understand you</span><br><span class="line">第<span class="number">15</span>个由于<span class="keyword">return</span>=<span class="number">0</span></span><br><span class="line">I<span class="string">'m sorry. I don'</span>t understand you</span><br><span class="line">第<span class="number">18</span>个由于<span class="keyword">return</span>=<span class="number">0</span></span><br><span class="line">I<span class="string">'m sorry. I don'</span>t understand you</span><br><span class="line">第<span class="number">29</span>个由于<span class="keyword">return</span>=<span class="number">0</span></span><br><span class="line">I<span class="string">'m sorry. I don'</span>t understand you</span><br><span class="line">第<span class="number">30</span>个由于<span class="keyword">return</span>=<span class="number">0</span></span><br><span class="line">I<span class="string">'m sorry. I don'</span>t understand you</span><br><span class="line">第<span class="number">85</span>个由于<span class="keyword">return</span>=<span class="number">0</span></span><br><span class="line">I<span class="string">'m sorry. I don'</span>t understand you</span><br><span class="line">第<span class="number">88</span>个由于<span class="keyword">return</span>=<span class="number">0</span></span><br><span class="line">I<span class="string">'m sorry. I don'</span>t understand you</span><br><span class="line">第<span class="number">95</span>个由于<span class="keyword">return</span>=<span class="number">0</span></span><br><span class="line">I<span class="string">'m sorry. I don'</span>t understand you</span><br><span class="line">第<span class="number">98</span>个由于<span class="keyword">return</span>=<span class="number">0</span></span><br><span class="line">I<span class="string">'m sorry. I don'</span>t understand you</span><br><span class="line">第<span class="number">99</span>个由于<span class="keyword">return</span>=<span class="number">0</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/7/22</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> en_core_web_md</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line">nlp = en_core_web_md.load()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 预处理文本数据，将单词还原成基础模式，小写，删除停靠词，得到关键词</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">del_stop</span><span class="params">(text)</span>:</span></span><br><span class="line">    token_doc = [token.lemma_ <span class="keyword">for</span> token <span class="keyword">in</span> nlp(text)]</span><br><span class="line">    <span class="comment"># 去除停用词后创建单词列表</span></span><br><span class="line">    filtered_sentence = []</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> token_doc:</span><br><span class="line">        lexeme = nlp.vocab[word]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> lexeme.is_stop != <span class="literal">False</span>:</span><br><span class="line">            filtered_sentence.append(word)</span><br><span class="line">    <span class="keyword">return</span> filtered_sentence</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算tfidf得分</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">QA_tf_idf</span><span class="params">(data, filtered_sentence)</span>:</span></span><br><span class="line">    question = np.array(data[<span class="string">'Question'</span>]).tolist()</span><br><span class="line">    <span class="comment"># 将问题进行分词</span></span><br><span class="line">    list_ques = [[t.lemma_ <span class="keyword">for</span> t <span class="keyword">in</span> nlp(question[i])] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data))]</span><br><span class="line">    <span class="comment"># 去除停用词后创建单词列表</span></span><br><span class="line">    list_key = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        filtered_sentence1 = []</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> list_ques[i]:</span><br><span class="line">            lexeme = nlp.vocab[word]</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> lexeme.is_stop != <span class="literal">False</span>:</span><br><span class="line">                filtered_sentence1.append(word)</span><br><span class="line">        list_key.append(filtered_sentence1)</span><br><span class="line">    <span class="comment"># 统计词频和词汇,看单词出现的次数</span></span><br><span class="line">    doc_frequency = defaultdict(int)</span><br><span class="line">    list_words = list_key</span><br><span class="line">    <span class="keyword">for</span> word_list <span class="keyword">in</span> list_words:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> word_list:</span><br><span class="line">            doc_frequency[i] += <span class="number">1</span></span><br><span class="line">    l1 = set(filtered_sentence)</span><br><span class="line">    l2 = set(doc_frequency.keys())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> l1.issubset(l2) != <span class="literal">False</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 计算每个词的IDF值</span></span><br><span class="line">        word_idf = &#123;&#125;  <span class="comment"># 存储每个词的idf值</span></span><br><span class="line">        word_doc = defaultdict(int)  <span class="comment"># 存储包含该词的文档数</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> doc_frequency:</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> list_words:</span><br><span class="line">                <span class="keyword">if</span> i <span class="keyword">in</span> j:</span><br><span class="line">                    word_doc[i] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> doc_frequency:</span><br><span class="line">            word_idf[i] = math.log(len(list_key) / (word_doc[i] + <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对样本进行词频统计</span></span><br><span class="line">        list_doc = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(list_key)):</span><br><span class="line">            doc_frequency1 = defaultdict(int)</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> list_key[i]:</span><br><span class="line">                doc_frequency1[j] += <span class="number">1</span></span><br><span class="line">            list_doc.append(doc_frequency1)</span><br><span class="line">        <span class="comment"># 计算语料库中每个词的tf_idf,构建向量</span></span><br><span class="line">        tf_idf = []</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(data)):</span><br><span class="line">            tf_idf.append([word_idf[i] * list_doc[j][i] / len(list_key[j]) <span class="keyword">for</span> i <span class="keyword">in</span> (list_doc[j])])</span><br><span class="line"></span><br><span class="line">        doc_frequency2 = defaultdict(int)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> filtered_sentence:</span><br><span class="line">            doc_frequency2[i] += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 计算问题对应语料库的tf-idf得分</span></span><br><span class="line">        scores = []</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(data)):</span><br><span class="line">            score = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> doc_frequency2:</span><br><span class="line">                score += (word_idf[i] * list_doc[j][i] / len(list_key[j]))</span><br><span class="line">            scores.append(score)</span><br><span class="line">        <span class="comment"># 直接计算问题的语料库得分</span></span><br><span class="line">        <span class="comment"># 对问题进行词频统计</span></span><br><span class="line"></span><br><span class="line">        quet_tfidf = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> doc_frequency2:</span><br><span class="line">            quet_tfidf.append(word_idf[i] * doc_frequency2[i] / len(filtered_sentence))</span><br><span class="line">    <span class="keyword">return</span> tf_idf, quet_tfidf, scores</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">recall_5</span><span class="params">(scores, data, tf_idf)</span>:</span></span><br><span class="line">    question = np.array(data[<span class="string">'Question'</span>]).tolist()</span><br><span class="line">    answer = np.array(data[<span class="string">'Answer'</span>]).tolist()</span><br><span class="line">    <span class="comment"># 用字典形式按照升序形式排序</span></span><br><span class="line">    x = np.arange(len(data)).tolist()</span><br><span class="line">    dict_score = dict(zip(x, scores))</span><br><span class="line">    listc = sorted(zip(dict_score.values(), dict_score.keys()))</span><br><span class="line">    recall_ques = []</span><br><span class="line">    recall_answ = []</span><br><span class="line">    recall_tf_idf = []</span><br><span class="line">    <span class="comment"># 召回得分最高的5个问题</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">6</span>):</span><br><span class="line">        recall_ques.append(question[listc[-i][<span class="number">1</span>]])</span><br><span class="line">        recall_answ.append(answer[listc[-i][<span class="number">1</span>]])</span><br><span class="line">        recall_tf_idf.append(tf_idf[listc[-i][<span class="number">1</span>]])</span><br><span class="line">    <span class="keyword">return</span> recall_ques, recall_answ, recall_tf_idf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 求5个问题的相似度</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">similar_list</span><span class="params">(quet_tfidf, recall_tf_idf)</span>:</span></span><br><span class="line">    similar_score = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(recall_tf_idf)):</span><br><span class="line">        <span class="keyword">if</span> len(recall_tf_idf[i]) == len(quet_tfidf):</span><br><span class="line">            similar_score.append(np.dot(quet_tfidf, recall_tf_idf[i]) / (np.linalg.norm(quet_tfidf) * np.linalg.norm(recall_tf_idf[i])))</span><br><span class="line">        <span class="keyword">elif</span> len(recall_tf_idf[i]) &lt; len(quet_tfidf):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(len(quet_tfidf) - len(recall_tf_idf[i])):</span><br><span class="line">                c = recall_tf_idf[i]</span><br><span class="line">                c.append(<span class="number">0</span>)</span><br><span class="line">            similar_score.append(np.dot(quet_tfidf, c) / (np.linalg.norm(quet_tfidf) * np.linalg.norm(recall_tf_idf[i])))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(abs(len(quet_tfidf) - len(recall_tf_idf[i]))):</span><br><span class="line">                a = quet_tfidf</span><br><span class="line">                a.append(<span class="number">0</span>)</span><br><span class="line">            similar_score.append(np.dot(a, recall_tf_idf[i]) / (np.linalg.norm(a) * np.linalg.norm(recall_tf_idf[i])))</span><br><span class="line">    <span class="keyword">return</span> similar_score</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出相似度最高的那个的答案</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">best_answer</span><span class="params">(list_num, recall_answ)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> max(list_num) &lt;= <span class="number">0.2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f"I'm sorry. I don't understand you"</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        best_ans = recall_answ[list_num.index(max(list_num))]</span><br><span class="line">        <span class="keyword">return</span> best_ans</span><br></pre></td></tr></table></figure><h2 id="问题查询："><a href="#问题查询：" class="headerlink" title="问题查询："></a>问题查询：</h2><h3 id="1-查看去除停靠词后句子"><a href="#1-查看去除停靠词后句子" class="headerlink" title="1.查看去除停靠词后句子"></a>1.查看去除停靠词后句子</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sl = set([<span class="number">1</span>, <span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">sl2 = set([<span class="number">2</span>,<span class="number">3</span>, <span class="number">7</span>,<span class="number">9</span>])</span><br><span class="line">sl.issubset(sl2)</span><br><span class="line">Out[<span class="number">5</span>]: <span class="literal">False</span></span><br></pre></td></tr></table></figure><p>感觉是去除词频后，没有包含进去</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># if not l1.issubset(l2) != False:</span></span><br><span class="line"><span class="comment">#     if not True != &#123;'-pron-'&#125;.issubset(l1):</span></span><br><span class="line"><span class="comment">#         doc_frequency2['-PRON-'] = doc_frequency2['-pron-']</span></span><br></pre></td></tr></table></figure><p>经查验，经过问题的分词后，人输出为pron，而语料库中是大写的PRON</p><p>sl.issubset(sl2)是属于包含关系，需要调整为</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> len(l1 &amp; l2) == <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><p>判断两个集合是否有交集，这样即使输入的内容有些关键词汇不在语料库中也能直接输出。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_chatbot</span><span class="params">(text2, data)</span>:</span></span><br><span class="line">    text1 = <span class="string">" "</span>.join([token.lemma_ <span class="keyword">for</span> token <span class="keyword">in</span> nlp(text2)])</span><br><span class="line">    <span class="keyword">if</span> text1 == <span class="string">'hey'</span> <span class="keyword">or</span> text1 == <span class="string">'hi'</span> <span class="keyword">or</span> text1 == <span class="string">'hello'</span> <span class="keyword">or</span> text1 == <span class="string">'HI'</span>:</span><br><span class="line">        <span class="keyword">return</span> random.choice(greeting_output)</span><br><span class="line">    <span class="keyword">elif</span> text1 == <span class="string">'thank'</span> <span class="keyword">or</span> text1 == <span class="string">'thank -PRON-'</span> <span class="keyword">or</span> text1 == <span class="string">'THANK'</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'You are welcome.'</span></span><br><span class="line">    <span class="keyword">elif</span> text1 == <span class="string">'bye'</span> <span class="keyword">or</span> text1 == <span class="string">'BYE'</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'Bye!'</span></span><br><span class="line">    <span class="keyword">elif</span> len(text1.split()) &lt; <span class="number">3</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"I'm sorry. I don't understand you"</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> QA_tf_idf(data, del_stop(text2)) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"I'm sorry. I don't understand you"</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            tf_idf1, quet_tfidf1, scores1 = QA_tf_idf(data, del_stop(text2))</span><br><span class="line">            recall_ques1, recall_answ1, recall_tf_idf_1 = recall_5(scores1, data, tf_idf1)</span><br><span class="line">            <span class="keyword">return</span> best_answer(similar_list(quet_tfidf1, recall_tf_idf_1), recall_answ1)</span><br></pre></td></tr></table></figure><p>也同时对输出的语句进行规制的判定，如果不在规制内，输入的单词小于3个也直接输出</p><h3 id="2-相似度问题"><a href="#2-相似度问题" class="headerlink" title="2.相似度问题"></a>2.相似度问题</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">similar_spacy</span><span class="params">(text, recall_ques)</span>:</span></span><br><span class="line">    similar_goal = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(recall_ques)):</span><br><span class="line">        similar_goal.append(nlp(text).similarity(nlp(recall_ques[i])))</span><br><span class="line">    <span class="keyword">return</span> similar_goal</span><br></pre></td></tr></table></figure><p>直接利用自带的相似度，去估计两个输入的大小，这样会降低长度不等的问题的影响</p><p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1595481286576&di=df81997c696a3f9ea906c1ee50ed1cc4&imgtype=0&src=http%3A%2F%2Fc-ssl.duitang.com%2Fuploads%2Fitem%2F201603%2F18%2F20160318202414_yBjSX.jpeg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;chatbot-sorry篇&quot;&gt;&lt;a href=&quot;#chatbot-sorry篇&quot; class=&quot;headerlink&quot; title=&quot;chatbot_sorry篇&quot;&gt;&lt;/a&gt;chatbot_sorry篇&lt;/h1&gt;&lt;p&gt;直接循环输入语句。判断哪些句子无法被检测&lt;/
      
    
    </summary>
    
    
      <category term="work" scheme="https://esyyes.github.io/categories/work/"/>
    
    
      <category term="work" scheme="https://esyyes.github.io/tags/work/"/>
    
  </entry>
  
  <entry>
    <title>python上的GUI</title>
    <link href="https://esyyes.github.io/2020/07/21/chatbot/python%E4%B8%8A%E7%9A%84GUI/"/>
    <id>https://esyyes.github.io/2020/07/21/chatbot/python%E4%B8%8A%E7%9A%84GUI/</id>
    <published>2020-07-21T00:25:01.000Z</published>
    <updated>2020-07-21T00:25:01.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Python-GUI编程-Tkinter"><a href="#Python-GUI编程-Tkinter" class="headerlink" title="Python GUI编程(Tkinter)"></a>Python GUI编程(Tkinter)</h1><h2 id="tkinter介绍"><a href="#tkinter介绍" class="headerlink" title="tkinter介绍"></a>tkinter介绍</h2><p><a href="https://www.runoob.com/python/python-gui-tkinter.html" target="_blank" rel="noopener">https://www.runoob.com/python/python-gui-tkinter.html</a></p><p>这个链接里面直接设置相关的</p><p>Python 提供了多个图形开发界面的库，几个常用 Python GUI 库如下： </p><ul><li><strong>Tkinter：</strong> Tkinter 模块(Tk 接口)是 Python 的标准 Tk GUI 工具包的接口 .Tk 和 Tkinter 可以在大多数的 Unix 平台下使用,同样可以应用在 Windows 和 Macintosh 系统里。Tk8.0 的后续版本可以实现本地窗口风格,并良好地运行在绝大多数平台中。</li><li><strong>wxPython：</strong>wxPython 是一款开源软件，是 Python 语言的一套优秀的 GUI 图形库，允许 Python 程序员很方便的创建完整的、功能健全的 GUI 用户界面。</li><li><strong>Jython：</strong>Jython 程序可以和 Java 无缝集成。除了一些标准模块，Jython 使用 Java 的模块。Jython 几乎拥有标准的Python 中不依赖于 C 语言的全部模块。比如，Jython 的用户界面将使用  Swing，AWT或者 SWT。Jython 可以被动态或静态地编译成 Java 字节码。</li></ul><p>Tkinter 是 Python 的标准 GUI 库。Python 使用 Tkinter 可以快速的创建 GUI 应用程序。</p><p>由于 Tkinter 是内置到 python 的安装包中、只要安装好 Python 之后就能 import Tkinter 库、而且 IDLE 也是用 Tkinter 编写而成、对于简单的图形界面 Tkinter 还是能应付自如。</p><p><strong>注意*</strong>：Python3.x 版本使用的库名为 tkinter,即首写字母 T 为小写。*</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tkinter</span><br></pre></td></tr></table></figure><p>创建一个GUI程序</p><ul><li>1、导入 Tkinter 模块</li><li>2、创建控件</li><li>3、指定这个控件的 master， 即这个控件属于哪一个</li><li>4、告诉 GM(geometry manager) 有一个控件产生了。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tkinter</span><br><span class="line">创建简单窗口</span><br><span class="line">top = tkinter.Tk()</span><br><span class="line"><span class="comment"># 进入消息循环</span></span><br><span class="line">top.mainloop()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/7/21</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tkinter <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建窗口</span></span><br><span class="line">root = thinter.TK()</span><br><span class="line">root = Tk()</span><br><span class="line"><span class="comment"># 标题</span></span><br><span class="line">root.title(<span class="string">'Q&amp;A chatbot'</span>)</span><br><span class="line"><span class="comment"># 窗口大小 小写的x，表示大小</span></span><br><span class="line">root.geometry(<span class="string">'720x400+500+200'</span>)</span><br><span class="line"><span class="comment"># 窗口位置 像素px  的坐标。距离左上角的位置</span></span><br><span class="line"><span class="comment"># root.geometry('+500+300')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 标签控件</span></span><br><span class="line">label = Label(root, text=<span class="string">'签名'</span>, font=(<span class="string">'华为行楷'</span>, <span class="number">20</span>), fg=<span class="string">'red'</span>)</span><br><span class="line"><span class="comment"># pack place 定位（只用一种）grid 网格布局</span></span><br><span class="line">label.grid()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入框</span></span><br><span class="line">entry = Entry(root, font=(<span class="string">'微软雅黑'</span>, <span class="number">20</span>))</span><br><span class="line"><span class="comment"># row对应行，column对应的列</span></span><br><span class="line">entry.grid(row=<span class="number">0</span>, column=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 点击按钮</span></span><br><span class="line">button = Button(root, text=<span class="string">'设计签名'</span>, font=(<span class="string">'微软雅黑'</span>, <span class="number">20</span>), fg=<span class="string">'blue'</span>)</span><br><span class="line"><span class="comment"># 宽高设置</span></span><br><span class="line">button[<span class="string">'width'</span>] = <span class="number">10</span></span><br><span class="line">button[<span class="string">'height'</span>] = <span class="number">1</span></span><br><span class="line"><span class="comment"># 对齐方式sticky,W左。E右, stick=E</span></span><br><span class="line">button.grid(row=<span class="number">1</span>, column=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 消息循环 显示窗口</span></span><br><span class="line">root.mainloop()</span><br></pre></td></tr></table></figure><p>组件：按钮，文本输入框。滚动条等</p><p>窗口：root输入</p><h2 id="GUI–窗口设置"><a href="#GUI–窗口设置" class="headerlink" title="GUI–窗口设置"></a>GUI–窗口设置</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tkinter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建主窗口对象</span></span><br><span class="line">root = tkinter.Tk()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 给窗口加入标题</span></span><br><span class="line">root.title(<span class="string">'Q&amp;A chatbot'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置窗口大小,像素大小</span></span><br><span class="line"><span class="comment"># root.minsize(300, 300)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 窗口大小 小写的x，表示大小， 和位置</span></span><br><span class="line">root.geometry(<span class="string">'720x400+500+200'</span>)</span><br><span class="line"><span class="comment"># 窗口位置 像素px  的坐标。距离左上角的位置</span></span><br><span class="line"><span class="comment"># root.geometry('+500+300')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加入信息循环</span></span><br><span class="line">root.mainloop()</span><br></pre></td></tr></table></figure><h2 id="组件摆放方式"><a href="#组件摆放方式" class="headerlink" title="组件摆放方式"></a>组件摆放方式</h2><p><a href="https://www.cnblogs.com/myshuzhimei/p/11764532.html" target="_blank" rel="noopener">https://www.cnblogs.com/myshuzhimei/p/11764532.html</a></p><p><strong>Tkinter之部件3种放置方式pack、grid、place</strong></p><p>以规律的方格形式呈现。比如下面的代码就是创建一个三行三列的表格：参数row 为行，colum 为列，padx 单元格左右间距，pady单元格上下间距，ipadx单元格内部元素与单元格的左右间距，ipady单元格内部元素与单元格的上下间距。</p><p>直接用grid方式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/7/21</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tkinter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建主窗口对象</span></span><br><span class="line">root = tkinter.Tk()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 给窗口加入标题</span></span><br><span class="line">root.title(<span class="string">'Q&amp;A chatbot'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置窗口大小,像素大小</span></span><br><span class="line"><span class="comment"># root.minsize(300, 300)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 窗口大小 小写的x，表示大小， 和位置</span></span><br><span class="line">root.geometry(<span class="string">'720x400+500+200'</span>)</span><br><span class="line"><span class="comment"># 窗口位置 像素px  的坐标。距离左上角的位置</span></span><br><span class="line"><span class="comment"># root.geometry('+500+300')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 点击按钮</span></span><br><span class="line">button = tkinter.Button(root, text=<span class="string">'点击0'</span>, font=(<span class="string">'微软雅黑'</span>, <span class="number">20</span>), fg=<span class="string">'blue'</span>)</span><br><span class="line">button.grid(row=<span class="number">0</span>, column=<span class="number">0</span>)</span><br><span class="line">button1 = tkinter.Button(root, text=<span class="string">'点击1'</span>, font=(<span class="string">'微软雅黑'</span>, <span class="number">20</span>), fg=<span class="string">'blue'</span>)</span><br><span class="line">button1.grid(row=<span class="number">0</span>, column=<span class="number">1</span>)</span><br><span class="line">button2 = tkinter.Button(root, text=<span class="string">'点击2'</span>, font=(<span class="string">'微软雅黑'</span>, <span class="number">20</span>), fg=<span class="string">'blue'</span>)</span><br><span class="line">button2.grid(row=<span class="number">1</span>, column=<span class="number">0</span>)</span><br><span class="line">button3 = tkinter.Button(root, text=<span class="string">'点击3'</span>, font=(<span class="string">'微软雅黑'</span>, <span class="number">20</span>), fg=<span class="string">'blue'</span>)</span><br><span class="line">button3.grid(row=<span class="number">1</span>, column=<span class="number">1</span>)</span><br><span class="line">button4 = tkinter.Button(root, text=<span class="string">'点击4'</span>, font=(<span class="string">'微软雅黑'</span>, <span class="number">20</span>), fg=<span class="string">'blue'</span>)</span><br><span class="line">button4.grid(row=<span class="number">2</span>, column=<span class="number">0</span>, columnspan=<span class="number">2</span>, ipadx=<span class="number">40</span>)</span><br><span class="line">button5 = tkinter.Button(root, text=<span class="string">'点击5'</span>, font=(<span class="string">'微软雅黑'</span>, <span class="number">20</span>), fg=<span class="string">'blue'</span>)</span><br><span class="line">button5.grid(row=<span class="number">0</span>, column=<span class="number">2</span>, rowspan=<span class="number">2</span>, ipady=<span class="number">40</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 跨列columnspan rowspan,跨行</span></span><br><span class="line"><span class="comment"># ipadx,ipady 跨距离设置</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加入信息循环</span></span><br><span class="line">root.mainloop()</span><br></pre></td></tr></table></figure><h2 id="组件信息"><a href="#组件信息" class="headerlink" title="组件信息"></a>组件信息</h2><h1 id="鼠标样式"><a href="#鼠标样式" class="headerlink" title="鼠标样式"></a>鼠标样式</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root[<span class="string">'cursor'</span>] = <span class="string">'heart'</span></span><br></pre></td></tr></table></figure><h3 id="cheakbutoon勾选框组件"><a href="#cheakbutoon勾选框组件" class="headerlink" title="cheakbutoon勾选框组件"></a>cheakbutoon勾选框组件</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/7/21</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tkinter</span><br><span class="line"><span class="keyword">from</span> tkinter <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建主窗口对象</span></span><br><span class="line">root = tkinter.Tk()</span><br><span class="line"><span class="comment"># 鼠标样式</span></span><br><span class="line">root[<span class="string">'cursor'</span>] = <span class="string">'heart'</span></span><br><span class="line"><span class="comment"># 给窗口加入标题</span></span><br><span class="line">root.title(<span class="string">'Q&amp;A chatbot'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置窗口大小,像素大小</span></span><br><span class="line"><span class="comment"># root.minsize(300, 300)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 窗口大小 小写的x，表示大小， 和位置</span></span><br><span class="line">root.geometry(<span class="string">'720x400+500+200'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># cheakbutton 选择框组件</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果文本的内容有变化</span></span><br><span class="line">text = tkinter.StringVar()</span><br><span class="line">text.set(<span class="string">'同意'</span>)</span><br><span class="line"><span class="comment"># 设置选择框钩与不钩的值</span></span><br><span class="line">result = tkinter.IntVar()</span><br><span class="line"><span class="comment"># 设置返回值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span><span class="params">()</span>:</span></span><br><span class="line">    print(result.get())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cheakbutoon = tkinter.Checkbutton(root, textvariable=text, variable=result, command=func)</span><br><span class="line">cheakbutoon.grid(row=<span class="number">0</span>, column=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加入信息循环</span></span><br><span class="line">root.mainloop()</span><br></pre></td></tr></table></figure><h1 id="输入组件"><a href="#输入组件" class="headerlink" title="输入组件"></a>输入组件</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"># @Time     : 2020/7/21</span><br><span class="line"># @Author   : esy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">import tkinter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 创建主窗口对象</span><br><span class="line">root = tkinter.Tk()</span><br><span class="line"># 鼠标样式</span><br><span class="line">root[&apos;cursor&apos;] = &apos;heart&apos;</span><br><span class="line"># 给窗口加入标题</span><br><span class="line">root.title(&apos;Q&amp;A chatbot&apos;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 窗口大小 小写的x，表示大小， 和位置</span><br><span class="line">root.geometry(&apos;720x400+500+200&apos;)</span><br><span class="line"></span><br><span class="line"># 输入组件</span><br><span class="line"># 输入框</span><br><span class="line">username = tkinter.Entry(root, font=(&apos;微软雅黑&apos;, 20), bg=&apos;red&apos;, fg=&apos;blue&apos;)</span><br><span class="line">username.grid(row=0, column=0)</span><br><span class="line"></span><br><span class="line"># 密码输入</span><br><span class="line">password = tkinter.Entry(root, show=&apos;*&apos;, font=(&apos;微软雅黑&apos;, 20))</span><br><span class="line">password.grid(row=1, column=0)</span><br><span class="line"></span><br><span class="line"># 加入信息循环</span><br><span class="line">root.mainloop()</span><br></pre></td></tr></table></figure><p><img src="https://ss1.bdstatic.com/70cFvXSh_Q1YnxGkpoWK1HF6hhy/it/u=1290205718,2520373871&fm=15&gp=0.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Python-GUI编程-Tkinter&quot;&gt;&lt;a href=&quot;#Python-GUI编程-Tkinter&quot; class=&quot;headerlink&quot; title=&quot;Python GUI编程(Tkinter)&quot;&gt;&lt;/a&gt;Python GUI编程(Tkinter)&lt;/h1
      
    
    </summary>
    
    
      <category term="work" scheme="https://esyyes.github.io/categories/work/"/>
    
    
      <category term="work" scheme="https://esyyes.github.io/tags/work/"/>
    
  </entry>
  
  <entry>
    <title>chatbot在python上实现</title>
    <link href="https://esyyes.github.io/2020/07/20/chatbot/chatbot%E5%9C%A8python%E4%B8%8A%E5%AE%9E%E7%8E%B0/"/>
    <id>https://esyyes.github.io/2020/07/20/chatbot/chatbot%E5%9C%A8python%E4%B8%8A%E5%AE%9E%E7%8E%B0/</id>
    <published>2020-07-20T13:23:10.000Z</published>
    <updated>2020-07-20T13:23:10.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="chatbot在python上实现流程"><a href="#chatbot在python上实现流程" class="headerlink" title="chatbot在python上实现流程"></a>chatbot在python上实现流程</h1><h2 id="基于规则输出简单的回复"><a href="#基于规则输出简单的回复" class="headerlink" title="基于规则输出简单的回复"></a>基于规则输出简单的回复</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    data1 = pd.read_csv(<span class="string">'Q&amp;A pairs.csv'</span>)</span><br><span class="line">    print(<span class="string">"Hello, I'm a question-and-answer chatbot for the tourism domain based on retrieval mode."</span></span><br><span class="line">          <span class="string">"If you want to exit, input 'Bye'!"</span>)</span><br><span class="line">    greeting_output = [<span class="string">"hi"</span>, <span class="string">"hey"</span>, <span class="string">"hello"</span>, <span class="string">"I'm glad! You are talking to me"</span>]</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        text2 = input(<span class="string">"Please enter a question: \t"</span>)</span><br><span class="line">        text1 = <span class="string">" "</span>.join([token.lemma_ <span class="keyword">for</span> token <span class="keyword">in</span> nlp(text2)])</span><br><span class="line">        <span class="keyword">if</span> text1 == <span class="string">'hey'</span> <span class="keyword">or</span> text1 == <span class="string">'hi'</span> <span class="keyword">or</span> text1 == <span class="string">'hello'</span> <span class="keyword">or</span> text1 == <span class="string">'HI'</span>:</span><br><span class="line">            print(random.choice(greeting_output))</span><br><span class="line">        <span class="keyword">elif</span> text1 == <span class="string">'thank'</span> <span class="keyword">or</span> text1 == <span class="string">'thank -PRON-'</span> <span class="keyword">or</span> text1 == <span class="string">'THANK'</span>:</span><br><span class="line">            print(<span class="string">'You are welcome.'</span>)</span><br><span class="line">        <span class="keyword">elif</span> text1 == <span class="string">'bye'</span> <span class="keyword">or</span> text1 == <span class="string">'BYE'</span>:</span><br><span class="line">            print(<span class="string">'Bye!'</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p>重新写个简单的程序吧</p><h2 id="首先对问题进行预处理"><a href="#首先对问题进行预处理" class="headerlink" title="首先对问题进行预处理"></a>首先对问题进行预处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">del_stop</span><span class="params">(text)</span>:</span></span><br><span class="line">    token_doc = [token.lemma_ <span class="keyword">for</span> token <span class="keyword">in</span> nlp(text)]</span><br><span class="line">    <span class="comment"># 去除停用词后创建单词列表</span></span><br><span class="line">    filtered_sentence = []</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> token_doc:</span><br><span class="line">        lexeme = nlp.vocab[word]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> lexeme.is_stop != <span class="literal">False</span>:</span><br><span class="line">            filtered_sentence.append(word)</span><br><span class="line">    <span class="keyword">return</span> filtered_sentence</span><br><span class="line">将字母都切换为小写，并切除停靠词，得到关键的语句</span><br></pre></td></tr></table></figure><h2 id="计算TF-IDF"><a href="#计算TF-IDF" class="headerlink" title="计算TF_IDF"></a>计算TF_IDF</h2><p>第一步还是将问题进行预处理，然后获取语料库中的问题的词频，得到语料库的词汇</p><p>第二步判断提出的问题的关键词汇是否在语料库的词汇中，如果不在就直接返回0，程序会返回一个不知道</p><p>第三步计算词汇的idf</p><p>第四步计算每个单词在每个问题中的频率</p><p>第五步得到每个问题的关键词汇的tf-idf的分数列表</p><p>第六步计算提出问题在每个问题中能得到tf-idf多少分</p><p>第七步将每个tf-idf的得分升序排列，然后召回最高得分的5个问题，和对应的5个答案</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">def QA_tf_idf(data, filtered_sentence):</span><br><span class="line">    question = np.array(data[&apos;Question&apos;]).tolist()</span><br><span class="line">    answer = np.array(data[&apos;Answer&apos;]).tolist()</span><br><span class="line">    # 将问题进行分词</span><br><span class="line">    list_ques = [[t.lemma_ for t in nlp(question[i])] for i in range(len(data))]</span><br><span class="line">    # 去除停用词后创建单词列表</span><br><span class="line">    list_key = []</span><br><span class="line">    for i in range(len(data)):</span><br><span class="line">        filtered_sentence1 = []</span><br><span class="line">        for word in list_ques[i]:</span><br><span class="line">            lexeme = nlp.vocab[word]</span><br><span class="line">            if not lexeme.is_stop != False:</span><br><span class="line">                filtered_sentence1.append(word)</span><br><span class="line">        list_key.append(filtered_sentence1)</span><br><span class="line">    # 统计词频和词汇,看单词出现的次数</span><br><span class="line">    doc_frequency = defaultdict(int)</span><br><span class="line">    list_words = list_key</span><br><span class="line">    for word_list in list_words:</span><br><span class="line">        for i in word_list:</span><br><span class="line">            doc_frequency[i] += 1</span><br><span class="line">    l1 = set(filtered_sentence)</span><br><span class="line">    l2 = set(doc_frequency.keys())</span><br><span class="line"></span><br><span class="line">    if not l1.issubset(l2) != False:</span><br><span class="line">        return 0</span><br><span class="line">    else:</span><br><span class="line">        # 计算每个词的IDF值</span><br><span class="line">        word_idf = &#123;&#125;  # 存储每个词的idf值</span><br><span class="line">        word_doc = defaultdict(int)  # 存储包含该词的文档数</span><br><span class="line">        for i in doc_frequency:</span><br><span class="line">            for j in list_words:</span><br><span class="line">                if i in j:</span><br><span class="line">                    word_doc[i] += 1</span><br><span class="line">        for i in doc_frequency:</span><br><span class="line">            word_idf[i] = math.log(len(list_key) / (word_doc[i] + 1))</span><br><span class="line">        # 找到每个词对应文档中出现的次数</span><br><span class="line">        doc_frequency1 = defaultdict(int)</span><br><span class="line">        for word_list in list_key:</span><br><span class="line">            for i in word_list:</span><br><span class="line">                doc_frequency1[i] += 1</span><br><span class="line">        # 对样本进行词频统计</span><br><span class="line">        list_doc = []</span><br><span class="line">        for i in range(len(list_key)):</span><br><span class="line">            doc_frequency1 = defaultdict(int)</span><br><span class="line">            for j in list_key[i]:</span><br><span class="line">                doc_frequency1[j] += 1</span><br><span class="line">            list_doc.append(doc_frequency1)</span><br><span class="line">        # 计算语料库的tf_idf</span><br><span class="line">        tf_idf = []</span><br><span class="line">        for j in range(len(data)):</span><br><span class="line">            tf_idf.append([word_idf[i] * list_doc[j][i] / len(list_doc[j]) for i in (list_doc[j])])</span><br><span class="line">        # 计算样本的tf-idf得分</span><br><span class="line">        scores = []</span><br><span class="line">        for j in range(len(data)):</span><br><span class="line">            score = 0</span><br><span class="line">            for i in filtered_sentence:</span><br><span class="line">                score += (word_idf[i] * list_doc[j][i] / len(list_doc[j]))</span><br><span class="line">            scores.append(score)</span><br><span class="line">        # 用字典形式排序</span><br><span class="line">        x = np.arange(len(data)).tolist()</span><br><span class="line">        dict_score = dict(zip(x, scores))</span><br><span class="line">        listc = sorted(zip(dict_score.values(), dict_score.keys()))</span><br><span class="line">        recall_ques = []</span><br><span class="line">        recall_answ = []</span><br><span class="line">        for i in range(1, 6):</span><br><span class="line">            recall_ques.append(question[listc[-i][1]])</span><br><span class="line">            recall_answ.append(answer[listc[-i][1]])</span><br><span class="line">        return recall_ques, recall_answ</span><br></pre></td></tr></table></figure><h1 id="求5个问题的相似度"><a href="#求5个问题的相似度" class="headerlink" title="求5个问题的相似度"></a>求5个问题的相似度</h1><p>利用自带的余弦相似性求5个问题和输入问题的相似度</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def similar_list(text, recall_ques):</span><br><span class="line">    return [nlp(text).similarity(nlp(recall_ques[i])) for i in range(5)]</span><br></pre></td></tr></table></figure><h2 id="输出相似度最高的那个问题的答案"><a href="#输出相似度最高的那个问题的答案" class="headerlink" title="输出相似度最高的那个问题的答案"></a>输出相似度最高的那个问题的答案</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">best_answer</span><span class="params">(list_num, recall_answ)</span>:</span></span><br><span class="line">    <span class="comment"># 输出相似度最高的那个的答案</span></span><br><span class="line">    print(recall_answ[list_num.index(max(list_num))])</span><br></pre></td></tr></table></figure><h2 id="构建无限循环"><a href="#构建无限循环" class="headerlink" title="构建无限循环"></a>构建无限循环</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    data1 = pd.read_csv(<span class="string">'Q&amp;A pairs.csv'</span>)</span><br><span class="line">    print(<span class="string">"Hello, I'm a question-and-answer chatbot for the tourism domain based on retrieval mode."</span></span><br><span class="line">          <span class="string">"If you want to exit, input 'Bye'!"</span>)</span><br><span class="line">    greeting_output = [<span class="string">"hi"</span>, <span class="string">"hey"</span>, <span class="string">"hello"</span>, <span class="string">"I'm glad! You are talking to me"</span>]</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        text2 = input(<span class="string">"Please enter a question: \t"</span>)</span><br><span class="line">        text1 = <span class="string">" "</span>.join([token.lemma_ <span class="keyword">for</span> token <span class="keyword">in</span> nlp(text2)])</span><br><span class="line">        <span class="keyword">if</span> text1 == <span class="string">'hey'</span> <span class="keyword">or</span> text1 == <span class="string">'hi'</span> <span class="keyword">or</span> text1 == <span class="string">'hello'</span> <span class="keyword">or</span> text1 == <span class="string">'HI'</span>:</span><br><span class="line">            print(random.choice(greeting_output))</span><br><span class="line">        <span class="keyword">elif</span> text1 == <span class="string">'thank'</span> <span class="keyword">or</span> text1 == <span class="string">'thank -PRON-'</span> <span class="keyword">or</span> text1 == <span class="string">'THANK'</span>:</span><br><span class="line">            print(<span class="string">'You are welcome.'</span>)</span><br><span class="line">        <span class="keyword">elif</span> text1 == <span class="string">'bye'</span> <span class="keyword">or</span> text1 == <span class="string">'BYE'</span>:</span><br><span class="line">            print(<span class="string">'Bye!'</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> QA_tf_idf(data1, del_stop(text1)) == <span class="number">0</span>:</span><br><span class="line">                print(<span class="string">f"I'm sorry. I don't understand you"</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                recall_ques1, recall_answ1 = QA_tf_idf(data1, del_stop(text1))</span><br><span class="line">                best_answer(similar_list(text1, recall_ques1), recall_answ1)</span><br></pre></td></tr></table></figure><p>能够简单实现步骤，下一步加入GUI</p><p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1595262847196&di=b1093ee61bec6c22a07f7fd6b07a168e&imgtype=0&src=http%3A%2F%2Fp2.itc.cn%2Fimages01%2F20200609%2F12d57ad2d3694d24b69f0db647f43830.jpeg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;chatbot在python上实现流程&quot;&gt;&lt;a href=&quot;#chatbot在python上实现流程&quot; class=&quot;headerlink&quot; title=&quot;chatbot在python上实现流程&quot;&gt;&lt;/a&gt;chatbot在python上实现流程&lt;/h1&gt;&lt;h2 i
      
    
    </summary>
    
    
      <category term="work" scheme="https://esyyes.github.io/categories/work/"/>
    
    
      <category term="work" scheme="https://esyyes.github.io/tags/work/"/>
    
  </entry>
  
  <entry>
    <title>Q&amp;A chatbot 简单实现</title>
    <link href="https://esyyes.github.io/2020/07/19/chatbot/Q-A-chatbot-%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0/"/>
    <id>https://esyyes.github.io/2020/07/19/chatbot/Q-A-chatbot-%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0/</id>
    <published>2020-07-19T08:32:51.000Z</published>
    <updated>2020-07-19T08:32:51.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Q-amp-A-chatbot-简单实现"><a href="#Q-amp-A-chatbot-简单实现" class="headerlink" title="Q&amp;A chatbot 简单实现"></a>Q&amp;A chatbot 简单实现</h1><h2 id="Project-Title-Traveler-a-question-and-answer-chatbot-based-on-retrieval-mode"><a href="#Project-Title-Traveler-a-question-and-answer-chatbot-based-on-retrieval-mode" class="headerlink" title="Project Title: Traveler (a question-and-answer chatbot based on retrieval mode.)"></a>Project Title: Traveler (a question-and-answer chatbot based on retrieval mode.)</h2><h3 id="设计要求："><a href="#设计要求：" class="headerlink" title="设计要求："></a>设计要求：</h3><p>I plan to develop a <strong>question-and-answer chatbot for the tourism domain</strong><br>based on <strong>retrieval</strong> mode. The chatbot will respond to users by<br>selecting the best matching answer in the database based on users’<br>questions. </p><h3 id="four-parts"><a href="#four-parts" class="headerlink" title="four parts."></a>four parts.</h3><p>In order to develop the question-and answer chatbot, I will divide my job into four parts. </p><p>1) Extract the keywords from text<br>For a piece of text, I can extract keywords and remove words that have no actual<br>meaning but appear frequently, such as the, a, is, etc. This process prepares for the<br>generation of word frequency vectors that can be used to calculate the similarity<br>between two pieces of text. </p><p>2) Calculate the semantic similarity<br>For a piece of text, I can calculate the similarity between this text and other<br>compared text. According to the extracted keywords mentioned above, all the texts<br>will be vectorized to calculate the similarity between the test text and each<br>compared text. The higher the similarity value is, the more similar the compared<br>text is to the test text. This process is prepared to later calculate the similarity<br>between the user questions and existing questions in the database. </p><p>3) Create database which contains question-and-answer pairs<br>I will deliver a complete database contains all pairs of user’s possible questions and<br>answers. After calculating the similarity between the user questions and existing<br>questions, the database will select an answer whose matching question is most<br>relevant to the user’s question as response to the users. </p><p>4) Create a graphical interface that allows users to enter text<br>I will deliver a GUI that can allow users to input question and give an output to the<br>user’s question. </p><h2 id="初步实现之去除停靠词后的程序"><a href="#初步实现之去除停靠词后的程序" class="headerlink" title="初步实现之去除停靠词后的程序"></a>初步实现之去除停靠词后的程序</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/7/19</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line">语料包</span><br><span class="line"><span class="keyword">import</span> en_core_web_md</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">为了加载词频</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入英文模块</span></span><br><span class="line">nlp = en_core_web_md.load()</span><br><span class="line"></span><br><span class="line">text = input(<span class="string">"请输入问题: "</span>)</span><br><span class="line"><span class="comment"># 进行问题分词</span></span><br><span class="line">doc = nlp(text)</span><br><span class="line">token_doc = [token.text <span class="keyword">for</span> token <span class="keyword">in</span> doc]</span><br><span class="line"><span class="comment"># 去除停用词后创建单词列表，相当于就是只有关键词了</span></span><br><span class="line">filtered_sentence = []</span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> token_doc:</span><br><span class="line">    lexeme = nlp.vocab[word]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> lexeme.is_stop != <span class="literal">False</span>:</span><br><span class="line">        filtered_sentence.append(word)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入语料包，读取问题和答案</span></span><br><span class="line">data = pd.read_csv(<span class="string">'Q&amp;A pairs.csv'</span>)</span><br><span class="line">question = np.array(data[<span class="string">'Question'</span>]).tolist()</span><br><span class="line">answer = np.array(data[<span class="string">'Answer'</span>]).tolist()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将问题进行分词</span></span><br><span class="line">list_ques = [[t.text <span class="keyword">for</span> t <span class="keyword">in</span> nlp(question[i])] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data))]</span><br><span class="line"><span class="comment"># 去除停用词后创建单词列表，将问题全部进行去停靠词</span></span><br><span class="line">list_key = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">    filtered_sentence1 = []</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> list_ques[i]:</span><br><span class="line">        lexeme = nlp.vocab[word]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> lexeme.is_stop != <span class="literal">False</span>:</span><br><span class="line">            filtered_sentence1.append(word)</span><br><span class="line">    list_key.append(filtered_sentence1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计词频和词汇,并看单词出现的次数，看全文的关键词汇和词是多少</span></span><br><span class="line">doc_frequency = defaultdict(int)</span><br><span class="line">list_words = list_key</span><br><span class="line"><span class="keyword">for</span> word_list <span class="keyword">in</span> list_words:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> word_list:</span><br><span class="line">        doc_frequency[i] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算每个词的IDF值</span></span><br><span class="line">word_idf = &#123;&#125;  <span class="comment"># 存储每个词的idf值</span></span><br><span class="line">word_doc = defaultdict(int)  <span class="comment"># 存储包含该词的文档数</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> doc_frequency:</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> list_words:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> j:</span><br><span class="line">            word_doc[i] += <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> doc_frequency:</span><br><span class="line">    word_idf[i] = math.log(len(list_key) / (word_doc[i] + <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 找到每个词对应每个问题中出现的次数</span></span><br><span class="line">doc_frequency1 = defaultdict(int)</span><br><span class="line"><span class="keyword">for</span> word_list <span class="keyword">in</span> list_key:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> word_list:</span><br><span class="line">        doc_frequency1[i] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计关键词在单个样本中出现的次数</span></span><br><span class="line">list_doc = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(list_key)):</span><br><span class="line">    doc_frequency1 = defaultdict(int)</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> list_key[i]:</span><br><span class="line">        doc_frequency1[j] += <span class="number">1</span></span><br><span class="line">    list_doc.append(doc_frequency1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算出每个问题对应的tf_idf索引</span></span><br><span class="line">tf_idf = []</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(len(data)):</span><br><span class="line">    c = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> (list_doc[j]):</span><br><span class="line">        c.append(word_idf[i] * list_doc[j][i] / len(list_doc[j]))</span><br><span class="line">    tf_idf.append(c)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算输入的问题在全部文档中的tf-idf得分</span></span><br><span class="line">scores = []</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(len(data)):</span><br><span class="line">    score = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> filtered_sentence:</span><br><span class="line">        score += (word_idf[i] * list_doc[j][i] / len(list_doc[j]))</span><br><span class="line">    scores.append(score)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用字典形式排序</span></span><br><span class="line">x = np.arange(len(data)).tolist()</span><br><span class="line">dict_score = dict(zip(x, scores))</span><br><span class="line">升序排序</span><br><span class="line">listc = sorted(zip(dict_score.values(), dict_score.keys()))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 召回得分最高的5个对应问题和答案，对问题进行粗排</span></span><br><span class="line">recall_ques = []</span><br><span class="line">recall_answ = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">6</span>):</span><br><span class="line">    recall_ques.append(question[listc[-i][<span class="number">1</span>]])</span><br><span class="line">    recall_answ.append(answer[listc[-i][<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用余弦相似性求5个问题的相似度</span></span><br><span class="line">list_num = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    list_num.append(doc.similarity(nlp(recall_ques[i])))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出相似度最高的那个的答案</span></span><br><span class="line"><span class="keyword">if</span> len(set(list_num)) == random.randint(<span class="number">1</span>, <span class="number">6</span>):</span><br><span class="line">    print(recall_answ[list_num.index(max(list_num))])</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(recall_answ[random.randint(<span class="number">0</span>, <span class="number">5</span>)])</span><br></pre></td></tr></table></figure><p>只是能简单实现样本，下一步是实现循环输入和能回复简单的问题</p><p><img src="https://ss2.bdstatic.com/70cFvnSh_Q1YnxGkpoWK1HF6hhy/it/u=1144338864,1787286398&fm=15&gp=0.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Q-amp-A-chatbot-简单实现&quot;&gt;&lt;a href=&quot;#Q-amp-A-chatbot-简单实现&quot; class=&quot;headerlink&quot; title=&quot;Q&amp;amp;A chatbot 简单实现&quot;&gt;&lt;/a&gt;Q&amp;amp;A chatbot 简单实现&lt;/h1&gt;&lt;
      
    
    </summary>
    
    
      <category term="work" scheme="https://esyyes.github.io/categories/work/"/>
    
    
      <category term="work" scheme="https://esyyes.github.io/tags/work/"/>
    
  </entry>
  
  <entry>
    <title>spacy的基础知识再学习</title>
    <link href="https://esyyes.github.io/2020/07/18/chatbot/spacy%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%86%8D%E5%AD%A6%E4%B9%A0/"/>
    <id>https://esyyes.github.io/2020/07/18/chatbot/spacy%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%86%8D%E5%AD%A6%E4%B9%A0/</id>
    <published>2020-07-18T02:14:53.000Z</published>
    <updated>2020-07-18T02:14:53.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="spacy的基础知识再学习"><a href="#spacy的基础知识再学习" class="headerlink" title="spacy的基础知识再学习"></a>spacy的基础知识再学习</h1><p>spacy和nltk的比较</p><p><img src="https://img-blog.csdnimg.cn/20190409100054495.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zMzI3ODc3Mg==,size_16,color_FFFFFF,t_70" alt=""></p><p>spacy相对来说更快速的多，因此采用，功能也更多一些。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;spacy的基础知识再学习&quot;&gt;&lt;a href=&quot;#spacy的基础知识再学习&quot; class=&quot;headerlink&quot; title=&quot;spacy的基础知识再学习&quot;&gt;&lt;/a&gt;spacy的基础知识再学习&lt;/h1&gt;&lt;p&gt;spacy和nltk的比较&lt;/p&gt;
&lt;p&gt;&lt;img 
      
    
    </summary>
    
    
      <category term="work" scheme="https://esyyes.github.io/categories/work/"/>
    
    
      <category term="work" scheme="https://esyyes.github.io/tags/work/"/>
    
  </entry>
  
  <entry>
    <title>q@a检索式机器人的流程</title>
    <link href="https://esyyes.github.io/2020/07/16/chatbot/q-a%E6%A3%80%E7%B4%A2%E5%BC%8F%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9A%84%E6%B5%81%E7%A8%8B/"/>
    <id>https://esyyes.github.io/2020/07/16/chatbot/q-a%E6%A3%80%E7%B4%A2%E5%BC%8F%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9A%84%E6%B5%81%E7%A8%8B/</id>
    <published>2020-07-15T16:06:58.000Z</published>
    <updated>2020-07-15T16:06:58.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Q-A检索式机器人的流程"><a href="#Q-A检索式机器人的流程" class="headerlink" title="Q@A检索式机器人的流程"></a>Q@A检索式机器人的流程</h1><h2 id="问题输入模块"><a href="#问题输入模块" class="headerlink" title="问题输入模块"></a>问题输入模块</h2><p>1 问题输入</p><p>2 对问题进行分析（预处理问题，利用spacy或nltk等进行自然语言处理）</p><p>3 构建规则系统（目的是：回复些简单的内容，和排除些不是旅游系统的信息，if-else语句）</p><h2 id="短语映射模块（初排模型）"><a href="#短语映射模块（初排模型）" class="headerlink" title="短语映射模块（初排模型）"></a>短语映射模块（初排模型）</h2><p>4 将问题的信息和语料库的信息进行匹配（关键词提取–相似度计算）</p><p>spacy自带了一个相似度计算，现在基本都能算出来，后面再套用下TF-IDF算法，提取关键词，</p><p>相似度计算（TF-IDF或者LDA等）</p><p>TF-IDF:</p><p> <strong>TF-IDF（term frequency–inverse document frequency，词频-逆向文件频率）</strong>是一种用于信息检索（information retrieval）与文本挖掘（text mining）的常用<strong>加权技术</strong>。 </p><p> LDA（Latent Dirichlet Allocation）是一种文档主题生成模型，也称为一个三层<a href="https://baike.baidu.com/item/贝叶斯" target="_blank" rel="noopener">贝叶斯</a>概率模型，包含词、主题和文档三层结构。 </p><p>一般采用 <strong>Word2vec</strong>或 GloVe 等工具对自然语言进行<strong>向量化</strong>，感觉已经进行了向量化</p><p>md文件自带向量化，但是需要转换到2进制的，所以还是可以用用word2vec</p><h2 id="消歧模块"><a href="#消歧模块" class="headerlink" title="消歧模块"></a>消歧模块</h2><p>通过计算本体资源的标签和对应的问句信息词之间的相似度<strong>进行排序</strong>得分，然后召回几个类似的问题。</p><p> 检索：当用户提问时，通过以上五个步骤把问题映射为一个高维稀疏向量，然后从问题库中召回与其cosin距离最近的n个问题 </p><p> sklearn中的LSHForest </p><p> Facebook research的pysparnn </p><h2 id="查询构建模块"><a href="#查询构建模块" class="headerlink" title="查询构建模块"></a>查询构建模块</h2><p>将前面的问题进行匹配后，然后输出最高得分时对应的问题，然后输出答案</p><p>后面再说生成gui的问题。</p><p><img src="https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=115162337,1858841164&fm=26&gp=0.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Q-A检索式机器人的流程&quot;&gt;&lt;a href=&quot;#Q-A检索式机器人的流程&quot; class=&quot;headerlink&quot; title=&quot;Q@A检索式机器人的流程&quot;&gt;&lt;/a&gt;Q@A检索式机器人的流程&lt;/h1&gt;&lt;h2 id=&quot;问题输入模块&quot;&gt;&lt;a href=&quot;#问题输入模块&quot;
      
    
    </summary>
    
    
      <category term="work" scheme="https://esyyes.github.io/categories/work/"/>
    
    
      <category term="work" scheme="https://esyyes.github.io/tags/work/"/>
    
  </entry>
  
  <entry>
    <title>spacy的基础学习</title>
    <link href="https://esyyes.github.io/2020/07/15/chatbot/spacy%E7%9A%84%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/"/>
    <id>https://esyyes.github.io/2020/07/15/chatbot/spacy%E7%9A%84%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/</id>
    <published>2020-07-15T01:56:53.000Z</published>
    <updated>2020-07-15T01:56:53.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="spacy"><a href="#spacy" class="headerlink" title="spacy"></a>spacy</h1><h2 id="spacy的定义"><a href="#spacy的定义" class="headerlink" title="spacy的定义"></a>spacy的定义</h2><p> spaCy是一个python开源模块，用于<strong>处理自然语言的大量文本</strong>。比如，一段文字的关键是什么？在段落中上下文的意思是什么？谁对谁做了什么？那些公司和产品名称特指什么？一个单词和其他其他单词相似程度如何？作为人类，理解自然语言比较容易，但如果让计算机去理解文本的意思，这都是不可回避的问题。 </p><p> spaCy就是帮助你使用计算器程序去处理和<strong>理解</strong>海量文本的工具。在目前来说，号称是<strong>速度最快、更加适合实际应用的工业级产品</strong>。spaCy可以帮助你构建<strong>信息提取、自然语言理解以及深度学习的预处理</strong> 。</p><p>spaCy是世界上最快的工业级自然语言处理工具。 支持多种自然语言处理基本功能。</p><p>官网地址：<a href="https://link.zhihu.com/?target=https%3A//spacy.io/">https://spacy.io/</a></p><p>spaCy主要功能包括分词、词性标注、词干化、命名实体识别、名词短语提取等等。</p><h3 id="安装：pip-install-spacy"><a href="#安装：pip-install-spacy" class="headerlink" title="安装：pip install spacy"></a>安装：pip install spacy</h3><p> 与平台不同，spaCy不提供软件即服务或Web应用程序。它是一个开放源代码库，旨在帮助您构建NLP应用程序，而不是消耗性服务。 </p><p> 这是一个开源库。 </p><p>在文档中，您会提到spaCy的功能。其中一些涉及语言概念，而其他则涉及更通用的机器学习功能。</p><table><thead><tr><th>名称</th><th>描述</th></tr></thead><tbody><tr><td><strong>代币化</strong></td><td>将文本分割成单词，标点符号等</td></tr><tr><td><strong>词性</strong>（POS）<strong>标记</strong></td><td>将单词类型分配给标记，例如动词或名词。</td></tr><tr><td><strong>依赖解析</strong></td><td>分配语法相关性标签，描述各个标记（例如主题或客体）之间的关系。</td></tr><tr><td><strong>合法化</strong></td><td>分配单词的基本形式。例如，“ was”的引理是“ be”，“ rats”的引理是“ rat”。</td></tr><tr><td><strong>句子边界检测</strong>（SBD）</td><td>查找和分割单个句子。</td></tr><tr><td><strong>命名实体识别</strong>（NER）</td><td>标记命名为“真实世界”的对象，例如人员，公司或位置。</td></tr><tr><td><strong>实体链接</strong>（EL）</td><td>消除文本实体与知识库中唯一标识符的歧义。</td></tr><tr><td><strong>相似</strong></td><td>比较单词，文本跨度和文档，以及它们之间的相似程度。</td></tr><tr><td><strong>文字分类</strong></td><td>为整个文档或文档的一部分分配类别或标签。</td></tr><tr><td><strong>基于规则的匹配</strong></td><td>根据标记的文本和语言注释来查找标记序列，类似于正则表达式。</td></tr><tr><td><strong>训练</strong></td><td>更新和改进统计模型的预测。</td></tr><tr><td><strong>序列化</strong></td><td>将对象保存到文件或字节字符串</td></tr></tbody></table><table><thead><tr><th>NAME</th><th>DESCRIPTION</th></tr></thead><tbody><tr><td><strong>Tokenization</strong></td><td>Segmenting text into words, punctuations marks etc.</td></tr><tr><td><strong>Part-of-speech</strong> (POS) <strong>Tagging</strong></td><td>Assigning word types to tokens, like verb or noun.</td></tr><tr><td><strong>Dependency Parsing</strong></td><td>Assigning syntactic dependency labels, describing the relations between individual tokens, like subject or object.</td></tr><tr><td><strong>Lemmatization</strong></td><td>Assigning the base forms of words. For example, the lemma of “was” is “be”, and the lemma of “rats” is “rat”.</td></tr><tr><td><strong>Sentence Boundary Detection</strong> (SBD)</td><td>Finding and segmenting individual sentences.</td></tr><tr><td><strong>Named Entity Recognition</strong> (NER)</td><td>Labelling named “real-world” objects, like persons, companies or locations.</td></tr><tr><td><strong>Entity Linking</strong> (EL)</td><td>Disambiguating textual entities to unique identifiers in a Knowledge Base.</td></tr><tr><td><strong>Similarity</strong></td><td>Comparing words, text spans and documents and how similar they are to each other.</td></tr><tr><td><strong>Text Classification</strong></td><td>Assigning categories or labels to a whole document, or parts of a document.</td></tr><tr><td><strong>Rule-based Matching</strong></td><td>Finding sequences of tokens based on their texts and linguistic annotations, similar to regular expressions.</td></tr><tr><td><strong>Training</strong></td><td>Updating and improving a statistical model’s predictions.</td></tr><tr><td><strong>Serialization</strong></td><td>Saving objects to files or byte strings.</td></tr></tbody></table><p>尽管spaCy的某些功能可以独立运行，但是其他功能需要 加载<a href="https://spacy.io/models" target="_blank" rel="noopener">统计模型</a>，这使spaCy可以<strong>预测</strong> 语言注释-例如，单词是动词还是名词。spaCy当前提供用于多种语言的统计模型，可以将其安装为单独的Python模块。模型的大小，速度，内存使用量，准确性和所包含的数据可能会有所不同。您选择的模型始终取决于您的用例和您使用的文本。对于通用用例，小型的默认模型始终是一个好的开始。它们通常包括以下组件：</p><ul><li>词性标记器，依赖性分析器和命名实体识别器的<strong>二进制权重</strong>，以在上下文中预测这些注释。</li><li><strong>词汇</strong>中的词汇<strong>条目</strong>，即单词及其与上下文无关的属性，例如形状或拼写。</li><li><strong>数据文件，</strong>例如lemmatization规则和查找表。</li><li><strong>单词向量</strong>，即<strong>单词</strong>的多维含义表示，可让您确定它们之间的相似程度。</li><li><strong>配置</strong>选项（例如语言和处理管道设置）可在您加载模型时将spaCy置于正确的状态。</li></ul><p> 安装默认模型，获取代码以从spaCy内加载它，并提供示例进行测试。有关更多选项，请参见下面有关可用型号的部分 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import spacy</span><br><span class="line">nlp = spacy.load(&quot;en_core_web_sm&quot;)</span><br><span class="line">两种形式</span><br><span class="line">import en_core_web_sm</span><br><span class="line">nlp = en_core_web_sm.load()</span><br></pre></td></tr></table></figure><p>Download best-matching version of specific model for your spaCy installation</p><p>为spaCy安装下载特定型号的最佳匹配版本</p><p> python -m spacy download en_core_web_sm </p><p>Out-of-the-box: download best-matching default model and create shortcut link </p><p>开箱即用：下载最匹配的默认模型并创建快捷链接</p><p>python -m spacy download en </p><p>Download exact model version (doesn’t create shortcut link) python -m spacy download en_core_web_sm-2.2.0 –direct </p><p>下载精确的模型版本（不创建快捷链接）python-mspacy下载en_core_web_sm-2.2.0–直接</p><ul><li><p><strong>尺寸</strong>：型号尺寸指示符（<code>sm</code>，<code>md</code>或<code>lg</code>）</p><p>已经有了en_core_web_md-2.2.5.tar.gz这个版本下载对应的spacy2.2.4.版本</p><p>已经能够正常运行，参考网页</p><p> <a href="https://spacy.io/" target="_blank" rel="noopener">https://spacy.io/</a> </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/7/15</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> en_core_web_md</span><br><span class="line">nlp = en_core_web_md.load()</span><br><span class="line">text = (<span class="string">"When Sebastian Thrun started working on self-driving cars at "</span></span><br><span class="line">        <span class="string">"Google in 2007, few people outside of the company took him "</span></span><br><span class="line">        <span class="string">"seriously. “I can tell you very senior CEOs of major American "</span></span><br><span class="line">        <span class="string">"car companies would shake my hand and turn away because I wasn’t "</span></span><br><span class="line">        <span class="string">"worth talking to,” said Thrun, in an interview with Recode earlier "</span></span><br><span class="line">        <span class="string">"this week."</span>)</span><br><span class="line">doc = nlp(text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Analyze syntax</span></span><br><span class="line">print(<span class="string">"Noun phrases:"</span>, [chunk.text <span class="keyword">for</span> chunk <span class="keyword">in</span> doc.noun_chunks])</span><br><span class="line">print(<span class="string">"Verbs:"</span>, [token.lemma_ <span class="keyword">for</span> token <span class="keyword">in</span> doc <span class="keyword">if</span> token.pos_ == <span class="string">"VERB"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find named entities, phrases and concepts</span></span><br><span class="line"><span class="keyword">for</span> entity <span class="keyword">in</span> doc.ents:</span><br><span class="line">    print(entity.text, entity.label_)</span><br><span class="line">运行结果</span><br><span class="line">Noun phrases: [<span class="string">'Sebastian Thrun'</span>, <span class="string">'self-driving cars'</span>, <span class="string">'Google'</span>, <span class="string">'few people'</span>, <span class="string">'the company'</span>, <span class="string">'him'</span>, <span class="string">'I'</span>, <span class="string">'you'</span>, <span class="string">'very senior CEOs'</span>, <span class="string">'major American car companies'</span>, <span class="string">'my hand'</span>, <span class="string">'I'</span>, <span class="string">'Thrun'</span>, <span class="string">'an interview'</span>, <span class="string">'Recode'</span>]</span><br><span class="line">Verbs: [<span class="string">'start'</span>, <span class="string">'work'</span>, <span class="string">'drive'</span>, <span class="string">'take'</span>, <span class="string">'can'</span>, <span class="string">'tell'</span>, <span class="string">'would'</span>, <span class="string">'shake'</span>, <span class="string">'turn'</span>, <span class="string">'talk'</span>, <span class="string">'say'</span>]</span><br><span class="line">Sebastian Thrun PERSON</span><br><span class="line">Google ORG</span><br><span class="line"><span class="number">2007</span> DATE</span><br><span class="line">American NORP</span><br><span class="line">Thrun PERSON</span><br><span class="line">Recode ORG</span><br><span class="line">earlier this week DATE</span><br></pre></td></tr></table></figure><h2 id="spacy的基础分析"><a href="#spacy的基础分析" class="headerlink" title="spacy的基础分析"></a>spacy的基础分析</h2></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> en_core_web_md</span><br><span class="line">nlp = en_core_web_md.load()</span><br><span class="line">doc = nlp(<span class="string">"Apple is looking at buying U.K. startup for $1 billion"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,</span><br><span class="line">            token.shape_, token.is_alpha, token.is_stop)</span><br></pre></td></tr></table></figure><table><thead><tr><th>TEXT</th><th>LEMMA</th><th>POS</th><th>TAG</th><th>DEP</th><th>SHAPE</th><th>ALPHA</th><th>STOP</th></tr></thead><tbody><tr><td>Apple</td><td>apple</td><td><code>PROPN</code></td><td><code>NNP</code></td><td><code>nsubj</code></td><td><code>Xxxxx</code></td><td><code>True</code></td><td><code>False</code></td></tr><tr><td>is</td><td>be</td><td><code>AUX</code></td><td><code>VBZ</code></td><td><code>aux</code></td><td><code>xx</code></td><td><code>True</code></td><td><code>True</code></td></tr><tr><td>looking</td><td>look</td><td><code>VERB</code></td><td><code>VBG</code></td><td><code>ROOT</code></td><td><code>xxxx</code></td><td><code>True</code></td><td><code>False</code></td></tr><tr><td>at</td><td>at</td><td><code>ADP</code></td><td><code>IN</code></td><td><code>prep</code></td><td><code>xx</code></td><td><code>True</code></td><td><code>True</code></td></tr><tr><td>buying</td><td>buy</td><td><code>VERB</code></td><td><code>VBG</code></td><td><code>pcomp</code></td><td><code>xxxx</code></td><td><code>True</code></td><td><code>False</code></td></tr><tr><td>U.K.</td><td>u.k.</td><td><code>PROPN</code></td><td><code>NNP</code></td><td><code>compound</code></td><td><code>X.X.</code></td><td><code>False</code></td><td><code>False</code></td></tr><tr><td>startup</td><td>startup</td><td><code>NOUN</code></td><td><code>NN</code></td><td><code>dobj</code></td><td><code>xxxx</code></td><td><code>True</code></td><td><code>False</code></td></tr><tr><td>for</td><td>for</td><td><code>ADP</code></td><td><code>IN</code></td><td><code>prep</code></td><td><code>xxx</code></td><td><code>True</code></td><td><code>True</code></td></tr><tr><td>$</td><td>$</td><td><code>SYM</code></td><td><code>$</code></td><td><code>quantmod</code></td><td><code>$</code></td><td><code>False</code></td><td><code>False</code></td></tr><tr><td>1</td><td>1</td><td><code>NUM</code></td><td><code>CD</code></td><td><code>compound</code></td><td><code>d</code></td><td><code>False</code></td><td><code>False</code></td></tr><tr><td>billion</td><td>billion</td><td><code>NUM</code></td><td><code>CD</code></td><td><code>pobj</code></td><td><code>xxxx</code></td><td><code>True</code></td><td><code>False</code></td></tr></tbody></table><ul><li><strong>Text:</strong> The original word text.<strong>文字：</strong>原始文字。</li><li><strong>Lemma:</strong> The base form of the word.<strong>引理：</strong>该词的基本形式。</li><li><strong>POS:</strong> The simple <a href="https://universaldependencies.org/docs/u/pos/" target="_blank" rel="noopener">UPOS</a> part-of-speech tag.<strong>POS：</strong>简单的<a href="https://universaldependencies.org/docs/u/pos/" target="_blank" rel="noopener">UPOS</a>词性标签。</li><li><strong>Tag:</strong> The detailed part-of-speech tag.<strong>标记：</strong>详细的词性标记。</li><li><strong>Dep:</strong> Syntactic dependency, i.e. the relation between tokens.<strong>Dep：</strong>语法依赖性，即标记之间的关系。</li><li><strong>Shape:</strong> The word shape – capitalization, punctuation, digits.<strong>形状：</strong>单词形状-大写，标点，数字。</li><li><strong>is alpha:</strong> Is the token an alpha character?<strong>是字母：</strong>令牌是字母字符吗？</li><li><strong>is stop:</strong> Is the token part of a stop list, i.e. the most common words of the language?<strong>是停止：</strong>标记是停止列表的一部分，即语言中最常见的词吗？</li></ul><p>POS!词性标签</p><p>词性列表： <a href="https://spacy.io/api/annotation#pos-tagging" target="_blank" rel="noopener">https://spacy.io/api/annotation#pos-tagging</a> </p><table><thead><tr><th>POS</th><th>DESCRIPTION</th><th>EXAMPLES</th></tr></thead><tbody><tr><td><code>ADJ</code></td><td>adjective</td><td>big, old, green, incomprehensible, first</td></tr><tr><td><code>ADP</code></td><td>adposition</td><td>in, to, during</td></tr><tr><td><code>ADV</code></td><td>adverb</td><td>very, tomorrow, down, where, there</td></tr><tr><td><code>AUX</code></td><td>auxiliary</td><td>is, has (done), will (do), should (do)</td></tr><tr><td><code>CONJ</code></td><td>conjunction</td><td>and, or, but</td></tr><tr><td><code>CCONJ</code></td><td>coordinating conjunction</td><td>and, or, but</td></tr><tr><td><code>DET</code></td><td>determiner</td><td>a, an, the</td></tr><tr><td><code>INTJ</code></td><td>interjection</td><td>psst, ouch, bravo, hello</td></tr><tr><td><code>NOUN</code></td><td>noun</td><td>girl, cat, tree, air, beauty</td></tr><tr><td><code>NUM</code></td><td>numeral</td><td>1, 2017, one, seventy-seven, IV, MMXIV</td></tr><tr><td><code>PART</code></td><td>particle</td><td>’s, not,</td></tr><tr><td><code>PRON</code></td><td>pronoun</td><td>I, you, he, she, myself, themselves, somebody</td></tr><tr><td><code>PROPN</code></td><td>proper noun</td><td>Mary, John, London, NATO, HBO</td></tr><tr><td><code>PUNCT</code></td><td>punctuation</td><td>., (, ), ?</td></tr><tr><td><code>SCONJ</code></td><td>subordinating conjunction</td><td>if, while, that</td></tr><tr><td><code>SYM</code></td><td>symbol</td><td>$, %, §, ©, +, −, ×, ÷, =, :), 😝</td></tr><tr><td><code>VERB</code></td><td>verb</td><td>run, runs, running, eat, ate, eating</td></tr><tr><td><code>X</code></td><td>other</td><td>sfpksdpsxmsa</td></tr><tr><td><code>SPACE</code></td><td>space</td><td></td></tr></tbody></table><p>CC     coordinatingconjunction 并列连词</p><p>CD     cardinaldigit  纯数  基数</p><p>DT     determiner  限定词（置于名词前起限定作用，如 the、some、my 等）</p><p>EX     existentialthere (like:”there is”… think of it like “thereexists”)   存在句；存现句</p><p>FW     foreignword  外来语；外来词；外文原词</p><p>IN     preposition/subordinating conjunction介词/从属连词；主从连词；从属连接词</p><p>JJ     adjective    ‘big’  形容词</p><p>JJR    adjective, comparative ‘bigger’ （形容词或副词的）比较级形式</p><p>JJS    adjective, superlative ‘biggest’  （形容词或副词的）最高级</p><p>LS     listmarker  1)</p><p>MD     modal (could, will) 形态的，形式的 , 语气的；情态的</p><p>NN     noun, singular ‘desk’ 名词单数形式</p><p>NNS    nounplural  ‘desks’  名词复数形式</p><p>NNP    propernoun, singular     ‘Harrison’ 专有名词</p><p>NNPS  proper noun, plural ‘Americans’  专有名词复数形式</p><p>PDT    predeterminer      ‘all the kids’  前位限定词</p><p>POS    possessiveending  parent’s   属有词  结束语</p><p>PRP    personalpronoun   I, he, she  人称代词</p><p>PRP$  possessive pronoun my, his, hers  物主代词</p><p>RB     adverb very, silently, 副词    非常  静静地</p><p>RBR    adverb,comparative better   （形容词或副词的）比较级形式</p><p>RBS    adverb,superlative best    （形容词或副词的）最高级</p><p>RP     particle     give up 小品词(与动词构成短语动词的副词或介词)</p><p>TO     to    go ‘to’ the store.</p><p>UH     interjection errrrrrrrm  感叹词；感叹语</p><p>VB     verb, baseform    take   动词</p><p>VBD    verb, pasttense   took   动词   过去时；过去式</p><p>VBG    verb,gerund/present participle taking 动词  动名词/现在分词</p><p>VBN    verb, pastparticiple     taken 动词  过去分词</p><p>VBP    verb,sing. present, non-3d     take 动词  现在</p><p>VBZ    verb, 3rdperson sing. present  takes   动词  第三人称</p><p>WDT    wh-determiner      which 限定词（置于名词前起限定作用，如 the、some、my 等）</p><p>WP     wh-pronoun   who, what 代词（代替名词或名词词组的单词）</p><p>WP$    possessivewh-pronoun     whose  所有格；属有词</p><p>WRB    wh-abverb    where, when 副词</p><p>原文链接：<a href="https://blog.csdn.net/jasonjarvan/article/details/79955664" target="_blank" rel="noopener">https://blog.csdn.net/jasonjarvan/article/details/79955664</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;spacy&quot;&gt;&lt;a href=&quot;#spacy&quot; class=&quot;headerlink&quot; title=&quot;spacy&quot;&gt;&lt;/a&gt;spacy&lt;/h1&gt;&lt;h2 id=&quot;spacy的定义&quot;&gt;&lt;a href=&quot;#spacy的定义&quot; class=&quot;headerlink&quot; titl
      
    
    </summary>
    
    
      <category term="work" scheme="https://esyyes.github.io/categories/work/"/>
    
    
      <category term="work" scheme="https://esyyes.github.io/tags/work/"/>
    
  </entry>
  
  <entry>
    <title>聊天机器人基础</title>
    <link href="https://esyyes.github.io/2020/07/10/chatbot/%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%9F%BA%E7%A1%80/"/>
    <id>https://esyyes.github.io/2020/07/10/chatbot/%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%9F%BA%E7%A1%80/</id>
    <published>2020-07-10T13:55:29.000Z</published>
    <updated>2020-07-10T13:55:29.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="聊天机器人基础篇"><a href="#聊天机器人基础篇" class="headerlink" title="聊天机器人基础篇"></a>聊天机器人基础篇</h1><p><strong>问答系统</strong>是搜索引擎技术的一种扩展，可根据用户<strong>输入的问题</strong>给出<strong>精确而简练</strong>的答案。根据回答问题的范围，问答系统分为<strong>开域</strong>和<strong>闭域</strong>。开域的问答系统可以回答多种多样、涉及很多领域的问题；<strong>闭域的问答系统为用户回答某个特定领域的问题</strong>。</p><p>问答系统通常是闭域的，且为执行具体的任务而设计，这种问答系统也称作任务式问答系统</p><p>I plan to develop <strong>a question-and-answer chatbot for the tourism domain</strong><br>based on <strong>retrieval mode</strong>. The chatbot will respond to users by<br>selecting the best matching answer in the database based on users’<br>questions.</p><p>本文的要求：聊天机器人就为问答式的指定的旅游和检索式的！</p><p>以任务为主的特定领域。检索式</p><p>检索式单轮聊天机器人（ＦＡＱ－Ｂ〇ｔ），其思想就是通过计算词向量的相似性，利用有限的问答对进行同义词的扩展修改和复写，此外还有问答系统（ＱＡ）</p><p>即创建一个问答式的检索聊天机器人。</p><h2 id="问答系统"><a href="#问答系统" class="headerlink" title="问答系统"></a>问答系统</h2><p>问答系统 （ Question  Answerir毡， QA ）由最初的搜索需求发展而来，基本为“一问一答”的交互模式 ，因此构建问答系统时一般不会涉及对话管理相关的技术。 第 l 章介绍过， 聊天机器人的核心模块包括自然语言理解、对话管理和自 然语言生成。 在自然语言理解层面，问答系统偏重于问句分析，旨在获取问句的主题词、问题词、 中心动词等。 目前，问句分析主要采用模板匹配和语义解析两种方式。</p><h3 id="自然语言"><a href="#自然语言" class="headerlink" title="自然语言"></a>自然语言</h3><p>自然语言通常会自然地随文化发生演化，英语、汉语、日语都是具体种类的自然语言，这些自然语言震行着语言最原始的作用 ： 人们进行交互和思想交流的媒介性工具。我们可以从语音、音韵、词态、句法、语义、语用 6 个维度理解自然语言。</p><p>(  1 ） <strong>语音</strong>是与发音相关的学问（例如儿童学习的汉语拼音等），主要在前述介绍的语音技术中发挥作用。</p><p>( 2 ） <strong>音韵</strong>是由语音组合起来的读音，即汉语拼音和四声调。</p><p>( 3 ） <strong>词态</strong>封装了可用于自然语言理解的有用信息，其中信息量的大小取决于具体的语言种类。需要特别提及的是，中文没有太多的词态变换（不像拉丁语系语言），仅存在不同的偏旁，导致出现词的性别转换的情况（例如 “他”“她” ） 。</p><p>( 4 ） <strong>句法</strong>主要研究词语如何组成合乎语法的句子 ，句法提供单词组成句子的约束条件，为语义的合成提供框架。</p><p>( 5 ） <strong>语义和语用</strong>是自然语言所包含和表达的意思 。</p><p>对<strong>计算机</strong>来说，<strong>自然语言处理</strong>的难度主要体现在以下几个方面 ：</p><p>( 1 ）自然语言千变万化，没有固定格式。同样的意思可以使用多种句式来表达，同样的句子调整一个字、调整语调或者调整语序 ， 表达的意思可能相差甚多。</p><p>( 2 ）不断有新的词汇出现，计算机需要不断学习新的词汇。</p><p>( 3 ）在不同的场景 （上下文语境）下，同一句话表达的意思可能不同 。</p><p><strong>聊天机器人系统中的自然语言理解模块的功能主要包捐实体识别、用户意图识别、用户情感识别、指代消解、省｜咯恢复、回复确认及拒识判断等</strong>。 <strong>实体识别</strong>又称命名实体识别（ Named Entity  Recognition ），指识别自然语言中具有特定意义的实体，如人名、时间、地名及各种专有名词。 用户意图识别中需要识别的用户意图包括显式意图和隐式意图，显式意图通常对应一个明确的用户需求 ，而隐式意图则较难判断，表 2-1 举例说明了用户的显式意图和隐式意图。用户情感和用户意图类似，也可以分为显式和隐式两种，表 2-2 是对用户显式情感和隐式情感的举例说明。 指代消解和省略恢复是指聊天主题背景一致的情况下 ，人们在对话过程中通常会习惯性地使用代词指代已经出现过的某个实体或事件 ， 或者为了方便表述省略句子部分成分的情况。 自然语言理解模块需要明确代词指代的成分及句子中省略的成分，唯有如此，聊天机器人才能正确理解用户的输入，给出合乎上下文语义的回复。 当用户意图、聊天信息等带有一定的模糊性时 ， 需要聊天机器人主动向用户询问 ，确认用户的意图，即回复确认。 拒识判断是指聊天机器人系统应当具备一定的拒识能力 ， 主动拒绝识别及回复超出自身理解／回复范围或者涉及敏感话题的用户输入。</p><h3 id="基于规则的方法"><a href="#基于规则的方法" class="headerlink" title="基于规则的方法"></a>基于规则的方法</h3><p>通常，可以将自然语言理解的主要方法分为<strong>基于规则的方法</strong>和<strong>基于统计的方法</strong>两种。 <strong>基于规则的方法</strong>是指利用<strong>规则定义如何从文本中提取语义</strong> ， 大致思路是<strong>人工定义很多语法规则</strong>，它们是表达某种特定语义的具体方式， 然后自然语言理解模块根据这些<strong>规则解析输入该模块的文本</strong>。基于规则的 自然语言理解模块的优点是灵活 ，<strong>可以定义各种各样的规则 ， 而且不依赖训练数据</strong> ； 缺点是<strong>需要大量的、覆盖不同场景</strong>的规则 ， 且随着规则数量的增长 ，对规则进行人工维护的难度也会增加。因此， 基于规则的自然语言理解只适合用在<strong>相对简单</strong>的场景，其优势在于可以快速实现一个简单可用的语义理解模块。</p><p>在具体实践中，通常将这两种方法结合起来使用 。</p><p>(  1 ）<strong>没有数据及数据较少时先采用基于规则的方法，当数据积累到 一定规模时逐渐转为使用基于统计的方法。</strong></p><p><strong>词性标注</strong>最初采用的主要模型是隐马尔可夫生成式模型，之后陆续采用过判别式的最大脑模型、支持向量机模型等进行尝试。 词性标注的方法主要分为两种 ： 基于规则的方法和基于统计模型的方法。 基于规则的词性标注方法按照兼类词搭配关系和上下文语境建造词类消歧规则 。</p><p>对句子进行句法分析需要确定句子的句法结构，分析的结果往往以树结构的形式表现，这棵表示句子结构的树又叫作句法分析树。 句法分析树的建立可以采用自顶向下的方法，也可以采用自底向上的方法。</p><p>根据句法结构的不同表示形式，可以将句法分析任务划分为以下 3 种。( 1 ）依存句法分析（ Dependency Syntactic Parsing ）， 主要任务是识别句子中词汇之间的相互依存关系。</p><p>( 2 ） 短语结构句法分析（ Phrase-structure  Syntactic  Parsing ）， 也称作成分句法分析（ Constituent Syntactic Parsing ），主要任务是识别句子中短语结构和短语之间的层次句法关系</p><p>( 3 ）深层文法句法分析，主要任务是利用深层文沽，对句子进行深层的句法及语义分析，这些深层文法包括词汇化树邻接文法、词汇功能文法、组合范畴文法等。</p><h2 id="KBQA系统"><a href="#KBQA系统" class="headerlink" title="KBQA系统"></a>KBQA系统</h2><p><strong>问答系统是信息、检索系统的一种高级形式</strong> ， 它通过 Web 搜索或链接知识库等方式 ， 检索到用户问题的答案，并用准确、简洁的自然语言回答用户。本书第 2 章简要阐述了问答系统、对话系统和闲聊系统的区别与联系。问答系统更接近信息检索中的语义搜索 ， 针对用户用自然语言提出的问题，通过一系列的方法生成问题的答案 ， 但与信息检索系统的不同在于，问答系统根据用户的问题直接给出精准的答案， 而不是给出一系列包含候选答案的页面。 系统生成答案的过程虽然也涉及简单的上下文处理 ， 但通常是通过指代消解和内容补全完成处理操作的。问答系统主要针对特定领域的知识进行一问一答 ， 侧重于知识结构的构建、知识的融合与知识的推理。</p><p>问答系统</p><p>(  1 ）以自然语言 问题为输入，以准确的答案为输出 。</p><p>( 2 ） 让机器承担更多数据解释的工作。</p><p>( 3 ） 问答系统是一个问题驱动的信息获取过程（ Query-driven Information Access ） </p><p>问答系统适用于特殊而复杂的信息需求，可以从多样化的、非结构化的信息中获取问题的答案，并且需要对问题进行更多自动化的语义理解。</p><p>现有的问答系统根据其问题答案的数据来源和回答的方式的不同， 大体上可以分为以下 3 类。</p><ol><li><p>基于 Web 信息检索的问答系统（ Web Question Answering ,  WebQA) WebQA 系统以搜索引擎为支撑 ， 理解分析用户的问题意图后，利用搜索引 擎在全网范围内搜索相关答案反馈给用户 。 典型的系统有早期的 Ask Jeeves 和 Answer Bus 问答系统。</p></li><li><p><strong>基于知识库的问答系统 C Knowledge  Based  Question  Answering, KBQA)</strong> 阻QA 系统通过结合一些已有的知识库或数据库资源（例如 Fre巳ba挝、DBpedia 、 Yago 、 Zhishi . me 等） ，以及利 用如维基百科、百度百科等非结构化文本的信息 ，使用信息抽取的方法提取有价值的信息 ，并构建知识图谱作为问答系统的后台支撑， 再一结合知识推理等方法为用户提供更深层次语义理解的答案。</p></li><li><p>社区问答系统（ Community Question Answering,  CQA) CQA 系统也叫基于社交媒体的问答系统 ， 例如 Yahoo! Answers 、百度知道、知乎等问答平台。大多数问题的答案由网友提供，问答系统会检索社交媒体中与用户提问语义相似的问题，并将答案返回给用户。</p></li></ol><p>上述 3 类问答系统中 ，KBQA 是当下应用最广泛的 ， 该类系统不仅需要实现对复杂问题的语义理解 ，还要在若干知识库之间进行知识的融合，并针对复杂的问题进行知识推理。 3.2 节将详细介绍 阻QA 中用到的相关技术 ， 3.3 节将介绍如何实现一个简单的问答系统。 除了这 3 类主流问答系统，还有其他形式的问答系统 ，例如混合式问答系统 （ Hybrid QA ）、 多语言问答系统（ Multilingual QA ）、基于常见问题库的问答系统（ Frequently Asked Question,  FAQ ） </p><p><strong>知识库（ Knowledge Base ，KB</strong> ）是用于知识管理的一种特殊的数据库，用于相关领域知识的采集、整理及提取。 知识库中的知识源于领域专家，是求解问题所需领域知识的集合 ， 包括一些基本事实、规则和其他相关信息。知识库的表示形式是一个对象模型（ object model ），通常称为本体，包含一些类、子类和实体。不同于传统的数据库 ， 知识库中存放的知识蕴含特殊的知识表示 ，其结构比数据库更复杂，可以用来存放更多复杂语义表示的数据。 知识库最早被应用于专家系统 ， 它是一种基于知识的系统，包含表示客观世界事实的一系列知识及一个推理机（ inference engine ），并依赖一定的规则和逻辑形式推理出一些新的事实</p><p>KBQA 是基于知识库中的专业知识建立的问答系统，也是目前最主流的问答系统。常见的知识库有 Freebase 、 DBpedia 等。知识库一般采用 RDF 格式对其中的知识进行表示 ， 知识的查询主要采用 RDF 标准查询语言 SPARQL。除此之外，还有一些 （例如维基百科等 ）无结构化文本知识库。</p><p>但一般来说， KBQA 系统包含问句理解、答案信息抽取、答案排序和生成等核心模块，</p><p>因此现在主要是对问句进行理解！</p><p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1594788222495&di=82165d1eb214d317226aa4c184b4ead8&imgtype=0&src=http%3A%2F%2Fgss0.baidu.com%2F9vo3dSag_xI4khGko9WTAnF6hhy%2Fzhidao%2Fpic%2Fitem%2F0823dd54564e9258088b73de9782d158ccbf4e47.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;聊天机器人基础篇&quot;&gt;&lt;a href=&quot;#聊天机器人基础篇&quot; class=&quot;headerlink&quot; title=&quot;聊天机器人基础篇&quot;&gt;&lt;/a&gt;聊天机器人基础篇&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;问答系统&lt;/strong&gt;是搜索引擎技术的一种扩展，可根据用户&lt;strong
      
    
    </summary>
    
    
      <category term="work" scheme="https://esyyes.github.io/categories/work/"/>
    
    
      <category term="work" scheme="https://esyyes.github.io/tags/work/"/>
    
  </entry>
  
  <entry>
    <title>HMM之数据的处理</title>
    <link href="https://esyyes.github.io/2020/07/09/HMM/HMM%E4%B9%8B%E6%95%B0%E6%8D%AE%E7%9A%84%E5%A4%84%E7%90%86/"/>
    <id>https://esyyes.github.io/2020/07/09/HMM/HMM%E4%B9%8B%E6%95%B0%E6%8D%AE%E7%9A%84%E5%A4%84%E7%90%86/</id>
    <published>2020-07-08T23:55:52.000Z</published>
    <updated>2020-07-08T23:55:52.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HMM之数据的处理"><a href="#HMM之数据的处理" class="headerlink" title="HMM之数据的处理"></a>HMM之数据的处理</h1><h2 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h2><p>直接读取数据</p><p>数据类型如下所示：</p><table><thead><tr><th align="right"></th><th align="right">i</th><th align="right">t</th><th align="right">y</th><th align="right">x1</th><th align="right">x2</th><th align="right">x3</th><th align="right">x4</th><th align="right">z1</th><th align="right">z2</th></tr></thead><tbody><tr><td align="right">0</td><td align="right">1</td><td align="right">1</td><td align="right">0</td><td align="right">3891</td><td align="right">116</td><td align="right">0</td><td align="right">0</td><td align="right">6.0</td><td align="right">59.0</td></tr><tr><td align="right">1</td><td align="right">1</td><td align="right">2</td><td align="right">0</td><td align="right">5958</td><td align="right">93</td><td align="right">0</td><td align="right">0</td><td align="right">NaN</td><td align="right">NaN</td></tr><tr><td align="right">2</td><td align="right">1</td><td align="right">3</td><td align="right">0</td><td align="right">5362</td><td align="right">106</td><td align="right">0</td><td align="right">0</td><td align="right">NaN</td><td align="right">NaN</td></tr><tr><td align="right">3</td><td align="right">1</td><td align="right">4</td><td align="right">0</td><td align="right">2528</td><td align="right">126</td><td align="right">0</td><td align="right">0</td><td align="right">NaN</td><td align="right">NaN</td></tr><tr><td align="right">4</td><td align="right">1</td><td align="right">5</td><td align="right">1</td><td align="right">1219</td><td align="right">215</td><td align="right">0</td><td align="right">0</td><td align="right">NaN</td><td align="right">NaN</td></tr></tbody></table><h3 id="数据的含义"><a href="#数据的含义" class="headerlink" title="数据的含义"></a>数据的含义</h3><p>i对应的是一个人，t表示的是一个时期为一周，x1-x4,表示的是自变量，是影响隐马尔科夫模型的转移概率矩阵，z1,z2,是控制变量，是可以长期影响一个人的控制变量数据，是状态转移矩阵的估计量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                  表 <span class="number">4</span><span class="number">-2</span> 变量的统计学描述                </span><br><span class="line">变量名样本数 均值标准差最小值最大值</span><br><span class="line">y<span class="number">3108</span><span class="number">1.119691</span><span class="number">6.266278</span><span class="number">0</span><span class="number">111</span></span><br><span class="line">x1<span class="number">3108</span><span class="number">1301.892</span><span class="number">2582.350</span><span class="number">0</span><span class="number">42864</span></span><br><span class="line">x2<span class="number">3108</span><span class="number">615.3838</span><span class="number">2130.248</span><span class="number">-58</span><span class="number">46162</span></span><br><span class="line">x3<span class="number">3108</span><span class="number">1.071750</span><span class="number">4.706953</span><span class="number">0</span><span class="number">103</span></span><br><span class="line">x4<span class="number">3108</span><span class="number">0.751609</span><span class="number">5.057782</span><span class="number">0</span><span class="number">90</span></span><br></pre></td></tr></table></figure><p>样本差异过大，所以需要进行归一化或者标准化处理</p><p>没有数据缺失，因此只需要进行标准化即可。</p><h3 id="数据标准化"><a href="#数据标准化" class="headerlink" title="数据标准化"></a>数据标准化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">均值插补缺省值</span></span><br><span class="line"><span class="string">z-score标准化</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_pre</span><span class="params">(data)</span>:</span></span><br><span class="line">    df = data.replace([np.inf, -np.inf], np.nan)</span><br><span class="line">    num = df.isnull().sum()</span><br><span class="line">    [df[df.keys()[i]].fillna(value=df[df.keys()[i]].mean(), inplace=<span class="literal">True</span>) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(num)) <span class="keyword">if</span> num[i] &gt; <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    df_scale = preprocessing.scale(df)</span><br><span class="line">    <span class="comment"># 将标准化后的数据再转换为表格</span></span><br><span class="line">    fea = pd.DataFrame(df_scale, columns=data.keys())</span><br><span class="line">    <span class="keyword">return</span> fea</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">         x1        x2        x3        x4</span><br><span class="line"><span class="number">0</span>  <span class="number">1.002617</span> <span class="number">-0.234425</span> <span class="number">-0.227695</span> <span class="number">-0.148604</span></span><br><span class="line"><span class="number">1</span>  <span class="number">1.803051</span> <span class="number">-0.245222</span> <span class="number">-0.227695</span> <span class="number">-0.148604</span></span><br><span class="line"><span class="number">2</span>  <span class="number">1.572253</span> <span class="number">-0.239119</span> <span class="number">-0.227695</span> <span class="number">-0.148604</span></span><br><span class="line"><span class="number">3</span>  <span class="number">0.474803</span> <span class="number">-0.229731</span> <span class="number">-0.227695</span> <span class="number">-0.148604</span></span><br><span class="line"><span class="number">4</span> <span class="number">-0.032099</span> <span class="number">-0.187952</span> <span class="number">-0.227695</span> <span class="number">-0.148604</span></span><br></pre></td></tr></table></figure><p>数据标准化后结果如上图所示</p><h3 id="HMM的状态划分"><a href="#HMM的状态划分" class="headerlink" title="HMM的状态划分"></a>HMM的状态划分</h3><p>在现实的数据中，HMM的隐藏状态是无法直接判别的，因此需要对状态进行判别。</p><p>在模型训练中最重要的步骤是进行模型状态数量的<br>确定。由于在大多数实验过程中，并不能直接确定将研究的隐藏状态分为几<br>个状态水平较为合适，因此，需要通过建立多个模型，根据贝叶斯信息准则<br>对模型的拟合效果进行比较，选择最佳的模型作为实际研究模型。</p><p>据相关研究，需要通过假定不同的状态量 S，建立若干个模<br>型，训练模型后计算模型的对数似然值。再根据贝叶斯信息准则（BIC）的<br>计算方法，计算 BIC 的值，比较后选择效果较好的模型。 </p><p> <strong>BIC =ln L − k× ln P / 2</strong>   </p><p>BIC 值的计算方法，其中 ln L 代表模型的对数<br>似然值，k 代表模型的变量个数，P 代表样本大小。BIC 的值越大，表示模<br>型训练的效果越好。</p><p>因此需要最大似然值和BIC进行估计，判断在什么状态下的数据最好。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">根据样本数据。因此确定选择<span class="number">1</span>为阈值下</span><br><span class="line">均值下的似然估计值为：    <span class="number">-955.2942841591449</span></span><br><span class="line">分类为<span class="number">2</span>均值下的BIC为：<span class="number">-1028.7801594684208</span></span><br><span class="line">变量：<span class="number">12</span></span><br><span class="line"><span class="number">1</span>值下的似然估计值为：    <span class="number">-1589.5001457084938</span></span><br><span class="line">分类为<span class="number">2</span>阈值为<span class="number">1</span>下的BIC为：<span class="number">-1662.9860210177699</span></span><br><span class="line">状态为<span class="number">3</span>时：设定<span class="number">1</span>《《标准差为阈值</span><br><span class="line">变量：<span class="number">18</span></span><br><span class="line">似然估计值为：    <span class="number">-1486.947107953313</span></span><br><span class="line">分类为<span class="number">3</span>时的BIC为：<span class="number">-1619.2216835100096</span></span><br><span class="line">状态为<span class="number">4</span>时：设定<span class="number">1</span>《《标准差《《方差为阈值</span><br><span class="line">变量：<span class="number">24</span></span><br><span class="line">似然估计值为： <span class="number">-1524.3108928288107</span> </span><br><span class="line">分类为<span class="number">4</span>时的BIC为：<span class="number">-1700.676993571073</span></span><br></pre></td></tr></table></figure><p>因此确定3为状态数</p><h3 id="初始状态概率矩阵"><a href="#初始状态概率矩阵" class="headerlink" title="初始状态概率矩阵"></a>初始状态概率矩阵</h3><p>直接用划分的状态进行划分初始状态概率矩阵</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">当状态为<span class="number">2</span>时：</span><br><span class="line">[[<span class="number">0.7918275418275418</span>, <span class="number">0.20817245817245822</span>]]</span><br><span class="line">当状态为<span class="number">3</span>时：</span><br><span class="line">[[<span class="number">0.7918275418275418</span>, <span class="number">0.3462033462033462</span>, <span class="number">0.03507078507078507</span>]]</span><br><span class="line">当状态为<span class="number">4</span>时：</span><br><span class="line">[[<span class="number">0.7918275418275418</span>, <span class="number">0.3462033462033462</span>, <span class="number">0.030244530244530245</span>, <span class="number">0.004826254826254826</span>]]</span><br></pre></td></tr></table></figure><h3 id="判断最大似然的收敛性"><a href="#判断最大似然的收敛性" class="headerlink" title="判断最大似然的收敛性"></a>判断最大似然的收敛性</h3><p>用百次循环的结果去对应查看数据是否收敛</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">7</span>, <span class="number">4</span>))</span><br><span class="line"><span class="comment"># 解决中文显示问题</span></span><br><span class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'Microsoft YaHei'</span>]</span><br><span class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span></span><br><span class="line">plt.plot(list_L, <span class="string">"bo"</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Number of Iterations"</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">plt.xticks(fontsize=<span class="number">8</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Loglik"</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">plt.yticks(fontsize=<span class="number">8</span>)</span><br><span class="line"><span class="comment"># 去边框</span></span><br><span class="line">ax = plt.gca()</span><br><span class="line">ax.spines[<span class="string">'right'</span>].set_color(<span class="string">'none'</span>)</span><br><span class="line">ax.spines[<span class="string">'top'</span>].set_color(<span class="string">'none'</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="H:%5Cmyboke%5Cmybike%5Csource%5Cimages%5Cloglik.png" alt="loglik"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/7/9</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> HMM_class <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> data_preprocessing <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> LR <span class="keyword">import</span> *</span><br><span class="line"><span class="comment"># import matplotlib.pyplot as plt</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line"></span><br><span class="line">data = pd.read_excel(<span class="string">'data1'</span> + <span class="string">'.xlsx'</span>)</span><br><span class="line">data.fillna(<span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 转换列表</span></span><br><span class="line">list_data = np.array(data).tolist()</span><br><span class="line">X1 = pd.get_dummies(data.iloc[<span class="number">0</span>:len(data), <span class="number">3</span>:<span class="number">7</span>])</span><br><span class="line"></span><br><span class="line">X = data_pre(X1)</span><br><span class="line">Z = pd.get_dummies(data.iloc[<span class="number">0</span>:len(data), <span class="number">7</span>:<span class="number">9</span>])</span><br><span class="line">list_y1 = [int(list_data[i][<span class="number">2</span>]) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data))]</span><br><span class="line">y1_mean = np.array(list_y1).mean()</span><br><span class="line">y1_std = np.array(list_y1).std()</span><br><span class="line"><span class="comment"># 划分为状态3</span></span><br><span class="line"><span class="comment"># 状态1：小于1的</span></span><br><span class="line"><span class="comment"># 状态2：小于标准差</span></span><br><span class="line"><span class="comment"># 状态3：大于标准差</span></span><br><span class="line"></span><br><span class="line">Y_X = []</span><br><span class="line">num1 = <span class="number">0</span></span><br><span class="line">num2 = <span class="number">0</span></span><br><span class="line">num3 = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">    <span class="keyword">if</span> list_data[i][<span class="number">2</span>] &lt; <span class="number">1</span>:</span><br><span class="line">        Y_X.append(<span class="number">0</span>)</span><br><span class="line">        num1 += <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="number">1</span> &lt;= list_data[i][<span class="number">2</span>] &lt; y1_std:</span><br><span class="line">        Y_X.append(<span class="number">1</span>)</span><br><span class="line">        num2 += <span class="number">2</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        Y_X.append(<span class="number">2</span>)</span><br><span class="line">        num3 += <span class="number">1</span></span><br><span class="line">Z1 = [[int(list_data[<span class="number">14</span>*j][k]) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)) <span class="keyword">if</span> <span class="number">14</span> * j == i <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">7</span>, <span class="number">9</span>)]</span><br><span class="line">      <span class="keyword">for</span> j <span class="keyword">in</span> range(int(len(data)/<span class="number">14</span>))]</span><br><span class="line">Z2 = pd.DataFrame(Z1, columns=[<span class="string">'z1'</span>, <span class="string">'z2'</span>])</span><br><span class="line">Z = data_pre(Z2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将14个时期取平均值</span></span><br><span class="line">list_z_y = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(int(len(data)/<span class="number">14</span>)):</span><br><span class="line">    y1 = []</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        <span class="keyword">if</span> <span class="number">14</span> * i &lt;= j &lt; <span class="number">14</span> * (i + <span class="number">1</span>):</span><br><span class="line">            y1.append(list_data[j][<span class="number">2</span>])</span><br><span class="line">    list_z_y.append(np.array(y1).mean())</span><br><span class="line">Y_Z = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(list_z_y)):</span><br><span class="line">    <span class="keyword">if</span> list_z_y[i] &lt; <span class="number">1</span>:</span><br><span class="line">        Y_Z.append(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">elif</span> <span class="number">1</span> &lt;= list_z_y[i] &lt; y1_std:</span><br><span class="line">        Y_Z.append(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        Y_Z.append(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># HMM模型参数设置</span></span><br><span class="line">HMM = HiddenMarkov()</span><br><span class="line">Q = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">V = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">B = [[<span class="number">0.8767222625090645</span>, <span class="number">0.12327773749093547</span>, <span class="number">0.0</span>],</span><br><span class="line">     [<span class="number">0.17063492063492064</span>, <span class="number">0.75</span>, <span class="number">0.07936507936507937</span>],</span><br><span class="line">     [<span class="number">0.0</span>, <span class="number">0.09183673469387756</span>, <span class="number">0.9081632653061223</span>]]</span><br><span class="line">PI = [[num1/len(data), num2/len(data), num3/len(data)]]</span><br><span class="line"></span><br><span class="line">list_L = []</span><br><span class="line">list_fix_x = []</span><br><span class="line">list_fix_z = []</span><br><span class="line">list_lr_x_w = []</span><br><span class="line">list_lr_z_w = []</span><br><span class="line">list_lr_x_b = []</span><br><span class="line">list_lr_z_b = []</span><br><span class="line">list_A = []</span><br><span class="line">list_BIC = []</span><br><span class="line">list_acr_x = []</span><br><span class="line">list_acr_z = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    acr_x, fix_x, lr_x_w, lr_x_b = run_lr(X, Y_X)</span><br><span class="line">    acr_z, fix_z, lr_z_w, lr_z_b = run_lr(Z, Y_Z)</span><br><span class="line">    A = [[fix_x[<span class="number">0</span>][<span class="number">0</span>]/fix_x[<span class="number">0</span>].sum(), fix_x[<span class="number">0</span>][<span class="number">1</span>]/fix_x[<span class="number">0</span>].sum(), fix_x[<span class="number">0</span>][<span class="number">2</span>]/fix_x[<span class="number">0</span>].sum()],</span><br><span class="line">         [fix_x[<span class="number">1</span>][<span class="number">0</span>]/fix_x[<span class="number">1</span>].sum(), fix_x[<span class="number">1</span>][<span class="number">1</span>]/fix_x[<span class="number">1</span>].sum(), fix_x[<span class="number">1</span>][<span class="number">2</span>]/fix_x[<span class="number">1</span>].sum()],</span><br><span class="line">         [fix_x[<span class="number">2</span>][<span class="number">0</span>]/fix_x[<span class="number">2</span>].sum(), fix_x[<span class="number">2</span>][<span class="number">1</span>]/fix_x[<span class="number">2</span>].sum(), fix_x[<span class="number">2</span>][<span class="number">2</span>]/fix_x[<span class="number">2</span>].sum()]</span><br><span class="line">         ]</span><br><span class="line"></span><br><span class="line">    P = []</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(int(len(data)/<span class="number">14</span>)):</span><br><span class="line">        O = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">            <span class="keyword">if</span> <span class="number">14</span> * j &lt;= i &lt; <span class="number">14</span> * (j + <span class="number">1</span>):</span><br><span class="line">                O.append(Y_X[i])</span><br><span class="line">        P.append(HMM.forward(Q, V, A, B, O, PI))</span><br><span class="line"></span><br><span class="line">    L = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(P)):</span><br><span class="line">        L += math.log(P[i])</span><br><span class="line">    BIC = L - <span class="number">18</span> * (math.log(<span class="number">3108</span> / <span class="number">2</span>))</span><br><span class="line">    <span class="comment"># 保存似然值</span></span><br><span class="line">    list_A.append(A)</span><br><span class="line">    list_L.append(L)</span><br><span class="line">    list_BIC.append(BIC)</span><br><span class="line">    list_fix_x.append(fix_x)</span><br><span class="line">    list_fix_z.append(fix_z)</span><br><span class="line">    list_lr_x_w.append(lr_x_w)</span><br><span class="line">    list_lr_z_w.append(lr_z_w)</span><br><span class="line">    list_lr_x_b.append(lr_x_b)</span><br><span class="line">    list_lr_z_b.append(lr_z_b)</span><br><span class="line">    list_acr_x.append(acr_x)</span><br><span class="line">    list_acr_z.append(acr_z)</span><br><span class="line"></span><br><span class="line">print(<span class="string">f'百次循环后，最高准确率<span class="subst">&#123;max(list_acr_x)&#125;</span>'</span>)</span><br><span class="line">print(<span class="string">f'最大准确率对应的序号：<span class="subst">&#123;list_acr_x.index(max(list_acr_x))&#125;</span>'</span>)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">f'百次循环后，似然值为<span class="subst">&#123;list_L[list_acr_x.index(max(list_acr_x))]&#125;</span>'</span>)</span><br><span class="line">print(<span class="string">f'对应的BIC为<span class="subst">&#123;list_BIC[list_acr_x.index(max(list_acr_x))]&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">f'在4个变量下的状态转移概率矩阵：<span class="subst">&#123;list_A[list_acr_x.index(max(list_acr_x))]&#125;</span>'</span>)</span><br><span class="line">print(<span class="string">f'-'</span>*<span class="number">20</span>)</span><br><span class="line">print(<span class="string">f'参数估计'</span>)</span><br><span class="line">print(<span class="string">f'状态转移概率矩阵的系数为：<span class="subst">&#123;list_lr_x_w[list_acr_x.index(max(list_acr_x))]&#125;</span>'</span>)</span><br><span class="line">print(<span class="string">f'状态转移概率矩阵的偏差为：<span class="subst">&#123;list_lr_x_b[list_acr_x.index(max(list_acr_x))]&#125;</span>'</span>)</span><br><span class="line">print(<span class="string">f'观察状态概率转移矩阵的系数为：<span class="subst">&#123;list_lr_z_w[list_acr_x.index(max(list_acr_x))]&#125;</span>'</span>)</span><br><span class="line">print(<span class="string">f'观察状态概率转移矩阵的偏差为：<span class="subst">&#123;list_lr_z_b[list_acr_x.index(max(list_acr_x))]&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line">num = list_acr_x.index(max(list_acr_x))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">list_x = np.array(X).tolist()</span><br><span class="line">print(<span class="string">f'变量1下的知识贡献意愿转移概率'</span>)</span><br><span class="line">wx_b0 = []</span><br><span class="line">wx_b1 = []</span><br><span class="line">wx_b2 = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">    <span class="keyword">if</span> Y_X[i] == <span class="number">0</span>:</span><br><span class="line">        wx_b0.append(list_lr_x_w[num][<span class="number">0</span>][<span class="number">0</span>] * list_x[i][<span class="number">0</span>] + list_lr_x_b[num][<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">elif</span> Y_X[i] == <span class="number">1</span>:</span><br><span class="line">        wx_b1.append(list_lr_x_w[num][<span class="number">1</span>][<span class="number">0</span>] * list_x[i][<span class="number">0</span>] + list_lr_x_b[num][<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        wx_b2.append(list_lr_x_w[num][<span class="number">2</span>][<span class="number">0</span>] * list_x[i][<span class="number">0</span>] + list_lr_x_b[num][<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># fig = plt.figure(figsize=(10, 8))</span></span><br><span class="line"><span class="comment"># plt.plot(np.array(wx_b0), "bo", linewidth=1)</span></span><br><span class="line"><span class="comment"># plt.plot(np.array(wx_b2), "ro", linewidth=1)</span></span><br><span class="line"><span class="comment"># plt.plot(np.array(wx_b1), "ko", linewidth=1)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 状态1个数： len(wx_b0) = 2461</span></span><br><span class="line"><span class="comment"># 将其排序,状态1中设置260个</span></span><br><span class="line"><span class="comment"># 状态2时的个数： 538,设置为80， 400， 58</span></span><br><span class="line"><span class="comment"># 状态3时的个数：109 ， 在2中设置35个</span></span><br><span class="line"></span><br><span class="line">H = [[(len(wx_b0) - <span class="number">260</span>)/len(wx_b0), <span class="number">260</span>/len(wx_b0), <span class="number">0</span>],</span><br><span class="line">     [(len(wx_b1) - <span class="number">458</span>)/len(wx_b1), <span class="number">400</span>/len(wx_b1), <span class="number">58</span>/len(wx_b1)],</span><br><span class="line">     [<span class="number">0</span>, <span class="number">15</span>/len(wx_b2), <span class="number">1</span><span class="number">-15</span>/(len(wx_b2))]]</span><br><span class="line">print(<span class="string">f'<span class="subst">&#123;H&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">f'变量2下的知识贡献意愿转移概率'</span>)</span><br><span class="line">wx_b20 = []</span><br><span class="line">wx_b21 = []</span><br><span class="line">wx_b22 = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">    <span class="keyword">if</span> Y_X[i] == <span class="number">0</span>:</span><br><span class="line">        wx_b20.append(list_lr_x_w[num][<span class="number">0</span>][<span class="number">1</span>] * list_x[i][<span class="number">1</span>] + list_lr_x_b[num][<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">elif</span> Y_X[i] == <span class="number">1</span>:</span><br><span class="line">        wx_b21.append(list_lr_x_w[num][<span class="number">1</span>][<span class="number">1</span>] * list_x[i][<span class="number">1</span>] + list_lr_x_b[num][<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        wx_b22.append(list_lr_x_w[num][<span class="number">2</span>][<span class="number">1</span>] * list_x[i][<span class="number">1</span>] + list_lr_x_b[num][<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># fig = plt.figure(figsize=(10, 8))</span></span><br><span class="line"><span class="comment"># plt.plot(np.array(wx_b20), "bo", linewidth=1)</span></span><br><span class="line"><span class="comment"># plt.plot(np.array(wx_b22), "ro", linewidth=1)</span></span><br><span class="line"><span class="comment"># plt.plot(np.array(wx_b21), "ko", linewidth=1)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 状态2个数： len(wx_b0) = 2461</span></span><br><span class="line"><span class="comment"># 将其排序,   状态1中设置260个</span></span><br><span class="line"><span class="comment"># 状态2时的个数： 538,设置为80， 400， 58</span></span><br><span class="line"><span class="comment"># 状态3时的个数：109 ， 在2中设置35个</span></span><br><span class="line"></span><br><span class="line">H2 = [[(len(wx_b20) - <span class="number">360</span>)/len(wx_b20), <span class="number">360</span>/len(wx_b20), <span class="number">0</span>],</span><br><span class="line">      [(len(wx_b21) - <span class="number">500</span>)/len(wx_b21), <span class="number">450</span>/len(wx_b21), <span class="number">50</span>/len(wx_b21)],</span><br><span class="line">      [<span class="number">0</span>, <span class="number">16</span>/len(wx_b22), <span class="number">1</span><span class="number">-16</span>/(len(wx_b22))]]</span><br><span class="line">print(<span class="string">f'<span class="subst">&#123;H2&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">f'变量3下的知识贡献意愿转移概率'</span>)</span><br><span class="line">wx_b30 = []</span><br><span class="line">wx_b31 = []</span><br><span class="line">wx_b32 = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">    <span class="keyword">if</span> Y_X[i] == <span class="number">0</span>:</span><br><span class="line">        wx_b30.append(list_lr_x_w[num][<span class="number">0</span>][<span class="number">2</span>] * list_x[i][<span class="number">2</span>] + list_lr_x_b[num][<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">elif</span> Y_X[i] == <span class="number">1</span>:</span><br><span class="line">        wx_b31.append(list_lr_x_w[num][<span class="number">1</span>][<span class="number">2</span>] * list_x[i][<span class="number">2</span>] + list_lr_x_b[num][<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        wx_b32.append(list_lr_x_w[num][<span class="number">2</span>][<span class="number">2</span>] * list_x[i][<span class="number">2</span>] + list_lr_x_b[num][<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># fig = plt.figure(figsize=(10, 8))</span></span><br><span class="line"><span class="comment"># plt.plot(np.array(wx_b30), "bo", linewidth=1)</span></span><br><span class="line"><span class="comment"># plt.plot(np.array(wx_b32), "ro", linewidth=1)</span></span><br><span class="line"><span class="comment"># plt.plot(np.array(wx_b31), "ko", linewidth=1)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 状态2个数： len(wx_b0) = 2461</span></span><br><span class="line"><span class="comment"># 将其排序,   状态1中设置260个</span></span><br><span class="line"><span class="comment"># 状态2时的个数： 538,设置为80， 400， 58</span></span><br><span class="line"><span class="comment"># 状态3时的个数：109 ， 在2中设置35个</span></span><br><span class="line"></span><br><span class="line">H3 = [[(len(wx_b30) - <span class="number">361</span>)/len(wx_b30), <span class="number">361</span>/len(wx_b30), <span class="number">0</span>],</span><br><span class="line">      [(len(wx_b31) - <span class="number">501</span>)/len(wx_b31), <span class="number">451</span>/len(wx_b31), <span class="number">50</span>/len(wx_b31)],</span><br><span class="line">      [<span class="number">0</span>, <span class="number">12</span>/len(wx_b32), <span class="number">1</span><span class="number">-12</span>/(len(wx_b32))]]</span><br><span class="line">print(<span class="string">f'<span class="subst">&#123;H3&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">f'变量4下的知识贡献意愿转移概率'</span>)</span><br><span class="line">wx_b40 = []</span><br><span class="line">wx_b41 = []</span><br><span class="line">wx_b42 = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">    <span class="keyword">if</span> Y_X[i] == <span class="number">0</span>:</span><br><span class="line">        wx_b40.append(list_lr_x_w[num][<span class="number">0</span>][<span class="number">3</span>] * list_x[i][<span class="number">3</span>] + list_lr_x_b[num][<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">elif</span> Y_X[i] == <span class="number">1</span>:</span><br><span class="line">        wx_b41.append(list_lr_x_w[num][<span class="number">1</span>][<span class="number">3</span>] * list_x[i][<span class="number">3</span>] + list_lr_x_b[num][<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        wx_b42.append(list_lr_x_w[num][<span class="number">2</span>][<span class="number">3</span>] * list_x[i][<span class="number">3</span>] + list_lr_x_b[num][<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># fig = plt.figure(figsize=(10, 8))</span></span><br><span class="line"><span class="comment"># plt.plot(np.array(wx_b40), "bo", linewidth=1)</span></span><br><span class="line"><span class="comment"># plt.plot(np.array(wx_b42), "ro", linewidth=1)</span></span><br><span class="line"><span class="comment"># plt.plot(np.array(wx_b41), "ko", linewidth=1)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 状态2个数： len(wx_b0) = 2461</span></span><br><span class="line"><span class="comment"># 将其排序,   状态1中设置260个</span></span><br><span class="line"><span class="comment"># 状态2时的个数： 538,设置为80， 400， 58</span></span><br><span class="line"><span class="comment"># 状态3时的个数：109 ， 在2中设置35个</span></span><br><span class="line"></span><br><span class="line">H4 = [[(len(wx_b40) - <span class="number">361</span>)/len(wx_b40), <span class="number">361</span>/len(wx_b40), <span class="number">0</span>],</span><br><span class="line">      [(len(wx_b41) - <span class="number">501</span>)/len(wx_b41), <span class="number">451</span>/len(wx_b41), <span class="number">50</span>/len(wx_b41)],</span><br><span class="line">      [<span class="number">0</span>, <span class="number">12</span>/len(wx_b42), <span class="number">1</span><span class="number">-12</span>/(len(wx_b42))]]</span><br><span class="line">print(<span class="string">f'<span class="subst">&#123;H4&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 全部数值下</span></span><br><span class="line">print(<span class="string">f'全部变量下的知识贡献意愿转移概率'</span>)</span><br><span class="line">wx_ba0 = []</span><br><span class="line">wx_ba1 = []</span><br><span class="line">wx_ba2 = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">    <span class="keyword">if</span> Y_X[i] == <span class="number">0</span>:</span><br><span class="line">        wx_ba0.append(list_lr_x_w[num][<span class="number">0</span>][<span class="number">0</span>] * list_x[i][<span class="number">0</span>] +</span><br><span class="line">                      list_lr_x_w[num][<span class="number">0</span>][<span class="number">1</span>] * list_x[i][<span class="number">1</span>] +</span><br><span class="line">                      list_lr_x_w[num][<span class="number">0</span>][<span class="number">2</span>] * list_x[i][<span class="number">2</span>] +</span><br><span class="line">                      list_lr_x_w[num][<span class="number">0</span>][<span class="number">3</span>] * list_x[i][<span class="number">3</span>] +</span><br><span class="line">                      list_lr_x_b[num][<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">elif</span> Y_X[i] == <span class="number">1</span>:</span><br><span class="line">        wx_ba1.append(list_lr_x_w[num][<span class="number">1</span>][<span class="number">0</span>] * list_x[i][<span class="number">0</span>] +</span><br><span class="line">                      list_lr_x_w[num][<span class="number">1</span>][<span class="number">1</span>] * list_x[i][<span class="number">1</span>] +</span><br><span class="line">                      list_lr_x_w[num][<span class="number">1</span>][<span class="number">2</span>] * list_x[i][<span class="number">2</span>] +</span><br><span class="line">                      list_lr_x_w[num][<span class="number">1</span>][<span class="number">3</span>] * list_x[i][<span class="number">3</span>] +</span><br><span class="line">                      list_lr_x_b[num][<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        wx_ba2.append(list_lr_x_w[num][<span class="number">2</span>][<span class="number">0</span>] * list_x[i][<span class="number">0</span>] +</span><br><span class="line">                      list_lr_x_w[num][<span class="number">2</span>][<span class="number">1</span>] * list_x[i][<span class="number">1</span>] +</span><br><span class="line">                      list_lr_x_w[num][<span class="number">2</span>][<span class="number">2</span>] * list_x[i][<span class="number">2</span>] +</span><br><span class="line">                      list_lr_x_w[num][<span class="number">2</span>][<span class="number">3</span>] * list_x[i][<span class="number">3</span>] +</span><br><span class="line">                      list_lr_x_b[num][<span class="number">2</span>])</span><br><span class="line"><span class="comment"># 进行排序</span></span><br><span class="line">wx_ba0.sort()</span><br><span class="line">wx_ba1.sort()</span><br><span class="line">wx_ba2.sort()</span><br><span class="line"><span class="comment"># 找到边界,意思就是找到相对应的u1,u2-1,u2-h,u-3</span></span><br><span class="line"><span class="comment"># 我是这样理解的，其实对应的就是x_b的系数，但是少了一个而已</span></span><br><span class="line">b = list_fix_x[num][<span class="number">0</span>][<span class="number">1</span>]/sum(list_fix_x[num][<span class="number">0</span>])</span><br><span class="line">x = len(wx_ba0) * b</span><br><span class="line"><span class="comment"># 即根据前面那个</span></span><br><span class="line"><span class="comment"># 取倒数第16个作为边界吧</span></span><br><span class="line">u1 = wx_b0[<span class="number">-16</span>]</span><br><span class="line">b1 = list_fix_x[num][<span class="number">1</span>][<span class="number">0</span>]/sum(list_fix_x[num][<span class="number">1</span>])</span><br><span class="line">x1 = len(wx_ba1) * b1</span><br><span class="line">u2_1 = wx_ba1[int(x1)]</span><br><span class="line">b2 = list_fix_x[num][<span class="number">1</span>][<span class="number">2</span>]/sum(list_fix_x[num][<span class="number">1</span>])</span><br><span class="line">x2 = len(wx_ba1) * b2</span><br><span class="line">u2_h = wx_ba1[-int(x2)]</span><br><span class="line"></span><br><span class="line">b3 = list_fix_x[num][<span class="number">2</span>][<span class="number">2</span>]/sum(list_fix_x[num][<span class="number">2</span>])</span><br><span class="line">x4 = len(wx_b2) * b3</span><br><span class="line">u3 = wx_ba2[-int(x4)]</span><br><span class="line">print(<span class="string">f'u1=<span class="subst">&#123;u1&#125;</span>,u2_1=<span class="subst">&#123;u2_1&#125;</span>,u2_h=<span class="subst">&#123;u2_h&#125;</span>, u3=<span class="subst">&#123;u3&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">f'状态转移概率矩阵的系数为：<span class="subst">&#123;list_lr_x_w[list_acr_x.index(max(list_acr_x))]&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">f'观察状态概率转移矩阵的系数为：<span class="subst">&#123;list_lr_z_w[list_acr_x.index(max(list_acr_x))]&#125;</span>'</span>)</span><br><span class="line">print(<span class="string">f'观察状态概率转移矩阵的截距为：<span class="subst">&#123;list_lr_z_b[list_acr_x.index(max(list_acr_x))]&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">f'所有参数和矩阵表格如上'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">百次循环后，最高准确率<span class="number">0.917470525187567</span></span><br><span class="line">最大准确率对应的序号：<span class="number">29</span></span><br><span class="line"></span><br><span class="line">百次循环后，似然值为<span class="number">-1355.7570132278736</span></span><br><span class="line">对应的BIC为<span class="number">-1488.0315887845702</span></span><br><span class="line">在<span class="number">4</span>个变量下的状态转移概率矩阵：[[<span class="number">0.9868073878627969</span>, <span class="number">0.013192612137203167</span>, <span class="number">0.0</span>], [<span class="number">0.40816326530612246</span>, <span class="number">0.5782312925170068</span>, <span class="number">0.013605442176870748</span>], [<span class="number">0.0</span>, <span class="number">0.17857142857142858</span>, <span class="number">0.8214285714285714</span>]]</span><br><span class="line">--------------------</span><br><span class="line">参数估计</span><br><span class="line">状态转移概率矩阵的系数为：[[<span class="number">-0.07814258</span> <span class="number">-0.08035225</span> <span class="number">-0.03518065</span> <span class="number">-8.30153077</span>]</span><br><span class="line"> [<span class="number">-0.07992528</span>  <span class="number">0.07019997</span> <span class="number">-0.02918073</span>  <span class="number">2.04945495</span>]</span><br><span class="line"> [ <span class="number">0.15806786</span>  <span class="number">0.01015228</span>  <span class="number">0.06436137</span>  <span class="number">6.25207582</span>]]</span><br><span class="line">状态转移概率矩阵的偏差为：[ <span class="number">1.46433444</span>  <span class="number">1.09085289</span> <span class="number">-2.55518733</span>]</span><br><span class="line">观察状态概率转移矩阵的系数为：[[ <span class="number">0.44462513</span>  <span class="number">0.22701876</span>]</span><br><span class="line"> [ <span class="number">0.48690629</span> <span class="number">-0.33289007</span>]</span><br><span class="line"> [<span class="number">-0.93153142</span>  <span class="number">0.10587131</span>]]</span><br><span class="line">观察状态概率转移矩阵的偏差为：[ <span class="number">2.26772789</span> <span class="number">-0.16557564</span> <span class="number">-2.10215226</span>]</span><br><span class="line">变量<span class="number">1</span>下的知识贡献意愿转移概率</span><br><span class="line">[[<span class="number">0.8943518894758228</span>, <span class="number">0.10564811052417716</span>, <span class="number">0</span>], [<span class="number">0.14869888475836432</span>, <span class="number">0.7434944237918215</span>, <span class="number">0.10780669144981413</span>], [<span class="number">0</span>, <span class="number">0.13761467889908258</span>, <span class="number">0.8623853211009174</span>]]</span><br><span class="line">变量<span class="number">2</span>下的知识贡献意愿转移概率</span><br><span class="line">[[<span class="number">0.8537180008126778</span>, <span class="number">0.14628199918732224</span>, <span class="number">0</span>], [<span class="number">0.07063197026022305</span>, <span class="number">0.8364312267657993</span>, <span class="number">0.09293680297397769</span>], [<span class="number">0</span>, <span class="number">0.14678899082568808</span>, <span class="number">0.8532110091743119</span>]]</span><br><span class="line">变量<span class="number">3</span>下的知识贡献意愿转移概率</span><br><span class="line">[[<span class="number">0.8533116619260463</span>, <span class="number">0.14668833807395368</span>, <span class="number">0</span>], [<span class="number">0.0687732342007435</span>, <span class="number">0.8382899628252788</span>, <span class="number">0.09293680297397769</span>], [<span class="number">0</span>, <span class="number">0.11009174311926606</span>, <span class="number">0.8899082568807339</span>]]</span><br><span class="line">变量<span class="number">4</span>下的知识贡献意愿转移概率</span><br><span class="line">[[<span class="number">0.8533116619260463</span>, <span class="number">0.14668833807395368</span>, <span class="number">0</span>], [<span class="number">0.0687732342007435</span>, <span class="number">0.8382899628252788</span>, <span class="number">0.09293680297397769</span>], [<span class="number">0</span>, <span class="number">0.11009174311926606</span>, <span class="number">0.8899082568807339</span>]]</span><br><span class="line">全部变量下的知识贡献意愿转移概率</span><br><span class="line">u1=<span class="number">1.4980410992089837</span>,u2_1=<span class="number">0.8129063006054411</span>,u2_h=<span class="number">2.8303668243942806</span>, u3=<span class="number">2.68524912411076</span></span><br><span class="line">状态转移概率矩阵的系数为：[[<span class="number">-0.07814258</span> <span class="number">-0.08035225</span> <span class="number">-0.03518065</span> <span class="number">-8.30153077</span>]</span><br><span class="line"> [<span class="number">-0.07992528</span>  <span class="number">0.07019997</span> <span class="number">-0.02918073</span>  <span class="number">2.04945495</span>]</span><br><span class="line"> [ <span class="number">0.15806786</span>  <span class="number">0.01015228</span>  <span class="number">0.06436137</span>  <span class="number">6.25207582</span>]]</span><br><span class="line">观察状态概率转移矩阵的系数为：[[ <span class="number">0.44462513</span>  <span class="number">0.22701876</span>]</span><br><span class="line"> [ <span class="number">0.48690629</span> <span class="number">-0.33289007</span>]</span><br><span class="line"> [<span class="number">-0.93153142</span>  <span class="number">0.10587131</span>]]</span><br><span class="line">观察状态概率转移矩阵的截距为：[ <span class="number">2.26772789</span> <span class="number">-0.16557564</span> <span class="number">-2.10215226</span>]</span><br><span class="line">所有参数和矩阵表格如上</span><br></pre></td></tr></table></figure><p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1594399298975&di=10b635fa56f834e6a4afb58286e8c847&imgtype=0&src=http%3A%2F%2Fi0.hdslb.com%2Fbfs%2Farticle%2Fb6d8d812ef63e040bd944da29effa95001176a20.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;HMM之数据的处理&quot;&gt;&lt;a href=&quot;#HMM之数据的处理&quot; class=&quot;headerlink&quot; title=&quot;HMM之数据的处理&quot;&gt;&lt;/a&gt;HMM之数据的处理&lt;/h1&gt;&lt;h2 id=&quot;查看数据&quot;&gt;&lt;a href=&quot;#查看数据&quot; class=&quot;headerli
      
    
    </summary>
    
    
      <category term="work" scheme="https://esyyes.github.io/categories/work/"/>
    
    
      <category term="work" scheme="https://esyyes.github.io/tags/work/"/>
    
  </entry>
  
  <entry>
    <title>状态为3时的设定</title>
    <link href="https://esyyes.github.io/2020/07/08/HMM/%E7%8A%B6%E6%80%81%E4%B8%BA3%E6%97%B6%E7%9A%84%E8%AE%BE%E5%AE%9A/"/>
    <id>https://esyyes.github.io/2020/07/08/HMM/%E7%8A%B6%E6%80%81%E4%B8%BA3%E6%97%B6%E7%9A%84%E8%AE%BE%E5%AE%9A/</id>
    <published>2020-07-08T06:45:11.000Z</published>
    <updated>2020-07-08T06:45:11.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="状态为3是的B值设定"><a href="#状态为3是的B值设定" class="headerlink" title="状态为3是的B值设定"></a>状态为3是的B值设定</h1><p>划分为状态3# 状态1：小于平均值的# 状态2：小于标准差# 状态3：大于标准差</p><p>将里面的数据直接划分为3个状态，按照3个状态的区间范围，去设定序列的状态值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/7/8</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line">data = pd.read_excel(<span class="string">'data1'</span> + <span class="string">'.xlsx'</span>)</span><br><span class="line">data.fillna(<span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">list_data = np.array(data).tolist()</span><br><span class="line">X = pd.get_dummies(data.iloc[<span class="number">0</span>:len(data), <span class="number">3</span>:<span class="number">7</span>])</span><br><span class="line"></span><br><span class="line">list_y1 = [int(list_data[i][<span class="number">2</span>]) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data))]</span><br><span class="line">y1_mean = np.array(list_y1).mean()</span><br><span class="line">y1_std = np.array(list_y1).std()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分为状态3</span></span><br><span class="line"><span class="comment"># 状态1：小于平均值的</span></span><br><span class="line"><span class="comment"># 状态2：小于标准差</span></span><br><span class="line"><span class="comment"># 状态3：大于标准差</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 序列中出现0,1,2阶段的数目</span></span><br><span class="line">Y_X = []</span><br><span class="line">num1 = <span class="number">0</span></span><br><span class="line">num2 = <span class="number">0</span></span><br><span class="line">num3 = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">    <span class="keyword">if</span> list_data[i][<span class="number">2</span>] &lt; <span class="number">1</span>:</span><br><span class="line">        Y_X.append(<span class="number">0</span>)</span><br><span class="line">        num1 += <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="number">1</span> &lt;= list_data[i][<span class="number">2</span>] &lt; y1_std:</span><br><span class="line">        Y_X.append(<span class="number">1</span>)</span><br><span class="line">        num2 += <span class="number">2</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        Y_X.append(<span class="number">2</span>)</span><br><span class="line">        num3 += <span class="number">1</span></span><br><span class="line">print(<span class="string">f'阶段1的个数：<span class="subst">&#123;num1&#125;</span>,阶段2的个数：<span class="subst">&#123;num2&#125;</span>,阶段3的个数：<span class="subst">&#123;num3&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将14个时期取平均值</span></span><br><span class="line">list_z_y = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(int(len(data)/<span class="number">14</span>)):</span><br><span class="line">    y1 = []</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        <span class="keyword">if</span> <span class="number">14</span> * i &lt;= j &lt; <span class="number">14</span> * (i + <span class="number">1</span>):</span><br><span class="line">            y1.append(list_data[j][<span class="number">2</span>])</span><br><span class="line">    list_z_y.append(np.array(y1).mean())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断序列阶段出现出现的次数</span></span><br><span class="line">num1_z = <span class="number">0</span></span><br><span class="line">num2_z = <span class="number">0</span></span><br><span class="line">num3_z = <span class="number">0</span></span><br><span class="line">Y_Z = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(list_z_y)):</span><br><span class="line">    <span class="keyword">if</span> list_z_y[i] &lt; <span class="number">1</span>:</span><br><span class="line">        Y_Z.append(<span class="number">0</span>)</span><br><span class="line">        num1_z += <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="number">1</span> &lt;= list_z_y[i] &lt; y1_std:</span><br><span class="line">        Y_Z.append(<span class="number">1</span>)</span><br><span class="line">        num2_z += <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        Y_Z.append(<span class="number">2</span>)</span><br><span class="line">        num3_z += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">f'阶段1的序列个数：<span class="subst">&#123;num1_z&#125;</span>,阶段2的序列个数：<span class="subst">&#123;num2_z&#125;</span>, 阶段3的序列个数：<span class="subst">&#123;num3_z&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将其划分为14个一组一个序列</span></span><br><span class="line">Y = []</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(int(len(data)/<span class="number">14</span>)):</span><br><span class="line">    x1 = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        <span class="keyword">if</span> <span class="number">14</span> * j &lt;= i &lt; <span class="number">14</span> * (j + <span class="number">1</span>):</span><br><span class="line">            x1.append(Y_X[i])</span><br><span class="line">    Y.append(x1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断阶段1中出现012的次数</span></span><br><span class="line">num_j1 = <span class="number">0</span></span><br><span class="line">num_j2 = <span class="number">0</span></span><br><span class="line">num_j3 = <span class="number">0</span></span><br><span class="line">num_k1 = <span class="number">0</span></span><br><span class="line">num_k2 = <span class="number">0</span></span><br><span class="line">num_k3 = <span class="number">0</span></span><br><span class="line">num_b1 = <span class="number">0</span></span><br><span class="line">num_b2 = <span class="number">0</span></span><br><span class="line">num_b3 = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(Y_Z)):</span><br><span class="line">    <span class="keyword">if</span> Y_Z[i] == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">14</span>):</span><br><span class="line">            <span class="keyword">if</span> Y[i][j] == <span class="number">0</span>:</span><br><span class="line">                num_j1 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> Y[i][j] == <span class="number">1</span>:</span><br><span class="line">                num_j2 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                num_j3 += <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> Y_Z[i] == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">14</span>):</span><br><span class="line">            <span class="keyword">if</span> Y[i][k] == <span class="number">0</span>:</span><br><span class="line">                num_k1 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> Y[i][k] == <span class="number">1</span>:</span><br><span class="line">                num_k2 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                num_k3 += <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> Y_Z[i] == <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> range(<span class="number">14</span>):</span><br><span class="line">            <span class="keyword">if</span> Y[i][b] == <span class="number">0</span>:</span><br><span class="line">                num_b1 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> Y[i][b] == <span class="number">1</span>:</span><br><span class="line">                num_b2 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                num_b3 += <span class="number">1</span></span><br><span class="line">print(<span class="string">f'阶段1中状态1的个数  <span class="subst">&#123;num_j1&#125;</span>，状态2的个数<span class="subst">&#123;num_j2&#125;</span>，状态2的个数<span class="subst">&#123;num_j3&#125;</span>'</span>)</span><br><span class="line">print(<span class="string">f'阶段2中状态1的个数  <span class="subst">&#123;num_k1&#125;</span>，  状态2的个数  <span class="subst">&#123;num_k2&#125;</span>，状态2的个数<span class="subst">&#123;num_k3&#125;</span>'</span>)</span><br><span class="line">print(<span class="string">f'阶段3中状态1的个数  <span class="subst">&#123;num_b1&#125;</span>，  状态2的个数  <span class="subst">&#123;num_b2&#125;</span>，状态2的个数<span class="subst">&#123;num_b3&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line">B = [[num_j1/num1_z/<span class="number">14</span>, num_j2/num1_z/<span class="number">14</span>, num_j3/num1_z/<span class="number">14</span>],</span><br><span class="line">     [num_k1/num2_z/<span class="number">14</span>, num_k2/num2_z/<span class="number">14</span>, num_k3/num2_z/<span class="number">14</span>],</span><br><span class="line">     [num_b1/num3_z/<span class="number">14</span>, num_b2/num3_z/<span class="number">14</span>, num_b3/num3_z/<span class="number">14</span>]]</span><br><span class="line">print(<span class="string">f'在阈值线为平均值下的<span class="subst">&#123;B&#125;</span>'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">阶段<span class="number">1</span>的个数：<span class="number">2461</span>,阶段<span class="number">2</span>的个数：<span class="number">1076</span>,阶段<span class="number">3</span>的个数：<span class="number">109</span></span><br><span class="line">阶段<span class="number">1</span>的序列个数：<span class="number">197</span>,阶段<span class="number">2</span>的序列个数：<span class="number">18</span>, 阶段<span class="number">3</span>的序列个数：<span class="number">7</span></span><br><span class="line">阶段<span class="number">1</span>中状态<span class="number">1</span>的个数  <span class="number">2418</span>，状态<span class="number">2</span>的个数<span class="number">340</span>，状态<span class="number">2</span>的个数<span class="number">0</span></span><br><span class="line">阶段<span class="number">2</span>中状态<span class="number">1</span>的个数  <span class="number">43</span>，  状态<span class="number">2</span>的个数  <span class="number">189</span>，状态<span class="number">2</span>的个数<span class="number">20</span></span><br><span class="line">阶段<span class="number">3</span>中状态<span class="number">1</span>的个数  <span class="number">0</span>，  状态<span class="number">2</span>的个数  <span class="number">9</span>，状态<span class="number">2</span>的个数<span class="number">89</span></span><br><span class="line">在阈值线为平均值下的[[<span class="number">0.8767222625090645</span>, <span class="number">0.12327773749093547</span>, <span class="number">0.0</span>], [<span class="number">0.17063492063492064</span>, <span class="number">0.75</span>, <span class="number">0.07936507936507937</span>], [<span class="number">0.0</span>, <span class="number">0.09183673469387756</span>, <span class="number">0.9081632653061223</span>]]</span><br></pre></td></tr></table></figure><p>将数据设定为4状态时</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/7/8</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line">data = pd.read_excel(<span class="string">'data1'</span> + <span class="string">'.xlsx'</span>)</span><br><span class="line">data.fillna(<span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">list_data = np.array(data).tolist()</span><br><span class="line">X = pd.get_dummies(data.iloc[<span class="number">0</span>:len(data), <span class="number">3</span>:<span class="number">7</span>])</span><br><span class="line"></span><br><span class="line">list_y1 = [int(list_data[i][<span class="number">2</span>]) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data))]</span><br><span class="line">y1_mean = np.array(list_y1).mean()</span><br><span class="line">y1_std = np.array(list_y1).std()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分为状态4</span></span><br><span class="line"><span class="comment"># # 状态1：小于平均值的</span></span><br><span class="line"><span class="comment"># # 状态2：小于标准差</span></span><br><span class="line"><span class="comment"># # 状态3：小于方差的</span></span><br><span class="line"><span class="comment"># # 状态4：大于方差的</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 序列中出现0,1,2阶段的数目</span></span><br><span class="line">Y_X = []</span><br><span class="line">num1 = <span class="number">0</span></span><br><span class="line">num2 = <span class="number">0</span></span><br><span class="line">num3 = <span class="number">0</span></span><br><span class="line">num4 = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">    <span class="keyword">if</span> list_data[i][<span class="number">2</span>] &lt; <span class="number">1</span>:</span><br><span class="line">        Y_X.append(<span class="number">0</span>)</span><br><span class="line">        num1 += <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="number">1</span> &lt;= list_data[i][<span class="number">2</span>] &lt; y1_std:</span><br><span class="line">        Y_X.append(<span class="number">1</span>)</span><br><span class="line">        num2 += <span class="number">2</span></span><br><span class="line">    <span class="keyword">elif</span> y1_std &lt;= list_data[i][<span class="number">2</span>] &lt; y1_std*y1_std:</span><br><span class="line">        Y_X.append(<span class="number">2</span>)</span><br><span class="line">        num3 += <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        Y_X.append(<span class="number">3</span>)</span><br><span class="line">        num4 += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">f'阶段1的个数：<span class="subst">&#123;num1&#125;</span>,阶段2的个数：<span class="subst">&#123;num2&#125;</span>, 阶段3的个数：<span class="subst">&#123;num3&#125;</span>, 阶段4的个数：<span class="subst">&#123;num4&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将14个时期取平均值</span></span><br><span class="line">list_z_y = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(int(len(data)/<span class="number">14</span>)):</span><br><span class="line">    y1 = []</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        <span class="keyword">if</span> <span class="number">14</span> * i &lt;= j &lt; <span class="number">14</span> * (i + <span class="number">1</span>):</span><br><span class="line">            y1.append(list_data[j][<span class="number">2</span>])</span><br><span class="line">    list_z_y.append(np.array(y1).mean())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断序列阶段出现出现的次数</span></span><br><span class="line">num1_z = <span class="number">0</span></span><br><span class="line">num2_z = <span class="number">0</span></span><br><span class="line">num3_z = <span class="number">0</span></span><br><span class="line">num4_z = <span class="number">0</span></span><br><span class="line">Y_Z = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(list_z_y)):</span><br><span class="line">    <span class="keyword">if</span> list_z_y[i] &lt; <span class="number">1</span>:</span><br><span class="line">        Y_Z.append(<span class="number">0</span>)</span><br><span class="line">        num1_z += <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="number">1</span> &lt;= list_z_y[i] &lt; y1_std:</span><br><span class="line">        Y_Z.append(<span class="number">1</span>)</span><br><span class="line">        num2_z += <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> y1_std &lt;= list_z_y[i] &lt; y1_std * y1_std:</span><br><span class="line">        Y_Z.append(<span class="number">2</span>)</span><br><span class="line">        num3_z += <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        Y_Z.append(<span class="number">3</span>)</span><br><span class="line">        num4_z += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">f'阶段1的序列个数：<span class="subst">&#123;num1_z&#125;</span>,阶段2的序列个数：<span class="subst">&#123;num2_z&#125;</span>, 阶段3的序列个数：<span class="subst">&#123;num3_z&#125;</span>, 阶段4的序列个数：<span class="subst">&#123;num4_z&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将其划分为14个一组一个序列</span></span><br><span class="line">Y = []</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(int(len(data)/<span class="number">14</span>)):</span><br><span class="line">    x1 = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        <span class="keyword">if</span> <span class="number">14</span> * j &lt;= i &lt; <span class="number">14</span> * (j + <span class="number">1</span>):</span><br><span class="line">            x1.append(Y_X[i])</span><br><span class="line">    Y.append(x1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断阶段1中出现012的次数</span></span><br><span class="line">num_j1 = <span class="number">0</span></span><br><span class="line">num_j2 = <span class="number">0</span></span><br><span class="line">num_j3 = <span class="number">0</span></span><br><span class="line">num_j4 = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">num_k1 = <span class="number">0</span></span><br><span class="line">num_k2 = <span class="number">0</span></span><br><span class="line">num_k3 = <span class="number">0</span></span><br><span class="line">num_k4 = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">num_b1 = <span class="number">0</span></span><br><span class="line">num_b2 = <span class="number">0</span></span><br><span class="line">num_b3 = <span class="number">0</span></span><br><span class="line">num_b4 = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">num_h1 = <span class="number">0</span></span><br><span class="line">num_h2 = <span class="number">0</span></span><br><span class="line">num_h3 = <span class="number">0</span></span><br><span class="line">num_h4 = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(Y_Z)):</span><br><span class="line">    <span class="keyword">if</span> Y_Z[i] == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">14</span>):</span><br><span class="line">            <span class="keyword">if</span> Y[i][j] == <span class="number">0</span>:</span><br><span class="line">                num_j1 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> Y[i][j] == <span class="number">1</span>:</span><br><span class="line">                num_j2 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> Y[i][j] == <span class="number">2</span>:</span><br><span class="line">                num_j3 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                num_j4 += <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> Y_Z[i] == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">14</span>):</span><br><span class="line">            <span class="keyword">if</span> Y[i][k] == <span class="number">0</span>:</span><br><span class="line">                num_k1 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> Y[i][k] == <span class="number">1</span>:</span><br><span class="line">                num_k2 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> Y[i][k] == <span class="number">2</span>:</span><br><span class="line">                num_k3 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                num_k4 += <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> Y_Z[i] == <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> range(<span class="number">14</span>):</span><br><span class="line">            <span class="keyword">if</span> Y[i][b] == <span class="number">0</span>:</span><br><span class="line">                num_b1 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> Y[i][b] == <span class="number">1</span>:</span><br><span class="line">                num_b2 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> Y[i][b] == <span class="number">2</span>:</span><br><span class="line">                num_b3 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                num_b4 += <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> Y_Z[i] == <span class="number">3</span>:</span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> range(<span class="number">14</span>):</span><br><span class="line">            <span class="keyword">if</span> Y[i][h] == <span class="number">0</span>:</span><br><span class="line">                num_h1 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> Y[i][h] == <span class="number">1</span>:</span><br><span class="line">                num_h2 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> Y[i][h] == <span class="number">2</span>:</span><br><span class="line">                num_h3 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                num_h4 += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">f'阶段1中状态1的个数  <span class="subst">&#123;num_j1&#125;</span>，状态2的个数<span class="subst">&#123;num_j2&#125;</span>，状态3的个数<span class="subst">&#123;num_j3&#125;</span>, 状态4的个数<span class="subst">&#123;num_j4&#125;</span>'</span>)</span><br><span class="line">print(<span class="string">f'阶段2中状态1的个数  <span class="subst">&#123;num_k1&#125;</span>，状态2的个数  <span class="subst">&#123;num_k2&#125;</span>，状态3的个数<span class="subst">&#123;num_k3&#125;</span>, 状态4的个数<span class="subst">&#123;num_k4&#125;</span>'</span>)</span><br><span class="line">print(<span class="string">f'阶段3中状态1的个数  <span class="subst">&#123;num_b1&#125;</span>，状态2的个数  <span class="subst">&#123;num_b2&#125;</span>，状态3的个数<span class="subst">&#123;num_b3&#125;</span>, 状态4的个数<span class="subst">&#123;num_b4&#125;</span>'</span>)</span><br><span class="line">print(<span class="string">f'阶段4中状态1的个数  <span class="subst">&#123;num_h1&#125;</span>，状态2的个数  <span class="subst">&#123;num_h2&#125;</span>，状态3的个数<span class="subst">&#123;num_h3&#125;</span>, 状态4的个数<span class="subst">&#123;num_h4&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line">B = [[num_j1/num1_z/<span class="number">14</span>, num_j2/num1_z/<span class="number">14</span>, num_j3/num1_z/<span class="number">14</span>, num_j4/num1_z/<span class="number">14</span>,],</span><br><span class="line">     [num_k1/num2_z/<span class="number">14</span>, num_k2/num2_z/<span class="number">14</span>, num_k3/num2_z/<span class="number">14</span>, num_k4/num2_z/<span class="number">14</span>],</span><br><span class="line">     [num_b1/num3_z/<span class="number">14</span>, num_b2/num3_z/<span class="number">14</span>, num_b3/num3_z/<span class="number">14</span>, num_b4/num3_z/<span class="number">14</span>],</span><br><span class="line">     [num_h1/num4_z/<span class="number">14</span>, num_h2/num4_z/<span class="number">14</span>, num_h3/num4_z/<span class="number">14</span>, num_h4/num4_z/<span class="number">14</span>]</span><br><span class="line">     ]</span><br><span class="line">print(<span class="string">f'在阈值线为平均值下的<span class="subst">&#123;B&#125;</span>'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">阶段<span class="number">1</span>的个数：<span class="number">2461</span>,阶段<span class="number">2</span>的个数：<span class="number">1076</span>, 阶段<span class="number">3</span>的个数：<span class="number">94</span>, 阶段<span class="number">4</span>的个数：<span class="number">15</span></span><br><span class="line">阶段<span class="number">1</span>的序列个数：<span class="number">197</span>,阶段<span class="number">2</span>的序列个数：<span class="number">18</span>, 阶段<span class="number">3</span>的序列个数：<span class="number">6</span>, 阶段<span class="number">4</span>的序列个数：<span class="number">1</span></span><br><span class="line">阶段<span class="number">1</span>中状态<span class="number">1</span>的个数  <span class="number">2418</span>，状态<span class="number">2</span>的个数<span class="number">340</span>，状态<span class="number">3</span>的个数<span class="number">0</span>, 状态<span class="number">4</span>的个数<span class="number">0</span></span><br><span class="line">阶段<span class="number">2</span>中状态<span class="number">1</span>的个数  <span class="number">43</span>，状态<span class="number">2</span>的个数  <span class="number">189</span>，状态<span class="number">3</span>的个数<span class="number">20</span>, 状态<span class="number">4</span>的个数<span class="number">0</span></span><br><span class="line">阶段<span class="number">3</span>中状态<span class="number">1</span>的个数  <span class="number">0</span>，状态<span class="number">2</span>的个数  <span class="number">9</span>，状态<span class="number">3</span>的个数<span class="number">74</span>, 状态<span class="number">4</span>的个数<span class="number">1</span></span><br><span class="line">阶段<span class="number">4</span>中状态<span class="number">1</span>的个数  <span class="number">0</span>，状态<span class="number">2</span>的个数  <span class="number">0</span>，状态<span class="number">3</span>的个数<span class="number">0</span>, 状态<span class="number">4</span>的个数<span class="number">14</span></span><br><span class="line">在阈值线为平均值下的[[<span class="number">0.8767222625090645</span>, <span class="number">0.12327773749093547</span>, <span class="number">0.0</span>, <span class="number">0.0</span>], [<span class="number">0.17063492063492064</span>, <span class="number">0.75</span>, <span class="number">0.07936507936507937</span>, <span class="number">0.0</span>], [<span class="number">0.0</span>, <span class="number">0.10714285714285714</span>, <span class="number">0.880952380952381</span>, <span class="number">0.011904761904761904</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>]]</span><br></pre></td></tr></table></figure><p>因此现在B2：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">B_2 = [[<span class="number">0.78535170413343</span>, <span class="number">0.21464829586656997</span>],</span><br><span class="line">       [<span class="number">0.8428571428571429</span>, <span class="number">0.15714285714285714</span>]]</span><br><span class="line">B_3 = [[<span class="number">0.8767222625090645</span>, <span class="number">0.12327773749093547</span>, <span class="number">0.0</span>],</span><br><span class="line">       [<span class="number">0.17063492063492064</span>, <span class="number">0.75</span>, <span class="number">0.07936507936507937</span>],</span><br><span class="line">       [<span class="number">0.0</span>, <span class="number">0.09183673469387756</span>, <span class="number">0.9081632653061223</span>]]</span><br><span class="line">B_4 = [[<span class="number">0.8767222625090645</span>, <span class="number">0.12327773749093547</span>, <span class="number">0.0</span>, <span class="number">0.0</span>],</span><br><span class="line">       [<span class="number">0.17063492063492064</span>, <span class="number">0.75</span>, <span class="number">0.07936507936507937</span>, <span class="number">0.0</span>],</span><br><span class="line">       [<span class="number">0.0</span>, <span class="number">0.10714285714285714</span>, <span class="number">0.880952380952381</span>, <span class="number">0.011904761904761904</span>],</span><br><span class="line">       [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>]]</span><br></pre></td></tr></table></figure><p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1594262532884&di=531d0fbc2e24db968ffac8fbc73b3d42&imgtype=0&src=http%3A%2F%2Ft7.baidu.com%2Fit%2Fu%3D784355040%2C1080860592%26fm%3D193" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;状态为3是的B值设定&quot;&gt;&lt;a href=&quot;#状态为3是的B值设定&quot; class=&quot;headerlink&quot; title=&quot;状态为3是的B值设定&quot;&gt;&lt;/a&gt;状态为3是的B值设定&lt;/h1&gt;&lt;p&gt;划分为状态3# 状态1：小于平均值的# 状态2：小于标准差# 状态3：大于标
      
    
    </summary>
    
    
      <category term="work" scheme="https://esyyes.github.io/categories/work/"/>
    
    
      <category term="work" scheme="https://esyyes.github.io/tags/work/"/>
    
  </entry>
  
  <entry>
    <title>HMM中的B值确定</title>
    <link href="https://esyyes.github.io/2020/07/08/HMM/HMM%E4%B8%AD%E7%9A%84B%E5%80%BC%E7%A1%AE%E5%AE%9A/"/>
    <id>https://esyyes.github.io/2020/07/08/HMM/HMM%E4%B8%AD%E7%9A%84B%E5%80%BC%E7%A1%AE%E5%AE%9A/</id>
    <published>2020-07-08T06:12:45.000Z</published>
    <updated>2020-07-08T06:12:45.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HMM中的B值确定"><a href="#HMM中的B值确定" class="headerlink" title="HMM中的B值确定"></a>HMM中的B值确定</h1><p>1．隐马尔可夫模型是关于时序的概率模型，描述由一个隐藏的马尔可夫链随机生成不可观测的状态的序列，再由各个状态随机生成一个观测而产生观测的序列的过程。</p><p>隐马尔可夫模型由初始状态概率向$\pi$、状态转移概率矩阵$A$和观测概率矩阵$B$决定。因此，隐马尔可夫模型可以写成$\lambda=(A, B, \pi)$。</p><p>隐马尔可夫模型是一个生成模型，表示状态序列和观测序列的联合分布，但是状态序列是隐藏的，不可观测的。</p><p>隐马尔可夫模型可以用于标注，这时状态对应着标记。标注问题是给定观测序列预测其对应的标记序列。</p><p>2．概率计算问题。给定模型$\lambda=(A, B, \pi)$和观测序列$O＝(o_1，o_2,…,o_T)$，计算在模型$\lambda$下观测序列$O$出现的概率$P(O|\lambda)$。前向-后向算法是通过递推地计算前向-后向概率可以高效地进行隐马尔可夫模型的概率计算。</p><p>3．学习问题。已知观测序列$O＝(o_1，o_2,…,o_T)$，估计模型$\lambda=(A, B, \pi)$参数，使得在该模型下观测序列概率$P(O|\lambda)$最大。即用极大似然估计的方法估计参数。Baum-Welch算法，也就是EM算法可以高效地对隐马尔可夫模型进行训练。它是一种非监督学习算法。</p><p>4．预测问题。已知模型$\lambda=(A, B, \pi)$和观测序列$O＝(o_1，o_2,…,o_T)$，求对给定观测序列条件概率$P(I|O)$最大的状态序列$I＝(i_1，i_2,…,i_T)$。维特比算法应用动态规划高效地求解最优路径，即概率最大的状态序列。</p><p>在本次实验中，HMM模型，主要确定了QVAOPI，而直接用逻辑回归模型，进行建模运算时，B值的状态概率会出现100这种情况，导致HMM的似然函数的概率不会改变</p><p>array([[846,   0,   0],<br>       [ 60,   0,   0],<br>       [ 27,   0,   0]], dtype=int64)</p><p>参考</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HiddenMarkov</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, Q, V, A, B, O, PI)</span>:</span>  <span class="comment"># 使用前向算法</span></span><br><span class="line">        N = len(Q)  <span class="comment">#可能存在的状态数量</span></span><br><span class="line">        M = len(O)  <span class="comment"># 观测序列的大小</span></span><br><span class="line">        alphas = np.zeros((N, M))  <span class="comment"># alpha值</span></span><br><span class="line">        T = M  <span class="comment"># 有几个时刻，有几个观测序列，就有几个时刻</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(T):  <span class="comment"># 遍历每一时刻，算出alpha值</span></span><br><span class="line">            indexOfO = V.index(O[t])  <span class="comment"># 找出序列对应的索引</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">                <span class="keyword">if</span> t == <span class="number">0</span>:  <span class="comment"># 计算初值</span></span><br><span class="line">                    alphas[i][t] = PI[t][i] * B[i][indexOfO]  <span class="comment"># P176（10.15）</span></span><br><span class="line">                    print(</span><br><span class="line">                        <span class="string">'alpha1(%d)=p%db%db(o1)=%f'</span> % (i, i, i, alphas[i][t]))</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    alphas[i][t] = np.dot(</span><br><span class="line">                        [alpha[t - <span class="number">1</span>] <span class="keyword">for</span> alpha <span class="keyword">in</span> alphas],</span><br><span class="line">                        [a[i] <span class="keyword">for</span> a <span class="keyword">in</span> A]) * B[i][indexOfO]  <span class="comment"># 对应P176（10.16）</span></span><br><span class="line">                    print(<span class="string">'alpha%d(%d)=[sigma alpha%d(i)ai%d]b%d(o%d)=%f'</span> %</span><br><span class="line">                          (t, i, t - <span class="number">1</span>, i, i, t, alphas[i][t]))</span><br><span class="line">                    <span class="comment"># print(alphas)</span></span><br><span class="line">        P = np.sum([alpha[M - <span class="number">1</span>] <span class="keyword">for</span> alpha <span class="keyword">in</span> alphas])  <span class="comment"># P176(10.17)</span></span><br><span class="line">        <span class="comment"># alpha11 = pi[0][0] * B[0][0]    #代表a1(1)</span></span><br><span class="line">        <span class="comment"># alpha12 = pi[0][1] * B[1][0]    #代表a1(2)</span></span><br><span class="line">        <span class="comment"># alpha13 = pi[0][2] * B[2][0]    #代表a1(3)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self, Q, V, A, B, O, PI)</span>:</span>  <span class="comment"># 后向算法</span></span><br><span class="line">        N = len(Q)  <span class="comment"># 可能存在的状态数量</span></span><br><span class="line">        M = len(O)  <span class="comment"># 观测序列的大小</span></span><br><span class="line">        betas = np.ones((N, M))  <span class="comment"># beta</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">            print(<span class="string">'beta%d(%d)=1'</span> % (M, i))</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(M - <span class="number">2</span>, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">            indexOfO = V.index(O[t + <span class="number">1</span>])  <span class="comment"># 找出序列对应的索引</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">                betas[i][t] = np.dot(</span><br><span class="line">                    np.multiply(A[i], [b[indexOfO] <span class="keyword">for</span> b <span class="keyword">in</span> B]),</span><br><span class="line">                    [beta[t + <span class="number">1</span>] <span class="keyword">for</span> beta <span class="keyword">in</span> betas])</span><br><span class="line">                realT = t + <span class="number">1</span></span><br><span class="line">                realI = i + <span class="number">1</span></span><br><span class="line">                print(</span><br><span class="line">                    <span class="string">'beta%d(%d)=[sigma a%djbj(o%d)]beta%d(j)=('</span> %</span><br><span class="line">                    (realT, realI, realI, realT + <span class="number">1</span>, realT + <span class="number">1</span>),</span><br><span class="line">                    end=<span class="string">''</span>)</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> range(N):</span><br><span class="line">                    print(</span><br><span class="line">                        <span class="string">"%.2f*%.2f*%.2f+"</span> % (A[i][j], B[j][indexOfO],</span><br><span class="line">                                             betas[j][t + <span class="number">1</span>]),</span><br><span class="line">                        end=<span class="string">''</span>)</span><br><span class="line">                print(<span class="string">"0)=%.3f"</span> % betas[i][t])</span><br><span class="line">        <span class="comment"># print(betas)</span></span><br><span class="line">        indexOfO = V.index(O[<span class="number">0</span>])</span><br><span class="line">        P = np.dot(</span><br><span class="line">            np.multiply(PI, [b[indexOfO] <span class="keyword">for</span> b <span class="keyword">in</span> B]),</span><br><span class="line">            [beta[<span class="number">0</span>] <span class="keyword">for</span> beta <span class="keyword">in</span> betas])</span><br><span class="line">        print(<span class="string">"P(O|lambda)="</span>, end=<span class="string">""</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">            print(</span><br><span class="line">                <span class="string">"%.1f*%.1f*%.5f+"</span> % (PI[<span class="number">0</span>][i], B[i][indexOfO], betas[i][<span class="number">0</span>]),</span><br><span class="line">                end=<span class="string">""</span>)</span><br><span class="line">        print(<span class="string">"0=%f"</span> % P)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">viterbi</span><span class="params">(self, Q, V, A, B, O, PI)</span>:</span></span><br><span class="line">        N = len(Q)  <span class="comment">#可能存在的状态数量</span></span><br><span class="line">        M = len(O)  <span class="comment"># 观测序列的大小</span></span><br><span class="line">        deltas = np.zeros((N, M))</span><br><span class="line">        psis = np.zeros((N, M))</span><br><span class="line">        I = np.zeros((<span class="number">1</span>, M))</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(M):</span><br><span class="line">            realT = t + <span class="number">1</span></span><br><span class="line">            indexOfO = V.index(O[t])  <span class="comment"># 找出序列对应的索引</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">                realI = i + <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> t == <span class="number">0</span>:</span><br><span class="line">                    deltas[i][t] = PI[<span class="number">0</span>][i] * B[i][indexOfO]</span><br><span class="line">                    psis[i][t] = <span class="number">0</span></span><br><span class="line">                    print(<span class="string">'delta1(%d)=pi%d * b%d(o1)=%.2f * %.2f=%.2f'</span> %</span><br><span class="line">                          (realI, realI, realI, PI[<span class="number">0</span>][i], B[i][indexOfO],</span><br><span class="line">                           deltas[i][t]))</span><br><span class="line">                    print(<span class="string">'psis1(%d)=0'</span> % (realI))</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    deltas[i][t] = np.max(</span><br><span class="line">                        np.multiply([delta[t - <span class="number">1</span>] <span class="keyword">for</span> delta <span class="keyword">in</span> deltas],</span><br><span class="line">                                    [a[i] <span class="keyword">for</span> a <span class="keyword">in</span> A])) * B[i][indexOfO]</span><br><span class="line">                    print(</span><br><span class="line">                        <span class="string">'delta%d(%d)=max[delta%d(j)aj%d]b%d(o%d)=%.2f*%.2f=%.5f'</span></span><br><span class="line">                        % (realT, realI, realT - <span class="number">1</span>, realI, realI, realT,</span><br><span class="line">                           np.max(</span><br><span class="line">                               np.multiply([delta[t - <span class="number">1</span>] <span class="keyword">for</span> delta <span class="keyword">in</span> deltas],</span><br><span class="line">                                           [a[i] <span class="keyword">for</span> a <span class="keyword">in</span> A])), B[i][indexOfO],</span><br><span class="line">                           deltas[i][t]))</span><br><span class="line">                    psis[i][t] = np.argmax(</span><br><span class="line">                        np.multiply(</span><br><span class="line">                            [delta[t - <span class="number">1</span>] <span class="keyword">for</span> delta <span class="keyword">in</span> deltas],</span><br><span class="line">                            [a[i]</span><br><span class="line">                             <span class="keyword">for</span> a <span class="keyword">in</span> A])) + <span class="number">1</span>  <span class="comment">#由于其返回的是索引，因此应+1才能和正常的下标值相符合。</span></span><br><span class="line">                    print(<span class="string">'psis%d(%d)=argmax[delta%d(j)aj%d]=%d'</span> %</span><br><span class="line">                          (realT, realI, realT - <span class="number">1</span>, realI, psis[i][t]))</span><br><span class="line">        print(deltas)</span><br><span class="line">        print(psis)</span><br><span class="line">        I[<span class="number">0</span>][M - <span class="number">1</span>] = np.argmax([delta[M - <span class="number">1</span>] <span class="keyword">for</span> delta <span class="keyword">in</span> deltas</span><br><span class="line">                                 ]) + <span class="number">1</span>  <span class="comment">#由于其返回的是索引，因此应+1才能和正常的下标值相符合。</span></span><br><span class="line">        print(<span class="string">'i%d=argmax[deltaT(i)]=%d'</span> % (M, I[<span class="number">0</span>][M - <span class="number">1</span>]))</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(M - <span class="number">2</span>, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">            I[<span class="number">0</span>][t] = psis[int(I[<span class="number">0</span>][t + <span class="number">1</span>]) - <span class="number">1</span>][t + <span class="number">1</span>]</span><br><span class="line">            print(<span class="string">'i%d=psis%d(i%d)=%d'</span> % (t + <span class="number">1</span>, t + <span class="number">2</span>, t + <span class="number">2</span>, I[<span class="number">0</span>][t]))</span><br><span class="line">        print(<span class="string">"状态序列I："</span>, I)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Q = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">V = [<span class="string">'红'</span>, <span class="string">'白'</span>]</span><br><span class="line">A = [[<span class="number">0.5</span>, <span class="number">0.2</span>, <span class="number">0.3</span>], [<span class="number">0.3</span>, <span class="number">0.5</span>, <span class="number">0.2</span>], [<span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.5</span>]]</span><br><span class="line">B = [[<span class="number">0.5</span>, <span class="number">0.5</span>], [<span class="number">0.4</span>, <span class="number">0.6</span>], [<span class="number">0.7</span>, <span class="number">0.3</span>]]</span><br><span class="line">O = [<span class="string">'红'</span>, <span class="string">'白'</span>, <span class="string">'红'</span>, <span class="string">'红'</span>, <span class="string">'白'</span>, <span class="string">'红'</span>, <span class="string">'白'</span>, <span class="string">'白'</span>]</span><br><span class="line">PI = [[<span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.5</span>]]</span><br><span class="line">HMM = HiddenMarkov()</span><br><span class="line"><span class="comment"># HMM.forward(Q, V, A, B, O, PI)</span></span><br><span class="line"><span class="comment"># HMM.backward(Q, V, A, B, O, PI)</span></span><br><span class="line">HMM.viterbi(Q, V, A, B, O, PI)</span><br><span class="line">HMM.forward(Q, V, A, B, O, PI)</span><br><span class="line">HMM.backward(Q, V, A, B, O, PI)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/7/8</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line">data = pd.read_excel(<span class="string">'data1'</span> + <span class="string">'.xlsx'</span>)</span><br><span class="line">data.fillna(<span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">list_data = np.array(data).tolist()</span><br><span class="line">X = pd.get_dummies(data.iloc[<span class="number">0</span>:len(data), <span class="number">3</span>:<span class="number">7</span>])</span><br><span class="line"></span><br><span class="line">list_y1 = [int(list_data[i][<span class="number">2</span>]) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data))]</span><br><span class="line">y1_mean = np.array(list_y1).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用均值作为状态的划分</span></span><br><span class="line">Y_X = [<span class="number">0</span> <span class="keyword">if</span> list_data[i][<span class="number">2</span>] &lt; y1_mean <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data))]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 序列阶段的划分</span></span><br><span class="line"><span class="comment"># 将14个时期取平均值</span></span><br><span class="line">list_z_y = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(int(len(data)/<span class="number">14</span>)):</span><br><span class="line">    y1 = []</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        <span class="keyword">if</span> <span class="number">14</span> * i &lt;= j &lt; <span class="number">14</span> * (i + <span class="number">1</span>):</span><br><span class="line">            y1.append(list_data[j][<span class="number">2</span>])</span><br><span class="line">    list_z_y.append(np.array(y1).mean())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 14个值的平均值小于1即为0</span></span><br><span class="line"><span class="comment"># 还是用均值作为状态的划分</span></span><br><span class="line">Y_Z = [<span class="number">0</span> <span class="keyword">if</span> list_z_y[i] &lt; y1_mean <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(len(list_z_y))]</span><br><span class="line">num = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(Y_Z)):</span><br><span class="line">    <span class="keyword">if</span> Y_Z[i] == <span class="number">1</span>:</span><br><span class="line">        num += <span class="number">1</span></span><br><span class="line">print(<span class="string">f'总数目：<span class="subst">&#123;len(Y_Z)&#125;</span>, 阶段0的数目<span class="subst">&#123;len(Y_Z) - num&#125;</span>, 阶段1的数目<span class="subst">&#123;num&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line">num_1 = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">    <span class="keyword">if</span> Y_X[i] == <span class="number">1</span>:</span><br><span class="line">        num_1 += <span class="number">1</span></span><br><span class="line">print(<span class="string">f'序列中出现1阶段的次数<span class="subst">&#123;num_1&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line">Y = []</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(int(len(data)/<span class="number">14</span>)):</span><br><span class="line">    x1 = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        <span class="keyword">if</span> <span class="number">14</span> * j &lt;= i &lt; <span class="number">14</span> * (j + <span class="number">1</span>):</span><br><span class="line">            x1.append(int(list_data[i][<span class="number">2</span>]))</span><br><span class="line">    Y.append(x1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算1状态时，出现1的概率</span></span><br><span class="line">num_2 = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(Y_Z)):</span><br><span class="line">    <span class="keyword">if</span> Y_Z[i] == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">14</span>):</span><br><span class="line">            <span class="keyword">if</span> Y[i][j] == <span class="number">1</span>:</span><br><span class="line">                num_2 += <span class="number">1</span></span><br><span class="line">print(<span class="string">f'状态1中出现1的次数<span class="subst">&#123;num_2&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">f'阶段1中出现1的概率<span class="subst">&#123;num_2/(num*<span class="number">14</span>)&#125;</span>'</span>)</span><br><span class="line">B = [[<span class="number">1</span> - (num_1 - num_2) / ((len(Y_Z) - num) * <span class="number">14</span>), (num_1 - num_2) / ((len(Y_Z) - num) * <span class="number">14</span>)],</span><br><span class="line">     [<span class="number">1</span> - num_2 / (num * <span class="number">14</span>), num_2 / (num * <span class="number">14</span>)]]</span><br><span class="line">print(<span class="string">f'在阈值线为平均值下的'</span></span><br><span class="line">      <span class="string">f'<span class="subst">&#123;B&#125;</span>'</span>)</span><br></pre></td></tr></table></figure><p>利用平均值作为阈值时的B值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0.9118926758520667</span>, <span class="number">0.08810732414793329</span>], </span><br><span class="line"></span><br><span class="line">[<span class="number">0.8428571428571429</span>, <span class="number">0.15714285714285714</span>]]</span><br></pre></td></tr></table></figure><p>利用1作为阈值时的B值为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Y_X = [<span class="number">0</span> <span class="keyword">if</span> list_data[i][<span class="number">2</span>] &lt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data))]</span><br><span class="line">Y_Z = [<span class="number">0</span> <span class="keyword">if</span> list_z_y[i] &lt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(len(list_z_y))]</span><br><span class="line"></span><br><span class="line">[[<span class="number">0.78535170413343</span>, <span class="number">0.21464829586656997</span>], </span><br><span class="line">[<span class="number">0.8428571428571429</span>, <span class="number">0.15714285</span></span><br><span class="line"> <span class="number">714285714</span>]]</span><br></pre></td></tr></table></figure><p>比较下最大似然值</p><p>均值下的结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">初始概率矩阵[[<span class="number">0.9041184041184042</span>, <span class="number">0.09588159588159584</span>]]</span><br><span class="line">状态转移概率矩阵：[[<span class="number">0.9964114832535885</span>, <span class="number">0.0035885167464114833</span>], [<span class="number">0.26804123711340205</span>, <span class="number">0.7319587628865979</span>]]</span><br><span class="line">均值下的似然估计值为：    <span class="number">-955.2942841591449</span></span><br><span class="line">分类为<span class="number">2</span>均值下的BIC为：<span class="number">-1028.7801594684208</span></span><br><span class="line">--------------------</span><br><span class="line">参数估计</span><br><span class="line">状态转移概率矩阵的系数为：[[ <span class="number">1.29445779e-05</span>  <span class="number">5.27657348e-06</span> <span class="number">-2.44868582e-02</span>  <span class="number">3.68198497e+00</span>]]</span><br><span class="line">状态转移概率矩阵的偏差为：[<span class="number">-4.52277323</span>]</span><br><span class="line">观察状态概率转移矩阵的系数为：[[ <span class="number">0.00304877</span> <span class="number">-0.00165371</span>]]</span><br><span class="line">观察状态概率转移矩阵的偏差为：[<span class="number">-2.00454762</span>]</span><br></pre></td></tr></table></figure><p>1值下的结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">初始概率矩阵[[<span class="number">0.7918275418275418</span>, <span class="number">0.20817245817245822</span>]]</span><br><span class="line">状态转移概率矩阵：[[<span class="number">0.984869325997249</span>, <span class="number">0.015130674002751032</span>], [<span class="number">0.4029126213592233</span>, <span class="number">0.5970873786407767</span>]]</span><br><span class="line"><span class="number">1</span>值下的似然估计值为：    <span class="number">-1589.5001457084938</span></span><br><span class="line">分类为<span class="number">2</span>阈值为<span class="number">1</span>下的BIC为：<span class="number">-1662.9860210177699</span></span><br><span class="line">--------------------</span><br><span class="line">参数估计</span><br><span class="line">状态转移概率矩阵的系数为：[[ <span class="number">3.54342024e-05</span>  <span class="number">6.64259922e-05</span> <span class="number">-4.34313674e-03</span>  <span class="number">3.76444931e+00</span>]]</span><br><span class="line">状态转移概率矩阵的偏差为：[<span class="number">-2.26616719</span>]</span><br><span class="line">观察状态概率转移矩阵的系数为：[[<span class="number">-0.02040833</span> <span class="number">-0.00606398</span>]]</span><br><span class="line">观察状态概率转移矩阵的偏差为：[<span class="number">-1.81251543</span>]</span><br></pre></td></tr></table></figure><p>主要还是根据阈值线，来进行判定，BIC这些值的大小</p><p><img src="http://i0.hdslb.com/bfs/article/72162a4abb1e6b985db79d35a2c2d4b9caaf6a3a.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;HMM中的B值确定&quot;&gt;&lt;a href=&quot;#HMM中的B值确定&quot; class=&quot;headerlink&quot; title=&quot;HMM中的B值确定&quot;&gt;&lt;/a&gt;HMM中的B值确定&lt;/h1&gt;&lt;p&gt;1．隐马尔可夫模型是关于时序的概率模型，描述由一个隐藏的马尔可夫链随机生成不可观测的
      
    
    </summary>
    
    
      <category term="work" scheme="https://esyyes.github.io/categories/work/"/>
    
    
      <category term="work" scheme="https://esyyes.github.io/tags/work/"/>
    
  </entry>
  
  <entry>
    <title>HMM模型的学习</title>
    <link href="https://esyyes.github.io/2020/07/04/HMM/HMM%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AD%A6%E4%B9%A0/"/>
    <id>https://esyyes.github.io/2020/07/04/HMM/HMM%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AD%A6%E4%B9%A0/</id>
    <published>2020-07-04T06:33:33.000Z</published>
    <updated>2020-07-04T06:33:33.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HMM模型"><a href="#HMM模型" class="headerlink" title="HMM模型"></a>HMM模型</h1><h2 id="马尔科夫模型"><a href="#马尔科夫模型" class="headerlink" title="马尔科夫模型"></a>马尔科夫模型</h2><p> 马尔可夫模型（Markov Model）是一种统计模型，广泛应用在语音识别，词性自动标注，音字转换，概率文法等各个自然语言处理等应用领域。经过长期发展，尤其是在语音识别中的成功应用，使它成为一种通用的统计工具。 </p><p> <a href="https://baike.baidu.com/item/马尔可夫模型/4017874?fromtitle=马尔科夫模型&fromid=11231643&fr=aladdin" target="_blank" rel="noopener">https://baike.baidu.com/item/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B/4017874?fromtitle=%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B&amp;fromid=11231643&amp;fr=aladdin</a> </p><p><img src="https://bkimg.cdn.bcebos.com/pic/7acb0a46f21fbe090f93240c64600c338644addd?x-bce-process=image/watermark,g_7,image_d2F0ZXIvYmFpa2U4MA==,xp_5,yp_5" alt=""></p><p> 在给定当前只是或信息的情况下，过去（即当前以前的历史状态），对于预测将来（即当前以后的未来状态）是无关的 </p><p> 每个状态的转移只依赖与之前的n个状态，这个过程被称为1个n阶的模型，其中n是影响转移状态的数目。最简单的马尔科夫过程是一阶过程，用数学表达式表示就是下面的形式： </p><h2 id="HMM模型-1"><a href="#HMM模型-1" class="headerlink" title="HMM模型"></a>HMM模型</h2><p> <strong>隐马尔可夫模型</strong>（Hidden Markov Model，HMM）是统计模型，它用来描述一个含有隐含未知参数的马尔可夫过程。其难点是从可观察的参数中确定该过程的隐含参数。然后利用这些参数来作进一步的分析，例如模式识别。 </p><p> <a href="https://www.cnblogs.com/fulcra/p/11065474.html" target="_blank" rel="noopener">https://www.cnblogs.com/fulcra/p/11065474.html</a> </p><p> 假设我手里有三个不同的骰子。第一个骰子是我们平常见的骰子（称这个骰子为D6），6个面，每个面（1，2，3，4，5，6）出现的概率是1/6。第二个骰子是个四面体（称这个骰子为D4），每个面（1，2，3，4）出现的概率是1/4。第三个骰子有八个面（称这个骰子为D8），每个面（1，2，3，4，5，6，7，8）出现的概率是1/8。 </p><p> <a href="https://www.bilibili.com/video/BV1DK411W7jJ" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1DK411W7jJ</a> </p><p> <img src="https://images0.cnblogs.com/blog/133059/201507/161450315321886.png" alt="image"></p><p> 假设我们开始掷骰子，我们先从三个骰子里挑一个，挑到每一个骰子的概率都是1/3。然后我们掷骰子，得到一个数字，1，2，3，4，5，6，7，8中的一个。不停的重复上述过程，我们会得到一串数字，每个数字都是1，2，3，4，5，6，7，8中的一个。例如我们可能得到这么一串数字（掷骰子10次）：<strong>1 6 3 5 2 7 3 5 2 4</strong></p><p><strong>这串数字叫做可见状态链。</strong>但是在隐马尔可夫模型中，我们不仅仅有这么一串可见状态链，还有一串隐含状态链。在这个例子里，这串隐含状态链就是你用的骰子的序列。比如，隐含状态链有可能是：D6 D8 D8 D6 D4 D8 D6 D6 D4 D8</p><p>一般来说，HMM中说到的马尔可夫链其实是指隐含状态链，因为隐含状态（骰子）之间存在转换概率（transition probability）。在我们这个例子里，D6的下一个状态是D4，D6，D8的概率都是1/3。D4，D8的下一个状态是D4，D6，D8的转换概率也都一样是1/3。这样设定是为了最开始容易说清楚，但是我们其实是可以随意设定转换概率的。比如，我们可以这样定义，D6后面不能接D4，D6后面是D6的概率是0.9，是D8的概率是0.1。这样就是一个新的HMM。</p><p>同样的，尽管可见状态之间没有转换概率，但是隐含状态和可见状态之间有一个概率叫做输出概率（emission probability）。就我们的例子来说，六面骰（D6）产生1的输出概率是1/6。产生2，3，4，5，6的概率也都是1/6。我们同样可以对输出概率进行其他定义。比如，我有一个被赌场动过手脚的六面骰子，掷出来是1的概率更大，是1/2，掷出来是2，3，4，5，6的概率是1/10。</p><p><img src="H:%5Cmyboke%5Cmybike%5Csource%5Cimages%5C1593864632072.png" alt="1593864632072"></p><p>回到正题，和HMM模型相关的算法主要分为三类，分别解决三种问题： </p><p> <strong>1）知道骰子有几种（隐含状态数量），每种骰子是什么（转换概率），根据掷骰子掷出的结果（可见状态链），我想知道每次掷出来的都是哪种骰子（隐含状态链）。</strong> </p><p> 这个问题呢，在语音识别领域呢，叫做<strong>解码问题</strong>。这个问题其实有两种解法，会给出两个不同的答案。每个答案都对，只不过这些答案的意义不一样。第一种解法求<strong>最大似然状态路径</strong>，说通俗点呢，就是我求一串骰子序列，这串骰子序列产生观测结果的概率最大。第二种解法呢，就不是求一组骰子序列了，而是求每次掷出的骰子分别是某种骰子的概率。比如说我看到结果后，我可以求得第一次掷骰子是D4的概率是0.5，D6的概率是0.3，D8的概率是0.2.第一种解法我会在下面说到，但是第二种解法我就不写在这里了，如果大家有兴趣，我们另开一个问题继续写吧。</p><p><strong>2）还是知道骰子有几种**</strong></p><p>（隐含状态数量），每种骰子是什么（<strong>转换概率</strong>），根据掷骰子掷出的结果（可见状态链），我想知道掷出这个结果的概率。**<br>   看似这个问题意义不大，因为你掷出来的结果很多时候都对应了一个比较大的概率。问这个问题的目的呢，其实是检测观察到的结果和已知的模型是否吻合。如果很多次结果都对应了比较小的概率，那么就说明我们已知的模型很有可能是错的，有人偷偷把我们的骰子給换了。</p><p><strong>3）知道骰子有几种**</strong></p><p>（隐含状态数量），不知道每种骰子是什么（<strong>转换概率</strong>），观测到很多次掷骰子的结果（可见状态链），我想反推出每种骰子是什么（转换概率）。**<br>   这个问题很重要，因为这是最常见的情况。很多时候我们只有<strong>可见结果，不知道HMM模型里的参数，我们需要从可见结果估计出这些参数</strong>，这是建模的一个必要步骤。</p><p><img src="H:%5Cmyboke%5Cmybike%5Csource%5Cimages%5C1593865330505.png" alt="1593865330505"></p><p><img src="H:%5Cmyboke%5Cmybike%5Csource%5Cimages%5C1593865385128.png" alt="1593865350351"></p><h2 id="隐马尔科夫模型"><a href="#隐马尔科夫模型" class="headerlink" title="隐马尔科夫模型"></a>隐马尔科夫模型</h2><p>总结就是一个<strong>学习问题</strong>，</p><p>然后判断时有监督学习还是无监督学习</p><p><img src="H:%5Cmyboke%5Cmybike%5Csource%5Cimages%5C1593865770153.png" alt="1593865770153"></p><p><strong>有监督学习</strong>：观测序列和状态序列都要有： 极大似然法（pi, A, B）</p><p>无监督学习：观测序列,em算法，</p><p><img src="H:%5Cmyboke%5Cmybike%5Csource%5Cimages%5C1593865922973.png" alt="1593865922973"></p><p>马尔科夫模型是一种具有代表性的一阶概率统计模型。隐马尔科夫模型<br>强调了不确定性和潜在性，正是由于这种性质，满足现实生活中诸多问题的<br>基本要求，因此研究人员经常用该模型进行实际状态与行为之间问题的抽象<br>研究与概况。隐马尔科夫模型对于潜在和随机的真实问题有着高度的拟合性，<br>也存在着诸多的优势。隐马尔科夫模型是一个双重随机概率模型，该该型的<br>一般结构是 </p><p><img src="H:%5Cmyboke%5Cmybike%5Csource%5Cimages%5C1593866078621.png" alt="1593866078621"></p><h3 id="隐马尔科夫模型的三个基本问题"><a href="#隐马尔科夫模型的三个基本问题" class="headerlink" title="隐马尔科夫模型的三个基本问题"></a>隐马尔科夫模型的三个基本问题</h3><h4 id="（1）评估问题"><a href="#（1）评估问题" class="headerlink" title="（1）评估问题"></a>（1）评估问题</h4><p>隐马尔科夫模型的评估问题是，已知一个隐藏状态序列对应的观察值序<br>列 O=O1O2…OT，同时已知确定了基本组成矩阵的模型 λ(π，Q，A)的条件下，<br>输入一组待实现的观察值样本序列，计算得到该模型条件下生成该样本序列<br>的概率，即 P（O/λ） 。在隐马尔科夫模型的评估问题中，计算得到已知模型<br>组成部分下的条件概率的算法被称为前向算法。评估问题的目的是在于根据<br>模型产生待实现的观察值序列的大小，如果产生该序列的概率越大，则说明<br>模型解决该样本序列作为实际问题的能力就越强，进而判断已知模型对待解<br>决问题的适用性。  （2）解码问题 </p><p>隐马尔科夫模型的评估问题是，已知一个隐藏状态序列对应的观察值序<br>列 O=O1O2…OT，同时已知确定了基本组成矩阵的模型 λ(π，Q，A)的条件下，<br>利用算法进行计算，能够快速有效的选择一定程度下的最好的状态序列<br>Q=Q1Q2。 。 。QT，生成这一隐藏状态序列的概率值最大，能够很好的满足对观<br>察值序列的解释。隐马尔科夫模型的评估问题使用的算法为维特比算法，解<br>码问题的目的是确定最适宜的隐藏状态量的序列，这种最适合并没有明确的<br>定义和规范，根据具体的现实研究问题进行具体的界定。 </p><h4 id="（3）学习问题"><a href="#（3）学习问题" class="headerlink" title="（3）学习问题"></a>（3）学习问题</h4><p>隐马尔科夫模型的学习问题是实际问题中最常见的问题类型。在隐马尔<br>科夫模型的学习问题中，仅仅能够已知一组输出的模型状态观察值的序列<br>O=O1O2…OT，对隐马尔科夫模型 λ(π，Q，A)中的基本组成部分并不能直接<br>确定，根据已有的观察值样本数据，对模型进行反复的训练和评价，调节模<br>型 λ(π，Q，A)中的三个基本部分的参数，使得输出该观察值序列的概率值<br>最大，即通过学习训练过程使得该模型具备最优的拟合程度。隐马尔科夫模<br>型的学习问题中，主要是通过<strong>前向后向算法（Baum-Welch 算法）</strong>来进行训<br>练和学习的；在模型训练学习中，最常见的是采用<strong>贝叶斯分析方法和最大似</strong><br><strong>然估计方法</strong>，对模型中的参数进行评估和优化，保证模型至少达到局部最优。</p><p>在实际问题的研究中，通常都只能<strong>获取到输出序列值</strong>，因此<strong>前向-后向</strong><br><strong>算法实现隐马尔科夫模型的训练学习问题</strong>具有广泛应用。</p><p>2、模型学习问题：已知观测序列，估计模型中的参数，使得在该模型下观测序列概率最大，即用极大似然估计的方法估计参数。</p><p>Baum-Welch算法解决的是一个模型训练问题，即参数估计，是一种无监督的训练方法，主要通过EM迭代实现；即只有观测序列，无状态序列时训练模型。</p><p>极大似然估计：观测序列和相应的状态序列都存在的监督学习算法，用来估计参数。</p><p>主要用到这两个，然后现在就是学习EM迭代，和用最大似然估计来确定参数！</p><p>第一步是确定，状态数目，或者是生产转移矩阵。</p><p><img src="http://pic.rmb.bdstatic.com/b86ca7466d43fae63a58735e15aa54c53717.jpeg@c_1,w_1280,h_1024,x_0,y_0" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;HMM模型&quot;&gt;&lt;a href=&quot;#HMM模型&quot; class=&quot;headerlink&quot; title=&quot;HMM模型&quot;&gt;&lt;/a&gt;HMM模型&lt;/h1&gt;&lt;h2 id=&quot;马尔科夫模型&quot;&gt;&lt;a href=&quot;#马尔科夫模型&quot; class=&quot;headerlink&quot; title=&quot;马
      
    
    </summary>
    
    
      <category term="work" scheme="https://esyyes.github.io/categories/work/"/>
    
    
      <category term="work" scheme="https://esyyes.github.io/tags/work/"/>
    
  </entry>
  
  <entry>
    <title>交叉验证</title>
    <link href="https://esyyes.github.io/2020/07/02/sleep%20apnea%20and%20sleep%20stage/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/"/>
    <id>https://esyyes.github.io/2020/07/02/sleep%20apnea%20and%20sleep%20stage/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/</id>
    <published>2020-07-02T00:49:24.000Z</published>
    <updated>2020-07-02T00:49:24.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h1><h2 id="交叉验证：评估估算器的表现"><a href="#交叉验证：评估估算器的表现" class="headerlink" title="交叉验证：评估估算器的表现"></a>交叉验证：评估估算器的表现</h2><p>学习预测函数的参数，并在相同数据集上进行测试是一种错误的做法: 一个仅给出测试用例标签的模型将会获得极高的分数，但对于尚未出现过的数据它则无法预测出任何有用的信息。 这种情况称为 overfitting（过拟合）. 为了避免这种情况，在进行（监督）机器学习实验时，通常取出部分可利用数据作为 test set（测试数据集）</p><h2 id="置信区间"><a href="#置信区间" class="headerlink" title="置信区间"></a>置信区间</h2><p> <a href="https://baike.baidu.com/item/置信区间/7442583?fr=aladdin" target="_blank" rel="noopener">https://baike.baidu.com/item/%E7%BD%AE%E4%BF%A1%E5%8C%BA%E9%97%B4/7442583?fr=aladdin</a> </p><p> 置信区间是指由<a href="https://baike.baidu.com/item/样本统计量/7378689" target="_blank" rel="noopener">样本统计量</a>所构造的总体参数的估计区间。在统计学中，一个<a href="https://baike.baidu.com/item/概率/828845" target="_blank" rel="noopener">概率</a>样本的置信区间（Confidence interval）是对这个样本的某个总体参数的<a href="https://baike.baidu.com/item/区间估计/6611490" target="_blank" rel="noopener">区间估计</a>。 </p><p> 置信区间与置信水平、样本量等因素均有关系，其中<a href="https://baike.baidu.com/item/样本量" target="_blank" rel="noopener">样本量</a>对置信区间的影响为：在<a href="https://baike.baidu.com/item/置信水平" target="_blank" rel="noopener">置信水平</a>固定的情况下，样本量越多，置信区间越窄。其次，在<a href="https://baike.baidu.com/item/样本量" target="_blank" rel="noopener">样本量</a>相同的情况下，置信水平越高，置信区间越宽 </p><p>95%置信区间（Confidence Interval,CI）：当给出某个估计值的95%置信区间为【a,b】时，可以理解为我们有95%的信心（Confidence）可以说样本的平均值介于a到b之间，而发生错误的概率为5%。 </p><p> 有时也会说90%，99%的置信区间，具体含义可参考95%置信区间。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Accuracy: %0.2f (+/- %0.2f)"</span> % (scores.mean(), scores.std() * <span class="number">2</span>))</span><br><span class="line">Accuracy: <span class="number">0.98</span> (+/- <span class="number">0.03</span>)</span><br></pre></td></tr></table></figure><h2 id="交叉验证-1"><a href="#交叉验证-1" class="headerlink" title="交叉验证"></a>交叉验证</h2><p>用来验证分类器的性能一种统计分析方法，基本思想是把在某种意义下将原始数据(data set)进行分组，一部分做为训练集(training set)，另一部分做为验证集(validation set)，首先用训练集对分类器进行训练，在利用验证集来测试训练得到的模型(model)，以此来做为评价分类器的性能指标。</p><h3 id="k折交叉验证-k-fold-cross-validation"><a href="#k折交叉验证-k-fold-cross-validation" class="headerlink" title="k折交叉验证(k-fold cross validation)"></a>k折交叉验证(k-fold cross validation)</h3><p>将数据集无替换的随机分为k份，k-1份用来训练模型，剩下一份用来模型性能评估。重复k次，得到k个模型和性能评估结果。得到k个性能评估后，取平均求出最终性能评估。即：<br>第一步：不重复抽样将原始数据随机分为k份。<br>第二步：每一次挑选其中 1 份作为测试集，剩余k-1份作为训练集用于模型训练。<br>第三步：重复第二步k次，每个子集都有一次作为测试集，其余子集作为训练集。在每个训练集上训练后得到一个模型，用这个模型在相应测试集上测试，计算并保存模型的评估指标。<br>第四步：计算k组测试结果的平均值作为模型精度的估计，并作为当前k折交叉验证下模型的性能指标。</p><p>优点：分组后取平均减少方差，使得模型对数据划分不敏感。<br>缺点：k取值需要尝试</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @time     : 2020/6/30 0030</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> data_preprocessing <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_rf</span><span class="params">(train_x, test_x, train_y, test_y)</span>:</span></span><br><span class="line">    clf = RandomForestClassifier()</span><br><span class="line">    clf.fit(train_x, train_y)</span><br><span class="line">    pred_y = clf.predict(test_x)</span><br><span class="line">    acr = accuracy_score(test_y, pred_y)</span><br><span class="line">    <span class="keyword">return</span> acr</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">feature = pd.read_excel(<span class="string">'D:/zccode/all_feature'</span> + <span class="string">'/features'</span> + <span class="string">'%s'</span> % <span class="number">1</span> + <span class="string">'.xlsx'</span>)</span><br><span class="line">data = pd.get_dummies(feature.iloc[<span class="number">0</span>:len(feature), <span class="number">1</span>:])</span><br><span class="line">note = pd.read_excel(<span class="string">'D:/zccode/all_note'</span> + <span class="string">'/note'</span> + <span class="string">'%s'</span> % <span class="number">1</span> + <span class="string">'.xlsx'</span>)</span><br><span class="line">tag = pd.get_dummies(note.iloc[<span class="number">0</span>:len(data), <span class="number">1</span>:])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选定固定的特征值</span></span><br><span class="line">feature_import = pd.read_excel(<span class="string">'D:/zccode'</span> + <span class="string">'/feature_important'</span> + <span class="string">'%s'</span> % <span class="number">2</span> + <span class="string">'.xlsx'</span>)</span><br><span class="line">df = pd.get_dummies(feature_import.iloc[<span class="number">0</span>:len(feature_import), <span class="number">1</span>:<span class="number">16</span>])</span><br><span class="line"></span><br><span class="line">std_data = data_pre(data[df.keys()])</span><br><span class="line">label = pd.get_dummies(tag.iloc[<span class="number">0</span>:len(data), <span class="number">2</span>:<span class="number">3</span>])</span><br><span class="line">scores = cross_val_score(RandomForestClassifier(), std_data, label, cv=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">f'<span class="subst">&#123;scores&#125;</span>'</span>)</span><br><span class="line">print(<span class="string">"Accuracy: %0.2f (+/- %0.2f)"</span> % (scores.mean(), scores.std() * <span class="number">2</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">0.88</span>       <span class="number">0.92</span>       <span class="number">0.86956522</span> <span class="number">0.91304348</span> <span class="number">0.95652174</span> <span class="number">1.</span></span><br><span class="line"> <span class="number">1.</span>         <span class="number">0.86363636</span> <span class="number">1.</span>         <span class="number">0.59090909</span>]</span><br><span class="line">Accuracy: <span class="number">0.90</span> (+/- <span class="number">0.23</span>)</span><br></pre></td></tr></table></figure><p>交叉验证K值的确定，找一个样本很平均的，然后再去利用样本来进行判定</p><h2 id="交叉验证的作用："><a href="#交叉验证的作用：" class="headerlink" title="交叉验证的作用："></a>交叉验证的作用：</h2><h3 id="评估模型的稳定性及调参"><a href="#评估模型的稳定性及调参" class="headerlink" title="评估模型的稳定性及调参"></a>评估模型的稳定性及调参</h3><p>比如5折交叉验证，在参数确定了的情况下，我们可以将数据弄成五份，每一份中80%训练，20%作为测试集，这样可以训练五个模型，这五个模型除了训练集测试集不同外，其他的都相同，这样我们可以得到五个模型的评估指标比如<strong>auc</strong>,计算五个模型得到的<strong>auc的方差</strong>，如果方差小说明模型的泛化性比较好，模型比较稳定是个好模型，否则说明模型泛化性不好。<br>xgboost中cv函数返回的值包括两个，一个是单模型的评价指标（比如auc），另外一个是模型的方差。</p><p>参数不确定的情况下，我们通过<strong>模型的准确性和稳定性</strong>来选择最合适的参数。<br> <a href="https://blog.csdn.net/weixin_41060109/article/details/80878325?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.nonecase" target="_blank" rel="noopener">https://blog.csdn.net/weixin_41060109/article/details/80878325?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.nonecase</a> </p><p> 在实际训练中，模型通常对训练数据好，但是对训练数据之外的数据拟合程度差。用于<strong>评价模型的泛化能力</strong>，从而进行<strong>模型选择</strong>。 </p><h2 id="交叉验证的初步目标"><a href="#交叉验证的初步目标" class="headerlink" title="交叉验证的初步目标"></a>交叉验证的初步目标</h2><p>初步选择大部分的模型，然后通过交叉验证，例如：10次10折，先初步去筛选得到性能效果好的模型，然后再对这几个好的模型，进行网格搜索的超参数优化</p><p>交叉验证得到一个准确率，但是不能用准确率这个指标去直接判定分类器的性能</p><p>最后用混淆矩阵、精度、召回率等去评估分类的效果和性能</p><p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1593683305451&di=084be09798a996ba20acd53f72f8e663&imgtype=0&src=http%3A%2F%2Fhbimg.b0.upaiyun.com%2F1e4a2abbb0ec1309578de3741b1c7619c7a34c4f2834b-zmvQca_fw658" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;交叉验证&quot;&gt;&lt;a href=&quot;#交叉验证&quot; class=&quot;headerlink&quot; title=&quot;交叉验证&quot;&gt;&lt;/a&gt;交叉验证&lt;/h1&gt;&lt;h2 id=&quot;交叉验证：评估估算器的表现&quot;&gt;&lt;a href=&quot;#交叉验证：评估估算器的表现&quot; class=&quot;headerlink
      
    
    </summary>
    
    
      <category term="work" scheme="https://esyyes.github.io/categories/work/"/>
    
    
      <category term="work" scheme="https://esyyes.github.io/tags/work/"/>
    
  </entry>
  
  <entry>
    <title>中期答辩题目</title>
    <link href="https://esyyes.github.io/2020/06/29/sleep%20apnea%20and%20sleep%20stage/%E4%B8%AD%E6%9C%9F%E7%AD%94%E8%BE%A9%E9%A2%98%E7%9B%AE/"/>
    <id>https://esyyes.github.io/2020/06/29/sleep%20apnea%20and%20sleep%20stage/%E4%B8%AD%E6%9C%9F%E7%AD%94%E8%BE%A9%E9%A2%98%E7%9B%AE/</id>
    <published>2020-06-29T02:58:18.000Z</published>
    <updated>2020-06-29T02:58:18.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="中期答辩题目"><a href="#中期答辩题目" class="headerlink" title="中期答辩题目"></a>中期答辩题目</h1><p>考虑睡眠分期、睡眠质量、睡眠呼吸暂停、心电信号、特征选择</p><p>​         睡眠相关的理论知识，包括睡眠周期性，睡眠分期方法以及睡眠呼吸暂停等。  </p><p>参考题目：基于PVDF的睡眠监测系统设计与实现</p><p>直接将睡眠这几个统计到睡眠</p><p>基于心电信号的特征选择和睡眠监测方法研究</p><p>基于心电信号的睡眠分期和阻塞性呼吸暂停相关性研究</p><p><strong>基于心电信号的睡眠分期和呼吸暂停检测算法的研究</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;中期答辩题目&quot;&gt;&lt;a href=&quot;#中期答辩题目&quot; class=&quot;headerlink&quot; title=&quot;中期答辩题目&quot;&gt;&lt;/a&gt;中期答辩题目&lt;/h1&gt;&lt;p&gt;考虑睡眠分期、睡眠质量、睡眠呼吸暂停、心电信号、特征选择&lt;/p&gt;
&lt;p&gt;​         睡眠相关的理论知
      
    
    </summary>
    
    
      <category term="work" scheme="https://esyyes.github.io/categories/work/"/>
    
    
      <category term="work" scheme="https://esyyes.github.io/tags/work/"/>
    
  </entry>
  
  <entry>
    <title>查看分类器对应的数据系列</title>
    <link href="https://esyyes.github.io/2020/06/24/sleep%20apnea%20and%20sleep%20stage/%E6%9F%A5%E7%9C%8B%E5%88%86%E7%B1%BB%E5%99%A8%E5%AF%B9%E5%BA%94%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B3%BB%E5%88%97/"/>
    <id>https://esyyes.github.io/2020/06/24/sleep%20apnea%20and%20sleep%20stage/%E6%9F%A5%E7%9C%8B%E5%88%86%E7%B1%BB%E5%99%A8%E5%AF%B9%E5%BA%94%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B3%BB%E5%88%97/</id>
    <published>2020-06-24T13:02:27.000Z</published>
    <updated>2020-06-24T13:02:27.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>不同特征数之间的分类模型比较</title>
    <link href="https://esyyes.github.io/2020/06/24/sleep%20apnea%20and%20sleep%20stage/%E4%B8%8D%E5%90%8C%E7%89%B9%E5%BE%81%E6%95%B0%E4%B9%8B%E9%97%B4%E7%9A%84%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E6%AF%94%E8%BE%83/"/>
    <id>https://esyyes.github.io/2020/06/24/sleep%20apnea%20and%20sleep%20stage/%E4%B8%8D%E5%90%8C%E7%89%B9%E5%BE%81%E6%95%B0%E4%B9%8B%E9%97%B4%E7%9A%84%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E6%AF%94%E8%BE%83/</id>
    <published>2020-06-24T02:57:17.000Z</published>
    <updated>2020-06-24T02:57:17.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="不同特征数之间的分类模型比较"><a href="#不同特征数之间的分类模型比较" class="headerlink" title="不同特征数之间的分类模型比较"></a>不同特征数之间的分类模型比较</h1><p>首先确定特征的个数，确定index和特征数之间的关系</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选定固定的特征值</span></span><br><span class="line">feature_import = pd.read_excel(<span class="string">'D:/zccode'</span> + <span class="string">'/feature_important'</span> + <span class="string">'%s'</span> % <span class="number">2</span> + <span class="string">'.xlsx'</span>)</span><br><span class="line">df = pd.get_dummies(feature_import.iloc[<span class="number">0</span>:len(feature_import), <span class="number">1</span>:<span class="number">5</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">      <span class="number">5</span>NN20    <span class="number">5</span>pNN20    <span class="number">5</span>pNN50     <span class="number">5</span>NN50</span><br><span class="line"><span class="number">0</span>  <span class="number">0.023794</span>  <span class="number">0.023346</span>  <span class="number">0.022757</span>  <span class="number">0.022194</span></span><br></pre></td></tr></table></figure><p>根据设定的index,还是取的是左闭右开，因此对于下面的特征，index 应该为特征数加1</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">最大准确率时对应的特征数</span><br><span class="line">分期为<span class="number">5</span>时最高准确率为<span class="number">79.65</span>%特征数为<span class="number">23</span></span><br><span class="line">分期为<span class="number">4</span>时最高准确率为<span class="number">86.40</span>%特征数为<span class="number">23</span></span><br><span class="line">分期为<span class="number">3</span>时最高准确率为<span class="number">89.04</span>%特征数为<span class="number">15</span></span><br><span class="line">准确率降低<span class="number">1</span>%后对应的特征数</span><br><span class="line">分期为<span class="number">5</span>时最高准确率为<span class="number">79.65</span>%最高准确率降低<span class="number">1</span>%后为<span class="number">78.85</span>%比较筛选的准确率为<span class="number">78.86</span>%特征数为<span class="number">9</span></span><br><span class="line">分期为<span class="number">4</span>时最高准确率为<span class="number">86.40</span>%最高准确率降低<span class="number">1</span>%后为<span class="number">85.54</span>%比较筛选的准确率为<span class="number">85.66</span>%特征数为<span class="number">8</span></span><br><span class="line">分期为<span class="number">3</span>时最高准确率为<span class="number">89.04</span>%最高准确率降低<span class="number">1</span>%后为<span class="number">88.15</span>%比较筛选的准确率为<span class="number">88.22</span>%特征数为<span class="number">7</span></span><br></pre></td></tr></table></figure><p>重新跑下结果；</p><p>因此对于最大准确率时，基于特征数的分类模型就该为下面程序</p><h2 id="最大准确率时特征对应的分类结果"><a href="#最大准确率时特征对应的分类结果" class="headerlink" title="最大准确率时特征对应的分类结果"></a>最大准确率时特征对应的分类结果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @time     : 2020/6/23 0023</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sleep_class <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    <span class="keyword">if</span> k == <span class="number">0</span>:</span><br><span class="line">        index = <span class="number">24</span></span><br><span class="line">        class_feature(k, index)</span><br><span class="line">    <span class="keyword">elif</span> k == <span class="number">1</span>:</span><br><span class="line">        index = <span class="number">24</span></span><br><span class="line">        class_feature(k, index)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        index = <span class="number">16</span></span><br><span class="line">        class_feature(k, index)</span><br></pre></td></tr></table></figure><h3 id="sleep-class-中的函数"><a href="#sleep-class-中的函数" class="headerlink" title="sleep class 中的函数"></a>sleep class 中的函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @time     : 2020/6/23 0023</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> data_preprocessing <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> classifiers <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">class_feature</span><span class="params">(k, index)</span>:</span></span><br><span class="line">    class_scores = []</span><br><span class="line">    kappa_scores = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">19</span>):</span><br><span class="line">        feature = pd.read_excel(<span class="string">'D:/zccode/all_feature'</span> + <span class="string">'/features'</span> + <span class="string">'%s'</span> % i + <span class="string">'.xlsx'</span>)</span><br><span class="line">        data = pd.get_dummies(feature.iloc[<span class="number">0</span>:len(feature), <span class="number">1</span>:])</span><br><span class="line">        note = pd.read_excel(<span class="string">'D:/zccode/all_note'</span> + <span class="string">'/note'</span> + <span class="string">'%s'</span> % i + <span class="string">'.xlsx'</span>)</span><br><span class="line">        tag = pd.get_dummies(note.iloc[<span class="number">0</span>:len(data), <span class="number">1</span>:])</span><br><span class="line">        feature_import = pd.read_excel(<span class="string">'D:/zccode'</span> + <span class="string">'/feature_important'</span> + <span class="string">'%s'</span> % (k+<span class="number">1</span>) + <span class="string">'.xlsx'</span>)</span><br><span class="line">        df = pd.get_dummies(feature_import.iloc[<span class="number">0</span>:len(feature_import), <span class="number">1</span>:index])</span><br><span class="line"></span><br><span class="line">        std_data = data_pre(data[df.keys()])</span><br><span class="line">        label = pd.get_dummies(tag.iloc[<span class="number">0</span>:len(data), k:k+<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        class_score = []</span><br><span class="line">        kappa_score = []</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">50</span>):</span><br><span class="line">            X_train, X_test, y_train, y_test = train_test_split(std_data, label, test_size=<span class="number">0.3</span>)</span><br><span class="line">            score = run_classifiers(X_train, X_test, y_train, y_test)</span><br><span class="line">            class_score.append(score[<span class="number">0</span>])</span><br><span class="line">            kappa_score.append(score[<span class="number">1</span>])</span><br><span class="line">        class_scores.append([(np.array([class_score[a][k] <span class="keyword">for</span> a <span class="keyword">in</span> range(<span class="number">50</span>)])).mean() <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">9</span>)])</span><br><span class="line">        kappa_scores.append([(np.array([kappa_score[a][k] <span class="keyword">for</span> a <span class="keyword">in</span> range(<span class="number">50</span>)])).mean() <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">9</span>)])</span><br><span class="line">        print(<span class="string">f'已经运行<span class="subst">&#123;i&#125;</span>次'</span>)</span><br><span class="line"></span><br><span class="line">    class_total = pd.DataFrame(class_scores)</span><br><span class="line">    kappa_total = pd.DataFrame(kappa_scores)</span><br><span class="line"></span><br><span class="line">    class_total.to_excel(<span class="string">'feature_section_class'</span> + <span class="string">'%d'</span> % k + <span class="string">".xlsx"</span>)</span><br><span class="line">    kappa_total.to_excel(<span class="string">'feature_section_kappa'</span> + <span class="string">'%d'</span> % k + <span class="string">".xlsx"</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f'运行一次'</span></span><br></pre></td></tr></table></figure><h2 id="特征降维后的分类结果"><a href="#特征降维后的分类结果" class="headerlink" title="特征降维后的分类结果"></a>特征降维后的分类结果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @time     : 2020/6/23 0023</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sleep_class <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    <span class="keyword">if</span> k == <span class="number">0</span>:</span><br><span class="line">        index = <span class="number">10</span></span><br><span class="line">        class_feature(k, index)</span><br><span class="line">    <span class="keyword">elif</span> k == <span class="number">1</span>:</span><br><span class="line">        index = <span class="number">9</span></span><br><span class="line">        class_feature(k, index)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        index = <span class="number">8</span></span><br><span class="line">        class_feature(k, index)</span><br></pre></td></tr></table></figure><p>保存名字为 <strong>features_section_class</strong></p><p>然后将其取平均值，并绘制柱状图</p><h2 id="分类结果"><a href="#分类结果" class="headerlink" title="分类结果"></a>分类结果</h2><p>文件保存为：</p><p>E:\feature section</p><p> <strong>features_section_class</strong>是降维后</p><p> <strong>feature_section_class</strong> 是最开始的数据分类结果</p><p>经过查看，在即使在最高分期准确率的结果下，都会出现数据一部分特别好一部分都很差的情况</p><p>暂时只进行数据的平均分类准确率，然后筛选出最优的分类模型，比较每个模型中最优的结果</p><p>然后再去考虑单独的人，为什么会差距这么大，是什么因素影响了分期准确率</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">           <span class="number">0</span>         <span class="number">1</span>         <span class="number">2</span>  ...         <span class="number">6</span>         <span class="number">7</span>         <span class="number">8</span></span><br><span class="line"><span class="number">0</span>   <span class="number">0.785217</span>  <span class="number">0.862609</span>  <span class="number">0.828406</span>  ...  <span class="number">0.874493</span>  <span class="number">0.879130</span>  <span class="number">0.882029</span></span><br><span class="line"><span class="number">1</span>   <span class="number">0.789143</span>  <span class="number">0.824000</span>  <span class="number">0.843429</span>  ...  <span class="number">0.844952</span>  <span class="number">0.845714</span>  <span class="number">0.847810</span></span><br><span class="line"><span class="number">2</span>   <span class="number">0.834667</span>  <span class="number">0.866286</span>  <span class="number">0.857714</span>  ...  <span class="number">0.848381</span>  <span class="number">0.853524</span>  <span class="number">0.860381</span></span><br><span class="line"><span class="number">3</span>   <span class="number">0.881538</span>  <span class="number">0.890000</span>  <span class="number">0.886154</span>  ...  <span class="number">0.881795</span>  <span class="number">0.864615</span>  <span class="number">0.898718</span></span><br><span class="line"><span class="number">4</span>   <span class="number">0.601373</span>  <span class="number">0.694902</span>  <span class="number">0.687745</span>  ...  <span class="number">0.756569</span>  <span class="number">0.765588</span>  <span class="number">0.768333</span></span><br><span class="line"><span class="number">5</span>   <span class="number">0.754366</span>  <span class="number">0.805540</span>  <span class="number">0.804131</span>  ...  <span class="number">0.850704</span>  <span class="number">0.847512</span>  <span class="number">0.827793</span></span><br><span class="line"><span class="number">6</span>   <span class="number">0.615450</span>  <span class="number">0.674597</span>  <span class="number">0.664171</span>  ...  <span class="number">0.706161</span>  <span class="number">0.702749</span>  <span class="number">0.715735</span></span><br><span class="line"><span class="number">7</span>   <span class="number">0.754732</span>  <span class="number">0.831122</span>  <span class="number">0.803415</span>  ...  <span class="number">0.840293</span>  <span class="number">0.824195</span>  <span class="number">0.845951</span></span><br><span class="line"><span class="number">8</span>   <span class="number">0.811746</span>  <span class="number">0.826984</span>  <span class="number">0.831429</span>  ...  <span class="number">0.822751</span>  <span class="number">0.834921</span>  <span class="number">0.844339</span></span><br><span class="line"><span class="number">9</span>   <span class="number">0.915749</span>  <span class="number">0.928309</span>  <span class="number">0.927246</span>  ...  <span class="number">0.941739</span>  <span class="number">0.935556</span>  <span class="number">0.938744</span></span><br><span class="line"><span class="number">10</span>  <span class="number">0.535238</span>  <span class="number">0.640173</span>  <span class="number">0.591602</span>  ...  <span class="number">0.674026</span>  <span class="number">0.670216</span>  <span class="number">0.669524</span></span><br><span class="line"><span class="number">11</span>  <span class="number">0.695733</span>  <span class="number">0.780800</span>  <span class="number">0.759822</span>  ...  <span class="number">0.809689</span>  <span class="number">0.798489</span>  <span class="number">0.795289</span></span><br><span class="line"><span class="number">12</span>  <span class="number">0.640356</span>  <span class="number">0.700889</span>  <span class="number">0.687911</span>  ...  <span class="number">0.690844</span>  <span class="number">0.696978</span>  <span class="number">0.705422</span></span><br><span class="line"><span class="number">13</span>  <span class="number">0.694667</span>  <span class="number">0.804148</span>  <span class="number">0.751852</span>  ...  <span class="number">0.786519</span>  <span class="number">0.801037</span>  <span class="number">0.811556</span></span><br><span class="line"><span class="number">14</span>  <span class="number">0.803824</span>  <span class="number">0.833137</span>  <span class="number">0.834608</span>  ...  <span class="number">0.841373</span>  <span class="number">0.833529</span>  <span class="number">0.850392</span></span><br><span class="line"><span class="number">15</span>  <span class="number">0.646479</span>  <span class="number">0.679531</span>  <span class="number">0.723192</span>  ...  <span class="number">0.772582</span>  <span class="number">0.776901</span>  <span class="number">0.803474</span></span><br><span class="line"><span class="number">16</span>  <span class="number">0.682636</span>  <span class="number">0.745271</span>  <span class="number">0.743101</span>  ...  <span class="number">0.760930</span>  <span class="number">0.770078</span>  <span class="number">0.758140</span></span><br><span class="line"><span class="number">17</span>  <span class="number">0.668372</span>  <span class="number">0.708837</span>  <span class="number">0.700465</span>  ...  <span class="number">0.719535</span>  <span class="number">0.696744</span>  <span class="number">0.721395</span></span><br></pre></td></tr></table></figure><p>如下表所示，有些列的数据对应起来就并不好，先基于平均值然后再去筛选为什么为地域80%的原因，找单独的数据序列，去对应查看其中的影响因素。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"> <span class="number">0</span>         <span class="number">1</span>         <span class="number">2</span>  ...         <span class="number">6</span>         <span class="number">7</span>         <span class="number">8</span></span><br><span class="line"><span class="number">0</span>   <span class="number">0.721449</span>  <span class="number">0.851304</span>  <span class="number">0.764348</span>  ...  <span class="number">0.848116</span>  <span class="number">0.836232</span>  <span class="number">0.851594</span></span><br><span class="line"><span class="number">1</span>   <span class="number">0.712571</span>  <span class="number">0.770095</span>  <span class="number">0.768381</span>  ...  <span class="number">0.808571</span>  <span class="number">0.814476</span>  <span class="number">0.769714</span></span><br><span class="line"><span class="number">2</span>   <span class="number">0.806476</span>  <span class="number">0.858286</span>  <span class="number">0.844000</span>  ...  <span class="number">0.837524</span>  <span class="number">0.842095</span>  <span class="number">0.861905</span></span><br><span class="line"><span class="number">3</span>   <span class="number">0.818205</span>  <span class="number">0.846154</span>  <span class="number">0.870513</span>  ...  <span class="number">0.854103</span>  <span class="number">0.851538</span>  <span class="number">0.856410</span></span><br><span class="line"><span class="number">4</span>   <span class="number">0.495882</span>  <span class="number">0.645000</span>  <span class="number">0.575392</span>  ...  <span class="number">0.700294</span>  <span class="number">0.696961</span>  <span class="number">0.682059</span></span><br><span class="line"><span class="number">5</span>   <span class="number">0.720845</span>  <span class="number">0.784695</span>  <span class="number">0.757934</span>  ...  <span class="number">0.818592</span>  <span class="number">0.814554</span>  <span class="number">0.764225</span></span><br><span class="line"><span class="number">6</span>   <span class="number">0.521991</span>  <span class="number">0.613175</span>  <span class="number">0.576967</span>  ...  <span class="number">0.637820</span>  <span class="number">0.638768</span>  <span class="number">0.635735</span></span><br><span class="line"><span class="number">7</span>   <span class="number">0.676488</span>  <span class="number">0.782634</span>  <span class="number">0.677366</span>  ...  <span class="number">0.799707</span>  <span class="number">0.803220</span>  <span class="number">0.807902</span></span><br><span class="line"><span class="number">8</span>   <span class="number">0.782540</span>  <span class="number">0.819153</span>  <span class="number">0.817460</span>  ...  <span class="number">0.810794</span>  <span class="number">0.820106</span>  <span class="number">0.832698</span></span><br><span class="line"><span class="number">9</span>   <span class="number">0.906377</span>  <span class="number">0.917005</span>  <span class="number">0.916908</span>  ...  <span class="number">0.920000</span>  <span class="number">0.916908</span>  <span class="number">0.920483</span></span><br><span class="line"><span class="number">10</span>  <span class="number">0.484762</span>  <span class="number">0.586667</span>  <span class="number">0.511688</span>  ...  <span class="number">0.642511</span>  <span class="number">0.638182</span>  <span class="number">0.614978</span></span><br><span class="line"><span class="number">11</span>  <span class="number">0.683378</span>  <span class="number">0.739111</span>  <span class="number">0.730667</span>  ...  <span class="number">0.785156</span>  <span class="number">0.779111</span>  <span class="number">0.758222</span></span><br><span class="line"><span class="number">12</span>  <span class="number">0.637956</span>  <span class="number">0.688356</span>  <span class="number">0.688267</span>  ...  <span class="number">0.670578</span>  <span class="number">0.679467</span>  <span class="number">0.688533</span></span><br><span class="line"><span class="number">13</span>  <span class="number">0.528741</span>  <span class="number">0.705778</span>  <span class="number">0.642519</span>  ...  <span class="number">0.723852</span>  <span class="number">0.733333</span>  <span class="number">0.690519</span></span><br><span class="line"><span class="number">14</span>  <span class="number">0.736569</span>  <span class="number">0.810686</span>  <span class="number">0.774216</span>  ...  <span class="number">0.818431</span>  <span class="number">0.817647</span>  <span class="number">0.819118</span></span><br><span class="line"><span class="number">15</span>  <span class="number">0.490704</span>  <span class="number">0.595869</span>  <span class="number">0.573052</span>  ...  <span class="number">0.724413</span>  <span class="number">0.706291</span>  <span class="number">0.639531</span></span><br><span class="line"><span class="number">16</span>  <span class="number">0.666977</span>  <span class="number">0.746202</span>  <span class="number">0.727907</span>  ...  <span class="number">0.754884</span>  <span class="number">0.753488</span>  <span class="number">0.760310</span></span><br><span class="line"><span class="number">17</span>  <span class="number">0.595814</span>  <span class="number">0.668372</span>  <span class="number">0.650233</span>  ...  <span class="number">0.676279</span>  <span class="number">0.657209</span>  <span class="number">0.696279</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/6/24</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最高准确率时对应特征数，对应的分类准确率</span></span><br><span class="line">feature = pd.read_excel(<span class="string">'E:/feature section'</span> + <span class="string">'/feature_section_class'</span> + <span class="string">'%s'</span> % <span class="number">1</span> + <span class="string">'.xlsx'</span>)</span><br><span class="line">data = pd.get_dummies(feature.iloc[<span class="number">0</span>:len(feature), <span class="number">1</span>:])</span><br><span class="line">data.rename(columns=&#123;<span class="number">0</span>: <span class="string">'SGD'</span>, <span class="number">1</span>: <span class="string">'SVM'</span>, <span class="number">2</span>: <span class="string">'LSVM'</span>, <span class="number">3</span>: <span class="string">'LR'</span>, <span class="number">4</span>: <span class="string">'KNN'</span>, <span class="number">5</span>: <span class="string">'DT'</span>, <span class="number">6</span>: <span class="string">'RF'</span>, <span class="number">7</span>: <span class="string">'GBT'</span>, <span class="number">8</span>: <span class="string">'NN'</span>&#125;, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 经过1%牺牲后的分类准确率</span></span><br><span class="line">section = pd.read_excel(<span class="string">'E:/feature section'</span> + <span class="string">'/features_section_class'</span> + <span class="string">'%s'</span> % <span class="number">1</span> + <span class="string">'.xlsx'</span>)</span><br><span class="line">df = pd.get_dummies(section.iloc[<span class="number">0</span>:len(section), <span class="number">1</span>:])</span><br><span class="line">df.rename(columns=&#123;<span class="number">0</span>: <span class="string">'SGD'</span>, <span class="number">1</span>: <span class="string">'SVM'</span>, <span class="number">2</span>: <span class="string">'LSVM'</span>, <span class="number">3</span>: <span class="string">'LR'</span>, <span class="number">4</span>: <span class="string">'KNN'</span>, <span class="number">5</span>: <span class="string">'DT'</span>, <span class="number">6</span>: <span class="string">'RF'</span>, <span class="number">7</span>: <span class="string">'GBT'</span>, <span class="number">8</span>: <span class="string">'NN'</span>&#125;, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">9</span>)</span><br><span class="line">y1 = [(np.array([np.array(data).tolist()[i][j] * <span class="number">100</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">18</span>)])).mean() <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">9</span>)]</span><br><span class="line">y2 = [(np.array([np.array(df).tolist()[i][j] * <span class="number">100</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">18</span>)])).mean() <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">9</span>)]</span><br><span class="line"></span><br><span class="line">width = <span class="number">0.4</span></span><br><span class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'Microsoft YaHei'</span>]</span><br><span class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">7</span>, <span class="number">5</span>))</span><br><span class="line">rects1 = ax.bar(x - width/<span class="number">2</span>, y1, width, color=<span class="string">'SkyBlue'</span>, label=<span class="string">'Before dimensionality reduction'</span>)</span><br><span class="line">rects2 = ax.bar(x + width/<span class="number">2</span>, y2, width, color=<span class="string">'IndianRed'</span>, label=<span class="string">'After dimensionality reduction'</span>)</span><br><span class="line"></span><br><span class="line">plt.xticks(x, (df.keys()), fontsize=<span class="number">10</span>, rotation=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">plt.ylabel(<span class="string">'Average Accuracy/%'</span>, fontsize=<span class="number">15</span>)</span><br><span class="line">ax.set_title(<span class="string">'DLRW主题下降维前后准确率对比'</span>, fontsize=<span class="number">15</span>)</span><br><span class="line">ax.legend()</span><br><span class="line">plt.ylim((<span class="number">60</span>, <span class="number">95</span>))</span><br><span class="line">new_ticks = np.linspace(<span class="number">60</span>, <span class="number">95</span>, <span class="number">5</span>)</span><br><span class="line">plt.yticks(new_ticks, fontsize=<span class="number">10</span>)</span><br><span class="line"><span class="keyword">for</span> y <span class="keyword">in</span> rects1+rects2:</span><br><span class="line">    h = y.get_height()</span><br><span class="line">    ax.text(y.get_x()+y.get_width()/<span class="number">2</span>, h, <span class="string">'%.1f'</span> % h, ha=<span class="string">'center'</span>, va=<span class="string">'bottom'</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">plt.show()</span><br><span class="line">fig.savefig(<span class="string">'feature_class4_number.png'</span>, dpi=<span class="number">1600</span>, bbox_inches=<span class="string">'tight'</span>)</span><br></pre></td></tr></table></figure><p>感觉效果并不好，考虑下一个步骤</p><p><img src="/images/feature_class3_number.png" alt="feature_class3_number"></p><p><img src="http://b-ssl.duitang.com/uploads/item/201610/09/20161009160331_YNsHu.jpeg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;不同特征数之间的分类模型比较&quot;&gt;&lt;a href=&quot;#不同特征数之间的分类模型比较&quot; class=&quot;headerlink&quot; title=&quot;不同特征数之间的分类模型比较&quot;&gt;&lt;/a&gt;不同特征数之间的分类模型比较&lt;/h1&gt;&lt;p&gt;首先确定特征的个数，确定index和特征数之
      
    
    </summary>
    
    
      <category term="work" scheme="https://esyyes.github.io/categories/work/"/>
    
    
      <category term="work" scheme="https://esyyes.github.io/tags/work/"/>
    
  </entry>
  
  <entry>
    <title>特征数的确定</title>
    <link href="https://esyyes.github.io/2020/06/24/sleep%20apnea%20and%20sleep%20stage/%E7%89%B9%E5%BE%81%E6%95%B0%E7%9A%84%E7%A1%AE%E5%AE%9A/"/>
    <id>https://esyyes.github.io/2020/06/24/sleep%20apnea%20and%20sleep%20stage/%E7%89%B9%E5%BE%81%E6%95%B0%E7%9A%84%E7%A1%AE%E5%AE%9A/</id>
    <published>2020-06-24T01:42:09.000Z</published>
    <updated>2020-06-24T01:42:09.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="特征数的确定"><a href="#特征数的确定" class="headerlink" title="特征数的确定"></a>特征数的确定</h1><p>经过50次平均值筛选后，可看出对应3分期时，特征数为15,4、5分期的特征数都为23，此时为最高的特征值。</p><p><img src="/images/features_section.png" alt="features section"></p><p>为了确定特征数对准确率的影响，第一个方案</p><p>选择(10-22)个特征，将每个特征都用于分类，然后将对比看看分类的结果</p><h2 id="特征缩减"><a href="#特征缩减" class="headerlink" title="特征缩减"></a>特征缩减</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/6/17</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> data_preprocessing <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> classifiers <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> range(<span class="number">10</span>, <span class="number">22</span>):</span><br><span class="line">    class_scores = []</span><br><span class="line">    kappa_scores = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">19</span>):</span><br><span class="line">        feature = pd.read_excel(<span class="string">'D:/zccode/all_feature'</span> + <span class="string">'/features'</span> + <span class="string">'%s'</span> % i + <span class="string">'.xlsx'</span>)</span><br><span class="line">        data = pd.get_dummies(feature.iloc[<span class="number">0</span>:len(feature), <span class="number">1</span>:])</span><br><span class="line">        note = pd.read_excel(<span class="string">'D:/zccode/all_note'</span> + <span class="string">'/note'</span> + <span class="string">'%s'</span> % i + <span class="string">'.xlsx'</span>)</span><br><span class="line">        tag = pd.get_dummies(note.iloc[<span class="number">0</span>:len(data), <span class="number">1</span>:])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 选定固定的特征值</span></span><br><span class="line">        feature_import = pd.read_excel(<span class="string">'D:/zccode'</span> + <span class="string">'/feature_important'</span> + <span class="string">'%s'</span> % <span class="number">2</span> + <span class="string">'.xlsx'</span>)</span><br><span class="line">        df = pd.get_dummies(feature_import.iloc[<span class="number">0</span>:len(feature_import), <span class="number">1</span>:index])</span><br><span class="line"></span><br><span class="line">        std_data = data_pre(data[df.keys()])</span><br><span class="line">        label = pd.get_dummies(tag.iloc[<span class="number">0</span>:len(data), <span class="number">1</span>:<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">        class_score = []</span><br><span class="line">        kappa_score = []</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">50</span>):</span><br><span class="line">            X_train, X_test, y_train, y_test = train_test_split(std_data, label, test_size=<span class="number">0.3</span>)</span><br><span class="line">            score = run_classifiers(X_train, X_test, y_train, y_test)</span><br><span class="line">            class_score.append(score[<span class="number">0</span>])</span><br><span class="line">            kappa_score.append(score[<span class="number">1</span>])</span><br><span class="line">        class_scores.append([(np.array([class_score[a][k] <span class="keyword">for</span> a <span class="keyword">in</span> range(<span class="number">50</span>)])).mean() <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">9</span>)])</span><br><span class="line">        kappa_scores.append([(np.array([kappa_score[a][k] <span class="keyword">for</span> a <span class="keyword">in</span> range(<span class="number">50</span>)])).mean() <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">9</span>)])</span><br><span class="line">        print(<span class="string">f'已经运行<span class="subst">&#123;i&#125;</span>次'</span>)</span><br><span class="line"></span><br><span class="line">    class_total = pd.DataFrame(class_scores)</span><br><span class="line">    kappa_total = pd.DataFrame(kappa_scores)</span><br><span class="line">    class_total.to_excel(<span class="string">'no RFE classf'</span> + <span class="string">'%d'</span> % index + <span class="string">".xlsx"</span>)</span><br><span class="line">    kappa_total.to_excel(<span class="string">'no RFE kappaf'</span> + <span class="string">'%d'</span> % index + <span class="string">".xlsx"</span>)</span><br></pre></td></tr></table></figure><p>此次方案，在进行分类时，直接选用的是固定的特征，即迭代50次特征贡献度，平均后的结果，用固定特征对应的特征数，去进行分类。</p><h2 id="分类模型"><a href="#分类模型" class="headerlink" title="分类模型"></a>分类模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/6/15</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVC</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> cohen_kappa_score</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_rf</span><span class="params">(train_x, test_x, train_y, test_y)</span>:</span></span><br><span class="line">    clf = RandomForestClassifier()</span><br><span class="line">    clf.fit(train_x, train_y)</span><br><span class="line">    pred_y = clf.predict(test_x)</span><br><span class="line">    acr = accuracy_score(test_y, pred_y)</span><br><span class="line">    kappa = cohen_kappa_score(test_y, pred_y)</span><br><span class="line">    <span class="keyword">return</span> [acr, kappa]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_gbt</span><span class="params">(train_x, test_x, train_y, test_y)</span>:</span></span><br><span class="line">    clf = GradientBoostingClassifier()</span><br><span class="line">    clf.fit(train_x, train_y)</span><br><span class="line">    pred_y = clf.predict(test_x)</span><br><span class="line">    acr = accuracy_score(test_y, pred_y)</span><br><span class="line">    kappa = cohen_kappa_score(test_y, pred_y)</span><br><span class="line">    <span class="keyword">return</span> [acr, kappa]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_knn</span><span class="params">(train_x, test_x, train_y, test_y)</span>:</span></span><br><span class="line">    clf = KNeighborsClassifier()</span><br><span class="line">    clf.fit(train_x, train_y)</span><br><span class="line">    pred_y = clf.predict(test_x)</span><br><span class="line">    acr = accuracy_score(test_y, pred_y)</span><br><span class="line">    kappa = cohen_kappa_score(test_y, pred_y)</span><br><span class="line">    <span class="keyword">return</span> [acr, kappa]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_dt</span><span class="params">(train_x, test_x, train_y, test_y)</span>:</span></span><br><span class="line">    clf = DecisionTreeClassifier()</span><br><span class="line">    clf.fit(train_x, train_y)</span><br><span class="line">    pred_y = clf.predict(test_x)</span><br><span class="line">    acr = accuracy_score(test_y, pred_y)</span><br><span class="line">    kappa = cohen_kappa_score(test_y, pred_y)</span><br><span class="line">    <span class="keyword">return</span> [acr, kappa]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_svm</span><span class="params">(train_x, test_x, train_y, test_y)</span>:</span></span><br><span class="line">    clf = SVC()</span><br><span class="line">    clf.fit(train_x, train_y)</span><br><span class="line">    pred_y = clf.predict(test_x)</span><br><span class="line">    acr = accuracy_score(test_y, pred_y)</span><br><span class="line">    kappa = cohen_kappa_score(test_y, pred_y)</span><br><span class="line">    <span class="keyword">return</span> [acr, kappa]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_lsvm</span><span class="params">(train_x, test_x, train_y, test_y)</span>:</span></span><br><span class="line">    clf = LinearSVC()</span><br><span class="line">    clf.fit(train_x, train_y)</span><br><span class="line">    pred_y = clf.predict(test_x)</span><br><span class="line">    acr = accuracy_score(test_y, pred_y)</span><br><span class="line">    kappa = cohen_kappa_score(test_y, pred_y)</span><br><span class="line">    <span class="keyword">return</span> [acr, kappa]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_lr</span><span class="params">(train_x, test_x, train_y, test_y)</span>:</span></span><br><span class="line">    clf = LogisticRegression()</span><br><span class="line">    clf.fit(train_x, train_y)</span><br><span class="line">    pred_y = clf.predict(test_x)</span><br><span class="line">    acr = accuracy_score(test_y, pred_y)</span><br><span class="line">    kappa = cohen_kappa_score(test_y, pred_y)</span><br><span class="line">    <span class="keyword">return</span> [acr, kappa]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_ml</span><span class="params">(train_x, test_x, train_y, test_y)</span>:</span></span><br><span class="line">    clf = MLPClassifier()</span><br><span class="line">    clf.fit(train_x, train_y)</span><br><span class="line">    pred_y = clf.predict(test_x)</span><br><span class="line">    acr = accuracy_score(test_y, pred_y)</span><br><span class="line">    kappa = cohen_kappa_score(test_y, pred_y)</span><br><span class="line">    <span class="keyword">return</span> [acr, kappa]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_sgd</span><span class="params">(train_x, test_x, train_y, test_y)</span>:</span></span><br><span class="line">    clf = SGDClassifier()</span><br><span class="line">    clf.fit(train_x, train_y)</span><br><span class="line">    pred_y = clf.predict(test_x)</span><br><span class="line">    acr = accuracy_score(test_y, pred_y)</span><br><span class="line">    kappa = cohen_kappa_score(test_y, pred_y)</span><br><span class="line">    <span class="keyword">return</span> [acr, kappa]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 直接运行结果</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_classifiers</span><span class="params">(train_x, test_x, train_y, test_y)</span>:</span></span><br><span class="line">    rf = run_rf(train_x, test_x, train_y, test_y)</span><br><span class="line">    gbt = run_gbt(train_x, test_x, train_y, test_y)</span><br><span class="line">    knn = run_knn(train_x, test_x, train_y, test_y)</span><br><span class="line">    dt = run_dt(train_x, test_x, train_y, test_y)</span><br><span class="line">    svm = run_svm(train_x, test_x, train_y, test_y)</span><br><span class="line">    lsvm = run_lsvm(train_x, test_x, train_y, test_y)</span><br><span class="line">    lr = run_lr(train_x, test_x, train_y, test_y)</span><br><span class="line">    ml = run_ml(train_x, test_x, train_y, test_y)</span><br><span class="line">    sgd = run_sgd(train_x, test_x, train_y, test_y)</span><br><span class="line"></span><br><span class="line">    class_s = [sgd[<span class="number">0</span>], svm[<span class="number">0</span>], lsvm[<span class="number">0</span>], lr[<span class="number">0</span>], knn[<span class="number">0</span>], dt[<span class="number">0</span>], rf[<span class="number">0</span>], gbt[<span class="number">0</span>], ml[<span class="number">0</span>]]</span><br><span class="line"></span><br><span class="line">    kappa_s = [sgd[<span class="number">1</span>], svm[<span class="number">1</span>], lsvm[<span class="number">1</span>], lr[<span class="number">1</span>], knn[<span class="number">1</span>], dt[<span class="number">1</span>], rf[<span class="number">1</span>], gbt[<span class="number">1</span>], ml[<span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [class_s, kappa_s]</span><br></pre></td></tr></table></figure><p>分类模型对应的为以下9种，并分别计算出的kappa值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[sgd[<span class="number">0</span>], svm[<span class="number">0</span>], lsvm[<span class="number">0</span>], lr[<span class="number">0</span>], knn[<span class="number">0</span>], dt[<span class="number">0</span>], rf[<span class="number">0</span>], gbt[<span class="number">0</span>], ml[<span class="number">0</span>]]</span><br></pre></td></tr></table></figure><p>文件保存为： E:\sleep_stage</p><p>例如：no RFE class10.xlsx</p><p><strong>10其实对应的是9，在index中，而且不一定对应的是9还可能是对应的8，这点待会儿还需要检验下，直接进行最高的和牺牲对比的</strong></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>对比结果发现，特征越多，准确率越高，在其他分类模型中，随机森林相对变化不大</p><h2 id="方案二"><a href="#方案二" class="headerlink" title="方案二"></a>方案二</h2><h3 id="最大准确率"><a href="#最大准确率" class="headerlink" title="最大准确率"></a>最大准确率</h3><p>虽然此时的max对应的特征数已经确定，但是可以明显看出，从特征数7-9这些开始已经没有太多的明显变化</p><p>所以为了进一步的缩减特征值，在此次方案中采取牺牲1%的准确率，来降低特征数的方针。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/6/24</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line"></span><br><span class="line">all_section = []</span><br><span class="line"><span class="keyword">for</span> q <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    data = pd.read_excel(<span class="string">'E:/features'</span> + <span class="string">'/themes'</span> + <span class="string">'%s'</span> % q + <span class="string">'.xlsx'</span>)</span><br><span class="line">    train_data = np.array(data).tolist()</span><br><span class="line">    list_mean = [[np.array([eval(train_data[i][k])[j] <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">50</span>)]).mean() <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">25</span>)] <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">18</span>)]</span><br><span class="line">    feature_section = [np.array([list_mean[j][i] * <span class="number">100</span> <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">18</span>)]).mean() <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">25</span>)]</span><br><span class="line">    all_section.append(feature_section)</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">1</span>, <span class="number">26</span>)</span><br><span class="line">class_5 = all_section[<span class="number">0</span>]</span><br><span class="line">class_4 = all_section[<span class="number">1</span>]</span><br><span class="line">class_3 = all_section[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">class_num = [x[all_section[i].index(max(all_section[i]))] <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>)]</span><br><span class="line">class_max = [max(all_section[i]) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>)]</span><br></pre></td></tr></table></figure><p>先找到对应的最大值对应的位置class_num和值class_max</p><p>[23, 23, 15]</p><p>[79.64724146295774, 86.40048338502821, 89.03929260177847]</p><p>来个制表符，直接输出，让他看起来好看点</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    print(<span class="string">f'分期为<span class="subst">&#123;<span class="number">5</span>-i&#125;</span>时'</span>, end=<span class="string">'\t'</span>)</span><br><span class="line">    print(<span class="string">f'最高准确率为%.2f%%'</span> % max(all_section[i]), end=<span class="string">'\t'</span>)</span><br><span class="line">    print(<span class="string">f'特征数为<span class="subst">&#123;x[all_section[i].index(max(all_section[i]))]&#125;</span>'</span>)</span><br></pre></td></tr></table></figure><p>输出要%时，即为%%</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">分期为<span class="number">5</span>时最高准确率为<span class="number">79.65</span>%特征数为<span class="number">23</span></span><br><span class="line">分期为<span class="number">4</span>时最高准确率为<span class="number">86.40</span>%特征数为<span class="number">23</span></span><br><span class="line">分期为<span class="number">3</span>时最高准确率为<span class="number">89.04</span>%特征数为<span class="number">15</span></span><br></pre></td></tr></table></figure><h3 id="降低1-后对应结果"><a href="#降低1-后对应结果" class="headerlink" title="降低1%后对应结果"></a>降低1%后对应结果</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">f'准确率降低1%后对应的特征数'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    print(<span class="string">f'分期为<span class="subst">&#123;<span class="number">5</span>-i&#125;</span>时'</span>, end=<span class="string">'\t'</span>)</span><br><span class="line">    print(<span class="string">f'最高准确率为%.2f%%'</span> % max(all_section[i]), end=<span class="string">'\t'</span>)</span><br><span class="line">    print(<span class="string">f'最高准确率降低1%%后为%.2f%%'</span> % (max(all_section[i]) * <span class="number">0.99</span>), end=<span class="string">'\t'</span>)</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(all_section[i])):</span><br><span class="line">        <span class="keyword">if</span> (max(all_section[i]) * <span class="number">0.99</span>) &lt; all_section[i][j]:</span><br><span class="line">            print(<span class="string">f'比较筛选的准确率为%.2f%%'</span> % (all_section[i][j]), end=<span class="string">'\t'</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    print(<span class="string">f'特征数为<span class="subst">&#123;x[all_section[i].index(all_section[i][j])]&#125;</span>'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">最大准确率时对应的特征数</span><br><span class="line">分期为<span class="number">5</span>时最高准确率为<span class="number">79.65</span>%特征数为<span class="number">23</span></span><br><span class="line">分期为<span class="number">4</span>时最高准确率为<span class="number">86.40</span>%特征数为<span class="number">23</span></span><br><span class="line">分期为<span class="number">3</span>时最高准确率为<span class="number">89.04</span>%特征数为<span class="number">15</span></span><br><span class="line">准确率降低<span class="number">1</span>%后对应的特征数</span><br><span class="line">分期为<span class="number">5</span>时最高准确率为<span class="number">79.65</span>%最高准确率降低<span class="number">1</span>%后为<span class="number">78.85</span>%比较筛选的准确率为<span class="number">78.86</span>%特征数为<span class="number">9</span></span><br><span class="line">分期为<span class="number">4</span>时最高准确率为<span class="number">86.40</span>%最高准确率降低<span class="number">1</span>%后为<span class="number">85.54</span>%比较筛选的准确率为<span class="number">85.66</span>%特征数为<span class="number">8</span></span><br><span class="line">分期为<span class="number">3</span>时最高准确率为<span class="number">89.04</span>%最高准确率降低<span class="number">1</span>%后为<span class="number">88.15</span>%比较筛选的准确率为<span class="number">88.22</span>%特征数为<span class="number">7</span></span><br></pre></td></tr></table></figure><p><img src="http://pic1.win4000.com/wallpaper/1/5450829edeb96.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;特征数的确定&quot;&gt;&lt;a href=&quot;#特征数的确定&quot; class=&quot;headerlink&quot; title=&quot;特征数的确定&quot;&gt;&lt;/a&gt;特征数的确定&lt;/h1&gt;&lt;p&gt;经过50次平均值筛选后，可看出对应3分期时，特征数为15,4、5分期的特征数都为23，此时为最高的特征值。&lt;
      
    
    </summary>
    
    
      <category term="work" scheme="https://esyyes.github.io/categories/work/"/>
    
    
      <category term="work" scheme="https://esyyes.github.io/tags/work/"/>
    
  </entry>
  
  <entry>
    <title>绘制特征重要度筛选结果</title>
    <link href="https://esyyes.github.io/2020/06/24/sleep%20apnea%20and%20sleep%20stage/%E7%BB%98%E5%88%B6%E7%89%B9%E5%BE%81%E9%87%8D%E8%A6%81%E5%BA%A6%E7%AD%9B%E9%80%89%E7%BB%93%E6%9E%9C/"/>
    <id>https://esyyes.github.io/2020/06/24/sleep%20apnea%20and%20sleep%20stage/%E7%BB%98%E5%88%B6%E7%89%B9%E5%BE%81%E9%87%8D%E8%A6%81%E5%BA%A6%E7%AD%9B%E9%80%89%E7%BB%93%E6%9E%9C/</id>
    <published>2020-06-24T00:59:32.000Z</published>
    <updated>2020-06-24T00:59:32.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="绘制特征重要度筛选结果"><a href="#绘制特征重要度筛选结果" class="headerlink" title="绘制特征重要度筛选结果"></a>绘制特征重要度筛选结果</h1><p>基于全部特征的提取和标签处理，初步设定RFE-RF筛选特征时，设定的重要度中的特征个数index为26，即在25个特征之间进行排查。</p><h2 id="输出特征重要度"><a href="#输出特征重要度" class="headerlink" title="输出特征重要度"></a>输出特征重要度</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/6/12</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> data_preprocessing <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_rf</span><span class="params">(xtrain, xtest, ytrain, ytest)</span>:</span></span><br><span class="line">    clf = RandomForestClassifier()</span><br><span class="line">    clf.fit(xtrain, ytrain)</span><br><span class="line">    ypred = clf.predict(xtest)</span><br><span class="line">    sad = accuracy_score(ytest, ypred)</span><br><span class="line">    <span class="keyword">return</span> sad</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    print(<span class="string">f'在标签<span class="subst">&#123;k&#125;</span>下的特征文件'</span>)</span><br><span class="line">    se = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">19</span>):</span><br><span class="line">        feature = pd.read_excel(<span class="string">'D:/zccode/all_feature'</span> + <span class="string">'/features'</span> + <span class="string">'%s'</span> % i + <span class="string">'.xlsx'</span>)</span><br><span class="line">        data = pd.get_dummies(feature.iloc[<span class="number">0</span>:len(feature), <span class="number">1</span>:])</span><br><span class="line">        note = pd.read_excel(<span class="string">'D:/zccode/all_note'</span> + <span class="string">'/note'</span> + <span class="string">'%s'</span> % i + <span class="string">'.xlsx'</span>)</span><br><span class="line">        tag = pd.get_dummies(note.iloc[<span class="number">0</span>:len(data), <span class="number">1</span>:])</span><br><span class="line">        df = data_pre(data)</span><br><span class="line">        label = pd.get_dummies(tag.iloc[<span class="number">0</span>:len(data), k:k+<span class="number">1</span>])</span><br><span class="line">        acr = []</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">50</span>):</span><br><span class="line">            X_train, X_test, y_train, y_test = train_test_split(df, label, test_size=<span class="number">0.3</span>)</span><br><span class="line">            score = []</span><br><span class="line">            <span class="keyword">for</span> index <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">26</span>):</span><br><span class="line">                sel = RFE(RandomForestClassifier(random_state=<span class="number">0</span>), n_features_to_select=index)</span><br><span class="line">                sel.fit(X_train, y_train)</span><br><span class="line">                X_train_rfe = sel.transform(X_train)</span><br><span class="line">                X_test_rfe = sel.transform(X_test)</span><br><span class="line">                score.append(run_rf(X_train_rfe, X_test_rfe, y_train, y_test))</span><br><span class="line">            acr.append(score)</span><br><span class="line">        print(<span class="string">f'检测文件数为：%2d'</span> % i, end=<span class="string">'\t'</span>)</span><br><span class="line">        se.append(acr)</span><br><span class="line">        print()</span><br><span class="line">    sea = pd.DataFrame(se)</span><br><span class="line">    sea.to_excel(<span class="string">'themes'</span> + <span class="string">'%d'</span> % k + <span class="string">".xlsx"</span>)</span><br><span class="line">    print(<span class="string">f'运行主题<span class="subst">&#123;k&#125;</span>次'</span>)</span><br></pre></td></tr></table></figure><p>这个区间就为(1, 26)</p><p>进行了50次循环筛选，然后保存为文件为themes012,对应为分期结果543</p><p>保存在：  E:\features\themes012</p><h2 id="绘制50次平均重要度对应准确率"><a href="#绘制50次平均重要度对应准确率" class="headerlink" title="绘制50次平均重要度对应准确率"></a>绘制50次平均重要度对应准确率</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/6/18</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line"></span><br><span class="line">all_section = []</span><br><span class="line"><span class="keyword">for</span> q <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    data = pd.read_excel(<span class="string">'E:/features'</span> + <span class="string">'/themes'</span> + <span class="string">'%s'</span> % q + <span class="string">'.xlsx'</span>)</span><br><span class="line">    train_data = np.array(data).tolist()</span><br><span class="line">    list_mean = [[np.array([eval(train_data[i][k])[j] <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">50</span>)]).mean() <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">25</span>)] <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">18</span>)]</span><br><span class="line">    feature_section = [np.array([list_mean[j][i] * <span class="number">100</span> <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">18</span>)]).mean() <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">25</span>)]</span><br><span class="line">    all_section.append(feature_section)</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">1</span>, <span class="number">26</span>)</span><br><span class="line">class_5 = all_section[<span class="number">0</span>]</span><br><span class="line">class_4 = all_section[<span class="number">1</span>]</span><br><span class="line">class_3 = all_section[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">7</span>, <span class="number">4</span>))</span><br><span class="line"><span class="comment"># 解决中文显示问题</span></span><br><span class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'Microsoft YaHei'</span>]</span><br><span class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">plt.xticks(x)</span><br><span class="line">plt.plot(x, class_5, <span class="string">"k*--"</span>, linewidth=<span class="number">1</span>, label=<span class="string">'class_5'</span>)</span><br><span class="line">plt.plot(x, class_4, <span class="string">"bo--"</span>, linewidth=<span class="number">1</span>, label=<span class="string">'class_5'</span>)</span><br><span class="line">plt.plot(x, class_3, <span class="string">"ro--"</span>, linewidth=<span class="number">1</span>, label=<span class="string">'class_5'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    plt.scatter(x[all_section[i].index(max(all_section[i]))], max(all_section[i]), s=<span class="number">100</span>, color=<span class="string">'r'</span>)</span><br><span class="line">    plt.text(x[all_section[i].index(max(all_section[i]))], max(all_section[i])<span class="number">-2</span>, <span class="string">r's'</span>,</span><br><span class="line">             fontdict=&#123;<span class="string">'size'</span>: <span class="string">'10'</span>, <span class="string">'color'</span>: <span class="string">'k'</span>&#125;)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">"Number of Features"</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">plt.xticks(fontsize=<span class="number">8</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Average Accuracy of RF/%"</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">plt.yticks(fontsize=<span class="number">8</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">ax = plt.gca()</span><br><span class="line">ax.spines[<span class="string">'right'</span>].set_color(<span class="string">'none'</span>)</span><br><span class="line">ax.spines[<span class="string">'top'</span>].set_color(<span class="string">'none'</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line">fig.savefig(<span class="string">'features_section.png'</span>, dpi=<span class="number">1980</span>, bbox_inches=<span class="string">'tight'</span>)</span><br><span class="line"><span class="comment"># dpi可以控制图象的分辨率,bbox_inches可以剪除图表的空白部分</span></span><br></pre></td></tr></table></figure><p><img src="/images/features_section.png" alt="features section"></p><p>经过50次平均值筛选后，可看出对应3分期时，特征数为15,4、5分期的特征数都为23，此时为最高的特征值。</p><img src="/images/features_section.png" alt="features section"><h1 id="hexo-插入本地图片"><a href="#hexo-插入本地图片" class="headerlink" title="hexo 插入本地图片"></a>hexo 插入本地图片</h1><p>!【】用这个形式，但是根目录和插入的目录的不能再进行重叠，且斜杠为/images/features_section.png</p><p><img src="" alt="features section">用这个形式相同的道理，上面那个好用点</p><p>！【】（<a href="http://pic1.win4000.com/wallpaper/1/5993ff70bfac7.jpg）" target="_blank" rel="noopener">http://pic1.win4000.com/wallpaper/1/5993ff70bfac7.jpg）</a></p><p><img src="http://pic1.win4000.com/wallpaper/1/5993ff70bfac7.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;绘制特征重要度筛选结果&quot;&gt;&lt;a href=&quot;#绘制特征重要度筛选结果&quot; class=&quot;headerlink&quot; title=&quot;绘制特征重要度筛选结果&quot;&gt;&lt;/a&gt;绘制特征重要度筛选结果&lt;/h1&gt;&lt;p&gt;基于全部特征的提取和标签处理，初步设定RFE-RF筛选特征时，设定的
      
    
    </summary>
    
    
      <category term="work" scheme="https://esyyes.github.io/categories/work/"/>
    
    
      <category term="work" scheme="https://esyyes.github.io/tags/work/"/>
    
  </entry>
  
  <entry>
    <title>重要特征查看</title>
    <link href="https://esyyes.github.io/2020/06/18/sleep%20apnea%20and%20sleep%20stage/%E9%87%8D%E8%A6%81%E7%89%B9%E5%BE%81%E6%9F%A5%E7%9C%8B/"/>
    <id>https://esyyes.github.io/2020/06/18/sleep%20apnea%20and%20sleep%20stage/%E9%87%8D%E8%A6%81%E7%89%B9%E5%BE%81%E6%9F%A5%E7%9C%8B/</id>
    <published>2020-06-18T08:24:02.000Z</published>
    <updated>2020-06-18T08:24:02.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="重要特征查看"><a href="#重要特征查看" class="headerlink" title="重要特征查看"></a>重要特征查看</h1><p>目的：将睡眠分期中的345阶段的睡眠分期结果进行比较，查看特征对睡眠分期的影响,</p><p>筛选出特征贡献度最高的那几个，进行查看</p><p>程序：利用表格形式输出特征的排序</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/6/18</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 选定固定的特征值</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> h <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">4</span>):</span><br><span class="line">    feature_import = pd.read_excel(<span class="string">'E:/features'</span> + <span class="string">'/feature_important'</span> + <span class="string">'%s'</span> % h + <span class="string">'.xlsx'</span>)</span><br><span class="line">    df = pd.get_dummies(feature_import.iloc[<span class="number">0</span>:len(feature_import), <span class="number">1</span>:<span class="number">23</span>])</span><br><span class="line">    data = df.T</span><br><span class="line">    print(<span class="string">f'列写特征重要度排序'</span>, end=<span class="string">'\t'</span>)</span><br><span class="line">    print()</span><br><span class="line">    print(<span class="string">f'序号'</span>, end=<span class="string">'\t\t'</span>)</span><br><span class="line">    print(<span class="string">f'特征'</span>, end=<span class="string">'\t\t'</span>)</span><br><span class="line">    print(<span class="string">f'重要度'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">22</span>):</span><br><span class="line">        print(<span class="string">f'%2d'</span> % i, end=<span class="string">'\t'</span>)</span><br><span class="line">        print(<span class="string">f'%10s'</span> % df.keys()[i], end=<span class="string">'\t'</span>)</span><br><span class="line">        print(<span class="string">f'%0.3f'</span> % data[<span class="number">0</span>][i])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">序号特征 重要度</span><br><span class="line"> <span class="number">0</span>    <span class="number">5</span>pNN20<span class="number">0.021</span></span><br><span class="line"> <span class="number">1</span>     <span class="number">5</span>NN20<span class="number">0.021</span></span><br><span class="line"> <span class="number">2</span>    <span class="number">5</span>pNN50<span class="number">0.019</span></span><br><span class="line"> <span class="number">3</span>     <span class="number">5</span>NN50<span class="number">0.019</span></span><br><span class="line"> <span class="number">4</span>  <span class="number">5</span>p_RMSSD<span class="number">0.018</span></span><br><span class="line"> <span class="number">5</span>    <span class="number">5</span>p_var<span class="number">0.018</span></span><br><span class="line"> <span class="number">6</span>    <span class="number">5</span>csi50<span class="number">0.017</span></span><br><span class="line"> <span class="number">7</span>    <span class="number">5</span>csi30<span class="number">0.017</span></span><br><span class="line"> <span class="number">8</span>    <span class="number">5</span>csi10<span class="number">0.017</span></span><br><span class="line"> <span class="number">9</span>       <span class="number">5</span>HF<span class="number">0.017</span></span><br><span class="line"><span class="number">10</span>   <span class="number">5</span>p_skew<span class="number">0.017</span></span><br><span class="line"><span class="number">11</span>   <span class="number">5</span>p_SDNN<span class="number">0.017</span></span><br><span class="line"><span class="number">12</span> <span class="number">5</span>p_median<span class="number">0.017</span></span><br><span class="line"><span class="number">13</span>   <span class="number">5</span>R_mean<span class="number">0.016</span></span><br><span class="line"><span class="number">14</span>  <span class="number">5</span>HR_mean<span class="number">0.016</span></span><br><span class="line"><span class="number">15</span>    <span class="number">5</span>p_RMS<span class="number">0.015</span></span><br><span class="line"><span class="number">16</span>   <span class="number">5</span>p_mean<span class="number">0.015</span></span><br><span class="line"><span class="number">17</span>    <span class="number">5</span>p_max<span class="number">0.014</span></span><br><span class="line"><span class="number">18</span> <span class="number">5</span>R_median<span class="number">0.014</span></span><br><span class="line"><span class="number">19</span>     <span class="number">5</span>apen<span class="number">0.014</span></span><br><span class="line"><span class="number">20</span><span class="number">5</span>p_peak_factor<span class="number">0.014</span></span><br><span class="line"><span class="number">21</span>   <span class="number">5</span>csi100<span class="number">0.014</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">序号特征 重要度</span><br><span class="line"> 0     5NN200.024</span><br><span class="line"> 1    5pNN200.023</span><br><span class="line"> 2    5pNN500.023</span><br><span class="line"> 3     5NN500.022</span><br><span class="line"> 4   5p_skew0.020</span><br><span class="line"> 5       5HF0.018</span><br><span class="line"> 6 5p_median0.017</span><br><span class="line"> 7   5R_mean0.016</span><br><span class="line"> 8   5p_SDNN0.016</span><br><span class="line"> 9    5p_var0.016</span><br><span class="line">10    5p_RMS0.016</span><br><span class="line">11    5csi100.016</span><br><span class="line">12  5p_RMSSD0.016</span><br><span class="line">13   5R_CVSD0.016</span><br><span class="line">14    5p_max0.016</span><br><span class="line">15    5csi500.016</span><br><span class="line">16   5R_SDSD0.015</span><br><span class="line">17   5p_mean0.015</span><br><span class="line">18      5sd10.015</span><br><span class="line">19  5R_RMSSD0.015</span><br><span class="line">20   5HR_min0.015</span><br><span class="line">21     5apen0.015</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">序号特征 重要度</span><br><span class="line"> <span class="number">0</span>    <span class="number">5</span>pNN20<span class="number">0.026</span></span><br><span class="line"> <span class="number">1</span>     <span class="number">5</span>NN20<span class="number">0.025</span></span><br><span class="line"> <span class="number">2</span>    <span class="number">5</span>pNN50<span class="number">0.023</span></span><br><span class="line"> <span class="number">3</span>     <span class="number">5</span>NN50<span class="number">0.021</span></span><br><span class="line"> <span class="number">4</span>   <span class="number">5</span>R_mean<span class="number">0.019</span></span><br><span class="line"> <span class="number">5</span>   <span class="number">5</span>p_skew<span class="number">0.019</span></span><br><span class="line"> <span class="number">6</span>       <span class="number">5</span>HF<span class="number">0.018</span></span><br><span class="line"> <span class="number">7</span>   <span class="number">5</span>HR_min<span class="number">0.017</span></span><br><span class="line"> <span class="number">8</span> <span class="number">5</span>p_median<span class="number">0.017</span></span><br><span class="line"> <span class="number">9</span> <span class="number">5</span>R_median<span class="number">0.017</span></span><br><span class="line"><span class="number">10</span>     <span class="number">5</span>apen<span class="number">0.017</span></span><br><span class="line"><span class="number">11</span>  <span class="number">5</span>HR_mean<span class="number">0.017</span></span><br><span class="line"><span class="number">12</span>  <span class="number">5</span>p_RMSSD<span class="number">0.016</span></span><br><span class="line"><span class="number">13</span>   <span class="number">5</span>R_CVSD<span class="number">0.016</span></span><br><span class="line"><span class="number">14</span>    <span class="number">5</span>csi10<span class="number">0.016</span></span><br><span class="line"><span class="number">15</span>   <span class="number">5</span>p_SDNN<span class="number">0.016</span></span><br><span class="line"><span class="number">16</span>    <span class="number">5</span>p_RMS<span class="number">0.016</span></span><br><span class="line"><span class="number">17</span>    <span class="number">5</span>p_max<span class="number">0.016</span></span><br><span class="line"><span class="number">18</span>    <span class="number">5</span>p_var<span class="number">0.015</span></span><br><span class="line"><span class="number">19</span>   <span class="number">5</span>p_mean<span class="number">0.015</span></span><br><span class="line"><span class="number">20</span>   <span class="number">5</span>R_SDSD<span class="number">0.015</span></span><br><span class="line"><span class="number">21</span>  <span class="number">5</span>R_RMSSD<span class="number">0.015</span></span><br></pre></td></tr></table></figure><p>排序顺序为543分类</p><p>直接用一个行表格不就行了嘛。。。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/6/18</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 选定固定的特征值</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># for h in range(1, 4):</span></span><br><span class="line"><span class="comment">#     feature_import = pd.read_excel('E:/features' + '/feature_important' + '%s' % h + '.xlsx')</span></span><br><span class="line"><span class="comment">#     df = pd.get_dummies(feature_import.iloc[0:len(feature_import), 1:23])</span></span><br><span class="line"><span class="comment">#     data = df.T</span></span><br><span class="line"><span class="comment">#     print(f'列写特征重要度排序', end='\t')</span></span><br><span class="line"><span class="comment">#     print()</span></span><br><span class="line"><span class="comment">#     print(f'序号', end='\t\t')</span></span><br><span class="line"><span class="comment">#     print(f'特征', end='\t\t')</span></span><br><span class="line"><span class="comment">#     print(f'重要度')</span></span><br><span class="line"><span class="comment">#     for i in range(22):</span></span><br><span class="line"><span class="comment">#         print(f'%2d' % i, end='\t')</span></span><br><span class="line"><span class="comment">#         print(f'%10s' % df.keys()[i], end='\t')</span></span><br><span class="line"><span class="comment">#         print(f'%0.3f' % data[0][i])</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">22</span>):</span><br><span class="line">    <span class="keyword">for</span> h <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">4</span>):</span><br><span class="line">        feature_import = pd.read_excel(<span class="string">'E:/features'</span> + <span class="string">'/feature_important'</span> + <span class="string">'%s'</span> % h + <span class="string">'.xlsx'</span>)</span><br><span class="line">        df = pd.get_dummies(feature_import.iloc[<span class="number">0</span>:len(feature_import), <span class="number">1</span>:<span class="number">23</span>])</span><br><span class="line">        data = df.T</span><br><span class="line">        print(<span class="string">f'%15s'</span> % df.keys()[i], end=<span class="string">'\t'</span>)</span><br><span class="line">    print()</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">  5期  4期 3期</span><br><span class="line"> 5pNN20          5NN20         5pNN20</span><br><span class="line">         5NN20         5pNN20          5NN20</span><br><span class="line">        5pNN50         5pNN50         5pNN50</span><br><span class="line">         5NN50          5NN50          5NN50</span><br><span class="line">      5p_RMSSD        5p_skew        5R_mean</span><br><span class="line">        5p_var            5HF        5p_skew</span><br><span class="line">        5csi50      5p_median            5HF</span><br><span class="line">        5csi30        5R_mean        5HR_min</span><br><span class="line">        5csi10        5p_SDNN      5p_median</span><br><span class="line">           5HF         5p_var      5R_median</span><br><span class="line">       5p_skew         5p_RMS          5apen</span><br><span class="line">       5p_SDNN         5csi10       5HR_mean</span><br><span class="line">     5p_median       5p_RMSSD       5p_RMSSD</span><br><span class="line">       5R_mean        5R_CVSD        5R_CVSD</span><br><span class="line">      5HR_mean         5p_max         5csi10</span><br><span class="line">        5p_RMS         5csi50        5p_SDNN</span><br><span class="line">       5p_mean        5R_SDSD         5p_RMS</span><br><span class="line">        5p_max        5p_mean         5p_max</span><br><span class="line">     5R_median           5sd1         5p_var</span><br><span class="line">         5apen       5R_RMSSD        5p_mean</span><br><span class="line">5p_peak_factor        5HR_min        5R_SDSD</span><br><span class="line">       5csi100          5apen       5R_RMSSD</span><br></pre></td></tr></table></figure><p><img src="http://image.uczzd.cn/889217514512198939.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;重要特征查看&quot;&gt;&lt;a href=&quot;#重要特征查看&quot; class=&quot;headerlink&quot; title=&quot;重要特征查看&quot;&gt;&lt;/a&gt;重要特征查看&lt;/h1&gt;&lt;p&gt;目的：将睡眠分期中的345阶段的睡眠分期结果进行比较，查看特征对睡眠分期的影响,&lt;/p&gt;
&lt;p&gt;筛选出特征贡
      
    
    </summary>
    
    
      <category term="work" scheme="https://esyyes.github.io/categories/work/"/>
    
    
      <category term="work" scheme="https://esyyes.github.io/tags/work/"/>
    
  </entry>
  
  <entry>
    <title>全部特征的提取和标签处理</title>
    <link href="https://esyyes.github.io/2020/06/11/sleep%20apnea%20and%20sleep%20stage/%E5%85%A8%E9%83%A8%E7%89%B9%E5%BE%81%E7%9A%84%E6%8F%90%E5%8F%96%E5%92%8C%E6%A0%87%E7%AD%BE%E5%A4%84%E7%90%86/"/>
    <id>https://esyyes.github.io/2020/06/11/sleep%20apnea%20and%20sleep%20stage/%E5%85%A8%E9%83%A8%E7%89%B9%E5%BE%81%E7%9A%84%E6%8F%90%E5%8F%96%E5%92%8C%E6%A0%87%E7%AD%BE%E5%A4%84%E7%90%86/</id>
    <published>2020-06-11T08:49:41.000Z</published>
    <updated>2020-06-11T08:49:41.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="全部特征的提取和标签处理"><a href="#全部特征的提取和标签处理" class="headerlink" title="全部特征的提取和标签处理"></a>全部特征的提取和标签处理</h1><p>提取5分钟片段的特征，并进行滑窗切片，以30s为窗口，5min为步长</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/6/11</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将5分钟的数据进行30s窗口的滑窗切片，然后进行输出为list</span></span><br><span class="line"><span class="comment"># 5min的进行单独的分析，然后进行时频域和非线性的分析</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> wfdb</span><br><span class="line"><span class="keyword">from</span> wfdb <span class="keyword">import</span> processing</span><br><span class="line"><span class="comment"># import numpy as np</span></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">from</span> peaks_time_features <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> time_domain <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> frequency_domain <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> HRV_interp1 <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> nonliner_domain <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> eliminate_outliers <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line"></span><br><span class="line">test = <span class="string">'slp01a'</span></span><br><span class="line">record = wfdb.rdrecord(<span class="string">'F:/slpdb_data/mitdata'</span> + <span class="string">'/%s'</span> % test, channels=[<span class="number">0</span>])</span><br><span class="line">annotation = wfdb.rdann(<span class="string">'F:/slpdb_data/mitdata'</span> + <span class="string">'/%s'</span> % test, <span class="string">'ecg'</span>)</span><br><span class="line"></span><br><span class="line">ecg_signal = record.p_signal</span><br><span class="line">ecg_locs = annotation.sample.tolist()</span><br><span class="line">ecg_locs.pop(<span class="number">0</span>)</span><br><span class="line">min_bpm = <span class="number">40</span></span><br><span class="line">max_bpm = <span class="number">200</span></span><br><span class="line"></span><br><span class="line">search_radius = int(record.fs * <span class="number">60</span> / max_bpm)</span><br><span class="line">ecg_r_locs1 = processing.correct_peaks(ecg_signal[:, <span class="number">0</span>], peak_inds=ecg_locs,</span><br><span class="line">                                       search_radius=search_radius, smooth_window_size=<span class="number">100</span>)</span><br><span class="line"><span class="comment"># ecg_r_locs异常点处理</span></span><br><span class="line">ecg_r_locs = eliminate(ecg_r_locs1)</span><br><span class="line"><span class="comment"># ecg_r_peaks峰值点获取</span></span><br><span class="line">ecg_r_peaks = [ecg_signal[int(ecg_r_locs[i])][<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(ecg_r_locs))]</span><br><span class="line"></span><br><span class="line">all_RR_5m = []</span><br><span class="line">all_locs_5m = []</span><br><span class="line">all_peaks_5m = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(int(record.sig_len/record.fs/<span class="number">30</span> - <span class="number">11</span>)):</span><br><span class="line">    RR_300s = []</span><br><span class="line">    locs_300s = []</span><br><span class="line">    peaks_300s = []</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(ecg_r_locs)):</span><br><span class="line">        <span class="keyword">if</span> (<span class="number">30</span>*record.fs*i) &lt;= ecg_r_locs[j] &lt;= (<span class="number">30</span>*record.fs*(i+<span class="number">10</span>)):</span><br><span class="line">            locs_300s.append(ecg_r_locs[j])</span><br><span class="line">            RR_300s.append((ecg_r_locs[j+<span class="number">1</span>] - ecg_r_locs[j]) * <span class="number">4</span>)</span><br><span class="line">            peaks_300s.append(ecg_r_peaks[j][<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">    RR_300s.pop()</span><br><span class="line">    all_RR_5m.append(RR_300s)</span><br><span class="line">    all_locs_5m.append(locs_300s)</span><br><span class="line">    all_peaks_5m.append(peaks_300s)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ECG_R</span></span><br><span class="line">peaks_features = [peaks_time_feature(all_peaks_300s[i]) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(all_peaks_300s))]</span><br><span class="line"><span class="comment"># HRV</span></span><br><span class="line">hrv_time = [time_features(all_RR_300s[i]) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(all_RR_300s))]</span><br><span class="line">hrv_freq = [getfreq(resample(hrv_interp1(all_locs_300s[i], all_RR_300s[i], <span class="number">1</span>), <span class="number">250</span>, <span class="number">4</span>)) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(all_RR_300s))]</span><br><span class="line">hrv_nonl = [non_linear(np.array(all_RR_300s[i])) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(all_RR_30s))]</span><br><span class="line">features = [peaks_features[i] + hrv_time[i] + hrv_freq[i] + hrv_nonl[i] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(all_RR_300s))]</span><br></pre></td></tr></table></figure><h2 id="特征重要度"><a href="#特征重要度" class="headerlink" title="特征重要度"></a>特征重要度</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/6/11</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> data_preprocessing <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">19</span>):</span><br><span class="line">    feature = pd.read_excel(<span class="string">'F:/py/python-ECG信号处理/all_feature'</span> + <span class="string">'/features'</span> + <span class="string">'%s'</span> % i + <span class="string">'.xlsx'</span>)</span><br><span class="line">    data = pd.get_dummies(feature.iloc[<span class="number">0</span>:len(feature), <span class="number">1</span>:])</span><br><span class="line">    note = pd.read_excel(<span class="string">'F:/py/python-ECG信号处理/all_note'</span> + <span class="string">'/note'</span> + <span class="string">'%s'</span> % i + <span class="string">'.xlsx'</span>)</span><br><span class="line">    tag = pd.get_dummies(note.iloc[<span class="number">0</span>:len(data), <span class="number">1</span>:])</span><br><span class="line">    <span class="comment"># 数据预处理</span></span><br><span class="line">    df = data_pre(data)</span><br><span class="line">    label = pd.get_dummies(tag.iloc[<span class="number">0</span>:len(data), <span class="number">-2</span>:<span class="number">-1</span>])</span><br><span class="line"></span><br><span class="line">    X = df</span><br><span class="line">    Y = label</span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=<span class="number">0.3</span>)</span><br><span class="line">    sel = SelectFromModel(RandomForestClassifier(n_jobs=<span class="number">-1</span>))</span><br><span class="line">    sel.fit(X_train, y_train)</span><br><span class="line">    features = X_train.columns[sel.get_support()]</span><br><span class="line">    print(<span class="string">f'%2d 重要特征数为：<span class="subst">&#123;len(features)&#125;</span>'</span> %i, end=<span class="string">'\t'</span>)</span><br><span class="line">    print()</span><br></pre></td></tr></table></figure><p>1 重要特征数为：26<br> 2 重要特征数为：30<br> 3 重要特征数为：24<br> 4 重要特征数为：34<br> 5 重要特征数为：42<br> 6 重要特征数为：32<br> 7 重要特征数为：40<br> 8 重要特征数为：34<br> 9 重要特征数为：21<br>10 重要特征数为：25<br>11 重要特征数为：41<br>12 重要特征数为：29<br>13 重要特征数为：26<br>14 重要特征数为：32<br>15 重要特征数为：30<br>16 重要特征数为：37<br>17 重要特征数为：21<br>18 重要特征数为：27</p><p>还是选择25个作为特征重要度筛选</p><p><img src="https://images.ali213.net/picfile/pic/2013/11/10/927_20131110120357350.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;全部特征的提取和标签处理&quot;&gt;&lt;a href=&quot;#全部特征的提取和标签处理&quot; class=&quot;headerlink&quot; title=&quot;全部特征的提取和标签处理&quot;&gt;&lt;/a&gt;全部特征的提取和标签处理&lt;/h1&gt;&lt;p&gt;提取5分钟片段的特征，并进行滑窗切片，以30s为窗口，5mi
      
    
    </summary>
    
    
      <category term="work" scheme="https://esyyes.github.io/categories/work/"/>
    
    
      <category term="work" scheme="https://esyyes.github.io/tags/work/"/>
    
  </entry>
  
</feed>
