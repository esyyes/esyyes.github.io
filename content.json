{"meta":{"title":"ESY","subtitle":"miao","description":"miao","author":"esy","url":"https://esyyes.github.io","root":"/"},"pages":[{"title":"about","date":"2019-11-18T07:46:06.000Z","updated":"2019-11-20T03:10:32.564Z","comments":true,"path":"about/index.html","permalink":"https://esyyes.github.io/about/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-11-20T03:06:24.000Z","updated":"2019-11-20T03:09:40.977Z","comments":true,"path":"tags/index.html","permalink":"https://esyyes.github.io/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-11-20T03:07:48.000Z","updated":"2019-11-20T03:08:27.128Z","comments":true,"path":"categories/index.html","permalink":"https://esyyes.github.io/categories/index.html","excerpt":"","text":""},{"title":"yourdiy","date":"2019-11-18T07:47:13.000Z","updated":"2019-11-18T07:47:13.996Z","comments":true,"path":"yourdiy/index.html","permalink":"https://esyyes.github.io/yourdiy/index.html","excerpt":"","text":""}],"posts":[{"title":"UI界面美化","slug":"UI界面美化","date":"2020-08-08T09:11:31.000Z","updated":"2020-08-08T09:11:31.000Z","comments":true,"path":"2020/08/08/UI界面美化/","link":"","permalink":"https://esyyes.github.io/2020/08/08/UI%E7%95%8C%E9%9D%A2%E7%BE%8E%E5%8C%96/","excerpt":"","text":"UI界面美化想要加入背景图片，和让界面不能进行放大 问题： Image画布这些导入的图片一定要是gif 还有不能将输入框中的背景色调的很白这种，光标会导致消失 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122# -*- coding: utf-8 -*-# @Time : 2020/8/7# @Author : esyfrom tkinter import *import tkinter as tkfrom PIL import ImageTk, Imageimport pandas as pdimport timefrom chatbot_gui import *data = pd.read_excel('Q&amp;A pairs.xlsx')hello = \"Nice to meet you! My name is BoBo. I'm glad to answer any questions about traveling in Beijing! How can I help you? \" + '\\n'questionlist = [\"If you have the following questions, please enter the number directly: \", \"1: Are there any famous scenic spots in Beijing\", \"2: What are the famous delicacies in Beijing\", \"3: What's the fare on the Beijing subway\", \"4: Where can I rent a car in Beijing \", \"5: What are the opening hours of the Forbidden City\" ]answerlist = [\"There are many famous scenic spots in Beijing, such as the Forbidden City, Tian 'anmen Square, the Great Wall at Badaling, the Summer Palace, the Bird's Nest, the Old Summer Palace and so on\", \"Beijing's famous delicacies include Peking duck, old Beijing noodles with Fried sauce, Mutton cooked in a copper pan, Beijing Zhizi Barbecue, Fried liver, Fried tripe and so on\", \"The subway fare in Beijing is usually between 3 and 10 yuan, and 25 to 50 yuan if you take the airport line\", \"To tell the truth, it is very inconvenient for foreigners to rent a car in China, because they need to prepare and submit a lot of materials, such as the renter's passport, the city residence permit for more than 1 year, the Chinese driving license, and a guarantor of the city's household registration. The guarantor shall provide his/her household register, identity card, guarantee undertaking and so on. If you are only traveling for a short time, we suggest you take the subway, bus or taxi, which will be much more convenient\", \"April 1st to October 31st (peak season) from Tuesday to Sunday 08:30 to 17:00, closed on Mondays; November 1 - March 31 of the following year (off-season) From Tuesday to Sunday 08:30-16:30, closed on Monday; Mondays are not closed during legal holidays.\" ]def sendMsgEvent(event): # 发送消息事件 if event.keysym == 'Return': sendMsg() return 'break'def sendMsg(): # 发送消息 strMsg1 = \"user: \" + time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + '\\n' txtMsgList.config(state='normal') txtMsgList.insert(END, strMsg1, 'color') txtMsgList.insert(END, txtMsg.get('0.0', END)) # 开始回复消息 answer = \"chatbot: \" + time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + '\\n' best = run_chatbot(txtMsg.get('0.0', END)[:-1], data) + '\\n' txtMsgList.insert(END, answer, 'color') if txtMsg.get('0.0', END)[:-1] == '1': txtMsgList.insert(END, answerlist[0]) txtMsgList.insert(INSERT, '\\n') elif txtMsg.get('0.0', END)[:-1] == '2': txtMsgList.insert(END, answerlist[1]) txtMsgList.insert(INSERT, '\\n') elif txtMsg.get('0.0', END)[:-1] == '3': txtMsgList.insert(END, answerlist[2]) txtMsgList.insert(INSERT, '\\n') elif txtMsg.get('0.0', END)[:-1] == '4': txtMsgList.insert(END, answerlist[3]) txtMsgList.insert(INSERT, '\\n') elif txtMsg.get('0.0', END)[:-1] == '5': txtMsgList.insert(END, answerlist[4]) txtMsgList.insert(INSERT, '\\n') else: txtMsgList.insert(END, best) txtMsgList.config(state='disabled') txtMsgList.yview(END) txtMsg.delete('0.0', END)# 创建窗口root = Tk()# 标题root.title('Q&amp;A chatbot')# 读取图标root.iconbitmap('F:\\s.ico')# 窗口大小root.geometry('800x650+300+100')# 固定窗口root.resizable(width=False, height=False)# 背景canvas = tk.Canvas(root, width=800, height=650, bd=0, highlightthickness=0)imgpath = '3.gif'img = Image.open(imgpath).resize((800, 650))photo = ImageTk.PhotoImage(img)canvas.create_image(400, 325, image=photo)canvas.grid()# 发送信息框txtMsg = Text(root, font=('Times New Roman', 15))txtMsg.grid()canvas.create_window(400, 500, width=650, height=200, window=txtMsg)# 绑定一个控制键，进行发送信息txtMsg.bind(\"&lt;KeyPress-Return&gt;\", sendMsgEvent)button = Button(root, text='Send (S)', font=('Times New Roman', 12), command=sendMsg, bg=\"#afb4db\")button.grid()canvas.create_window(685, 615, width=80, height=30, window=button)# 布局1txtMsgList = Text(root, insertbackground='#f6f5ec', font=('Times New Roman', 15))txtMsgList.tag_config('color', foreground='#6a6da9')strMsg = \"BoBo: \" + time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + '\\n'txtMsgList.insert(END, strMsg, 'color')# 输入问候语txtMsgList.insert(END, hello)# 输入待查询的5个问题txtMsgList.insert(END, strMsg, 'color')for i in range(len(questionlist)): txtMsgList.insert(END, questionlist[i]) txtMsgList.insert(INSERT, '\\n')txtMsgList.config(state='disabled')txtMsgList.grid()canvas.create_window(400, 200, width=650, height=380, window=txtMsgList)# 滚动条scrollbar = Scrollbar(root, command=txtMsgList.yview, cursor=\"heart\")txtMsgList['yscrollcommand'] = scrollbar.setscrollbar.grid()canvas.create_window(730, 200, width=10, height=380, window=scrollbar)# 消息循环 显示窗口root.mainloop()","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"q&a数据补充","slug":"q-a数据补充","date":"2020-08-08T09:01:12.000Z","updated":"2020-08-08T09:01:12.000Z","comments":true,"path":"2020/08/08/q-a数据补充/","link":"","permalink":"https://esyyes.github.io/2020/08/08/q-a%E6%95%B0%E6%8D%AE%E8%A1%A5%E5%85%85/","excerpt":"","text":"q&amp;a数据补充数据量只有100多条，数据太少，不利于实验的进行 因此考虑采用爬虫的方式，进行数据的补充。 网站： http://english.visitbeijing.com.cn/f/list.html?c1=u8e9t0ae 关于北京旅游的所有信息都有 进行爬虫后，初步筛选数据 读取爬取的旅游文本数据12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485# -*- coding: utf-8 -*-# @Time : 2020/8/5# @Author : esyimport pandas as pdimport numpy as npdata = pd.read_csv('旅游.csv')df = np.array(data).tolist()name = []for i in range(len(data)): name.append(df[i][0])names = pd.DataFrame(name, columns=&#123;'name'&#125;)names.fillna(value=0, inplace=True)names = np.array(names).tolist()all_data = []place = []for i in range(len(data)): if names[i][0] != 0: all_data.append(df[i]) place.append(names[i][0])price = []for i in range(len(all_data)): if all_data[i][1][0:4] == '门票价格': price.append(all_data[i][1][5:].strip()) else: price.append(0)daoyu = []for i in range(len(all_data)): daoyu.append(all_data[i][2])daoyu = pd.DataFrame(daoyu, columns=&#123;'daoyu'&#125;)daoyu.fillna(value=0, inplace=True)daoyu = np.array(daoyu).tolist()introduce = []for i in range(len(all_data)): if all_data[i][1][0] == '导': introduce.append(all_data[i][1][5:].replace(' ', '')) elif daoyu[i][0] != 0 and daoyu[i][0][0] != '地': if daoyu[i][0][0] == '导': introduce.append(all_data[i][2][5:].replace(' ', '')) else: introduce.append(0)dizhi = []for i in range(len(all_data)): dizhi.append(all_data[i][3])dizhi = pd.DataFrame(dizhi, columns=&#123;'dizhi'&#125;)dizhi.fillna(value=0, inplace=True)dizhi = np.array(dizhi).tolist()dizhi1 = []for i in range(len(all_data)): dizhi1.append(all_data[i][4])dizhi1 = pd.DataFrame(dizhi1, columns=&#123;'dizhi'&#125;)dizhi1.fillna(value=0, inplace=True)dizhi1 = np.array(dizhi1).tolist()site = []for i in range(len(all_data)): if daoyu[i][0] != 0 and daoyu[i][0][0] != '导': site.append(daoyu[i][0][5:].replace(' ', '')) elif dizhi[i][0] != 0 and dizhi[i][0][0] != '导': site.append(dizhi[i][0][5:].replace(' ', '')) elif dizhi1[i][0] != 0 and dizhi1[i][0][0] != '导': site.append(dizhi1[i][0][5:].replace(' ', '')) else: site.append(0)place = pd.DataFrame(place, columns=&#123;'place'&#125;)price = pd.DataFrame(price, columns=&#123;'price'&#125;)introduce = pd.DataFrame(introduce, columns=&#123;'introduce'&#125;)site = pd.DataFrame(site, columns=&#123;'site'&#125;)datas = pd.concat([place, price, introduce, site], axis=1)datas.to_excel('datas.xlsx') 并将新的数据转换为xlsx12345678import pandas as pdf = open(r'C:\\Users\\86184\\Desktop\\D.txt', 'r', encoding='utf-8')all_data = []for element in f: all_data.append(element.split(\"\\t\"))data = pd.DataFrame(all_data)data.to_excel('new_data.xlsx') 生成对应所需的问题1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# -*- coding: utf-8 -*-# @Time : 2020/8/5# @Author : esyimport pandas as pdimport numpy as npimport randomdata = pd.read_excel('new_data.xlsx')df = np.array(data).tolist()# 生成价格的问题price0 = 'How much is the entrance fee of the 'price1 = 'How much is the ticket of the 'price_list = []price_asnw = []for i in range(len(data)): if df[i][1] == '0': pass else: if 0 == random.randint(0, 1): price_list.append(price0 + df[i][0]) price_asnw.append(df[i][1]) else: price_list.append(price1 + df[i][0]) price_asnw.append(df[i][1])# 生成导语tell0 = 'Tell me something about the 'tell1 = 'description of the 'tell_list = []tell_asnw = []for i in range(len(data)): if 0 == random.randint(0, 1): tell_list.append(tell0 + df[i][0]) tell_asnw.append(df[i][2]) else: tell_list.append(tell1 + df[i][0]) tell_asnw.append(df[i][2])# 生成地址where = 'Where is the 'site_list = []site_asnw = []for i in range(len(data)): site_list.append(where + df[i][0]) site_asnw.append(df[i][3])price = pd.DataFrame(price_list)tell = pd.DataFrame(tell_list)site = pd.DataFrame(site_list)question = pd.concat([price, tell, site], axis=0)price_a = pd.DataFrame(price_asnw)tell_a = pd.DataFrame(tell_asnw)site_a = pd.DataFrame(site_asnw)answer = pd.concat([price_a, tell_a, site_a], axis=0)QA = pd.concat([question, answer], axis=1)QA.to_excel('Q&amp;A pairs.xlsx') 价格的答案需要更改1234567891011121314151617181920212223# -*- coding: utf-8 -*-# @Time : 2020/8/5# @Author : esyimport pandas as pdimport numpy as npdata = pd.read_excel('Q&amp;A pairs.xlsx')df = np.array(data).tolist()answer = ' yuan per person'ans = []for i in range(165): if df[i][1] == 'free': ans.append(df[i][1]) elif df[i][1][5] == 'R': ans.append('About ' + df[i][1][9:] + answer) else: ans.append('About ' + df[i][1][5:] + ' per person')anss = pd.DataFrame(ans)anss.to_excel('ans.xlsx') 比较所有的数据和原始数据的重复情况并删除重复后的生成数据 1234567891011121314151617181920212223242526272829# -*- coding: utf-8 -*-# @Time : 2020/8/5# @Author : esyimport pandas as pdimport numpy as npdata0 = pd.read_excel('Q&amp;A pairs.xlsx')data1 = pd.read_csv('Q&amp;A pairs1.csv')df0 = np.array(data0).tolist()df1 = np.array(data1).tolist()print(len(df0))# 进行查重for i in range(len(data0)): for j in range(len(data1)): if df0[i][0] == df1[j][0]: print(f'数据0第&#123;i&#125;个问题与数据1的第&#123;j&#125;个一样')del df0[1]del df0[396]print(len(df0))shuju0 = pd.DataFrame(df0)shuju1 = pd.DataFrame(df1)shuju = pd.concat([shuju1, shuju0], axis=0)shuju.to_excel('shuju.xlsx')","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"chatbot_版本1总结","slug":"chatbot-版本1总结","date":"2020-08-08T08:51:14.000Z","updated":"2020-08-08T08:51:14.000Z","comments":true,"path":"2020/08/08/chatbot-版本1总结/","link":"","permalink":"https://esyyes.github.io/2020/08/08/chatbot-%E7%89%88%E6%9C%AC1%E6%80%BB%E7%BB%93/","excerpt":"","text":"chatbot_版本1总结检索式聊天机器人之旅游篇 数据：100条，数据匮乏，很多语句输出是错误的 流程： 对数据库中的数据进行spacy分词，还原，消除停靠词处理 利用规则语句输出一些简单的话 判断小于3个或者关键词不在数据中的，就输出sorry 利用tf-idf计算，然后将输入问题的关键词跟对应句子的进行得分计算 召回5个问题 计算相似度 利用自己写的余弦相似度和spacy自带的余弦相似度计算 输出相似度高于0.7且相似度最高的答案 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187# -*- coding: utf-8 -*-# @Time : 2020/7/29# @Author : esyimport mathimport en_core_web_mdimport numpy as npimport warningsfrom collections import defaultdictimport randomwarnings.filterwarnings(\"ignore\")nlp = en_core_web_md.load()greeting_output = [\"hi\", \"hey\", \"hello\", \"I'm glad! You are talking to me\"]# 预处理文本数据，将单词还原成基础模式，小写，删除停靠词，得到关键词def del_stop(text): token_doc = [token.lemma_ for token in nlp(text)] # 去除停用词后创建单词列表 filtered_sentence = [] for word in token_doc: lexeme = nlp.vocab[word] if not lexeme.is_stop != False: filtered_sentence.append(word) return filtered_sentence# 计算tfidf得分def QA_tf_idf(data, filtered_sentence): question = np.array(data['Question']).tolist() # 去除停用词后创建单词列表 list_key = [] for i in range(len(data)): list_key.append(del_stop(question[i])) # 统计词频和词汇,看单词出现的次数 doc_frequency = defaultdict(int) list_words = list_key for word_list in list_words: for i in word_list: doc_frequency[i] += 1 doc_frequency2 = defaultdict(int) for i in filtered_sentence: doc_frequency2[i] += 1 # doc_frequency.update(&#123;'-PRON-': doc_frequency.pop('-pron-')&#125;) l1 = set(doc_frequency2.keys()) l2 = set(doc_frequency.keys()) if len(l1 &amp; l2) == 0: return 0 else: # 计算每个词的IDF值 word_idf = &#123;&#125; # 存储每个词的idf值 word_doc = defaultdict(int) # 存储包含该词的文档数 for i in doc_frequency: for j in list_words: if i in j: word_doc[i] += 1 for i in doc_frequency: word_idf[i] = math.log(len(list_key) / (word_doc[i] + 1)) # 对样本进行词频统计 list_doc = [] for i in range(len(list_key)): doc_frequency1 = defaultdict(int) for j in list_key[i]: doc_frequency1[j] += 1 list_doc.append(doc_frequency1) # 计算语料库中每个词的tf_idf,构建向量 tf_idf = [] for j in range(len(data)): tf_idf.append([word_idf[i] * list_doc[j][i] / len(list_key[j]) for i in (list_doc[j])]) # 计算问题对应语料库的tf-idf得分 scores = [] for j in range(len(data)): score = 0 for i in doc_frequency2: if i not in doc_frequency: pass else: score += (word_idf[i] * list_doc[j][i] / len(list_key[j])) scores.append(score) # 直接计算问题的语料库得分 # 对问题进行词频统计 quet_tfidf = [] for i in doc_frequency2: if i not in doc_frequency: pass else: quet_tfidf.append(word_idf[i] * doc_frequency2[i] / len(filtered_sentence)) return tf_idf, quet_tfidf, scoresdef recall_5(scores, data, tf_idf): question = np.array(data['Question']).tolist() answer = np.array(data['Answer']).tolist() # 用字典形式按照升序形式排序 x = np.arange(len(data)).tolist() dict_score = dict(zip(x, scores)) listc = sorted(zip(dict_score.values(), dict_score.keys())) recall_ques = [] recall_answ = [] recall_tf_idf = [] # 召回得分最高的5个问题 for i in range(1, 6): recall_ques.append(question[listc[-i][1]]) recall_answ.append(answer[listc[-i][1]]) recall_tf_idf.append(tf_idf[listc[-i][1]]) return recall_ques, recall_answ, recall_tf_idf# 求5个问题的相似度def similar_list(quet_tfidf, recall_tf_idf): similar_score = [] for i in range(len(recall_tf_idf)): if len(recall_tf_idf[i]) == len(quet_tfidf): similar_score.append(np.dot(quet_tfidf, recall_tf_idf[i]) / (np.linalg.norm(quet_tfidf) * np.linalg.norm(recall_tf_idf[i]))) elif len(recall_tf_idf[i]) &lt; len(quet_tfidf): for j in range(len(quet_tfidf) - len(recall_tf_idf[i])): c = recall_tf_idf[i] c.append(0) similar_score.append(np.dot(quet_tfidf, c) / (np.linalg.norm(quet_tfidf) * np.linalg.norm(recall_tf_idf[i]))) else: for j in range(abs(len(quet_tfidf) - len(recall_tf_idf[i]))): a = quet_tfidf a.append(0) similar_score.append(np.dot(a, recall_tf_idf[i]) / (np.linalg.norm(a) * np.linalg.norm(recall_tf_idf[i]))) return similar_scoredef similar_spacy(text, recall_ques): similar_goal = [] for i in range(len(recall_ques)): similar_goal.append(nlp(text).similarity(nlp(recall_ques[i]))) return similar_goal# 输出相似度最高的那个的答案def best_answer(list_num, recall_answ): if max(list_num) &lt;= 0.5: return f\"I'm sorry. I don't understand you\" else: best_ans = recall_answ[list_num.index(max(list_num))] return best_ansdef run_chatbot(text2, data): text1 = \" \".join([token.lemma_ for token in nlp(text2)]) if text1 == 'hey' or text1 == 'hi' or text1 == 'hello' or text1 == 'HI': return random.choice(greeting_output) elif text1 == 'thank' or text1 == 'thank -PRON-' or text1 == 'THANK': return 'You are welcome.' elif text1 == 'bye' or text1 == 'BYE': return 'Bye!' elif len(text1.split()) &lt; 3: return \"I'm sorry. I don't understand you\" else: if QA_tf_idf(data, del_stop(text2)) == 0: return \"I'm sorry. I don't understand you\" else: tf_idf1, quet_tfidf1, scores1 = QA_tf_idf(data, del_stop(text2)) recall_ques1, recall_answ1, recall_tf_idf_1 = recall_5(scores1, data, tf_idf1) return best_answer(similar_spacy(text2, recall_ques1), recall_answ1)def run_chatbot_python(text2, data): text1 = \" \".join([token.lemma_ for token in nlp(text2)]) # 进行简单回复 if text1 == 'hey' or text1 == 'hi' or text1 == 'hello' or text1 == 'HI': print(random.choice(greeting_output)) elif text1 == 'thank' or text1 == 'thank -PRON-' or text1 == 'THANK': print('You are welcome.') elif len(text1.split()) &lt; 3: print(f\"I'm sorry. I don't understand you\") else: if QA_tf_idf(data, del_stop(text2)) == 0: print(f\"I'm sorry. I don't understand you\") else: tf_idf1, quet_tfidf1, scores1 = QA_tf_idf(data, del_stop(text2)) recall_ques1, recall_answ1, recall_tf_idf_1 = recall_5(scores1, data, tf_idf1) print(f'召回的5个问题') for j in range(5): print(f'第&#123;j + 1&#125;问题：&#123;recall_ques1[j]&#125;', end='\\t') print(f'相似度：&#123;similar_spacy(text2, recall_ques1)[j]&#125;') print(f'最佳答案：') print(f'&#123;best_answer(similar_spacy(text2, recall_ques1), recall_answ1)&#125;') 运行python12345678910111213141516171819# -*- coding: utf-8 -*-# @Time : 2020/7/29# @Author : esyfrom chatbot_gui import *import pandas as pddata = pd.read_csv('Q&amp;A pairs.csv')print(\"Hello, I'm a question-and-answer chatbot for the tourism domain based on retrieval mode.\" \"If you want to exit, input 'Bye'!\")while True: text = input(\"Please enter a question: \\t\") if text == 'bye' or text == 'BYE': print('Bye!') break else: run_chatbot_python(text, data) 生成简单的gui界面123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132# -*- coding: utf-8 -*-# @Time : 2020/7/21# @Author : esyimport pandas as pdfrom tkinter import *import tkinterimport timefrom chatbot_gui import *data = pd.read_excel('Q&amp;A pairs.xlsx')hello = \"Nice to meet you! My name is BoBo. I'm glad to answer any questions about traveling in Beijing! How can I help you? \" + '\\n'questionlist = [\"If you have the following questions, please enter the number directly: \", \"1: Are there any famous scenic spots in Beijing\", \"2: What are the famous delicacies in Beijing\", \"3: What's the fare on the Beijing subway\", \"4: Where can I rent a car in Beijing \", \"5: What are the opening hours of the Forbidden City\" ]answerlist = [\"There are many famous scenic spots in Beijing, such as the Forbidden City, Tian 'anmen Square, the Great Wall at Badaling, the Summer Palace, the Bird's Nest, the Old Summer Palace and so on\", \"Beijing's famous delicacies include Peking duck, old Beijing noodles with Fried sauce, Mutton cooked in a copper pan, Beijing Zhizi Barbecue, Fried liver, Fried tripe and so on\", \"The subway fare in Beijing is usually between 3 and 10 yuan, and 25 to 50 yuan if you take the airport line\", \"To tell the truth, it is very inconvenient for foreigners to rent a car in China, because they need to prepare and submit a lot of materials, such as the renter's passport, the city residence permit for more than 1 year, the Chinese driving license, and a guarantor of the city's household registration. The guarantor shall provide his/her household register, identity card, guarantee undertaking and so on. If you are only traveling for a short time, we suggest you take the subway, bus or taxi, which will be much more convenient\", \"April 1st to October 31st (peak season) from Tuesday to Sunday 08:30 to 17:00, closed on Mondays; November 1 - March 31 of the following year (off-season) From Tuesday to Sunday 08:30-16:30, closed on Monday; Mondays are not closed during legal holidays.\" ]# 创建窗口root = Tk()# 标题root.title('Q&amp;A chatbot')# 读取图标root.iconbitmap('F:\\s.ico')# 窗口大小root.geometry('800x650+300+100')# 固定窗口root.resizable(width=False, height=False)# 加入背景图# 聊天窗口布局，布置3个frm1 = Frame(width=800, height=400)frm4 = Frame(width=800, height=7)frm2 = Frame(width=800, height=200)# frm3 = Frame(width=800, height=30)frm1.config(bg=\"#f6f5ec\")frm2.config(bg=\"#f6f5ec\")# frm3.config(bg=\"#f6f5ec\")frm4.config(bg=\"#f6f5ec\")frm1.grid()frm4.grid()frm2.grid()# frm3.grid()root.configure(background='#f6f5ec')def sendMsg(): # 发送消息 strMsg1 = \"user: \" + time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + '\\n' txtMsgList.config(state='normal') txtMsgList.insert(END, strMsg1, 'color') txtMsgList.insert(END, txtMsg.get('0.0', END)) # 开始回复消息 answer = \"chatbot: \" + time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + '\\n' best = run_chatbot(txtMsg.get('0.0', END)[:-1], data) + '\\n' txtMsgList.insert(END, answer, 'color') if txtMsg.get('0.0', END)[:-1] == '1': txtMsgList.insert(END, answerlist[0]) txtMsgList.insert(INSERT, '\\n') elif txtMsg.get('0.0', END)[:-1] == '2': txtMsgList.insert(END, answerlist[1]) txtMsgList.insert(INSERT, '\\n') elif txtMsg.get('0.0', END)[:-1] == '3': txtMsgList.insert(END, answerlist[2]) txtMsgList.insert(INSERT, '\\n') elif txtMsg.get('0.0', END)[:-1] == '4': txtMsgList.insert(END, answerlist[3]) txtMsgList.insert(INSERT, '\\n') elif txtMsg.get('0.0', END)[:-1] == '5': txtMsgList.insert(END, answerlist[4]) txtMsgList.insert(INSERT, '\\n') else: txtMsgList.insert(END, best) txtMsgList.config(state='disabled') txtMsgList.yview(END) txtMsg.delete('0.0', END)def sendMsgEvent(event): # 发送消息事件 if event.keysym == 'Return': sendMsg() return 'break'# 布局2# 多重文本框输入，建立输入窗口txtMsg = Text(frm2, height=5, width=60, font=('Times New Roman', 15))txtMsg.grid(row=0, column=0, stick=E)scrollbar1 = Scrollbar(frm2, command=txtMsg.yview, cursor=\"heart\")txtMsg['yscrollcommand'] = scrollbar1.setscrollbar1.grid(row=0, column=1, stick=E)# 绑定一个控制键，进行发送信息txtMsg.bind(\"&lt;KeyPress-Return&gt;\", sendMsgEvent)button = Button(frm2, text='Send (S)', font=('Times New Roman', 12), command=sendMsg, bg=\"#afb4db\")button.grid(row=1, column=0, ipadx=8, stick=E)# 布局1txtMsgList = Text(frm1, height=15, width=60, font=('Times New Roman', 15))txtMsgList.tag_config('color', foreground='#6a6da9')strMsg = \"BoBo: \" + time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + '\\n'txtMsgList.insert(END, strMsg, 'color')# 输入问候语txtMsgList.insert(END, hello)# 输入待查询的5个问题txtMsgList.insert(END, strMsg, 'color')for i in range(len(questionlist)): txtMsgList.insert(END, questionlist[i]) txtMsgList.insert(INSERT, '\\n')txtMsgList.config(state='disabled')txtMsgList.grid(row=0, column=0, stick=E)# 滚动条scrollbar = Scrollbar(frm1, command=txtMsgList.yview, cursor=\"heart\")txtMsgList['yscrollcommand'] = scrollbar.setscrollbar.grid(row=0, column=1, ipady=100, stick=E)# 消息循环 显示窗口root.mainloop() 通过布局的形式，展示GUI界面 问题数据量太少，需要补充 GUI界面需要美化。","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"GUI界面的完善","slug":"chatbot/GUI界面的完善","date":"2020-07-28T11:14:03.000Z","updated":"2020-07-28T11:14:03.000Z","comments":true,"path":"2020/07/28/chatbot/GUI界面的完善/","link":"","permalink":"https://esyyes.github.io/2020/07/28/chatbot/GUI%E7%95%8C%E9%9D%A2%E7%9A%84%E5%AE%8C%E5%96%84/","excerpt":"","text":"GUI界面的完善已实现功能 按回车键输出消息，并不会在文本中表示回车 问题描述 在按下回车键时，不仅会触发我们绑定的方法，还会触发回车键原本的换行效果， 但我们希望只触发绑定的方法而不进行换行。 解决方法 在绑定事件函数的末尾加上 return ‘break’ 即可阻止按键的默认操作 123456789101112def sendMsgEvent(event): # 发送消息事件 if event.keysym == 'Return': sendMsg() return 'break'加入break即可让回车键按下发送后不进行跳行# 布局2# 多重文本框输入，建立输入窗口txtMsg = Text(frm2, height=5, width=60, font=('微软雅黑', 15))txtMsg.grid(row=0, column=0, stick=E)# 绑定一个控制键，进行发送信息txtMsg.bind(\"&lt;KeyPress-Return&gt;\", sendMsgEvent) 按下按钮后发送并返回消息 12345678910111213def sendMsg(): # 发送消息 strMsg = \"user:\" + time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + '\\n' txtMsgList.config(state='normal') txtMsgList.insert(END, strMsg, 'greencolor') txtMsgList.insert(END, txtMsg.get('0.0', END)) # 开始回复消息 answer = \"chatbot:\" + '\\n' # get('0.0', END)[:-1],0,end获取所有数据，会加入一个换行符，‘\\n'，因此需要加入一个【：-1】 best = run_chatbot(txtMsg.get('0.0', END)[:-1], data) + '\\n' txtMsgList.insert(END, answer, 'greencolor') txtMsgList.insert(END, best) txtMsgList.config(state='disabled') txtMsg.delete('0.0', END) bind的用法：控件.bind(event, handler),其中event是tkinter已经定义好的的事件，handler是处理器，可以是一个处理函数，如果相关事件发生, handler 函数会被触发, 事件对象 event 会传递给 handler 函数 基本所有控件都能bind 常见event有： 鼠标单击事件：鼠标左键点击为 , 鼠标中键点击为 , 鼠标右键点击为 , 向上滚动滑轮为 , 向下滚动滑轮为 . 鼠标双击事件.：鼠标左键点击为 , 鼠标中键点击为 , 鼠标右键点击为 . 鼠标释放事件：鼠标左键点击为 , 鼠标中键点击为 , 鼠标右键点击为 . 鼠标相对当前控件的位置会被存储在 event 对象中的 x 和 y 字段中传递给回调函数. 鼠标移入控件事件： 获得焦点事件： 鼠标移出控件事件: 失去焦点事件: 鼠标按下移动事件：鼠标左键点击为 , 鼠标中键点击为 , 鼠标右键点击为 . 鼠标相对当前控件的位置会被存储在 event 对象中的 x 和 y 字段中传递给回调函数. 键盘按下事件:，event中的keysym ,keycode,char都可以获取按下的键【其他想要获取值的也可以先看看event中有什么】 键位绑定事件：回车键，,,,,,……. 控件大小改变事件：，新的控件大小会存储在 event 对象中的 width 和 height 属性传递. 有些平台上该事件也可能代表控件位置改变. Event中的属性： widget：产生事件的控件 x, y：当前鼠标的位置 x_root, y_root：当前鼠标相对于屏幕左上角的位置，以像素为单位。 char：字符代码（仅限键盘事件），作为字符串。 keysym：关键符号（仅限键盘事件）。 keycode：关键代码（仅限键盘事件）。 num：按钮号码（仅限鼠标按钮事件）。 width, height：小部件的新大小（以像素为单位）（仅限配置事件）。 type：事件类型。","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"样本数据的生成","slug":"HMM/样本数据的生成","date":"2020-07-27T08:14:56.000Z","updated":"2020-07-27T08:14:56.000Z","comments":true,"path":"2020/07/27/HMM/样本数据的生成/","link":"","permalink":"https://esyyes.github.io/2020/07/27/HMM/%E6%A0%B7%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E7%94%9F%E6%88%90/","excerpt":"","text":"样本数据的生成样本数据只有222个，其中不活跃状态的197个，一般状态的18个，活跃状态的7个，样本数据太不活跃，所以需要将样本进行生成。 初步打算：不活跃的不变 一般状态的增加180个， 活跃状态的增加190个 利用random生成 https://www.jb51.net/article/152731.htm 标注差在进行变换，所以分类个数永远不是一个定值 先随机生成数据 12345678910111213141516171819202122232425import randomimport pandas as pdimport numpy as npdata = pd.read_excel('data1' + '.xlsx')data.fillna(0, inplace=True)# 转换列表list_data = np.array(data).tolist()list_y1 = [int(list_data[i][2]) for i in range(len(data))]y1_mean = np.array(list_y1).mean()y1_std = np.array(list_y1).std()for i in range(14*200): list_y1.append(random.randint(0, 10))for i in range(14*50): list_y1.append(random.randint(3, 25))for i in range(14*50): list_y1.append(random.randint(15, 50))for i in range(14*50): list_y1.append(random.randint(35, 120)) 状态查看 12345678910111213141516171819202122list_z_y = []for i in range(int(len(list_y1)/14)): y1 = [] for j in range(len(list_y1)): if 14 * i &lt;= j &lt; 14 * (i + 1): y1.append(list_y1[j]) list_z_y.append(np.array(y1).mean())Y_Z = []num1 = 0num2 = 0num3 = 0for i in range(len(list_z_y)): if list_z_y[i] &lt; 1: Y_Z.append(0) num1 += 1 elif 1 &lt;= list_z_y[i] &lt; np.array(list_y1).std(): Y_Z.append(1) num2 += 1 else: Y_Z.append(2) num3 += 1197:273:102 基于原本的数据看下规律 1234# 将Y_Z变成字典形式xuhao = np.arange(len(Y_Z)).tolist()dict_Y_Z = dict(zip(xuhao, Y_Z))sort_dict = sorted(zip(dict_Y_Z.values(), dict_Y_Z.keys())) 对原本的数据进行排序 123456789101112131415161718192021222324252627282930[(0, 217), (0, 218), (0, 219), (0, 220), (0, 221), (1, 10), (1, 17), (1, 33), (1, 37), (1, 44), (1, 70), (1, 75), (1, 85), (1, 91), (1, 98), (1, 103), (1, 107), (1, 142), (1, 146), (1, 152), (1, 179), (1, 181), (1, 209), (2, 54), (2, 129), (2, 144), (2, 158), (2, 172), (2, 198), (2, 206) 查看下对应状态下的x1,x2,x3,x4的变化 数据10 11 1 2 799 520 3 3 3 37 11 2 4 645 533 5 1 11 3 1 659 651 2 2 11 4 0 989 916 3 1 11 5 5 817 442 0 3 11 6 6 753 350 1 4 11 7 2 745 626 1 5 11 8 3 807 503 0 2 11 9 3 774 304 2 2 11 10 3 1265 294 0 4 11 11 5 668 36 0 2 11 12 4 1075 472 1 1 11 13 5 1420 372 1 3 11 14 4 912 320 1 4 18 1 3 26 144 2 4 2 18 18 2 4 24 95 2 3 18 3 2 16 107 0 1 18 4 5 14 76 2 3 18 5 7 32 398 0 5 18 6 4 11 91 0 3 18 7 1 13 35 0 3 18 8 1 29 144 0 0 18 9 4 12 100 0 2 18 10 4 12 65 0 1 18 11 3 19 41 0 4 18 12 2 10 47 1 1 18 13 3 46 46 1 3 34 1 1 5757 3368 5 0 1 99 34 2 1 8469 4823 4 0 34 3 1 8290 5837 1 2 34 4 3 4158 5776 2 1 34 5 2 2713 10177 6 1 34 6 2 2351 6625 1 2 34 7 3 1679 3366 0 1 34 8 1 1847 3648 5 2 34 9 2 3032 3022 1 1 34 10 8 2006 2113 3 3 34 11 4 1700 2165 2 2 34 12 8 1179 1162 2 3 34 13 6 1970 1484 0 1 34 14 4 1828 1784 2 2 38 1 2 891 5400 1 1 0 99 38 2 6 281 447 0 3 38 3 2 316 745 0 2 38 4 9 737 630 0 2 38 5 4 191 467 0 1 38 6 1 250 510 0 0 38 7 1 202 487 1 1 38 8 0 322 530 1 0 38 9 7 352 584 0 3 38 10 6 250 416 1 4 38 11 3 364 418 1 1 38 12 1 382 632 1 1 38 13 10 448 482 0 2 38 14 10 461 1009 1 4 45 1 2 2901 26 0 2 2 19 45 2 0 4919 20 0 0 45 3 1 4489 21 0 1 45 4 3 1614 20 0 1 45 5 3 442 13 0 3 45 6 2 703 13 0 1 45 7 3 130 13 0 1 45 8 1 108 15 0 0 45 9 2 215 14 0 2 45 10 2 141 16 0 2 45 11 3 476 17 0 1 45 12 6 230 5 0 5 45 13 2 378 18 0 2 45 14 1 377 13 0 0 71 1 1 29 17 1 1 0 18 71 2 0 4 9 0 0 71 3 0 0 12 1 0 71 4 0 449 7 0 0 71 5 3 122 12 0 1 71 6 0 67 10 0 0 71 7 2 57 8 1 2 71 8 1 9 10 0 0 71 9 1 2 9 2 0 71 10 2 280 8 0 1 71 11 4 128 7 0 1 71 12 1 35 8 2 0 71 13 1 143 10 0 1 71 14 0 181 12 0 0 状态为活跃时 207 1 57 761 4429 0 42 0 3 207 2 85 109 497 0 68 207 3 78 119 439 0 71 207 4 96 173 447 0 83 207 5 86 152 430 0 70 207 6 71 268 461 0 59 207 7 75 189 712 1 57 207 8 94 208 982 0 82 207 9 54 153 932 0 63 207 10 68 156 991 0 51 207 11 103 174 949 0 89 207 12 111 138 616 0 90 207 13 111 185 867 0 85 207 14 44 343 358 0 54 173 1 6 3645 41 0 4 1 25 173 2 10 6873 39 0 5 173 3 8 6508 39 0 5 173 4 21 1906 62 1 13 173 5 20 103 44 0 12 173 6 19 102 41 0 14 173 7 12 91 55 0 9 173 8 12 81 137 1 11 173 9 20 869 217 1 13 173 10 10 107 136 0 6 173 11 18 117 90 0 12 173 12 14 133 458 1 10 173 13 15 878 2711 1 9 173 14 16 247 197 0 13 生成数据+在原有基础上生成数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130# -*- coding: utf-8 -*-# @Time : 2020/7/27# @Author : esyimport randomimport pandas as pdimport numpy as npdata = pd.read_excel('data1' + '.xlsx')data.fillna(0, inplace=True)# 转换列表list_data = np.array(data).tolist()list_i1 = [int(list_data[i][0]) for i in range(len(data))]list_t1 = [int(list_data[i][1]) for i in range(len(data))]list_y1 = [int(list_data[i][2]) for i in range(len(data))]list_x1 = [int(list_data[i][3]) for i in range(len(data))]list_x2 = [int(list_data[i][4]) for i in range(len(data))]list_x3 = [int(list_data[i][5]) for i in range(len(data))]list_x4 = [int(list_data[i][6]) for i in range(len(data))]list_z1 = [int(list_data[i][7]) for i in range(len(data))]list_z2 = [int(list_data[i][8]) for i in range(len(data))]y1_mean = np.array(list_y1).mean()y1_std = np.array(list_y1).std()for i in range(14*200): list_y1.append(random.randint(0, 10))for i in range(14*50): list_y1.append(random.randint(3, 25))for i in range(14*80): list_y1.append(random.randint(15, 50))for i in range(14*50): list_y1.append(random.randint(35, 120))list_z_y = []for i in range(int(len(list_y1)/14)): y1 = [] for j in range(len(list_y1)): if 14 * i &lt;= j &lt; 14 * (i + 1): y1.append(list_y1[j]) list_z_y.append(np.array(y1).mean())Y_Z = []num1 = 0num2 = 0num3 = 0for i in range(len(list_z_y)): if list_z_y[i] &lt; 1: Y_Z.append(0) num1 += 1 elif 1 &lt;= list_z_y[i] &lt; np.array(list_y1).std(): Y_Z.append(1) num2 += 1 else: Y_Z.append(2) num3 += 1# 将Y_Z变成字典形式dict_Y_Z = dict(zip(np.arange(len(Y_Z)).tolist(), Y_Z))sort_dict = sorted(zip(dict_Y_Z.values(), dict_Y_Z.keys()))for i in range(len(data), len(list_y1)): if list_y1[i] &lt; 1: list_x1.append(random.randint(1, 2000)) list_x2.append(random.randint(1, 1000)) list_x3.append(random.randint(0, 1)) list_x4.append(random.randint(0, 2)) elif 1 &lt;= list_y1[i] &lt; np.array(list_y1).std(): list_x1.append(random.randint(200, 5000)) list_x2.append(random.randint(200, 2000)) list_x3.append(random.randint(0, 10)) list_x4.append(random.randint(5, 20)) else: list_x1.append(random.randint(2000, 10000)) list_x2.append(random.randint(1000, 5000)) list_x3.append(random.randint(2, 30)) list_x4.append(random.randint(10, 100))for i in range(len(data), len(list_y1)): if i % 14 == 0: if Y_Z[int(i/14)] == 0: list_z1.append(random.randint(0, 9)) list_z2.append(random.randint(0, 9)) elif Y_Z[int(i/14)] == 1: list_z1.append(random.randint(0, 9)) list_z2.append(random.randint(5, 100)) else: list_z1.append(random.randint(0, 9)) list_z2.append(random.randint(50, 500)) else: list_z1.append(0) list_z2.append(0)num_i1 = 231for j in range(int(len(data)/14), int(len(list_y1)/14)): for i in range(len(data), len(list_y1)): if 14 * j &lt;= i &lt; 14 * (j + 1): list_i1.append(num_i1) num_i1 += 1for j in range(int(len(data)/14), int(len(list_y1)/14)): k = 0 for i in range(len(data), len(list_y1)): if 14 * j &lt;= i &lt; 14 * (j + 1): k = k + 1 list_t1.append(k)df_i1 = pd.DataFrame(list_i1, columns=['i'])df_t1 = pd.DataFrame(list_t1, columns=['t'])df_y1 = pd.DataFrame(list_y1, columns=['y'])df_x1 = pd.DataFrame(list_x1, columns=['x1'])df_x2 = pd.DataFrame(list_x2, columns=['x2'])df_x3 = pd.DataFrame(list_x3, columns=['x3'])df_x4 = pd.DataFrame(list_x4, columns=['x4'])df_z1 = pd.DataFrame(list_z1, columns=['z1'])df_z2 = pd.DataFrame(list_z2, columns=['z2'])all_data = pd.concat([df_i1, df_t1, df_y1, df_x1, df_x2, df_x3, df_x4, df_z1, df_z2], axis=1)all_data.to_excel('all_data.xlsx') 此时对应的参数设置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657百次循环后，最高准确率0.9383155397390273最大准确率对应的序号：50百次循环后，似然值为-4063.265863470829对应的BIC为-4195.540439027526在4个变量下的状态转移概率矩阵：[[0.9963942307692307, 0.003605769230769231, 0], [0.10307564422277639, 0.8969243557772236, 0.0], [0.0, 0.058704453441295545, 0.9412955465587044]]--------------------参数估计状态转移概率矩阵的系数为：[[ -0.12383302 -0.05998412 -0.24795679 -14.57070714] [ 0.0197879 -0.05702528 0.04541117 -0.50336113] [ 1.42194922 0.30341754 1.19921318 7.34666875]]状态转移概率矩阵的偏差为：[-8.58771943 -0.06000747 -3.32333259]观察状态概率转移矩阵的系数为：[[-1.01971402 -0.57938656] [ 0.83284649 -1.75792799] [ 0.25329582 2.1562813 ]]观察状态概率转移矩阵的偏差为：[-1.02302946 -0.42107895 -1.67846306]变量1下的知识贡献意愿转移概率[[0.904165130851456, 0.09583486914854404, 0], [0.8882108860141567, 0.0976324139614352, 0.014156700024408104], [0, 0.009270704573547589, 0.9907292954264524]]变量2下的知识贡献意愿转移概率[[0.8673055657943236, 0.13269443420567636, 0], [0.877959482548206, 0.1098364657066146, 0.0122040517451794], [0, 0.009888751545117428, 0.9901112484548825]]变量3下的知识贡献意愿转移概率[[0.8669369701437523, 0.13306302985624768, 0], [0.8777154015133024, 0.11008054674151818, 0.0122040517451794], [0, 0.007416563658838072, 0.992583436341162]]变量4下的知识贡献意愿转移概率[[0.8669369701437523, 0.13306302985624768, 0], [0.8777154015133024, 0.11008054674151818, 0.0122040517451794], [0, 0.007416563658838072, 0.992583436341162]]全部变量下的知识贡献意愿转移概率u1=-8.537239946774692,u2_1=-0.11583742328882626,u2_h=-0.7220150302930365, u3=-0.4933279734329048状态转移概率矩阵的系数为：[[ -0.12383302 -0.05998412 -0.24795679 -14.57070714] [ 0.0197879 -0.05702528 0.04541117 -0.50336113] [ 1.42194922 0.30341754 1.19921318 7.34666875]]观察状态概率转移矩阵的系数为：[[-1.01971402 -0.57938656] [ 0.83284649 -1.75792799] [ 0.25329582 2.1562813 ]]观察状态概率转移矩阵的截距为：[-1.02302946 -0.42107895 -1.67846306]所有参数和矩阵表格如上w1(x1)标准偏差为：0.02525464573099962w1(x2)标准偏差为：0.026393311062668005w1(x3)标准偏差为：0.07533481875592112w1(x4)标准偏差为：0.13181323299672285w2(x1)标准偏差为：0.01959329097587093w2(x2)标准偏差为：0.015565458670391606w2(x3)标准偏差为：0.01844469465856866w2(x4)标准偏差为：0.017210850554842068w3(x1)标准偏差为：0.08027460747756567w3(x2)标准偏差为：0.1133582520346092w3(x3)标准偏差为：0.09188332111057886w3(x4)标准偏差为：0.1810153307790173w1(Z1)标准偏差为：0.0722882365013184w1(Z2)标准偏差为：0.12683764260300465w2(Z1)标准偏差为：0.0722882365013184w2(Z2)标准偏差为：0.12683764260300465w3(Z1)标准偏差为：0.0722882365013184w3(Z2)标准偏差为：0.12683764260300465bz1截距的标准偏差为：0.07779008201467114bz2截距的标准偏差为：0.0651521267497443bz3截距的标准偏差为：0.08229776007120924bx1阈值的标准偏差为：0.05107259495619836bx2阈值的标准偏差为：0.015587987616212207bx3阈值的标准偏差为：0.06441769065231308 直接生成数据 1234math.log(3.9118942731277535)Out[5]: 1.36402172551076741.3640217255107674+5.4588414Out[6]: 6.822863125510767","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"gui界面暂定版和遇到的问题","slug":"chatbot/gui界面暂定版和遇到的问题","date":"2020-07-23T02:47:36.000Z","updated":"2020-07-23T02:47:36.000Z","comments":true,"path":"2020/07/23/chatbot/gui界面暂定版和遇到的问题/","link":"","permalink":"https://esyyes.github.io/2020/07/23/chatbot/gui%E7%95%8C%E9%9D%A2%E6%9A%82%E5%AE%9A%E7%89%88%E5%92%8C%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"gui界面暂定版和遇到的问题主要利用tkinter进行界面的生成 导入的库123456import pandas as pdfrom tkinter import *import timefrom chatbot_gui import *语料库数据data = pd.read_csv('Q&amp;A pairs.csv') GUI界面利用TK的基础流程123456调用库from tkinter import *# 创建窗口root = Tk()# 消息循环 显示窗口root.mainloop() 创建基础界面 利用frame创建4个布局,在初始的root窗口下 标题输入为Q&amp;A chatbot 聊天的窗口大小和固定出现的位置geometry(‘800x600+300+100’) 布局1展示内容信息,布局4是为了在展示和输入信息中加入一个杠杠为了好看 布局2是输入信息 布局3是给发送按钮 1234567891011121314151617# 创建窗口root = Tk()# 标题root.title(&apos;Q&amp;A chatbot&apos;)# 窗口大小root.geometry(&apos;800x600+300+100&apos;)# 聊天窗口布局，布置3个frm1 = Frame(width=800, height=400)frm4 = Frame(width=800, height=5)frm2 = Frame(width=800, height=160)frm3 = Frame(width=800, height=30)frm1.grid()frm4.grid()frm2.grid()frm3.grid()# 消息循环 显示窗口root.mainloop() 整体流程1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import pandas as pdfrom tkinter import *import timefrom chatbot_gui import *data = pd.read_csv('Q&amp;A pairs.csv')# 创建窗口root = Tk()# 标题root.title('Q&amp;A chatbot')# 窗口大小root.geometry('800x600+300+100')# 聊天窗口布局，布置3个frm1 = Frame(width=800, height=400)frm4 = Frame(width=800, height=5)frm2 = Frame(width=800, height=160)frm3 = Frame(width=800, height=30)frm1.grid()frm4.grid()frm2.grid()frm3.grid()df = []def sendMsg(): # 发送消息 strMsg = \"user:\" + time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + '\\n' txtMsgList.config(state='normal') txtMsgList.insert(END, strMsg, 'greencolor') txtMsgList.insert(END, txtMsg.get('0.0', END)) # 开始回复消息 answer = \"chatbot:\" + '\\n' # get('0.0', END)[:-1],0,end获取所有数据，会加入一个换行符，‘\\n'，因此需要加入一个【：-1】 best = run_chatbot(txtMsg.get('0.0', END)[:-1], data) + '\\n' txtMsgList.insert(END, answer, 'greencolor') txtMsgList.insert(END, best) txtMsgList.config(state='disabled') txtMsg.delete('0.0', END)def sendMsgEvent(event): # 发送消息事件 if event.keysym == 'Up': sendMsg()# 布局2# 多重文本框输入，建立输入窗口txtMsg = Text(frm2, height=5, width=60, font=('微软雅黑', 15))txtMsg.grid(row=0, column=0, stick=E)txtMsg.bind(\"&lt;KeyPress-Up&gt;\", sendMsgEvent)# 布局3# 建立发送点击按钮# 建立一个文本框，让他把button顶过去# 输入框entry = Entry(frm3, font=('微软雅黑', 12), state='disabled', relief='flat')# row对应行，column对应的列entry.grid(row=0, column=0, ipadx=220)button = Button(frm3, text='发 送 (S)', font=('微软雅黑', 12), command=sendMsg)button.grid(row=0, column=1, ipadx=8, stick=E)# 布局1txtMsgList = Text(frm1, height=15, width=60, font=('微软雅黑', 15), state='disabled')txtMsgList.tag_config('greencolor', foreground='#008C00')txtMsgList.grid(row=0, column=0, stick=E)txtMsgList.grid()# 消息循环 显示窗口root.mainloop() 遇到的问题txtMsg.get(‘0.0’, END)输出的是文本中所有的信息,会读取到一个/N的换行键,在对文件进行处理时无法直接运行读取 get(‘0.0’, END)[:-1],0,end获取所有数据，会加入一个换行符，‘\\n’，因此需要加入一个【：-1】 在输入时,可能会利用enter直接进行输出结果,或者文本中会出现enter这个换行键,导致文章内容无法读取 下一步考虑,在读取的函数中,加入删除换行键这个步骤 导入的chatbot_gui123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180# -*- coding: utf-8 -*-# @Time : 2020/7/22# @Author : esyimport mathimport en_core_web_mdimport numpy as npimport warningsfrom collections import defaultdictimport randomwarnings.filterwarnings(\"ignore\")nlp = en_core_web_md.load()greeting_output = [\"hi\", \"hey\", \"hello\", \"I'm glad! You are talking to me\"]# 预处理文本数据，将单词还原成基础模式，小写，删除停靠词，得到关键词def del_stop(text): token_doc = [token.lemma_ for token in nlp(text)] # 去除停用词后创建单词列表 filtered_sentence = [] for word in token_doc: lexeme = nlp.vocab[word] if not lexeme.is_stop != False: filtered_sentence.append(word) return filtered_sentence# 计算tfidf得分def QA_tf_idf(data, filtered_sentence): question = np.array(data['Question']).tolist() # 将问题进行分词 # list_ques = [[t.lemma_ for t in nlp(question[i])] for i in range(len(data))] # 去除停用词后创建单词列表 list_key = [] for i in range(len(data)): list_key.append(del_stop(question[i])) # filtered_sentence1 = [] # for word in list_ques[i]: # lexeme = nlp.vocab[word] # if not lexeme.is_stop != False: # filtered_sentence1.append(word) # list_key.append(filtered_sentence1) # 统计词频和词汇,看单词出现的次数 doc_frequency = defaultdict(int) list_words = list_key for word_list in list_words: for i in word_list: doc_frequency[i] += 1 doc_frequency2 = defaultdict(int) for i in filtered_sentence: doc_frequency2[i] += 1 # doc_frequency.update(&#123;'-PRON-': doc_frequency.pop('-pron-')&#125;) l1 = set(doc_frequency2.keys()) l2 = set(doc_frequency.keys()) if len(l1 &amp; l2) == 0: return 0 # if not l1.issubset(l2) != False: # if not True != &#123;'-pron-'&#125;.issubset(l1): # doc_frequency2['-PRON-'] = doc_frequency2['-pron-'] # else: # return 0 else: # 计算每个词的IDF值 word_idf = &#123;&#125; # 存储每个词的idf值 word_doc = defaultdict(int) # 存储包含该词的文档数 for i in doc_frequency: for j in list_words: if i in j: word_doc[i] += 1 for i in doc_frequency: word_idf[i] = math.log(len(list_key) / (word_doc[i] + 1)) # 对样本进行词频统计 list_doc = [] for i in range(len(list_key)): doc_frequency1 = defaultdict(int) for j in list_key[i]: doc_frequency1[j] += 1 list_doc.append(doc_frequency1) # 计算语料库中每个词的tf_idf,构建向量 tf_idf = [] for j in range(len(data)): tf_idf.append([word_idf[i] * list_doc[j][i] / len(list_key[j]) for i in (list_doc[j])]) # 计算问题对应语料库的tf-idf得分 scores = [] for j in range(len(data)): score = 0 for i in doc_frequency2: if i not in doc_frequency: pass else: score += (word_idf[i] * list_doc[j][i] / len(list_key[j])) scores.append(score) # 直接计算问题的语料库得分 # 对问题进行词频统计 quet_tfidf = [] for i in doc_frequency2: if i not in doc_frequency: pass else: quet_tfidf.append(word_idf[i] * doc_frequency2[i] / len(filtered_sentence)) return tf_idf, quet_tfidf, scoresdef recall_5(scores, data, tf_idf): question = np.array(data['Question']).tolist() answer = np.array(data['Answer']).tolist() # 用字典形式按照升序形式排序 x = np.arange(len(data)).tolist() dict_score = dict(zip(x, scores)) listc = sorted(zip(dict_score.values(), dict_score.keys())) recall_ques = [] recall_answ = [] recall_tf_idf = [] # 召回得分最高的5个问题 for i in range(1, 6): recall_ques.append(question[listc[-i][1]]) recall_answ.append(answer[listc[-i][1]]) recall_tf_idf.append(tf_idf[listc[-i][1]]) return recall_ques, recall_answ, recall_tf_idf# 求5个问题的相似度def similar_list(quet_tfidf, recall_tf_idf): similar_score = [] for i in range(len(recall_tf_idf)): if len(recall_tf_idf[i]) == len(quet_tfidf): similar_score.append(np.dot(quet_tfidf, recall_tf_idf[i]) / (np.linalg.norm(quet_tfidf) * np.linalg.norm(recall_tf_idf[i]))) elif len(recall_tf_idf[i]) &lt; len(quet_tfidf): for j in range(len(quet_tfidf) - len(recall_tf_idf[i])): c = recall_tf_idf[i] c.append(0) similar_score.append(np.dot(quet_tfidf, c) / (np.linalg.norm(quet_tfidf) * np.linalg.norm(recall_tf_idf[i]))) else: for j in range(abs(len(quet_tfidf) - len(recall_tf_idf[i]))): a = quet_tfidf a.append(0) similar_score.append(np.dot(a, recall_tf_idf[i]) / (np.linalg.norm(a) * np.linalg.norm(recall_tf_idf[i]))) return similar_scoredef similar_spacy(text, recall_ques): similar_goal = [] for i in range(len(recall_ques)): similar_goal.append(nlp(text).similarity(nlp(recall_ques[i]))) return similar_goal# 输出相似度最高的那个的答案def best_answer(list_num, recall_answ): if max(list_num) &lt;= 0.5: return f\"I'm sorry. I don't understand you\" else: if list_num.index(max(list_num)) == 0: best_ans = recall_answ[list_num.index(max(list_num))] else: best_ans = recall_answ[0] return best_ansdef run_chatbot(text2, data): text1 = \" \".join([token.lemma_ for token in nlp(text2)]) if text1 == 'hey' or text1 == 'hi' or text1 == 'hello' or text1 == 'HI': return random.choice(greeting_output) elif text1 == 'thank' or text1 == 'thank -PRON-' or text1 == 'THANK': return 'You are welcome.' elif text1 == 'bye' or text1 == 'BYE': return 'Bye!' elif len(text1.split()) &lt; 3: return \"I'm sorry. I don't understand you\" else: if QA_tf_idf(data, del_stop(text2)) == 0: return \"I'm sorry. I don't understand you\" else: tf_idf1, quet_tfidf1, scores1 = QA_tf_idf(data, del_stop(text2)) recall_ques1, recall_answ1, recall_tf_idf_1 = recall_5(scores1, data, tf_idf1) return best_answer(similar_spacy(text2, recall_ques1), recall_answ1","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"qachatbot暂定版","slug":"chatbot/qachatbot暂定版","date":"2020-07-23T02:35:38.000Z","updated":"2020-07-23T02:35:38.000Z","comments":true,"path":"2020/07/23/chatbot/qachatbot暂定版/","link":"","permalink":"https://esyyes.github.io/2020/07/23/chatbot/qachatbot%E6%9A%82%E5%AE%9A%E7%89%88/","excerpt":"","text":"qachatbot暂定版整体流程，输入模型，并对模型进行基于规则的判定 基于规则判断1234567891011121314151617def run_chatbot(text2, data): text1 = \" \".join([token.lemma_ for token in nlp(text2)]) if text1 == 'hey' or text1 == 'hi' or text1 == 'hello' or text1 == 'HI': return random.choice(greeting_output) elif text1 == 'thank' or text1 == 'thank -PRON-' or text1 == 'THANK': return 'You are welcome.' elif text1 == 'bye' or text1 == 'BYE': return 'Bye!' elif len(text1.split()) &lt; 3: return \"I'm sorry. I don't understand you\" else: if QA_tf_idf(data, del_stop(text2)) == 0: return \"I'm sorry. I don't understand you\" else: tf_idf1, quet_tfidf1, scores1 = QA_tf_idf(data, del_stop(text2)) recall_ques1, recall_answ1, recall_tf_idf_1 = recall_5(scores1, data, tf_idf1) return best_answer(similar_spacy(text2, recall_ques1), recall_answ1) 数据预处理12345678910# 预处理文本数据，将单词还原成基础模式，小写，删除停靠词，得到关键词def del_stop(text): token_doc = [token.lemma_ for token in nlp(text)] # 去除停用词后创建单词列表 filtered_sentence = [] for word in token_doc: lexeme = nlp.vocab[word] if not lexeme.is_stop != False: filtered_sentence.append(word) return filtered_sentence 调用的模块12345678910import mathimport en_core_web_mdimport numpy as npimport warningsfrom collections import defaultdictimport randomwarnings.filterwarnings(\"ignore\")nlp = en_core_web_md.load()greeting_output = [\"hi\", \"hey\", \"hello\", \"I'm glad! You are talking to me\"] 计算tf-idf得分流程步骤： 先对数据进行预处理 然后统计语料库中和输入问题的关键词汇 判断两个句子是不是有相交if len(l1 &amp; l2) == 0，如果相交的话就输出对应的tf-idf得分 输出问题中的关键词在语料库的每个问题中占的得分的多少 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# 计算tfidf得分def QA_tf_idf(data, filtered_sentence): question = np.array(data[&apos;Question&apos;]).tolist() # 将问题进行分词 # 去除停用词后创建单词列表 list_key = [] for i in range(len(data)): list_key.append(del_stop(question[i])) # filtered_sentence1 = [] # for word in list_ques[i]: # lexeme = nlp.vocab[word] # if not lexeme.is_stop != False: # filtered_sentence1.append(word) # list_key.append(filtered_sentence1) # 统计词频和词汇,看单词出现的次数 doc_frequency = defaultdict(int) list_words = list_key for word_list in list_words: for i in word_list: doc_frequency[i] += 1 doc_frequency2 = defaultdict(int) for i in filtered_sentence: doc_frequency2[i] += 1 # doc_frequency.update(&#123;&apos;-PRON-&apos;: doc_frequency.pop(&apos;-pron-&apos;)&#125;) l1 = set(doc_frequency2.keys()) l2 = set(doc_frequency.keys()) if len(l1 &amp; l2) == 0: return 0 # if not l1.issubset(l2) != False: # if not True != &#123;&apos;-pron-&apos;&#125;.issubset(l1): # doc_frequency2[&apos;-PRON-&apos;] = doc_frequency2[&apos;-pron-&apos;] # else: # return 0 else: # 计算每个词的IDF值 word_idf = &#123;&#125; # 存储每个词的idf值 word_doc = defaultdict(int) # 存储包含该词的文档数 for i in doc_frequency: for j in list_words: if i in j: word_doc[i] += 1 for i in doc_frequency: word_idf[i] = math.log(len(list_key) / (word_doc[i] + 1)) # 对样本进行词频统计 list_doc = [] for i in range(len(list_key)): doc_frequency1 = defaultdict(int) for j in list_key[i]: doc_frequency1[j] += 1 list_doc.append(doc_frequency1) # 计算语料库中每个词的tf_idf,构建向量 tf_idf = [] for j in range(len(data)): tf_idf.append([word_idf[i] * list_doc[j][i] / len(list_key[j]) for i in (list_doc[j])]) # 计算问题对应语料库的tf-idf得分 scores = [] for j in range(len(data)): score = 0 for i in doc_frequency2: if i not in doc_frequency: pass else: score += (word_idf[i] * list_doc[j][i] / len(list_key[j])) scores.append(score) # 直接计算问题的语料库得分 # 对问题进行词频统计 quet_tfidf = [] for i in doc_frequency2: if i not in doc_frequency: pass else: quet_tfidf.append(word_idf[i] * doc_frequency2[i] / len(filtered_sentence)) return tf_idf, quet_tfidf, scores 召回得分最高的5个问题和对应的答案12345678910111213141516def recall_5(scores, data, tf_idf): question = np.array(data['Question']).tolist() answer = np.array(data['Answer']).tolist() # 用字典形式按照升序形式排序 x = np.arange(len(data)).tolist() dict_score = dict(zip(x, scores)) listc = sorted(zip(dict_score.values(), dict_score.keys())) recall_ques = [] recall_answ = [] recall_tf_idf = [] # 召回得分最高的5个问题 for i in range(1, 6): recall_ques.append(question[listc[-i][1]]) recall_answ.append(answer[listc[-i][1]]) recall_tf_idf.append(tf_idf[listc[-i][1]]) return recall_ques, recall_answ, recall_tf_idf 求解问题的相似度利用tfidf得分求相似度1234567891011121314151617# 求5个问题的相似度def similar_list(quet_tfidf, recall_tf_idf): similar_score = [] for i in range(len(recall_tf_idf)): if len(recall_tf_idf[i]) == len(quet_tfidf): similar_score.append(np.dot(quet_tfidf, recall_tf_idf[i]) / (np.linalg.norm(quet_tfidf) * np.linalg.norm(recall_tf_idf[i]))) elif len(recall_tf_idf[i]) &lt; len(quet_tfidf): for j in range(len(quet_tfidf) - len(recall_tf_idf[i])): c = recall_tf_idf[i] c.append(0) similar_score.append(np.dot(quet_tfidf, c) / (np.linalg.norm(quet_tfidf) * np.linalg.norm(recall_tf_idf[i]))) else: for j in range(abs(len(quet_tfidf) - len(recall_tf_idf[i]))): a = quet_tfidf a.append(0) similar_score.append(np.dot(a, recall_tf_idf[i]) / (np.linalg.norm(a) * np.linalg.norm(recall_tf_idf[i]))) return similar_score 利用文本相似性求得分12345def similar_spacy(text, recall_ques): similar_goal = [] for i in range(len(recall_ques)): similar_goal.append(nlp(text).similarity(nlp(recall_ques[i]))) return similar_goal 召回相似性和得分最高的答案1234567891011# 输出相似度最高的那个的答案def best_answer(list_num, recall_answ): if max(list_num) &lt;= 0.5: return f\"I'm sorry. I don't understand you\" else: if list_num.index(max(list_num)) == 0: best_ans = recall_answ[list_num.index(max(list_num))] else: best_ans = recall_answ[0] return best_ans","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"chatbot_sorry篇","slug":"chatbot/chatbot-sorry篇","date":"2020-07-22T04:39:11.000Z","updated":"2020-07-22T04:39:11.000Z","comments":true,"path":"2020/07/22/chatbot/chatbot-sorry篇/","link":"","permalink":"https://esyyes.github.io/2020/07/22/chatbot/chatbot-sorry%E7%AF%87/","excerpt":"","text":"chatbot_sorry篇直接循环输入语句。判断哪些句子无法被检测 12345678910111213141516171819202122232425262728293031323334353637383940# -*- coding: utf-8 -*-# @Time : 2020/7/22# @Author : esyfrom chatbot_21 import *import pandas as pddata = pd.read_csv(&apos;Q&amp;A pairs.csv&apos;)print(&quot;Hello, I&apos;m a question-and-answer chatbot for the tourism domain based on retrieval mode.&quot; &quot;If you want to exit, input &apos;Bye&apos;!&quot;)greeting_output = [&quot;hi&quot;, &quot;hey&quot;, &quot;hello&quot;, &quot;I&apos;m glad! You are talking to me&quot;]for i in range(len(data)): question = np.array(data[&apos;Question&apos;]).tolist() text2 = question[i] # 将词还原到最基础模式 text1 = &quot; &quot;.join([token.lemma_ for token in nlp(text2)]) # 进行简单回复 if text1 == &apos;hey&apos; or text1 == &apos;hi&apos; or text1 == &apos;hello&apos; or text1 == &apos;HI&apos;: print(random.choice(greeting_output)) elif text1 == &apos;thank&apos; or text1 == &apos;thank -PRON-&apos; or text1 == &apos;THANK&apos;: print(&apos;You are welcome.&apos;) elif text1 == &apos;bye&apos; or text1 == &apos;BYE&apos;: print(&apos;Bye!&apos;) elif len(text1.split()) &lt; 3: print(f&quot;I&apos;m sorry. I don&apos;t understand you&quot;) print(f&apos;第&#123;i+1&#125;个由于n&lt;3&apos;) else: if QA_tf_idf(data, del_stop(text1)) == 0: print(f&quot;I&apos;m sorry. I don&apos;t understand you&quot;) print(f&apos;第&#123;i+1&#125;个由于return=0&apos;) else: tf_idf1, quet_tfidf1, scores1 = QA_tf_idf(data, del_stop(text1)) recall_ques1, recall_answ1, recall_tf_idf_1 = recall_5(scores1, data, tf_idf1) # print(f&apos;召回的5个问题&apos;) # for j in range(5): # print(f&apos;第&#123;j + 1&#125;问题：&#123;recall_ques1[j]&#125;&apos;, end=&apos;\\t&apos;) # print(f&apos;相似度：&#123;similar_list(quet_tfidf1, recall_tf_idf_1)[j]&#125;&apos;) # print(f&apos;最佳答案：&#123;best_answer(similar_list(quet_tfidf1, recall_tf_idf_1), recall_answ1)&#125;&apos;) 123456789101112131415161718192021222324I'm sorry. I don't understand you第4个由于return=0I'm sorry. I don't understand you第5个由于return=0I'm sorry. I don't understand you第9个由于return=0I'm sorry. I don't understand you第15个由于return=0I'm sorry. I don't understand you第18个由于return=0I'm sorry. I don't understand you第29个由于return=0I'm sorry. I don't understand you第30个由于return=0I'm sorry. I don't understand you第85个由于return=0I'm sorry. I don't understand you第88个由于return=0I'm sorry. I don't understand you第95个由于return=0I'm sorry. I don't understand you第98个由于return=0I'm sorry. I don't understand you第99个由于return=0 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137# -*- coding: utf-8 -*-# @Time : 2020/7/22# @Author : esyimport mathimport en_core_web_mdimport numpy as npimport warningsfrom collections import defaultdictwarnings.filterwarnings(\"ignore\")nlp = en_core_web_md.load()# 预处理文本数据，将单词还原成基础模式，小写，删除停靠词，得到关键词def del_stop(text): token_doc = [token.lemma_ for token in nlp(text)] # 去除停用词后创建单词列表 filtered_sentence = [] for word in token_doc: lexeme = nlp.vocab[word] if not lexeme.is_stop != False: filtered_sentence.append(word) return filtered_sentence# 计算tfidf得分def QA_tf_idf(data, filtered_sentence): question = np.array(data['Question']).tolist() # 将问题进行分词 list_ques = [[t.lemma_ for t in nlp(question[i])] for i in range(len(data))] # 去除停用词后创建单词列表 list_key = [] for i in range(len(data)): filtered_sentence1 = [] for word in list_ques[i]: lexeme = nlp.vocab[word] if not lexeme.is_stop != False: filtered_sentence1.append(word) list_key.append(filtered_sentence1) # 统计词频和词汇,看单词出现的次数 doc_frequency = defaultdict(int) list_words = list_key for word_list in list_words: for i in word_list: doc_frequency[i] += 1 l1 = set(filtered_sentence) l2 = set(doc_frequency.keys()) if not l1.issubset(l2) != False: return 0 else: # 计算每个词的IDF值 word_idf = &#123;&#125; # 存储每个词的idf值 word_doc = defaultdict(int) # 存储包含该词的文档数 for i in doc_frequency: for j in list_words: if i in j: word_doc[i] += 1 for i in doc_frequency: word_idf[i] = math.log(len(list_key) / (word_doc[i] + 1)) # 对样本进行词频统计 list_doc = [] for i in range(len(list_key)): doc_frequency1 = defaultdict(int) for j in list_key[i]: doc_frequency1[j] += 1 list_doc.append(doc_frequency1) # 计算语料库中每个词的tf_idf,构建向量 tf_idf = [] for j in range(len(data)): tf_idf.append([word_idf[i] * list_doc[j][i] / len(list_key[j]) for i in (list_doc[j])]) doc_frequency2 = defaultdict(int) for i in filtered_sentence: doc_frequency2[i] += 1 # 计算问题对应语料库的tf-idf得分 scores = [] for j in range(len(data)): score = 0 for i in doc_frequency2: score += (word_idf[i] * list_doc[j][i] / len(list_key[j])) scores.append(score) # 直接计算问题的语料库得分 # 对问题进行词频统计 quet_tfidf = [] for i in doc_frequency2: quet_tfidf.append(word_idf[i] * doc_frequency2[i] / len(filtered_sentence)) return tf_idf, quet_tfidf, scoresdef recall_5(scores, data, tf_idf): question = np.array(data['Question']).tolist() answer = np.array(data['Answer']).tolist() # 用字典形式按照升序形式排序 x = np.arange(len(data)).tolist() dict_score = dict(zip(x, scores)) listc = sorted(zip(dict_score.values(), dict_score.keys())) recall_ques = [] recall_answ = [] recall_tf_idf = [] # 召回得分最高的5个问题 for i in range(1, 6): recall_ques.append(question[listc[-i][1]]) recall_answ.append(answer[listc[-i][1]]) recall_tf_idf.append(tf_idf[listc[-i][1]]) return recall_ques, recall_answ, recall_tf_idf# 求5个问题的相似度def similar_list(quet_tfidf, recall_tf_idf): similar_score = [] for i in range(len(recall_tf_idf)): if len(recall_tf_idf[i]) == len(quet_tfidf): similar_score.append(np.dot(quet_tfidf, recall_tf_idf[i]) / (np.linalg.norm(quet_tfidf) * np.linalg.norm(recall_tf_idf[i]))) elif len(recall_tf_idf[i]) &lt; len(quet_tfidf): for j in range(len(quet_tfidf) - len(recall_tf_idf[i])): c = recall_tf_idf[i] c.append(0) similar_score.append(np.dot(quet_tfidf, c) / (np.linalg.norm(quet_tfidf) * np.linalg.norm(recall_tf_idf[i]))) else: for j in range(abs(len(quet_tfidf) - len(recall_tf_idf[i]))): a = quet_tfidf a.append(0) similar_score.append(np.dot(a, recall_tf_idf[i]) / (np.linalg.norm(a) * np.linalg.norm(recall_tf_idf[i]))) return similar_score# 输出相似度最高的那个的答案def best_answer(list_num, recall_answ): if max(list_num) &lt;= 0.2: return f\"I'm sorry. I don't understand you\" else: best_ans = recall_answ[list_num.index(max(list_num))] return best_ans 问题查询：1.查看去除停靠词后句子1234sl = set([1, 2,3])sl2 = set([2,3, 7,9])sl.issubset(sl2)Out[5]: False 感觉是去除词频后，没有包含进去 123# if not l1.issubset(l2) != False:# if not True != &#123;'-pron-'&#125;.issubset(l1):# doc_frequency2['-PRON-'] = doc_frequency2['-pron-'] 经查验，经过问题的分词后，人输出为pron，而语料库中是大写的PRON sl.issubset(sl2)是属于包含关系，需要调整为 12if len(l1 &amp; l2) == 0: return 0 判断两个集合是否有交集，这样即使输入的内容有些关键词汇不在语料库中也能直接输出。 1234567891011121314151617def run_chatbot(text2, data): text1 = \" \".join([token.lemma_ for token in nlp(text2)]) if text1 == 'hey' or text1 == 'hi' or text1 == 'hello' or text1 == 'HI': return random.choice(greeting_output) elif text1 == 'thank' or text1 == 'thank -PRON-' or text1 == 'THANK': return 'You are welcome.' elif text1 == 'bye' or text1 == 'BYE': return 'Bye!' elif len(text1.split()) &lt; 3: return \"I'm sorry. I don't understand you\" else: if QA_tf_idf(data, del_stop(text2)) == 0: return \"I'm sorry. I don't understand you\" else: tf_idf1, quet_tfidf1, scores1 = QA_tf_idf(data, del_stop(text2)) recall_ques1, recall_answ1, recall_tf_idf_1 = recall_5(scores1, data, tf_idf1) return best_answer(similar_list(quet_tfidf1, recall_tf_idf_1), recall_answ1) 也同时对输出的语句进行规制的判定，如果不在规制内，输入的单词小于3个也直接输出 2.相似度问题123456def similar_spacy(text, recall_ques): similar_goal = [] for i in range(len(recall_ques)): similar_goal.append(nlp(text).similarity(nlp(recall_ques[i]))) return similar_goal 直接利用自带的相似度，去估计两个输入的大小，这样会降低长度不等的问题的影响","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"python上的GUI","slug":"chatbot/python上的GUI","date":"2020-07-21T00:25:01.000Z","updated":"2020-07-21T00:25:01.000Z","comments":true,"path":"2020/07/21/chatbot/python上的GUI/","link":"","permalink":"https://esyyes.github.io/2020/07/21/chatbot/python%E4%B8%8A%E7%9A%84GUI/","excerpt":"","text":"Python GUI编程(Tkinter)tkinter介绍https://www.runoob.com/python/python-gui-tkinter.html 这个链接里面直接设置相关的 Python 提供了多个图形开发界面的库，几个常用 Python GUI 库如下： Tkinter： Tkinter 模块(Tk 接口)是 Python 的标准 Tk GUI 工具包的接口 .Tk 和 Tkinter 可以在大多数的 Unix 平台下使用,同样可以应用在 Windows 和 Macintosh 系统里。Tk8.0 的后续版本可以实现本地窗口风格,并良好地运行在绝大多数平台中。 wxPython：wxPython 是一款开源软件，是 Python 语言的一套优秀的 GUI 图形库，允许 Python 程序员很方便的创建完整的、功能健全的 GUI 用户界面。 Jython：Jython 程序可以和 Java 无缝集成。除了一些标准模块，Jython 使用 Java 的模块。Jython 几乎拥有标准的Python 中不依赖于 C 语言的全部模块。比如，Jython 的用户界面将使用 Swing，AWT或者 SWT。Jython 可以被动态或静态地编译成 Java 字节码。 Tkinter 是 Python 的标准 GUI 库。Python 使用 Tkinter 可以快速的创建 GUI 应用程序。 由于 Tkinter 是内置到 python 的安装包中、只要安装好 Python 之后就能 import Tkinter 库、而且 IDLE 也是用 Tkinter 编写而成、对于简单的图形界面 Tkinter 还是能应付自如。 注意*：Python3.x 版本使用的库名为 tkinter,即首写字母 T 为小写。* 1import tkinter 创建一个GUI程序 1、导入 Tkinter 模块 2、创建控件 3、指定这个控件的 master， 即这个控件属于哪一个 4、告诉 GM(geometry manager) 有一个控件产生了。 12345import tkinter创建简单窗口top = tkinter.Tk()# 进入消息循环top.mainloop() 12345678910111213141516171819202122232425262728293031323334353637# -*- coding: utf-8 -*-# @Time : 2020/7/21# @Author : esyfrom tkinter import *# 创建窗口root = thinter.TK()root = Tk()# 标题root.title('Q&amp;A chatbot')# 窗口大小 小写的x，表示大小root.geometry('720x400+500+200')# 窗口位置 像素px 的坐标。距离左上角的位置# root.geometry('+500+300')# 标签控件label = Label(root, text='签名', font=('华为行楷', 20), fg='red')# pack place 定位（只用一种）grid 网格布局label.grid()# 输入框entry = Entry(root, font=('微软雅黑', 20))# row对应行，column对应的列entry.grid(row=0, column=1)# 点击按钮button = Button(root, text='设计签名', font=('微软雅黑', 20), fg='blue')# 宽高设置button['width'] = 10button['height'] = 1# 对齐方式sticky,W左。E右, stick=Ebutton.grid(row=1, column=1)# 消息循环 显示窗口root.mainloop() 组件：按钮，文本输入框。滚动条等 窗口：root输入 GUI–窗口设置123456789101112131415161718import tkinter# 创建主窗口对象root = tkinter.Tk()# 给窗口加入标题root.title('Q&amp;A chatbot')# 设置窗口大小,像素大小# root.minsize(300, 300)# 窗口大小 小写的x，表示大小， 和位置root.geometry('720x400+500+200')# 窗口位置 像素px 的坐标。距离左上角的位置# root.geometry('+500+300')# 加入信息循环root.mainloop() 组件摆放方式https://www.cnblogs.com/myshuzhimei/p/11764532.html Tkinter之部件3种放置方式pack、grid、place 以规律的方格形式呈现。比如下面的代码就是创建一个三行三列的表格：参数row 为行，colum 为列，padx 单元格左右间距，pady单元格上下间距，ipadx单元格内部元素与单元格的左右间距，ipady单元格内部元素与单元格的上下间距。 直接用grid方式 12345678910111213141516171819202122232425262728293031323334353637383940# -*- coding: utf-8 -*-# @Time : 2020/7/21# @Author : esyimport tkinter# 创建主窗口对象root = tkinter.Tk()# 给窗口加入标题root.title('Q&amp;A chatbot')# 设置窗口大小,像素大小# root.minsize(300, 300)# 窗口大小 小写的x，表示大小， 和位置root.geometry('720x400+500+200')# 窗口位置 像素px 的坐标。距离左上角的位置# root.geometry('+500+300')# 点击按钮button = tkinter.Button(root, text='点击0', font=('微软雅黑', 20), fg='blue')button.grid(row=0, column=0)button1 = tkinter.Button(root, text='点击1', font=('微软雅黑', 20), fg='blue')button1.grid(row=0, column=1)button2 = tkinter.Button(root, text='点击2', font=('微软雅黑', 20), fg='blue')button2.grid(row=1, column=0)button3 = tkinter.Button(root, text='点击3', font=('微软雅黑', 20), fg='blue')button3.grid(row=1, column=1)button4 = tkinter.Button(root, text='点击4', font=('微软雅黑', 20), fg='blue')button4.grid(row=2, column=0, columnspan=2, ipadx=40)button5 = tkinter.Button(root, text='点击5', font=('微软雅黑', 20), fg='blue')button5.grid(row=0, column=2, rowspan=2, ipady=40)# 跨列columnspan rowspan,跨行# ipadx,ipady 跨距离设置# 加入信息循环root.mainloop() 组件信息鼠标样式1root['cursor'] = 'heart' cheakbutoon勾选框组件1234567891011121314151617181920212223242526272829303132333435363738# -*- coding: utf-8 -*-# @Time : 2020/7/21# @Author : esyimport tkinterfrom tkinter import *# 创建主窗口对象root = tkinter.Tk()# 鼠标样式root['cursor'] = 'heart'# 给窗口加入标题root.title('Q&amp;A chatbot')# 设置窗口大小,像素大小# root.minsize(300, 300)# 窗口大小 小写的x，表示大小， 和位置root.geometry('720x400+500+200')# cheakbutton 选择框组件# 如果文本的内容有变化text = tkinter.StringVar()text.set('同意')# 设置选择框钩与不钩的值result = tkinter.IntVar()# 设置返回值def func(): print(result.get())cheakbutoon = tkinter.Checkbutton(root, textvariable=text, variable=result, command=func)cheakbutoon.grid(row=0, column=0)# 加入信息循环root.mainloop() 输入组件123456789101112131415161718192021222324252627282930# -*- coding: utf-8 -*-# @Time : 2020/7/21# @Author : esyimport tkinter# 创建主窗口对象root = tkinter.Tk()# 鼠标样式root[&apos;cursor&apos;] = &apos;heart&apos;# 给窗口加入标题root.title(&apos;Q&amp;A chatbot&apos;)# 窗口大小 小写的x，表示大小， 和位置root.geometry(&apos;720x400+500+200&apos;)# 输入组件# 输入框username = tkinter.Entry(root, font=(&apos;微软雅黑&apos;, 20), bg=&apos;red&apos;, fg=&apos;blue&apos;)username.grid(row=0, column=0)# 密码输入password = tkinter.Entry(root, show=&apos;*&apos;, font=(&apos;微软雅黑&apos;, 20))password.grid(row=1, column=0)# 加入信息循环root.mainloop()","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"chatbot在python上实现","slug":"chatbot/chatbot在python上实现","date":"2020-07-20T13:23:10.000Z","updated":"2020-07-20T13:23:10.000Z","comments":true,"path":"2020/07/20/chatbot/chatbot在python上实现/","link":"","permalink":"https://esyyes.github.io/2020/07/20/chatbot/chatbot%E5%9C%A8python%E4%B8%8A%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"chatbot在python上实现流程基于规则输出简单的回复123456789101112131415if __name__ == '__main__': data1 = pd.read_csv('Q&amp;A pairs.csv') print(\"Hello, I'm a question-and-answer chatbot for the tourism domain based on retrieval mode.\" \"If you want to exit, input 'Bye'!\") greeting_output = [\"hi\", \"hey\", \"hello\", \"I'm glad! You are talking to me\"] while True: text2 = input(\"Please enter a question: \\t\") text1 = \" \".join([token.lemma_ for token in nlp(text2)]) if text1 == 'hey' or text1 == 'hi' or text1 == 'hello' or text1 == 'HI': print(random.choice(greeting_output)) elif text1 == 'thank' or text1 == 'thank -PRON-' or text1 == 'THANK': print('You are welcome.') elif text1 == 'bye' or text1 == 'BYE': print('Bye!') break 重新写个简单的程序吧 首先对问题进行预处理12345678910def del_stop(text): token_doc = [token.lemma_ for token in nlp(text)] # 去除停用词后创建单词列表 filtered_sentence = [] for word in token_doc: lexeme = nlp.vocab[word] if not lexeme.is_stop != False: filtered_sentence.append(word) return filtered_sentence将字母都切换为小写，并切除停靠词，得到关键的语句 计算TF_IDF第一步还是将问题进行预处理，然后获取语料库中的问题的词频，得到语料库的词汇 第二步判断提出的问题的关键词汇是否在语料库的词汇中，如果不在就直接返回0，程序会返回一个不知道 第三步计算词汇的idf 第四步计算每个单词在每个问题中的频率 第五步得到每个问题的关键词汇的tf-idf的分数列表 第六步计算提出问题在每个问题中能得到tf-idf多少分 第七步将每个tf-idf的得分升序排列，然后召回最高得分的5个问题，和对应的5个答案 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768def QA_tf_idf(data, filtered_sentence): question = np.array(data[&apos;Question&apos;]).tolist() answer = np.array(data[&apos;Answer&apos;]).tolist() # 将问题进行分词 list_ques = [[t.lemma_ for t in nlp(question[i])] for i in range(len(data))] # 去除停用词后创建单词列表 list_key = [] for i in range(len(data)): filtered_sentence1 = [] for word in list_ques[i]: lexeme = nlp.vocab[word] if not lexeme.is_stop != False: filtered_sentence1.append(word) list_key.append(filtered_sentence1) # 统计词频和词汇,看单词出现的次数 doc_frequency = defaultdict(int) list_words = list_key for word_list in list_words: for i in word_list: doc_frequency[i] += 1 l1 = set(filtered_sentence) l2 = set(doc_frequency.keys()) if not l1.issubset(l2) != False: return 0 else: # 计算每个词的IDF值 word_idf = &#123;&#125; # 存储每个词的idf值 word_doc = defaultdict(int) # 存储包含该词的文档数 for i in doc_frequency: for j in list_words: if i in j: word_doc[i] += 1 for i in doc_frequency: word_idf[i] = math.log(len(list_key) / (word_doc[i] + 1)) # 找到每个词对应文档中出现的次数 doc_frequency1 = defaultdict(int) for word_list in list_key: for i in word_list: doc_frequency1[i] += 1 # 对样本进行词频统计 list_doc = [] for i in range(len(list_key)): doc_frequency1 = defaultdict(int) for j in list_key[i]: doc_frequency1[j] += 1 list_doc.append(doc_frequency1) # 计算语料库的tf_idf tf_idf = [] for j in range(len(data)): tf_idf.append([word_idf[i] * list_doc[j][i] / len(list_doc[j]) for i in (list_doc[j])]) # 计算样本的tf-idf得分 scores = [] for j in range(len(data)): score = 0 for i in filtered_sentence: score += (word_idf[i] * list_doc[j][i] / len(list_doc[j])) scores.append(score) # 用字典形式排序 x = np.arange(len(data)).tolist() dict_score = dict(zip(x, scores)) listc = sorted(zip(dict_score.values(), dict_score.keys())) recall_ques = [] recall_answ = [] for i in range(1, 6): recall_ques.append(question[listc[-i][1]]) recall_answ.append(answer[listc[-i][1]]) return recall_ques, recall_answ 求5个问题的相似度利用自带的余弦相似性求5个问题和输入问题的相似度 12def similar_list(text, recall_ques): return [nlp(text).similarity(nlp(recall_ques[i])) for i in range(5)] 输出相似度最高的那个问题的答案123def best_answer(list_num, recall_answ): # 输出相似度最高的那个的答案 print(recall_answ[list_num.index(max(list_num))]) 构建无限循环123456789101112131415161718192021if __name__ == '__main__': data1 = pd.read_csv('Q&amp;A pairs.csv') print(\"Hello, I'm a question-and-answer chatbot for the tourism domain based on retrieval mode.\" \"If you want to exit, input 'Bye'!\") greeting_output = [\"hi\", \"hey\", \"hello\", \"I'm glad! You are talking to me\"] while True: text2 = input(\"Please enter a question: \\t\") text1 = \" \".join([token.lemma_ for token in nlp(text2)]) if text1 == 'hey' or text1 == 'hi' or text1 == 'hello' or text1 == 'HI': print(random.choice(greeting_output)) elif text1 == 'thank' or text1 == 'thank -PRON-' or text1 == 'THANK': print('You are welcome.') elif text1 == 'bye' or text1 == 'BYE': print('Bye!') break else: if QA_tf_idf(data1, del_stop(text1)) == 0: print(f\"I'm sorry. I don't understand you\") else: recall_ques1, recall_answ1 = QA_tf_idf(data1, del_stop(text1)) best_answer(similar_list(text1, recall_ques1), recall_answ1) 能够简单实现步骤，下一步加入GUI","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"Q&A chatbot 简单实现","slug":"chatbot/Q-A-chatbot-简单实现","date":"2020-07-19T08:32:51.000Z","updated":"2020-07-19T08:32:51.000Z","comments":true,"path":"2020/07/19/chatbot/Q-A-chatbot-简单实现/","link":"","permalink":"https://esyyes.github.io/2020/07/19/chatbot/Q-A-chatbot-%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"Q&amp;A chatbot 简单实现Project Title: Traveler (a question-and-answer chatbot based on retrieval mode.)设计要求：I plan to develop a question-and-answer chatbot for the tourism domainbased on retrieval mode. The chatbot will respond to users byselecting the best matching answer in the database based on users’questions. four parts.In order to develop the question-and answer chatbot, I will divide my job into four parts. 1) Extract the keywords from textFor a piece of text, I can extract keywords and remove words that have no actualmeaning but appear frequently, such as the, a, is, etc. This process prepares for thegeneration of word frequency vectors that can be used to calculate the similaritybetween two pieces of text. 2) Calculate the semantic similarityFor a piece of text, I can calculate the similarity between this text and othercompared text. According to the extracted keywords mentioned above, all the textswill be vectorized to calculate the similarity between the test text and eachcompared text. The higher the similarity value is, the more similar the comparedtext is to the test text. This process is prepared to later calculate the similaritybetween the user questions and existing questions in the database. 3) Create database which contains question-and-answer pairsI will deliver a complete database contains all pairs of user’s possible questions andanswers. After calculating the similarity between the user questions and existingquestions, the database will select an answer whose matching question is mostrelevant to the user’s question as response to the users. 4) Create a graphical interface that allows users to enter textI will deliver a GUI that can allow users to input question and give an output to theuser’s question. 初步实现之去除停靠词后的程序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119# -*- coding: utf-8 -*-# @Time : 2020/7/19# @Author : esyimport mathimport random语料包import en_core_web_mdimport pandas as pdimport numpy as npimport warnings为了加载词频from collections import defaultdictwarnings.filterwarnings(\"ignore\")# 导入英文模块nlp = en_core_web_md.load()text = input(\"请输入问题: \")# 进行问题分词doc = nlp(text)token_doc = [token.text for token in doc]# 去除停用词后创建单词列表，相当于就是只有关键词了filtered_sentence = []for word in token_doc: lexeme = nlp.vocab[word] if not lexeme.is_stop != False: filtered_sentence.append(word)# 导入语料包，读取问题和答案data = pd.read_csv('Q&amp;A pairs.csv')question = np.array(data['Question']).tolist()answer = np.array(data['Answer']).tolist()# 将问题进行分词list_ques = [[t.text for t in nlp(question[i])] for i in range(len(data))]# 去除停用词后创建单词列表，将问题全部进行去停靠词list_key = []for i in range(len(data)): filtered_sentence1 = [] for word in list_ques[i]: lexeme = nlp.vocab[word] if not lexeme.is_stop != False: filtered_sentence1.append(word) list_key.append(filtered_sentence1)# 统计词频和词汇,并看单词出现的次数，看全文的关键词汇和词是多少doc_frequency = defaultdict(int)list_words = list_keyfor word_list in list_words: for i in word_list: doc_frequency[i] += 1# 计算每个词的IDF值word_idf = &#123;&#125; # 存储每个词的idf值word_doc = defaultdict(int) # 存储包含该词的文档数for i in doc_frequency: for j in list_words: if i in j: word_doc[i] += 1for i in doc_frequency: word_idf[i] = math.log(len(list_key) / (word_doc[i] + 1))# 找到每个词对应每个问题中出现的次数doc_frequency1 = defaultdict(int)for word_list in list_key: for i in word_list: doc_frequency1[i] += 1# 统计关键词在单个样本中出现的次数list_doc = []for i in range(len(list_key)): doc_frequency1 = defaultdict(int) for j in list_key[i]: doc_frequency1[j] += 1 list_doc.append(doc_frequency1)# 计算出每个问题对应的tf_idf索引tf_idf = []for j in range(len(data)): c = [] for i in (list_doc[j]): c.append(word_idf[i] * list_doc[j][i] / len(list_doc[j])) tf_idf.append(c)# 计算输入的问题在全部文档中的tf-idf得分scores = []for j in range(len(data)): score = 0 for i in filtered_sentence: score += (word_idf[i] * list_doc[j][i] / len(list_doc[j])) scores.append(score)# 用字典形式排序x = np.arange(len(data)).tolist()dict_score = dict(zip(x, scores))升序排序listc = sorted(zip(dict_score.values(), dict_score.keys()))# 召回得分最高的5个对应问题和答案，对问题进行粗排recall_ques = []recall_answ = []for i in range(1, 6): recall_ques.append(question[listc[-i][1]]) recall_answ.append(answer[listc[-i][1]])# 利用余弦相似性求5个问题的相似度list_num = []for i in range(5): list_num.append(doc.similarity(nlp(recall_ques[i])))# 输出相似度最高的那个的答案if len(set(list_num)) == random.randint(1, 6): print(recall_answ[list_num.index(max(list_num))])else: print(recall_answ[random.randint(0, 5)]) 只是能简单实现样本，下一步是实现循环输入和能回复简单的问题","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"spacy的基础知识再学习","slug":"chatbot/spacy的基础知识再学习","date":"2020-07-18T02:14:53.000Z","updated":"2020-07-18T02:14:53.000Z","comments":true,"path":"2020/07/18/chatbot/spacy的基础知识再学习/","link":"","permalink":"https://esyyes.github.io/2020/07/18/chatbot/spacy%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%86%8D%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"spacy的基础知识再学习spacy和nltk的比较 spacy相对来说更快速的多，因此采用，功能也更多一些。","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"q@a检索式机器人的流程","slug":"chatbot/q-a检索式机器人的流程","date":"2020-07-15T16:06:58.000Z","updated":"2020-07-15T16:06:58.000Z","comments":true,"path":"2020/07/16/chatbot/q-a检索式机器人的流程/","link":"","permalink":"https://esyyes.github.io/2020/07/16/chatbot/q-a%E6%A3%80%E7%B4%A2%E5%BC%8F%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9A%84%E6%B5%81%E7%A8%8B/","excerpt":"","text":"Q@A检索式机器人的流程问题输入模块1 问题输入 2 对问题进行分析（预处理问题，利用spacy或nltk等进行自然语言处理） 3 构建规则系统（目的是：回复些简单的内容，和排除些不是旅游系统的信息，if-else语句） 短语映射模块（初排模型）4 将问题的信息和语料库的信息进行匹配（关键词提取–相似度计算） spacy自带了一个相似度计算，现在基本都能算出来，后面再套用下TF-IDF算法，提取关键词， 相似度计算（TF-IDF或者LDA等） TF-IDF: TF-IDF（term frequency–inverse document frequency，词频-逆向文件频率）是一种用于信息检索（information retrieval）与文本挖掘（text mining）的常用加权技术。 LDA（Latent Dirichlet Allocation）是一种文档主题生成模型，也称为一个三层贝叶斯概率模型，包含词、主题和文档三层结构。 一般采用 Word2vec或 GloVe 等工具对自然语言进行向量化，感觉已经进行了向量化 md文件自带向量化，但是需要转换到2进制的，所以还是可以用用word2vec 消歧模块通过计算本体资源的标签和对应的问句信息词之间的相似度进行排序得分，然后召回几个类似的问题。 检索：当用户提问时，通过以上五个步骤把问题映射为一个高维稀疏向量，然后从问题库中召回与其cosin距离最近的n个问题 sklearn中的LSHForest Facebook research的pysparnn 查询构建模块将前面的问题进行匹配后，然后输出最高得分时对应的问题，然后输出答案 后面再说生成gui的问题。","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"spacy的基础学习","slug":"chatbot/spacy的基础学习","date":"2020-07-15T01:56:53.000Z","updated":"2020-07-15T01:56:53.000Z","comments":true,"path":"2020/07/15/chatbot/spacy的基础学习/","link":"","permalink":"https://esyyes.github.io/2020/07/15/chatbot/spacy%E7%9A%84%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"spacyspacy的定义 spaCy是一个python开源模块，用于处理自然语言的大量文本。比如，一段文字的关键是什么？在段落中上下文的意思是什么？谁对谁做了什么？那些公司和产品名称特指什么？一个单词和其他其他单词相似程度如何？作为人类，理解自然语言比较容易，但如果让计算机去理解文本的意思，这都是不可回避的问题。 spaCy就是帮助你使用计算器程序去处理和理解海量文本的工具。在目前来说，号称是速度最快、更加适合实际应用的工业级产品。spaCy可以帮助你构建信息提取、自然语言理解以及深度学习的预处理 。 spaCy是世界上最快的工业级自然语言处理工具。 支持多种自然语言处理基本功能。 官网地址：https://spacy.io/ spaCy主要功能包括分词、词性标注、词干化、命名实体识别、名词短语提取等等。 安装：pip install spacy 与平台不同，spaCy不提供软件即服务或Web应用程序。它是一个开放源代码库，旨在帮助您构建NLP应用程序，而不是消耗性服务。 这是一个开源库。 在文档中，您会提到spaCy的功能。其中一些涉及语言概念，而其他则涉及更通用的机器学习功能。 名称 描述 代币化 将文本分割成单词，标点符号等 词性（POS）标记 将单词类型分配给标记，例如动词或名词。 依赖解析 分配语法相关性标签，描述各个标记（例如主题或客体）之间的关系。 合法化 分配单词的基本形式。例如，“ was”的引理是“ be”，“ rats”的引理是“ rat”。 句子边界检测（SBD） 查找和分割单个句子。 命名实体识别（NER） 标记命名为“真实世界”的对象，例如人员，公司或位置。 实体链接（EL） 消除文本实体与知识库中唯一标识符的歧义。 相似 比较单词，文本跨度和文档，以及它们之间的相似程度。 文字分类 为整个文档或文档的一部分分配类别或标签。 基于规则的匹配 根据标记的文本和语言注释来查找标记序列，类似于正则表达式。 训练 更新和改进统计模型的预测。 序列化 将对象保存到文件或字节字符串 NAME DESCRIPTION Tokenization Segmenting text into words, punctuations marks etc. Part-of-speech (POS) Tagging Assigning word types to tokens, like verb or noun. Dependency Parsing Assigning syntactic dependency labels, describing the relations between individual tokens, like subject or object. Lemmatization Assigning the base forms of words. For example, the lemma of “was” is “be”, and the lemma of “rats” is “rat”. Sentence Boundary Detection (SBD) Finding and segmenting individual sentences. Named Entity Recognition (NER) Labelling named “real-world” objects, like persons, companies or locations. Entity Linking (EL) Disambiguating textual entities to unique identifiers in a Knowledge Base. Similarity Comparing words, text spans and documents and how similar they are to each other. Text Classification Assigning categories or labels to a whole document, or parts of a document. Rule-based Matching Finding sequences of tokens based on their texts and linguistic annotations, similar to regular expressions. Training Updating and improving a statistical model’s predictions. Serialization Saving objects to files or byte strings. 尽管spaCy的某些功能可以独立运行，但是其他功能需要 加载统计模型，这使spaCy可以预测 语言注释-例如，单词是动词还是名词。spaCy当前提供用于多种语言的统计模型，可以将其安装为单独的Python模块。模型的大小，速度，内存使用量，准确性和所包含的数据可能会有所不同。您选择的模型始终取决于您的用例和您使用的文本。对于通用用例，小型的默认模型始终是一个好的开始。它们通常包括以下组件： 词性标记器，依赖性分析器和命名实体识别器的二进制权重，以在上下文中预测这些注释。 词汇中的词汇条目，即单词及其与上下文无关的属性，例如形状或拼写。 数据文件，例如lemmatization规则和查找表。 单词向量，即单词的多维含义表示，可让您确定它们之间的相似程度。 配置选项（例如语言和处理管道设置）可在您加载模型时将spaCy置于正确的状态。 安装默认模型，获取代码以从spaCy内加载它，并提供示例进行测试。有关更多选项，请参见下面有关可用型号的部分 12345import spacynlp = spacy.load(&quot;en_core_web_sm&quot;)两种形式import en_core_web_smnlp = en_core_web_sm.load() Download best-matching version of specific model for your spaCy installation 为spaCy安装下载特定型号的最佳匹配版本 python -m spacy download en_core_web_sm Out-of-the-box: download best-matching default model and create shortcut link 开箱即用：下载最匹配的默认模型并创建快捷链接 python -m spacy download en Download exact model version (doesn’t create shortcut link) python -m spacy download en_core_web_sm-2.2.0 –direct 下载精确的模型版本（不创建快捷链接）python-mspacy下载en_core_web_sm-2.2.0–直接 尺寸：型号尺寸指示符（sm，md或lg） 已经有了en_core_web_md-2.2.5.tar.gz这个版本下载对应的spacy2.2.4.版本 已经能够正常运行，参考网页 https://spacy.io/ 12345678910111213141516171819202122232425262728293031# -*- coding: utf-8 -*-# @Time : 2020/7/15# @Author : esyimport en_core_web_mdnlp = en_core_web_md.load()text = (\"When Sebastian Thrun started working on self-driving cars at \" \"Google in 2007, few people outside of the company took him \" \"seriously. “I can tell you very senior CEOs of major American \" \"car companies would shake my hand and turn away because I wasn’t \" \"worth talking to,” said Thrun, in an interview with Recode earlier \" \"this week.\")doc = nlp(text)# Analyze syntaxprint(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])# Find named entities, phrases and conceptsfor entity in doc.ents: print(entity.text, entity.label_)运行结果Noun phrases: ['Sebastian Thrun', 'self-driving cars', 'Google', 'few people', 'the company', 'him', 'I', 'you', 'very senior CEOs', 'major American car companies', 'my hand', 'I', 'Thrun', 'an interview', 'Recode']Verbs: ['start', 'work', 'drive', 'take', 'can', 'tell', 'would', 'shake', 'turn', 'talk', 'say']Sebastian Thrun PERSONGoogle ORG2007 DATEAmerican NORPThrun PERSONRecode ORGearlier this week DATE spacy的基础分析 1234567import en_core_web_mdnlp = en_core_web_md.load()doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")for token in doc: print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop) TEXT LEMMA POS TAG DEP SHAPE ALPHA STOP Apple apple PROPN NNP nsubj Xxxxx True False is be AUX VBZ aux xx True True looking look VERB VBG ROOT xxxx True False at at ADP IN prep xx True True buying buy VERB VBG pcomp xxxx True False U.K. u.k. PROPN NNP compound X.X. False False startup startup NOUN NN dobj xxxx True False for for ADP IN prep xxx True True $ $ SYM $ quantmod $ False False 1 1 NUM CD compound d False False billion billion NUM CD pobj xxxx True False Text: The original word text.文字：原始文字。 Lemma: The base form of the word.引理：该词的基本形式。 POS: The simple UPOS part-of-speech tag.POS：简单的UPOS词性标签。 Tag: The detailed part-of-speech tag.标记：详细的词性标记。 Dep: Syntactic dependency, i.e. the relation between tokens.Dep：语法依赖性，即标记之间的关系。 Shape: The word shape – capitalization, punctuation, digits.形状：单词形状-大写，标点，数字。 is alpha: Is the token an alpha character?是字母：令牌是字母字符吗？ is stop: Is the token part of a stop list, i.e. the most common words of the language?是停止：标记是停止列表的一部分，即语言中最常见的词吗？ POS!词性标签 词性列表： https://spacy.io/api/annotation#pos-tagging POS DESCRIPTION EXAMPLES ADJ adjective big, old, green, incomprehensible, first ADP adposition in, to, during ADV adverb very, tomorrow, down, where, there AUX auxiliary is, has (done), will (do), should (do) CONJ conjunction and, or, but CCONJ coordinating conjunction and, or, but DET determiner a, an, the INTJ interjection psst, ouch, bravo, hello NOUN noun girl, cat, tree, air, beauty NUM numeral 1, 2017, one, seventy-seven, IV, MMXIV PART particle ’s, not, PRON pronoun I, you, he, she, myself, themselves, somebody PROPN proper noun Mary, John, London, NATO, HBO PUNCT punctuation ., (, ), ? SCONJ subordinating conjunction if, while, that SYM symbol $, %, §, ©, +, −, ×, ÷, =, :), 😝 VERB verb run, runs, running, eat, ate, eating X other sfpksdpsxmsa SPACE space CC coordinatingconjunction 并列连词 CD cardinaldigit 纯数 基数 DT determiner 限定词（置于名词前起限定作用，如 the、some、my 等） EX existentialthere (like:”there is”… think of it like “thereexists”) 存在句；存现句 FW foreignword 外来语；外来词；外文原词 IN preposition/subordinating conjunction介词/从属连词；主从连词；从属连接词 JJ adjective ‘big’ 形容词 JJR adjective, comparative ‘bigger’ （形容词或副词的）比较级形式 JJS adjective, superlative ‘biggest’ （形容词或副词的）最高级 LS listmarker 1) MD modal (could, will) 形态的，形式的 , 语气的；情态的 NN noun, singular ‘desk’ 名词单数形式 NNS nounplural ‘desks’ 名词复数形式 NNP propernoun, singular ‘Harrison’ 专有名词 NNPS proper noun, plural ‘Americans’ 专有名词复数形式 PDT predeterminer ‘all the kids’ 前位限定词 POS possessiveending parent’s 属有词 结束语 PRP personalpronoun I, he, she 人称代词 PRP$ possessive pronoun my, his, hers 物主代词 RB adverb very, silently, 副词 非常 静静地 RBR adverb,comparative better （形容词或副词的）比较级形式 RBS adverb,superlative best （形容词或副词的）最高级 RP particle give up 小品词(与动词构成短语动词的副词或介词) TO to go ‘to’ the store. UH interjection errrrrrrrm 感叹词；感叹语 VB verb, baseform take 动词 VBD verb, pasttense took 动词 过去时；过去式 VBG verb,gerund/present participle taking 动词 动名词/现在分词 VBN verb, pastparticiple taken 动词 过去分词 VBP verb,sing. present, non-3d take 动词 现在 VBZ verb, 3rdperson sing. present takes 动词 第三人称 WDT wh-determiner which 限定词（置于名词前起限定作用，如 the、some、my 等） WP wh-pronoun who, what 代词（代替名词或名词词组的单词） WP$ possessivewh-pronoun whose 所有格；属有词 WRB wh-abverb where, when 副词 原文链接：https://blog.csdn.net/jasonjarvan/article/details/79955664","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"聊天机器人基础","slug":"chatbot/聊天机器人基础","date":"2020-07-10T13:55:29.000Z","updated":"2020-07-10T13:55:29.000Z","comments":true,"path":"2020/07/10/chatbot/聊天机器人基础/","link":"","permalink":"https://esyyes.github.io/2020/07/10/chatbot/%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%9F%BA%E7%A1%80/","excerpt":"","text":"聊天机器人基础篇问答系统是搜索引擎技术的一种扩展，可根据用户输入的问题给出精确而简练的答案。根据回答问题的范围，问答系统分为开域和闭域。开域的问答系统可以回答多种多样、涉及很多领域的问题；闭域的问答系统为用户回答某个特定领域的问题。 问答系统通常是闭域的，且为执行具体的任务而设计，这种问答系统也称作任务式问答系统 I plan to develop a question-and-answer chatbot for the tourism domainbased on retrieval mode. The chatbot will respond to users byselecting the best matching answer in the database based on users’questions. 本文的要求：聊天机器人就为问答式的指定的旅游和检索式的！ 以任务为主的特定领域。检索式 检索式单轮聊天机器人（ＦＡＱ－Ｂ〇ｔ），其思想就是通过计算词向量的相似性，利用有限的问答对进行同义词的扩展修改和复写，此外还有问答系统（ＱＡ） 即创建一个问答式的检索聊天机器人。 问答系统问答系统 （ Question Answerir毡， QA ）由最初的搜索需求发展而来，基本为“一问一答”的交互模式 ，因此构建问答系统时一般不会涉及对话管理相关的技术。 第 l 章介绍过， 聊天机器人的核心模块包括自然语言理解、对话管理和自 然语言生成。 在自然语言理解层面，问答系统偏重于问句分析，旨在获取问句的主题词、问题词、 中心动词等。 目前，问句分析主要采用模板匹配和语义解析两种方式。 自然语言自然语言通常会自然地随文化发生演化，英语、汉语、日语都是具体种类的自然语言，这些自然语言震行着语言最原始的作用 ： 人们进行交互和思想交流的媒介性工具。我们可以从语音、音韵、词态、句法、语义、语用 6 个维度理解自然语言。 ( 1 ） 语音是与发音相关的学问（例如儿童学习的汉语拼音等），主要在前述介绍的语音技术中发挥作用。 ( 2 ） 音韵是由语音组合起来的读音，即汉语拼音和四声调。 ( 3 ） 词态封装了可用于自然语言理解的有用信息，其中信息量的大小取决于具体的语言种类。需要特别提及的是，中文没有太多的词态变换（不像拉丁语系语言），仅存在不同的偏旁，导致出现词的性别转换的情况（例如 “他”“她” ） 。 ( 4 ） 句法主要研究词语如何组成合乎语法的句子 ，句法提供单词组成句子的约束条件，为语义的合成提供框架。 ( 5 ） 语义和语用是自然语言所包含和表达的意思 。 对计算机来说，自然语言处理的难度主要体现在以下几个方面 ： ( 1 ）自然语言千变万化，没有固定格式。同样的意思可以使用多种句式来表达，同样的句子调整一个字、调整语调或者调整语序 ， 表达的意思可能相差甚多。 ( 2 ）不断有新的词汇出现，计算机需要不断学习新的词汇。 ( 3 ）在不同的场景 （上下文语境）下，同一句话表达的意思可能不同 。 聊天机器人系统中的自然语言理解模块的功能主要包捐实体识别、用户意图识别、用户情感识别、指代消解、省｜咯恢复、回复确认及拒识判断等。 实体识别又称命名实体识别（ Named Entity Recognition ），指识别自然语言中具有特定意义的实体，如人名、时间、地名及各种专有名词。 用户意图识别中需要识别的用户意图包括显式意图和隐式意图，显式意图通常对应一个明确的用户需求 ，而隐式意图则较难判断，表 2-1 举例说明了用户的显式意图和隐式意图。用户情感和用户意图类似，也可以分为显式和隐式两种，表 2-2 是对用户显式情感和隐式情感的举例说明。 指代消解和省略恢复是指聊天主题背景一致的情况下 ，人们在对话过程中通常会习惯性地使用代词指代已经出现过的某个实体或事件 ， 或者为了方便表述省略句子部分成分的情况。 自然语言理解模块需要明确代词指代的成分及句子中省略的成分，唯有如此，聊天机器人才能正确理解用户的输入，给出合乎上下文语义的回复。 当用户意图、聊天信息等带有一定的模糊性时 ， 需要聊天机器人主动向用户询问 ，确认用户的意图，即回复确认。 拒识判断是指聊天机器人系统应当具备一定的拒识能力 ， 主动拒绝识别及回复超出自身理解／回复范围或者涉及敏感话题的用户输入。 基于规则的方法通常，可以将自然语言理解的主要方法分为基于规则的方法和基于统计的方法两种。 基于规则的方法是指利用规则定义如何从文本中提取语义 ， 大致思路是人工定义很多语法规则，它们是表达某种特定语义的具体方式， 然后自然语言理解模块根据这些规则解析输入该模块的文本。基于规则的 自然语言理解模块的优点是灵活 ，可以定义各种各样的规则 ， 而且不依赖训练数据 ； 缺点是需要大量的、覆盖不同场景的规则 ， 且随着规则数量的增长 ，对规则进行人工维护的难度也会增加。因此， 基于规则的自然语言理解只适合用在相对简单的场景，其优势在于可以快速实现一个简单可用的语义理解模块。 在具体实践中，通常将这两种方法结合起来使用 。 ( 1 ）没有数据及数据较少时先采用基于规则的方法，当数据积累到 一定规模时逐渐转为使用基于统计的方法。 词性标注最初采用的主要模型是隐马尔可夫生成式模型，之后陆续采用过判别式的最大脑模型、支持向量机模型等进行尝试。 词性标注的方法主要分为两种 ： 基于规则的方法和基于统计模型的方法。 基于规则的词性标注方法按照兼类词搭配关系和上下文语境建造词类消歧规则 。 对句子进行句法分析需要确定句子的句法结构，分析的结果往往以树结构的形式表现，这棵表示句子结构的树又叫作句法分析树。 句法分析树的建立可以采用自顶向下的方法，也可以采用自底向上的方法。 根据句法结构的不同表示形式，可以将句法分析任务划分为以下 3 种。( 1 ）依存句法分析（ Dependency Syntactic Parsing ）， 主要任务是识别句子中词汇之间的相互依存关系。 ( 2 ） 短语结构句法分析（ Phrase-structure Syntactic Parsing ）， 也称作成分句法分析（ Constituent Syntactic Parsing ），主要任务是识别句子中短语结构和短语之间的层次句法关系 ( 3 ）深层文法句法分析，主要任务是利用深层文沽，对句子进行深层的句法及语义分析，这些深层文法包括词汇化树邻接文法、词汇功能文法、组合范畴文法等。 KBQA系统问答系统是信息、检索系统的一种高级形式 ， 它通过 Web 搜索或链接知识库等方式 ， 检索到用户问题的答案，并用准确、简洁的自然语言回答用户。本书第 2 章简要阐述了问答系统、对话系统和闲聊系统的区别与联系。问答系统更接近信息检索中的语义搜索 ， 针对用户用自然语言提出的问题，通过一系列的方法生成问题的答案 ， 但与信息检索系统的不同在于，问答系统根据用户的问题直接给出精准的答案， 而不是给出一系列包含候选答案的页面。 系统生成答案的过程虽然也涉及简单的上下文处理 ， 但通常是通过指代消解和内容补全完成处理操作的。问答系统主要针对特定领域的知识进行一问一答 ， 侧重于知识结构的构建、知识的融合与知识的推理。 问答系统 ( 1 ）以自然语言 问题为输入，以准确的答案为输出 。 ( 2 ） 让机器承担更多数据解释的工作。 ( 3 ） 问答系统是一个问题驱动的信息获取过程（ Query-driven Information Access ） 问答系统适用于特殊而复杂的信息需求，可以从多样化的、非结构化的信息中获取问题的答案，并且需要对问题进行更多自动化的语义理解。 现有的问答系统根据其问题答案的数据来源和回答的方式的不同， 大体上可以分为以下 3 类。 基于 Web 信息检索的问答系统（ Web Question Answering , WebQA) WebQA 系统以搜索引擎为支撑 ， 理解分析用户的问题意图后，利用搜索引 擎在全网范围内搜索相关答案反馈给用户 。 典型的系统有早期的 Ask Jeeves 和 Answer Bus 问答系统。 基于知识库的问答系统 C Knowledge Based Question Answering, KBQA) 阻QA 系统通过结合一些已有的知识库或数据库资源（例如 Fre巳ba挝、DBpedia 、 Yago 、 Zhishi . me 等） ，以及利 用如维基百科、百度百科等非结构化文本的信息 ，使用信息抽取的方法提取有价值的信息 ，并构建知识图谱作为问答系统的后台支撑， 再一结合知识推理等方法为用户提供更深层次语义理解的答案。 社区问答系统（ Community Question Answering, CQA) CQA 系统也叫基于社交媒体的问答系统 ， 例如 Yahoo! Answers 、百度知道、知乎等问答平台。大多数问题的答案由网友提供，问答系统会检索社交媒体中与用户提问语义相似的问题，并将答案返回给用户。 上述 3 类问答系统中 ，KBQA 是当下应用最广泛的 ， 该类系统不仅需要实现对复杂问题的语义理解 ，还要在若干知识库之间进行知识的融合，并针对复杂的问题进行知识推理。 3.2 节将详细介绍 阻QA 中用到的相关技术 ， 3.3 节将介绍如何实现一个简单的问答系统。 除了这 3 类主流问答系统，还有其他形式的问答系统 ，例如混合式问答系统 （ Hybrid QA ）、 多语言问答系统（ Multilingual QA ）、基于常见问题库的问答系统（ Frequently Asked Question, FAQ ） 知识库（ Knowledge Base ，KB ）是用于知识管理的一种特殊的数据库，用于相关领域知识的采集、整理及提取。 知识库中的知识源于领域专家，是求解问题所需领域知识的集合 ， 包括一些基本事实、规则和其他相关信息。知识库的表示形式是一个对象模型（ object model ），通常称为本体，包含一些类、子类和实体。不同于传统的数据库 ， 知识库中存放的知识蕴含特殊的知识表示 ，其结构比数据库更复杂，可以用来存放更多复杂语义表示的数据。 知识库最早被应用于专家系统 ， 它是一种基于知识的系统，包含表示客观世界事实的一系列知识及一个推理机（ inference engine ），并依赖一定的规则和逻辑形式推理出一些新的事实 KBQA 是基于知识库中的专业知识建立的问答系统，也是目前最主流的问答系统。常见的知识库有 Freebase 、 DBpedia 等。知识库一般采用 RDF 格式对其中的知识进行表示 ， 知识的查询主要采用 RDF 标准查询语言 SPARQL。除此之外，还有一些 （例如维基百科等 ）无结构化文本知识库。 但一般来说， KBQA 系统包含问句理解、答案信息抽取、答案排序和生成等核心模块， 因此现在主要是对问句进行理解！","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"HMM之数据的处理","slug":"HMM/HMM之数据的处理","date":"2020-07-08T23:55:52.000Z","updated":"2020-07-08T23:55:52.000Z","comments":true,"path":"2020/07/09/HMM/HMM之数据的处理/","link":"","permalink":"https://esyyes.github.io/2020/07/09/HMM/HMM%E4%B9%8B%E6%95%B0%E6%8D%AE%E7%9A%84%E5%A4%84%E7%90%86/","excerpt":"","text":"HMM之数据的处理查看数据直接读取数据 数据类型如下所示： i t y x1 x2 x3 x4 z1 z2 0 1 1 0 3891 116 0 0 6.0 59.0 1 1 2 0 5958 93 0 0 NaN NaN 2 1 3 0 5362 106 0 0 NaN NaN 3 1 4 0 2528 126 0 0 NaN NaN 4 1 5 1 1219 215 0 0 NaN NaN 数据的含义i对应的是一个人，t表示的是一个时期为一周，x1-x4,表示的是自变量，是影响隐马尔科夫模型的转移概率矩阵，z1,z2,是控制变量，是可以长期影响一个人的控制变量数据，是状态转移矩阵的估计量。 1234567 表 4-2 变量的统计学描述 变量名 样本数 均值 标准差 最小值 最大值y 3108 1.119691 6.266278 0 111x1 3108 1301.892 2582.350 0 42864x2 3108 615.3838 2130.248 -58 46162x3 3108 1.071750 4.706953 0 103x4 3108 0.751609 5.057782 0 90 样本差异过大，所以需要进行归一化或者标准化处理 没有数据缺失，因此只需要进行标准化即可。 数据标准化123456789101112131415161718\"\"\"均值插补缺省值z-score标准化\"\"\"import pandas as pdimport numpy as npfrom sklearn import preprocessingdef data_pre(data): df = data.replace([np.inf, -np.inf], np.nan) num = df.isnull().sum() [df[df.keys()[i]].fillna(value=df[df.keys()[i]].mean(), inplace=True) for i in range(len(num)) if num[i] &gt; 0] df_scale = preprocessing.scale(df) # 将标准化后的数据再转换为表格 fea = pd.DataFrame(df_scale, columns=data.keys()) return fea 123456 x1 x2 x3 x40 1.002617 -0.234425 -0.227695 -0.1486041 1.803051 -0.245222 -0.227695 -0.1486042 1.572253 -0.239119 -0.227695 -0.1486043 0.474803 -0.229731 -0.227695 -0.1486044 -0.032099 -0.187952 -0.227695 -0.148604 数据标准化后结果如上图所示 HMM的状态划分在现实的数据中，HMM的隐藏状态是无法直接判别的，因此需要对状态进行判别。 在模型训练中最重要的步骤是进行模型状态数量的确定。由于在大多数实验过程中，并不能直接确定将研究的隐藏状态分为几个状态水平较为合适，因此，需要通过建立多个模型，根据贝叶斯信息准则对模型的拟合效果进行比较，选择最佳的模型作为实际研究模型。 据相关研究，需要通过假定不同的状态量 S，建立若干个模型，训练模型后计算模型的对数似然值。再根据贝叶斯信息准则（BIC）的计算方法，计算 BIC 的值，比较后选择效果较好的模型。 BIC =ln L − k× ln P / 2 BIC 值的计算方法，其中 ln L 代表模型的对数似然值，k 代表模型的变量个数，P 代表样本大小。BIC 的值越大，表示模型训练的效果越好。 因此需要最大似然值和BIC进行估计，判断在什么状态下的数据最好。 1234567891011121314根据样本数据。因此确定选择1为阈值下均值下的似然估计值为： -955.2942841591449分类为2均值下的BIC为： -1028.7801594684208变量：121值下的似然估计值为： -1589.5001457084938分类为2阈值为1下的BIC为：-1662.9860210177699状态为3时：设定1《《标准差为阈值变量：18似然估计值为： -1486.947107953313分类为3时的BIC为： -1619.2216835100096状态为4时：设定1《《标准差《《方差为阈值变量：24似然估计值为： -1524.3108928288107 分类为4时的BIC为： -1700.676993571073 因此确定3为状态数 初始状态概率矩阵直接用划分的状态进行划分初始状态概率矩阵 123456当状态为2时：[[0.7918275418275418, 0.20817245817245822]]当状态为3时：[[0.7918275418275418, 0.3462033462033462, 0.03507078507078507]]当状态为4时：[[0.7918275418275418, 0.3462033462033462, 0.030244530244530245, 0.004826254826254826]] 判断最大似然的收敛性用百次循环的结果去对应查看数据是否收敛 123456789101112131415fig = plt.figure(figsize=(7, 4))# 解决中文显示问题plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']plt.rcParams['axes.unicode_minus'] = Falseplt.plot(list_L, \"bo\", linewidth=1)plt.xlabel(\"Number of Iterations\", fontsize=10)plt.xticks(fontsize=8)plt.ylabel(\"Loglik\", fontsize=10)plt.yticks(fontsize=8)# 去边框ax = plt.gca()ax.spines['right'].set_color('none')ax.spines['top'].set_color('none')plt.show() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306# -*- coding: utf-8 -*-# @Time : 2020/7/9# @Author : esyfrom HMM_class import *from data_preprocessing import *from LR import *# import matplotlib.pyplot as pltimport mathimport warnings# 忽略警告warnings.filterwarnings(\"ignore\")data = pd.read_excel('data1' + '.xlsx')data.fillna(0, inplace=True)# 转换列表list_data = np.array(data).tolist()X1 = pd.get_dummies(data.iloc[0:len(data), 3:7])X = data_pre(X1)Z = pd.get_dummies(data.iloc[0:len(data), 7:9])list_y1 = [int(list_data[i][2]) for i in range(len(data))]y1_mean = np.array(list_y1).mean()y1_std = np.array(list_y1).std()# 划分为状态3# 状态1：小于1的# 状态2：小于标准差# 状态3：大于标准差Y_X = []num1 = 0num2 = 0num3 = 0for i in range(len(data)): if list_data[i][2] &lt; 1: Y_X.append(0) num1 += 1 elif 1 &lt;= list_data[i][2] &lt; y1_std: Y_X.append(1) num2 += 2 else: Y_X.append(2) num3 += 1Z1 = [[int(list_data[14*j][k]) for i in range(len(data)) if 14 * j == i for k in range(7, 9)] for j in range(int(len(data)/14))]Z2 = pd.DataFrame(Z1, columns=['z1', 'z2'])Z = data_pre(Z2)# 将14个时期取平均值list_z_y = []for i in range(int(len(data)/14)): y1 = [] for j in range(len(data)): if 14 * i &lt;= j &lt; 14 * (i + 1): y1.append(list_data[j][2]) list_z_y.append(np.array(y1).mean())Y_Z = []for i in range(len(list_z_y)): if list_z_y[i] &lt; 1: Y_Z.append(0) elif 1 &lt;= list_z_y[i] &lt; y1_std: Y_Z.append(1) else: Y_Z.append(2)# HMM模型参数设置HMM = HiddenMarkov()Q = [0, 1, 2]V = [0, 1, 2]B = [[0.8767222625090645, 0.12327773749093547, 0.0], [0.17063492063492064, 0.75, 0.07936507936507937], [0.0, 0.09183673469387756, 0.9081632653061223]]PI = [[num1/len(data), num2/len(data), num3/len(data)]]list_L = []list_fix_x = []list_fix_z = []list_lr_x_w = []list_lr_z_w = []list_lr_x_b = []list_lr_z_b = []list_A = []list_BIC = []list_acr_x = []list_acr_z = []for k in range(100): acr_x, fix_x, lr_x_w, lr_x_b = run_lr(X, Y_X) acr_z, fix_z, lr_z_w, lr_z_b = run_lr(Z, Y_Z) A = [[fix_x[0][0]/fix_x[0].sum(), fix_x[0][1]/fix_x[0].sum(), fix_x[0][2]/fix_x[0].sum()], [fix_x[1][0]/fix_x[1].sum(), fix_x[1][1]/fix_x[1].sum(), fix_x[1][2]/fix_x[1].sum()], [fix_x[2][0]/fix_x[2].sum(), fix_x[2][1]/fix_x[2].sum(), fix_x[2][2]/fix_x[2].sum()] ] P = [] for j in range(int(len(data)/14)): O = [] for i in range(len(data)): if 14 * j &lt;= i &lt; 14 * (j + 1): O.append(Y_X[i]) P.append(HMM.forward(Q, V, A, B, O, PI)) L = 0 for i in range(len(P)): L += math.log(P[i]) BIC = L - 18 * (math.log(3108 / 2)) # 保存似然值 list_A.append(A) list_L.append(L) list_BIC.append(BIC) list_fix_x.append(fix_x) list_fix_z.append(fix_z) list_lr_x_w.append(lr_x_w) list_lr_z_w.append(lr_z_w) list_lr_x_b.append(lr_x_b) list_lr_z_b.append(lr_z_b) list_acr_x.append(acr_x) list_acr_z.append(acr_z)print(f'百次循环后，最高准确率&#123;max(list_acr_x)&#125;')print(f'最大准确率对应的序号：&#123;list_acr_x.index(max(list_acr_x))&#125;')print()print(f'百次循环后，似然值为&#123;list_L[list_acr_x.index(max(list_acr_x))]&#125;')print(f'对应的BIC为&#123;list_BIC[list_acr_x.index(max(list_acr_x))]&#125;')print(f'在4个变量下的状态转移概率矩阵：&#123;list_A[list_acr_x.index(max(list_acr_x))]&#125;')print(f'-'*20)print(f'参数估计')print(f'状态转移概率矩阵的系数为：&#123;list_lr_x_w[list_acr_x.index(max(list_acr_x))]&#125;')print(f'状态转移概率矩阵的偏差为：&#123;list_lr_x_b[list_acr_x.index(max(list_acr_x))]&#125;')print(f'观察状态概率转移矩阵的系数为：&#123;list_lr_z_w[list_acr_x.index(max(list_acr_x))]&#125;')print(f'观察状态概率转移矩阵的偏差为：&#123;list_lr_z_b[list_acr_x.index(max(list_acr_x))]&#125;')num = list_acr_x.index(max(list_acr_x))list_x = np.array(X).tolist()print(f'变量1下的知识贡献意愿转移概率')wx_b0 = []wx_b1 = []wx_b2 = []for i in range(len(data)): if Y_X[i] == 0: wx_b0.append(list_lr_x_w[num][0][0] * list_x[i][0] + list_lr_x_b[num][0]) elif Y_X[i] == 1: wx_b1.append(list_lr_x_w[num][1][0] * list_x[i][0] + list_lr_x_b[num][1]) else: wx_b2.append(list_lr_x_w[num][2][0] * list_x[i][0] + list_lr_x_b[num][2])# fig = plt.figure(figsize=(10, 8))# plt.plot(np.array(wx_b0), \"bo\", linewidth=1)# plt.plot(np.array(wx_b2), \"ro\", linewidth=1)# plt.plot(np.array(wx_b1), \"ko\", linewidth=1)# plt.show()# 状态1个数： len(wx_b0) = 2461# 将其排序,状态1中设置260个# 状态2时的个数： 538,设置为80， 400， 58# 状态3时的个数：109 ， 在2中设置35个H = [[(len(wx_b0) - 260)/len(wx_b0), 260/len(wx_b0), 0], [(len(wx_b1) - 458)/len(wx_b1), 400/len(wx_b1), 58/len(wx_b1)], [0, 15/len(wx_b2), 1-15/(len(wx_b2))]]print(f'&#123;H&#125;')print(f'变量2下的知识贡献意愿转移概率')wx_b20 = []wx_b21 = []wx_b22 = []for i in range(len(data)): if Y_X[i] == 0: wx_b20.append(list_lr_x_w[num][0][1] * list_x[i][1] + list_lr_x_b[num][0]) elif Y_X[i] == 1: wx_b21.append(list_lr_x_w[num][1][1] * list_x[i][1] + list_lr_x_b[num][1]) else: wx_b22.append(list_lr_x_w[num][2][1] * list_x[i][1] + list_lr_x_b[num][2])# fig = plt.figure(figsize=(10, 8))# plt.plot(np.array(wx_b20), \"bo\", linewidth=1)# plt.plot(np.array(wx_b22), \"ro\", linewidth=1)# plt.plot(np.array(wx_b21), \"ko\", linewidth=1)# plt.show()# 状态2个数： len(wx_b0) = 2461# 将其排序, 状态1中设置260个# 状态2时的个数： 538,设置为80， 400， 58# 状态3时的个数：109 ， 在2中设置35个H2 = [[(len(wx_b20) - 360)/len(wx_b20), 360/len(wx_b20), 0], [(len(wx_b21) - 500)/len(wx_b21), 450/len(wx_b21), 50/len(wx_b21)], [0, 16/len(wx_b22), 1-16/(len(wx_b22))]]print(f'&#123;H2&#125;')print(f'变量3下的知识贡献意愿转移概率')wx_b30 = []wx_b31 = []wx_b32 = []for i in range(len(data)): if Y_X[i] == 0: wx_b30.append(list_lr_x_w[num][0][2] * list_x[i][2] + list_lr_x_b[num][0]) elif Y_X[i] == 1: wx_b31.append(list_lr_x_w[num][1][2] * list_x[i][2] + list_lr_x_b[num][1]) else: wx_b32.append(list_lr_x_w[num][2][2] * list_x[i][2] + list_lr_x_b[num][2])# fig = plt.figure(figsize=(10, 8))# plt.plot(np.array(wx_b30), \"bo\", linewidth=1)# plt.plot(np.array(wx_b32), \"ro\", linewidth=1)# plt.plot(np.array(wx_b31), \"ko\", linewidth=1)# plt.show()# 状态2个数： len(wx_b0) = 2461# 将其排序, 状态1中设置260个# 状态2时的个数： 538,设置为80， 400， 58# 状态3时的个数：109 ， 在2中设置35个H3 = [[(len(wx_b30) - 361)/len(wx_b30), 361/len(wx_b30), 0], [(len(wx_b31) - 501)/len(wx_b31), 451/len(wx_b31), 50/len(wx_b31)], [0, 12/len(wx_b32), 1-12/(len(wx_b32))]]print(f'&#123;H3&#125;')print(f'变量4下的知识贡献意愿转移概率')wx_b40 = []wx_b41 = []wx_b42 = []for i in range(len(data)): if Y_X[i] == 0: wx_b40.append(list_lr_x_w[num][0][3] * list_x[i][3] + list_lr_x_b[num][0]) elif Y_X[i] == 1: wx_b41.append(list_lr_x_w[num][1][3] * list_x[i][3] + list_lr_x_b[num][1]) else: wx_b42.append(list_lr_x_w[num][2][3] * list_x[i][3] + list_lr_x_b[num][2])# fig = plt.figure(figsize=(10, 8))# plt.plot(np.array(wx_b40), \"bo\", linewidth=1)# plt.plot(np.array(wx_b42), \"ro\", linewidth=1)# plt.plot(np.array(wx_b41), \"ko\", linewidth=1)# plt.show()# 状态2个数： len(wx_b0) = 2461# 将其排序, 状态1中设置260个# 状态2时的个数： 538,设置为80， 400， 58# 状态3时的个数：109 ， 在2中设置35个H4 = [[(len(wx_b40) - 361)/len(wx_b40), 361/len(wx_b40), 0], [(len(wx_b41) - 501)/len(wx_b41), 451/len(wx_b41), 50/len(wx_b41)], [0, 12/len(wx_b42), 1-12/(len(wx_b42))]]print(f'&#123;H4&#125;')# 全部数值下print(f'全部变量下的知识贡献意愿转移概率')wx_ba0 = []wx_ba1 = []wx_ba2 = []for i in range(len(data)): if Y_X[i] == 0: wx_ba0.append(list_lr_x_w[num][0][0] * list_x[i][0] + list_lr_x_w[num][0][1] * list_x[i][1] + list_lr_x_w[num][0][2] * list_x[i][2] + list_lr_x_w[num][0][3] * list_x[i][3] + list_lr_x_b[num][0]) elif Y_X[i] == 1: wx_ba1.append(list_lr_x_w[num][1][0] * list_x[i][0] + list_lr_x_w[num][1][1] * list_x[i][1] + list_lr_x_w[num][1][2] * list_x[i][2] + list_lr_x_w[num][1][3] * list_x[i][3] + list_lr_x_b[num][1]) else: wx_ba2.append(list_lr_x_w[num][2][0] * list_x[i][0] + list_lr_x_w[num][2][1] * list_x[i][1] + list_lr_x_w[num][2][2] * list_x[i][2] + list_lr_x_w[num][2][3] * list_x[i][3] + list_lr_x_b[num][2])# 进行排序wx_ba0.sort()wx_ba1.sort()wx_ba2.sort()# 找到边界,意思就是找到相对应的u1,u2-1,u2-h,u-3# 我是这样理解的，其实对应的就是x_b的系数，但是少了一个而已b = list_fix_x[num][0][1]/sum(list_fix_x[num][0])x = len(wx_ba0) * b# 即根据前面那个# 取倒数第16个作为边界吧u1 = wx_b0[-16]b1 = list_fix_x[num][1][0]/sum(list_fix_x[num][1])x1 = len(wx_ba1) * b1u2_1 = wx_ba1[int(x1)]b2 = list_fix_x[num][1][2]/sum(list_fix_x[num][1])x2 = len(wx_ba1) * b2u2_h = wx_ba1[-int(x2)]b3 = list_fix_x[num][2][2]/sum(list_fix_x[num][2])x4 = len(wx_b2) * b3u3 = wx_ba2[-int(x4)]print(f'u1=&#123;u1&#125;,u2_1=&#123;u2_1&#125;,u2_h=&#123;u2_h&#125;, u3=&#123;u3&#125;')print(f'状态转移概率矩阵的系数为：&#123;list_lr_x_w[list_acr_x.index(max(list_acr_x))]&#125;')print(f'观察状态概率转移矩阵的系数为：&#123;list_lr_z_w[list_acr_x.index(max(list_acr_x))]&#125;')print(f'观察状态概率转移矩阵的截距为：&#123;list_lr_z_b[list_acr_x.index(max(list_acr_x))]&#125;')print(f'所有参数和矩阵表格如上') 12345678910111213141516171819202122232425262728293031323334百次循环后，最高准确率0.917470525187567最大准确率对应的序号：29百次循环后，似然值为-1355.7570132278736对应的BIC为-1488.0315887845702在4个变量下的状态转移概率矩阵：[[0.9868073878627969, 0.013192612137203167, 0.0], [0.40816326530612246, 0.5782312925170068, 0.013605442176870748], [0.0, 0.17857142857142858, 0.8214285714285714]]--------------------参数估计状态转移概率矩阵的系数为：[[-0.07814258 -0.08035225 -0.03518065 -8.30153077] [-0.07992528 0.07019997 -0.02918073 2.04945495] [ 0.15806786 0.01015228 0.06436137 6.25207582]]状态转移概率矩阵的偏差为：[ 1.46433444 1.09085289 -2.55518733]观察状态概率转移矩阵的系数为：[[ 0.44462513 0.22701876] [ 0.48690629 -0.33289007] [-0.93153142 0.10587131]]观察状态概率转移矩阵的偏差为：[ 2.26772789 -0.16557564 -2.10215226]变量1下的知识贡献意愿转移概率[[0.8943518894758228, 0.10564811052417716, 0], [0.14869888475836432, 0.7434944237918215, 0.10780669144981413], [0, 0.13761467889908258, 0.8623853211009174]]变量2下的知识贡献意愿转移概率[[0.8537180008126778, 0.14628199918732224, 0], [0.07063197026022305, 0.8364312267657993, 0.09293680297397769], [0, 0.14678899082568808, 0.8532110091743119]]变量3下的知识贡献意愿转移概率[[0.8533116619260463, 0.14668833807395368, 0], [0.0687732342007435, 0.8382899628252788, 0.09293680297397769], [0, 0.11009174311926606, 0.8899082568807339]]变量4下的知识贡献意愿转移概率[[0.8533116619260463, 0.14668833807395368, 0], [0.0687732342007435, 0.8382899628252788, 0.09293680297397769], [0, 0.11009174311926606, 0.8899082568807339]]全部变量下的知识贡献意愿转移概率u1=1.4980410992089837,u2_1=0.8129063006054411,u2_h=2.8303668243942806, u3=2.68524912411076状态转移概率矩阵的系数为：[[-0.07814258 -0.08035225 -0.03518065 -8.30153077] [-0.07992528 0.07019997 -0.02918073 2.04945495] [ 0.15806786 0.01015228 0.06436137 6.25207582]]观察状态概率转移矩阵的系数为：[[ 0.44462513 0.22701876] [ 0.48690629 -0.33289007] [-0.93153142 0.10587131]]观察状态概率转移矩阵的截距为：[ 2.26772789 -0.16557564 -2.10215226]所有参数和矩阵表格如上","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"状态为3时的设定","slug":"HMM/状态为3时的设定","date":"2020-07-08T06:45:11.000Z","updated":"2020-07-08T06:45:11.000Z","comments":true,"path":"2020/07/08/HMM/状态为3时的设定/","link":"","permalink":"https://esyyes.github.io/2020/07/08/HMM/%E7%8A%B6%E6%80%81%E4%B8%BA3%E6%97%B6%E7%9A%84%E8%AE%BE%E5%AE%9A/","excerpt":"","text":"状态为3是的B值设定划分为状态3# 状态1：小于平均值的# 状态2：小于标准差# 状态3：大于标准差 将里面的数据直接划分为3个状态，按照3个状态的区间范围，去设定序列的状态值 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120# -*- coding: utf-8 -*-# @Time : 2020/7/8# @Author : esyimport pandas as pdimport numpy as npimport warnings# 忽略警告warnings.filterwarnings(\"ignore\")data = pd.read_excel('data1' + '.xlsx')data.fillna(0, inplace=True)list_data = np.array(data).tolist()X = pd.get_dummies(data.iloc[0:len(data), 3:7])list_y1 = [int(list_data[i][2]) for i in range(len(data))]y1_mean = np.array(list_y1).mean()y1_std = np.array(list_y1).std()# 划分为状态3# 状态1：小于平均值的# 状态2：小于标准差# 状态3：大于标准差# 序列中出现0,1,2阶段的数目Y_X = []num1 = 0num2 = 0num3 = 0for i in range(len(data)): if list_data[i][2] &lt; 1: Y_X.append(0) num1 += 1 elif 1 &lt;= list_data[i][2] &lt; y1_std: Y_X.append(1) num2 += 2 else: Y_X.append(2) num3 += 1print(f'阶段1的个数：&#123;num1&#125;,阶段2的个数：&#123;num2&#125;,阶段3的个数：&#123;num3&#125;')# 将14个时期取平均值list_z_y = []for i in range(int(len(data)/14)): y1 = [] for j in range(len(data)): if 14 * i &lt;= j &lt; 14 * (i + 1): y1.append(list_data[j][2]) list_z_y.append(np.array(y1).mean())# 判断序列阶段出现出现的次数num1_z = 0num2_z = 0num3_z = 0Y_Z = []for i in range(len(list_z_y)): if list_z_y[i] &lt; 1: Y_Z.append(0) num1_z += 1 elif 1 &lt;= list_z_y[i] &lt; y1_std: Y_Z.append(1) num2_z += 1 else: Y_Z.append(2) num3_z += 1print(f'阶段1的序列个数：&#123;num1_z&#125;,阶段2的序列个数：&#123;num2_z&#125;, 阶段3的序列个数：&#123;num3_z&#125;')# 将其划分为14个一组一个序列Y = []for j in range(int(len(data)/14)): x1 = [] for i in range(len(data)): if 14 * j &lt;= i &lt; 14 * (j + 1): x1.append(Y_X[i]) Y.append(x1)# 判断阶段1中出现012的次数num_j1 = 0num_j2 = 0num_j3 = 0num_k1 = 0num_k2 = 0num_k3 = 0num_b1 = 0num_b2 = 0num_b3 = 0for i in range(len(Y_Z)): if Y_Z[i] == 0: for j in range(14): if Y[i][j] == 0: num_j1 += 1 elif Y[i][j] == 1: num_j2 += 1 else: num_j3 += 1 elif Y_Z[i] == 1: for k in range(14): if Y[i][k] == 0: num_k1 += 1 elif Y[i][k] == 1: num_k2 += 1 else: num_k3 += 1 elif Y_Z[i] == 2: for b in range(14): if Y[i][b] == 0: num_b1 += 1 elif Y[i][b] == 1: num_b2 += 1 else: num_b3 += 1print(f'阶段1中状态1的个数 &#123;num_j1&#125;，状态2的个数&#123;num_j2&#125;，状态2的个数&#123;num_j3&#125;')print(f'阶段2中状态1的个数 &#123;num_k1&#125;， 状态2的个数 &#123;num_k2&#125;，状态2的个数&#123;num_k3&#125;')print(f'阶段3中状态1的个数 &#123;num_b1&#125;， 状态2的个数 &#123;num_b2&#125;，状态2的个数&#123;num_b3&#125;')B = [[num_j1/num1_z/14, num_j2/num1_z/14, num_j3/num1_z/14], [num_k1/num2_z/14, num_k2/num2_z/14, num_k3/num2_z/14], [num_b1/num3_z/14, num_b2/num3_z/14, num_b3/num3_z/14]]print(f'在阈值线为平均值下的&#123;B&#125;') 123456阶段1的个数：2461,阶段2的个数：1076,阶段3的个数：109阶段1的序列个数：197,阶段2的序列个数：18, 阶段3的序列个数：7阶段1中状态1的个数 2418，状态2的个数340，状态2的个数0阶段2中状态1的个数 43， 状态2的个数 189，状态2的个数20阶段3中状态1的个数 0， 状态2的个数 9，状态2的个数89在阈值线为平均值下的[[0.8767222625090645, 0.12327773749093547, 0.0], [0.17063492063492064, 0.75, 0.07936507936507937], [0.0, 0.09183673469387756, 0.9081632653061223]] 将数据设定为4状态时 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161# -*- coding: utf-8 -*-# @Time : 2020/7/8# @Author : esyimport pandas as pdimport numpy as npimport warnings# 忽略警告warnings.filterwarnings(\"ignore\")data = pd.read_excel('data1' + '.xlsx')data.fillna(0, inplace=True)list_data = np.array(data).tolist()X = pd.get_dummies(data.iloc[0:len(data), 3:7])list_y1 = [int(list_data[i][2]) for i in range(len(data))]y1_mean = np.array(list_y1).mean()y1_std = np.array(list_y1).std()# 划分为状态4# # 状态1：小于平均值的# # 状态2：小于标准差# # 状态3：小于方差的# # 状态4：大于方差的# 序列中出现0,1,2阶段的数目Y_X = []num1 = 0num2 = 0num3 = 0num4 = 0for i in range(len(data)): if list_data[i][2] &lt; 1: Y_X.append(0) num1 += 1 elif 1 &lt;= list_data[i][2] &lt; y1_std: Y_X.append(1) num2 += 2 elif y1_std &lt;= list_data[i][2] &lt; y1_std*y1_std: Y_X.append(2) num3 += 1 else: Y_X.append(3) num4 += 1print(f'阶段1的个数：&#123;num1&#125;,阶段2的个数：&#123;num2&#125;, 阶段3的个数：&#123;num3&#125;, 阶段4的个数：&#123;num4&#125;')# 将14个时期取平均值list_z_y = []for i in range(int(len(data)/14)): y1 = [] for j in range(len(data)): if 14 * i &lt;= j &lt; 14 * (i + 1): y1.append(list_data[j][2]) list_z_y.append(np.array(y1).mean())# 判断序列阶段出现出现的次数num1_z = 0num2_z = 0num3_z = 0num4_z = 0Y_Z = []for i in range(len(list_z_y)): if list_z_y[i] &lt; 1: Y_Z.append(0) num1_z += 1 elif 1 &lt;= list_z_y[i] &lt; y1_std: Y_Z.append(1) num2_z += 1 elif y1_std &lt;= list_z_y[i] &lt; y1_std * y1_std: Y_Z.append(2) num3_z += 1 else: Y_Z.append(3) num4_z += 1print(f'阶段1的序列个数：&#123;num1_z&#125;,阶段2的序列个数：&#123;num2_z&#125;, 阶段3的序列个数：&#123;num3_z&#125;, 阶段4的序列个数：&#123;num4_z&#125;')# 将其划分为14个一组一个序列Y = []for j in range(int(len(data)/14)): x1 = [] for i in range(len(data)): if 14 * j &lt;= i &lt; 14 * (j + 1): x1.append(Y_X[i]) Y.append(x1)# 判断阶段1中出现012的次数num_j1 = 0num_j2 = 0num_j3 = 0num_j4 = 0num_k1 = 0num_k2 = 0num_k3 = 0num_k4 = 0num_b1 = 0num_b2 = 0num_b3 = 0num_b4 = 0num_h1 = 0num_h2 = 0num_h3 = 0num_h4 = 0for i in range(len(Y_Z)): if Y_Z[i] == 0: for j in range(14): if Y[i][j] == 0: num_j1 += 1 elif Y[i][j] == 1: num_j2 += 1 elif Y[i][j] == 2: num_j3 += 1 else: num_j4 += 1 elif Y_Z[i] == 1: for k in range(14): if Y[i][k] == 0: num_k1 += 1 elif Y[i][k] == 1: num_k2 += 1 elif Y[i][k] == 2: num_k3 += 1 else: num_k4 += 1 elif Y_Z[i] == 2: for b in range(14): if Y[i][b] == 0: num_b1 += 1 elif Y[i][b] == 1: num_b2 += 1 elif Y[i][b] == 2: num_b3 += 1 else: num_b4 += 1 elif Y_Z[i] == 3: for h in range(14): if Y[i][h] == 0: num_h1 += 1 elif Y[i][h] == 1: num_h2 += 1 elif Y[i][h] == 2: num_h3 += 1 else: num_h4 += 1print(f'阶段1中状态1的个数 &#123;num_j1&#125;，状态2的个数&#123;num_j2&#125;，状态3的个数&#123;num_j3&#125;, 状态4的个数&#123;num_j4&#125;')print(f'阶段2中状态1的个数 &#123;num_k1&#125;，状态2的个数 &#123;num_k2&#125;，状态3的个数&#123;num_k3&#125;, 状态4的个数&#123;num_k4&#125;')print(f'阶段3中状态1的个数 &#123;num_b1&#125;，状态2的个数 &#123;num_b2&#125;，状态3的个数&#123;num_b3&#125;, 状态4的个数&#123;num_b4&#125;')print(f'阶段4中状态1的个数 &#123;num_h1&#125;，状态2的个数 &#123;num_h2&#125;，状态3的个数&#123;num_h3&#125;, 状态4的个数&#123;num_h4&#125;')B = [[num_j1/num1_z/14, num_j2/num1_z/14, num_j3/num1_z/14, num_j4/num1_z/14,], [num_k1/num2_z/14, num_k2/num2_z/14, num_k3/num2_z/14, num_k4/num2_z/14], [num_b1/num3_z/14, num_b2/num3_z/14, num_b3/num3_z/14, num_b4/num3_z/14], [num_h1/num4_z/14, num_h2/num4_z/14, num_h3/num4_z/14, num_h4/num4_z/14] ]print(f'在阈值线为平均值下的&#123;B&#125;') 1234567阶段1的个数：2461,阶段2的个数：1076, 阶段3的个数：94, 阶段4的个数：15阶段1的序列个数：197,阶段2的序列个数：18, 阶段3的序列个数：6, 阶段4的序列个数：1阶段1中状态1的个数 2418，状态2的个数340，状态3的个数0, 状态4的个数0阶段2中状态1的个数 43，状态2的个数 189，状态3的个数20, 状态4的个数0阶段3中状态1的个数 0，状态2的个数 9，状态3的个数74, 状态4的个数1阶段4中状态1的个数 0，状态2的个数 0，状态3的个数0, 状态4的个数14在阈值线为平均值下的[[0.8767222625090645, 0.12327773749093547, 0.0, 0.0], [0.17063492063492064, 0.75, 0.07936507936507937, 0.0], [0.0, 0.10714285714285714, 0.880952380952381, 0.011904761904761904], [0.0, 0.0, 0.0, 1.0]] 因此现在B2： 123456789B_2 = [[0.78535170413343, 0.21464829586656997], [0.8428571428571429, 0.15714285714285714]]B_3 = [[0.8767222625090645, 0.12327773749093547, 0.0], [0.17063492063492064, 0.75, 0.07936507936507937], [0.0, 0.09183673469387756, 0.9081632653061223]]B_4 = [[0.8767222625090645, 0.12327773749093547, 0.0, 0.0], [0.17063492063492064, 0.75, 0.07936507936507937, 0.0], [0.0, 0.10714285714285714, 0.880952380952381, 0.011904761904761904], [0.0, 0.0, 0.0, 1.0]]","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"HMM中的B值确定","slug":"HMM/HMM中的B值确定","date":"2020-07-08T06:12:45.000Z","updated":"2020-07-08T06:12:45.000Z","comments":true,"path":"2020/07/08/HMM/HMM中的B值确定/","link":"","permalink":"https://esyyes.github.io/2020/07/08/HMM/HMM%E4%B8%AD%E7%9A%84B%E5%80%BC%E7%A1%AE%E5%AE%9A/","excerpt":"","text":"HMM中的B值确定1．隐马尔可夫模型是关于时序的概率模型，描述由一个隐藏的马尔可夫链随机生成不可观测的状态的序列，再由各个状态随机生成一个观测而产生观测的序列的过程。 隐马尔可夫模型由初始状态概率向$\\pi$、状态转移概率矩阵$A$和观测概率矩阵$B$决定。因此，隐马尔可夫模型可以写成$\\lambda=(A, B, \\pi)$。 隐马尔可夫模型是一个生成模型，表示状态序列和观测序列的联合分布，但是状态序列是隐藏的，不可观测的。 隐马尔可夫模型可以用于标注，这时状态对应着标记。标注问题是给定观测序列预测其对应的标记序列。 2．概率计算问题。给定模型$\\lambda=(A, B, \\pi)$和观测序列$O＝(o_1，o_2,…,o_T)$，计算在模型$\\lambda$下观测序列$O$出现的概率$P(O|\\lambda)$。前向-后向算法是通过递推地计算前向-后向概率可以高效地进行隐马尔可夫模型的概率计算。 3．学习问题。已知观测序列$O＝(o_1，o_2,…,o_T)$，估计模型$\\lambda=(A, B, \\pi)$参数，使得在该模型下观测序列概率$P(O|\\lambda)$最大。即用极大似然估计的方法估计参数。Baum-Welch算法，也就是EM算法可以高效地对隐马尔可夫模型进行训练。它是一种非监督学习算法。 4．预测问题。已知模型$\\lambda=(A, B, \\pi)$和观测序列$O＝(o_1，o_2,…,o_T)$，求对给定观测序列条件概率$P(I|O)$最大的状态序列$I＝(i_1，i_2,…,i_T)$。维特比算法应用动态规划高效地求解最优路径，即概率最大的状态序列。 在本次实验中，HMM模型，主要确定了QVAOPI，而直接用逻辑回归模型，进行建模运算时，B值的状态概率会出现100这种情况，导致HMM的似然函数的概率不会改变 array([[846, 0, 0], [ 60, 0, 0], [ 27, 0, 0]], dtype=int64) 参考 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107import numpy as npclass HiddenMarkov: def forward(self, Q, V, A, B, O, PI): # 使用前向算法 N = len(Q) #可能存在的状态数量 M = len(O) # 观测序列的大小 alphas = np.zeros((N, M)) # alpha值 T = M # 有几个时刻，有几个观测序列，就有几个时刻 for t in range(T): # 遍历每一时刻，算出alpha值 indexOfO = V.index(O[t]) # 找出序列对应的索引 for i in range(N): if t == 0: # 计算初值 alphas[i][t] = PI[t][i] * B[i][indexOfO] # P176（10.15） print( 'alpha1(%d)=p%db%db(o1)=%f' % (i, i, i, alphas[i][t])) else: alphas[i][t] = np.dot( [alpha[t - 1] for alpha in alphas], [a[i] for a in A]) * B[i][indexOfO] # 对应P176（10.16） print('alpha%d(%d)=[sigma alpha%d(i)ai%d]b%d(o%d)=%f' % (t, i, t - 1, i, i, t, alphas[i][t])) # print(alphas) P = np.sum([alpha[M - 1] for alpha in alphas]) # P176(10.17) # alpha11 = pi[0][0] * B[0][0] #代表a1(1) # alpha12 = pi[0][1] * B[1][0] #代表a1(2) # alpha13 = pi[0][2] * B[2][0] #代表a1(3) def backward(self, Q, V, A, B, O, PI): # 后向算法 N = len(Q) # 可能存在的状态数量 M = len(O) # 观测序列的大小 betas = np.ones((N, M)) # beta for i in range(N): print('beta%d(%d)=1' % (M, i)) for t in range(M - 2, -1, -1): indexOfO = V.index(O[t + 1]) # 找出序列对应的索引 for i in range(N): betas[i][t] = np.dot( np.multiply(A[i], [b[indexOfO] for b in B]), [beta[t + 1] for beta in betas]) realT = t + 1 realI = i + 1 print( 'beta%d(%d)=[sigma a%djbj(o%d)]beta%d(j)=(' % (realT, realI, realI, realT + 1, realT + 1), end='') for j in range(N): print( \"%.2f*%.2f*%.2f+\" % (A[i][j], B[j][indexOfO], betas[j][t + 1]), end='') print(\"0)=%.3f\" % betas[i][t]) # print(betas) indexOfO = V.index(O[0]) P = np.dot( np.multiply(PI, [b[indexOfO] for b in B]), [beta[0] for beta in betas]) print(\"P(O|lambda)=\", end=\"\") for i in range(N): print( \"%.1f*%.1f*%.5f+\" % (PI[0][i], B[i][indexOfO], betas[i][0]), end=\"\") print(\"0=%f\" % P) def viterbi(self, Q, V, A, B, O, PI): N = len(Q) #可能存在的状态数量 M = len(O) # 观测序列的大小 deltas = np.zeros((N, M)) psis = np.zeros((N, M)) I = np.zeros((1, M)) for t in range(M): realT = t + 1 indexOfO = V.index(O[t]) # 找出序列对应的索引 for i in range(N): realI = i + 1 if t == 0: deltas[i][t] = PI[0][i] * B[i][indexOfO] psis[i][t] = 0 print('delta1(%d)=pi%d * b%d(o1)=%.2f * %.2f=%.2f' % (realI, realI, realI, PI[0][i], B[i][indexOfO], deltas[i][t])) print('psis1(%d)=0' % (realI)) else: deltas[i][t] = np.max( np.multiply([delta[t - 1] for delta in deltas], [a[i] for a in A])) * B[i][indexOfO] print( 'delta%d(%d)=max[delta%d(j)aj%d]b%d(o%d)=%.2f*%.2f=%.5f' % (realT, realI, realT - 1, realI, realI, realT, np.max( np.multiply([delta[t - 1] for delta in deltas], [a[i] for a in A])), B[i][indexOfO], deltas[i][t])) psis[i][t] = np.argmax( np.multiply( [delta[t - 1] for delta in deltas], [a[i] for a in A])) + 1 #由于其返回的是索引，因此应+1才能和正常的下标值相符合。 print('psis%d(%d)=argmax[delta%d(j)aj%d]=%d' % (realT, realI, realT - 1, realI, psis[i][t])) print(deltas) print(psis) I[0][M - 1] = np.argmax([delta[M - 1] for delta in deltas ]) + 1 #由于其返回的是索引，因此应+1才能和正常的下标值相符合。 print('i%d=argmax[deltaT(i)]=%d' % (M, I[0][M - 1])) for t in range(M - 2, -1, -1): I[0][t] = psis[int(I[0][t + 1]) - 1][t + 1] print('i%d=psis%d(i%d)=%d' % (t + 1, t + 2, t + 2, I[0][t])) print(\"状态序列I：\", I) 123456789101112Q = [1, 2, 3]V = ['红', '白']A = [[0.5, 0.2, 0.3], [0.3, 0.5, 0.2], [0.2, 0.3, 0.5]]B = [[0.5, 0.5], [0.4, 0.6], [0.7, 0.3]]O = ['红', '白', '红', '红', '白', '红', '白', '白']PI = [[0.2, 0.3, 0.5]]HMM = HiddenMarkov()# HMM.forward(Q, V, A, B, O, PI)# HMM.backward(Q, V, A, B, O, PI)HMM.viterbi(Q, V, A, B, O, PI)HMM.forward(Q, V, A, B, O, PI)HMM.backward(Q, V, A, B, O, PI) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# -*- coding: utf-8 -*-# @Time : 2020/7/8# @Author : esyimport pandas as pdimport numpy as npimport warnings# 忽略警告warnings.filterwarnings(\"ignore\")data = pd.read_excel('data1' + '.xlsx')data.fillna(0, inplace=True)list_data = np.array(data).tolist()X = pd.get_dummies(data.iloc[0:len(data), 3:7])list_y1 = [int(list_data[i][2]) for i in range(len(data))]y1_mean = np.array(list_y1).mean()# 用均值作为状态的划分Y_X = [0 if list_data[i][2] &lt; y1_mean else 1 for i in range(len(data))]# 序列阶段的划分# 将14个时期取平均值list_z_y = []for i in range(int(len(data)/14)): y1 = [] for j in range(len(data)): if 14 * i &lt;= j &lt; 14 * (i + 1): y1.append(list_data[j][2]) list_z_y.append(np.array(y1).mean())# 14个值的平均值小于1即为0# 还是用均值作为状态的划分Y_Z = [0 if list_z_y[i] &lt; y1_mean else 1 for i in range(len(list_z_y))]num = 0for i in range(len(Y_Z)): if Y_Z[i] == 1: num += 1print(f'总数目：&#123;len(Y_Z)&#125;, 阶段0的数目&#123;len(Y_Z) - num&#125;, 阶段1的数目&#123;num&#125;')num_1 = 0for i in range(len(data)): if Y_X[i] == 1: num_1 += 1print(f'序列中出现1阶段的次数&#123;num_1&#125;')Y = []for j in range(int(len(data)/14)): x1 = [] for i in range(len(data)): if 14 * j &lt;= i &lt; 14 * (j + 1): x1.append(int(list_data[i][2])) Y.append(x1)# 计算1状态时，出现1的概率num_2 = 0for i in range(len(Y_Z)): if Y_Z[i] == 1: for j in range(14): if Y[i][j] == 1: num_2 += 1print(f'状态1中出现1的次数&#123;num_2&#125;')print(f'阶段1中出现1的概率&#123;num_2/(num*14)&#125;')B = [[1 - (num_1 - num_2) / ((len(Y_Z) - num) * 14), (num_1 - num_2) / ((len(Y_Z) - num) * 14)], [1 - num_2 / (num * 14), num_2 / (num * 14)]]print(f'在阈值线为平均值下的' f'&#123;B&#125;') 利用平均值作为阈值时的B值： 123[[0.9118926758520667, 0.08810732414793329], [0.8428571428571429, 0.15714285714285714]] 利用1作为阈值时的B值为： 123456Y_X = [0 if list_data[i][2] &lt; 1 else 1 for i in range(len(data))]Y_Z = [0 if list_z_y[i] &lt; 1 else 1 for i in range(len(list_z_y))][[0.78535170413343, 0.21464829586656997], [0.8428571428571429, 0.15714285 714285714]] 比较下最大似然值 均值下的结果 12345678910初始概率矩阵[[0.9041184041184042, 0.09588159588159584]]状态转移概率矩阵：[[0.9964114832535885, 0.0035885167464114833], [0.26804123711340205, 0.7319587628865979]]均值下的似然估计值为： -955.2942841591449分类为2均值下的BIC为：-1028.7801594684208--------------------参数估计状态转移概率矩阵的系数为：[[ 1.29445779e-05 5.27657348e-06 -2.44868582e-02 3.68198497e+00]]状态转移概率矩阵的偏差为：[-4.52277323]观察状态概率转移矩阵的系数为：[[ 0.00304877 -0.00165371]]观察状态概率转移矩阵的偏差为：[-2.00454762] 1值下的结果 12345678910初始概率矩阵[[0.7918275418275418, 0.20817245817245822]]状态转移概率矩阵：[[0.984869325997249, 0.015130674002751032], [0.4029126213592233, 0.5970873786407767]]1值下的似然估计值为： -1589.5001457084938分类为2阈值为1下的BIC为：-1662.9860210177699--------------------参数估计状态转移概率矩阵的系数为：[[ 3.54342024e-05 6.64259922e-05 -4.34313674e-03 3.76444931e+00]]状态转移概率矩阵的偏差为：[-2.26616719]观察状态概率转移矩阵的系数为：[[-0.02040833 -0.00606398]]观察状态概率转移矩阵的偏差为：[-1.81251543] 主要还是根据阈值线，来进行判定，BIC这些值的大小","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"HMM模型的学习","slug":"HMM/HMM模型的学习","date":"2020-07-04T06:33:33.000Z","updated":"2020-07-04T06:33:33.000Z","comments":true,"path":"2020/07/04/HMM/HMM模型的学习/","link":"","permalink":"https://esyyes.github.io/2020/07/04/HMM/HMM%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"HMM模型马尔科夫模型 马尔可夫模型（Markov Model）是一种统计模型，广泛应用在语音识别，词性自动标注，音字转换，概率文法等各个自然语言处理等应用领域。经过长期发展，尤其是在语音识别中的成功应用，使它成为一种通用的统计工具。 https://baike.baidu.com/item/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B/4017874?fromtitle=%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B&amp;fromid=11231643&amp;fr=aladdin 在给定当前只是或信息的情况下，过去（即当前以前的历史状态），对于预测将来（即当前以后的未来状态）是无关的 每个状态的转移只依赖与之前的n个状态，这个过程被称为1个n阶的模型，其中n是影响转移状态的数目。最简单的马尔科夫过程是一阶过程，用数学表达式表示就是下面的形式： HMM模型 隐马尔可夫模型（Hidden Markov Model，HMM）是统计模型，它用来描述一个含有隐含未知参数的马尔可夫过程。其难点是从可观察的参数中确定该过程的隐含参数。然后利用这些参数来作进一步的分析，例如模式识别。 https://www.cnblogs.com/fulcra/p/11065474.html 假设我手里有三个不同的骰子。第一个骰子是我们平常见的骰子（称这个骰子为D6），6个面，每个面（1，2，3，4，5，6）出现的概率是1/6。第二个骰子是个四面体（称这个骰子为D4），每个面（1，2，3，4）出现的概率是1/4。第三个骰子有八个面（称这个骰子为D8），每个面（1，2，3，4，5，6，7，8）出现的概率是1/8。 https://www.bilibili.com/video/BV1DK411W7jJ 假设我们开始掷骰子，我们先从三个骰子里挑一个，挑到每一个骰子的概率都是1/3。然后我们掷骰子，得到一个数字，1，2，3，4，5，6，7，8中的一个。不停的重复上述过程，我们会得到一串数字，每个数字都是1，2，3，4，5，6，7，8中的一个。例如我们可能得到这么一串数字（掷骰子10次）：1 6 3 5 2 7 3 5 2 4 这串数字叫做可见状态链。但是在隐马尔可夫模型中，我们不仅仅有这么一串可见状态链，还有一串隐含状态链。在这个例子里，这串隐含状态链就是你用的骰子的序列。比如，隐含状态链有可能是：D6 D8 D8 D6 D4 D8 D6 D6 D4 D8 一般来说，HMM中说到的马尔可夫链其实是指隐含状态链，因为隐含状态（骰子）之间存在转换概率（transition probability）。在我们这个例子里，D6的下一个状态是D4，D6，D8的概率都是1/3。D4，D8的下一个状态是D4，D6，D8的转换概率也都一样是1/3。这样设定是为了最开始容易说清楚，但是我们其实是可以随意设定转换概率的。比如，我们可以这样定义，D6后面不能接D4，D6后面是D6的概率是0.9，是D8的概率是0.1。这样就是一个新的HMM。 同样的，尽管可见状态之间没有转换概率，但是隐含状态和可见状态之间有一个概率叫做输出概率（emission probability）。就我们的例子来说，六面骰（D6）产生1的输出概率是1/6。产生2，3，4，5，6的概率也都是1/6。我们同样可以对输出概率进行其他定义。比如，我有一个被赌场动过手脚的六面骰子，掷出来是1的概率更大，是1/2，掷出来是2，3，4，5，6的概率是1/10。 回到正题，和HMM模型相关的算法主要分为三类，分别解决三种问题： 1）知道骰子有几种（隐含状态数量），每种骰子是什么（转换概率），根据掷骰子掷出的结果（可见状态链），我想知道每次掷出来的都是哪种骰子（隐含状态链）。 这个问题呢，在语音识别领域呢，叫做解码问题。这个问题其实有两种解法，会给出两个不同的答案。每个答案都对，只不过这些答案的意义不一样。第一种解法求最大似然状态路径，说通俗点呢，就是我求一串骰子序列，这串骰子序列产生观测结果的概率最大。第二种解法呢，就不是求一组骰子序列了，而是求每次掷出的骰子分别是某种骰子的概率。比如说我看到结果后，我可以求得第一次掷骰子是D4的概率是0.5，D6的概率是0.3，D8的概率是0.2.第一种解法我会在下面说到，但是第二种解法我就不写在这里了，如果大家有兴趣，我们另开一个问题继续写吧。 2）还是知道骰子有几种** （隐含状态数量），每种骰子是什么（转换概率），根据掷骰子掷出的结果（可见状态链），我想知道掷出这个结果的概率。** 看似这个问题意义不大，因为你掷出来的结果很多时候都对应了一个比较大的概率。问这个问题的目的呢，其实是检测观察到的结果和已知的模型是否吻合。如果很多次结果都对应了比较小的概率，那么就说明我们已知的模型很有可能是错的，有人偷偷把我们的骰子給换了。 3）知道骰子有几种** （隐含状态数量），不知道每种骰子是什么（转换概率），观测到很多次掷骰子的结果（可见状态链），我想反推出每种骰子是什么（转换概率）。** 这个问题很重要，因为这是最常见的情况。很多时候我们只有可见结果，不知道HMM模型里的参数，我们需要从可见结果估计出这些参数，这是建模的一个必要步骤。 隐马尔科夫模型总结就是一个学习问题， 然后判断时有监督学习还是无监督学习 有监督学习：观测序列和状态序列都要有： 极大似然法（pi, A, B） 无监督学习：观测序列,em算法， 马尔科夫模型是一种具有代表性的一阶概率统计模型。隐马尔科夫模型强调了不确定性和潜在性，正是由于这种性质，满足现实生活中诸多问题的基本要求，因此研究人员经常用该模型进行实际状态与行为之间问题的抽象研究与概况。隐马尔科夫模型对于潜在和随机的真实问题有着高度的拟合性，也存在着诸多的优势。隐马尔科夫模型是一个双重随机概率模型，该该型的一般结构是 隐马尔科夫模型的三个基本问题（1）评估问题隐马尔科夫模型的评估问题是，已知一个隐藏状态序列对应的观察值序列 O=O1O2…OT，同时已知确定了基本组成矩阵的模型 λ(π，Q，A)的条件下，输入一组待实现的观察值样本序列，计算得到该模型条件下生成该样本序列的概率，即 P（O/λ） 。在隐马尔科夫模型的评估问题中，计算得到已知模型组成部分下的条件概率的算法被称为前向算法。评估问题的目的是在于根据模型产生待实现的观察值序列的大小，如果产生该序列的概率越大，则说明模型解决该样本序列作为实际问题的能力就越强，进而判断已知模型对待解决问题的适用性。 （2）解码问题 隐马尔科夫模型的评估问题是，已知一个隐藏状态序列对应的观察值序列 O=O1O2…OT，同时已知确定了基本组成矩阵的模型 λ(π，Q，A)的条件下，利用算法进行计算，能够快速有效的选择一定程度下的最好的状态序列Q=Q1Q2。 。 。QT，生成这一隐藏状态序列的概率值最大，能够很好的满足对观察值序列的解释。隐马尔科夫模型的评估问题使用的算法为维特比算法，解码问题的目的是确定最适宜的隐藏状态量的序列，这种最适合并没有明确的定义和规范，根据具体的现实研究问题进行具体的界定。 （3）学习问题隐马尔科夫模型的学习问题是实际问题中最常见的问题类型。在隐马尔科夫模型的学习问题中，仅仅能够已知一组输出的模型状态观察值的序列O=O1O2…OT，对隐马尔科夫模型 λ(π，Q，A)中的基本组成部分并不能直接确定，根据已有的观察值样本数据，对模型进行反复的训练和评价，调节模型 λ(π，Q，A)中的三个基本部分的参数，使得输出该观察值序列的概率值最大，即通过学习训练过程使得该模型具备最优的拟合程度。隐马尔科夫模型的学习问题中，主要是通过前向后向算法（Baum-Welch 算法）来进行训练和学习的；在模型训练学习中，最常见的是采用贝叶斯分析方法和最大似然估计方法，对模型中的参数进行评估和优化，保证模型至少达到局部最优。 在实际问题的研究中，通常都只能获取到输出序列值，因此前向-后向算法实现隐马尔科夫模型的训练学习问题具有广泛应用。 2、模型学习问题：已知观测序列，估计模型中的参数，使得在该模型下观测序列概率最大，即用极大似然估计的方法估计参数。 Baum-Welch算法解决的是一个模型训练问题，即参数估计，是一种无监督的训练方法，主要通过EM迭代实现；即只有观测序列，无状态序列时训练模型。 极大似然估计：观测序列和相应的状态序列都存在的监督学习算法，用来估计参数。 主要用到这两个，然后现在就是学习EM迭代，和用最大似然估计来确定参数！ 第一步是确定，状态数目，或者是生产转移矩阵。","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"交叉验证","slug":"sleep apnea and sleep stage/交叉验证","date":"2020-07-02T00:49:24.000Z","updated":"2020-07-02T00:49:24.000Z","comments":true,"path":"2020/07/02/sleep apnea and sleep stage/交叉验证/","link":"","permalink":"https://esyyes.github.io/2020/07/02/sleep%20apnea%20and%20sleep%20stage/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/","excerpt":"","text":"交叉验证交叉验证：评估估算器的表现学习预测函数的参数，并在相同数据集上进行测试是一种错误的做法: 一个仅给出测试用例标签的模型将会获得极高的分数，但对于尚未出现过的数据它则无法预测出任何有用的信息。 这种情况称为 overfitting（过拟合）. 为了避免这种情况，在进行（监督）机器学习实验时，通常取出部分可利用数据作为 test set（测试数据集） 置信区间 https://baike.baidu.com/item/%E7%BD%AE%E4%BF%A1%E5%8C%BA%E9%97%B4/7442583?fr=aladdin 置信区间是指由样本统计量所构造的总体参数的估计区间。在统计学中，一个概率样本的置信区间（Confidence interval）是对这个样本的某个总体参数的区间估计。 置信区间与置信水平、样本量等因素均有关系，其中样本量对置信区间的影响为：在置信水平固定的情况下，样本量越多，置信区间越窄。其次，在样本量相同的情况下，置信水平越高，置信区间越宽 95%置信区间（Confidence Interval,CI）：当给出某个估计值的95%置信区间为【a,b】时，可以理解为我们有95%的信心（Confidence）可以说样本的平均值介于a到b之间，而发生错误的概率为5%。 有时也会说90%，99%的置信区间，具体含义可参考95%置信区间。 12print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))Accuracy: 0.98 (+/- 0.03) 交叉验证用来验证分类器的性能一种统计分析方法，基本思想是把在某种意义下将原始数据(data set)进行分组，一部分做为训练集(training set)，另一部分做为验证集(validation set)，首先用训练集对分类器进行训练，在利用验证集来测试训练得到的模型(model)，以此来做为评价分类器的性能指标。 k折交叉验证(k-fold cross validation)将数据集无替换的随机分为k份，k-1份用来训练模型，剩下一份用来模型性能评估。重复k次，得到k个模型和性能评估结果。得到k个性能评估后，取平均求出最终性能评估。即：第一步：不重复抽样将原始数据随机分为k份。第二步：每一次挑选其中 1 份作为测试集，剩余k-1份作为训练集用于模型训练。第三步：重复第二步k次，每个子集都有一次作为测试集，其余子集作为训练集。在每个训练集上训练后得到一个模型，用这个模型在相应测试集上测试，计算并保存模型的评估指标。第四步：计算k组测试结果的平均值作为模型精度的估计，并作为当前k折交叉验证下模型的性能指标。 优点：分组后取平均减少方差，使得模型对数据划分不敏感。缺点：k取值需要尝试 123456789101112131415161718192021222324252627282930313233343536# -*- coding: utf-8 -*-# @time : 2020/6/30 0030# @Author : esyfrom sklearn.ensemble import RandomForestClassifierfrom sklearn.metrics import accuracy_scorefrom data_preprocessing import *from sklearn.model_selection import cross_val_scoreimport warningswarnings.filterwarnings(\"ignore\")def run_rf(train_x, test_x, train_y, test_y): clf = RandomForestClassifier() clf.fit(train_x, train_y) pred_y = clf.predict(test_x) acr = accuracy_score(test_y, pred_y) return acrfeature = pd.read_excel('D:/zccode/all_feature' + '/features' + '%s' % 1 + '.xlsx')data = pd.get_dummies(feature.iloc[0:len(feature), 1:])note = pd.read_excel('D:/zccode/all_note' + '/note' + '%s' % 1 + '.xlsx')tag = pd.get_dummies(note.iloc[0:len(data), 1:])# 选定固定的特征值feature_import = pd.read_excel('D:/zccode' + '/feature_important' + '%s' % 2 + '.xlsx')df = pd.get_dummies(feature_import.iloc[0:len(feature_import), 1:16])std_data = data_pre(data[df.keys()])label = pd.get_dummies(tag.iloc[0:len(data), 2:3])scores = cross_val_score(RandomForestClassifier(), std_data, label, cv=10)print(f'&#123;scores&#125;')print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2)) 123[0.88 0.92 0.86956522 0.91304348 0.95652174 1. 1. 0.86363636 1. 0.59090909]Accuracy: 0.90 (+/- 0.23) 交叉验证K值的确定，找一个样本很平均的，然后再去利用样本来进行判定 交叉验证的作用：评估模型的稳定性及调参比如5折交叉验证，在参数确定了的情况下，我们可以将数据弄成五份，每一份中80%训练，20%作为测试集，这样可以训练五个模型，这五个模型除了训练集测试集不同外，其他的都相同，这样我们可以得到五个模型的评估指标比如auc,计算五个模型得到的auc的方差，如果方差小说明模型的泛化性比较好，模型比较稳定是个好模型，否则说明模型泛化性不好。xgboost中cv函数返回的值包括两个，一个是单模型的评价指标（比如auc），另外一个是模型的方差。 参数不确定的情况下，我们通过模型的准确性和稳定性来选择最合适的参数。 https://blog.csdn.net/weixin_41060109/article/details/80878325?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.nonecase 在实际训练中，模型通常对训练数据好，但是对训练数据之外的数据拟合程度差。用于评价模型的泛化能力，从而进行模型选择。 交叉验证的初步目标初步选择大部分的模型，然后通过交叉验证，例如：10次10折，先初步去筛选得到性能效果好的模型，然后再对这几个好的模型，进行网格搜索的超参数优化 交叉验证得到一个准确率，但是不能用准确率这个指标去直接判定分类器的性能 最后用混淆矩阵、精度、召回率等去评估分类的效果和性能","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"中期答辩题目","slug":"sleep apnea and sleep stage/中期答辩题目","date":"2020-06-29T02:58:18.000Z","updated":"2020-06-29T02:58:18.000Z","comments":true,"path":"2020/06/29/sleep apnea and sleep stage/中期答辩题目/","link":"","permalink":"https://esyyes.github.io/2020/06/29/sleep%20apnea%20and%20sleep%20stage/%E4%B8%AD%E6%9C%9F%E7%AD%94%E8%BE%A9%E9%A2%98%E7%9B%AE/","excerpt":"","text":"中期答辩题目考虑睡眠分期、睡眠质量、睡眠呼吸暂停、心电信号、特征选择 ​ 睡眠相关的理论知识，包括睡眠周期性，睡眠分期方法以及睡眠呼吸暂停等。 参考题目：基于PVDF的睡眠监测系统设计与实现 直接将睡眠这几个统计到睡眠 基于心电信号的特征选择和睡眠监测方法研究 基于心电信号的睡眠分期和阻塞性呼吸暂停相关性研究 基于心电信号的睡眠分期和呼吸暂停检测算法的研究","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"查看分类器对应的数据系列","slug":"sleep apnea and sleep stage/查看分类器对应的数据系列","date":"2020-06-24T13:02:27.000Z","updated":"2020-06-24T13:02:27.000Z","comments":true,"path":"2020/06/24/sleep apnea and sleep stage/查看分类器对应的数据系列/","link":"","permalink":"https://esyyes.github.io/2020/06/24/sleep%20apnea%20and%20sleep%20stage/%E6%9F%A5%E7%9C%8B%E5%88%86%E7%B1%BB%E5%99%A8%E5%AF%B9%E5%BA%94%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B3%BB%E5%88%97/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"不同特征数之间的分类模型比较","slug":"sleep apnea and sleep stage/不同特征数之间的分类模型比较","date":"2020-06-24T02:57:17.000Z","updated":"2020-06-24T02:57:17.000Z","comments":true,"path":"2020/06/24/sleep apnea and sleep stage/不同特征数之间的分类模型比较/","link":"","permalink":"https://esyyes.github.io/2020/06/24/sleep%20apnea%20and%20sleep%20stage/%E4%B8%8D%E5%90%8C%E7%89%B9%E5%BE%81%E6%95%B0%E4%B9%8B%E9%97%B4%E7%9A%84%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E6%AF%94%E8%BE%83/","excerpt":"","text":"不同特征数之间的分类模型比较首先确定特征的个数，确定index和特征数之间的关系 12345import pandas as pd# 选定固定的特征值feature_import = pd.read_excel('D:/zccode' + '/feature_important' + '%s' % 2 + '.xlsx')df = pd.get_dummies(feature_import.iloc[0:len(feature_import), 1:5]) 12 5NN20 5pNN20 5pNN50 5NN500 0.023794 0.023346 0.022757 0.022194 根据设定的index,还是取的是左闭右开，因此对于下面的特征，index 应该为特征数加1 12345678最大准确率时对应的特征数分期为5时 最高准确率为79.65% 特征数为23分期为4时 最高准确率为86.40% 特征数为23分期为3时 最高准确率为89.04% 特征数为15准确率降低1%后对应的特征数分期为5时 最高准确率为79.65% 最高准确率降低1%后为78.85% 比较筛选的准确率为78.86% 特征数为9分期为4时 最高准确率为86.40% 最高准确率降低1%后为85.54% 比较筛选的准确率为85.66% 特征数为8分期为3时 最高准确率为89.04% 最高准确率降低1%后为88.15% 比较筛选的准确率为88.22% 特征数为7 重新跑下结果； 因此对于最大准确率时，基于特征数的分类模型就该为下面程序 最大准确率时特征对应的分类结果123456789101112131415# -*- coding: utf-8 -*-# @time : 2020/6/23 0023# @Author : esyfrom sleep_class import *for k in range(3): if k == 0: index = 24 class_feature(k, index) elif k == 1: index = 24 class_feature(k, index) else: index = 16 class_feature(k, index) sleep class 中的函数12345678910111213141516171819202122232425262728293031323334353637383940414243# -*- coding: utf-8 -*-# @time : 2020/6/23 0023# @Author : esyfrom data_preprocessing import *from sklearn.model_selection import train_test_splitfrom classifiers import *import warningswarnings.filterwarnings(\"ignore\")def class_feature(k, index): class_scores = [] kappa_scores = [] for i in range(1, 19): feature = pd.read_excel('D:/zccode/all_feature' + '/features' + '%s' % i + '.xlsx') data = pd.get_dummies(feature.iloc[0:len(feature), 1:]) note = pd.read_excel('D:/zccode/all_note' + '/note' + '%s' % i + '.xlsx') tag = pd.get_dummies(note.iloc[0:len(data), 1:]) feature_import = pd.read_excel('D:/zccode' + '/feature_important' + '%s' % (k+1) + '.xlsx') df = pd.get_dummies(feature_import.iloc[0:len(feature_import), 1:index]) std_data = data_pre(data[df.keys()]) label = pd.get_dummies(tag.iloc[0:len(data), k:k+1]) class_score = [] kappa_score = [] for x in range(50): X_train, X_test, y_train, y_test = train_test_split(std_data, label, test_size=0.3) score = run_classifiers(X_train, X_test, y_train, y_test) class_score.append(score[0]) kappa_score.append(score[1]) class_scores.append([(np.array([class_score[a][k] for a in range(50)])).mean() for k in range(9)]) kappa_scores.append([(np.array([kappa_score[a][k] for a in range(50)])).mean() for k in range(9)]) print(f'已经运行&#123;i&#125;次') class_total = pd.DataFrame(class_scores) kappa_total = pd.DataFrame(kappa_scores) class_total.to_excel('feature_section_class' + '%d' % k + \".xlsx\") kappa_total.to_excel('feature_section_kappa' + '%d' % k + \".xlsx\") return f'运行一次' 特征降维后的分类结果123456789101112131415# -*- coding: utf-8 -*-# @time : 2020/6/23 0023# @Author : esyfrom sleep_class import *for k in range(3): if k == 0: index = 10 class_feature(k, index) elif k == 1: index = 9 class_feature(k, index) else: index = 8 class_feature(k, index) 保存名字为 features_section_class 然后将其取平均值，并绘制柱状图 分类结果文件保存为： E:\\feature section features_section_class是降维后 feature_section_class 是最开始的数据分类结果 经过查看，在即使在最高分期准确率的结果下，都会出现数据一部分特别好一部分都很差的情况 暂时只进行数据的平均分类准确率，然后筛选出最优的分类模型，比较每个模型中最优的结果 然后再去考虑单独的人，为什么会差距这么大，是什么因素影响了分期准确率 12345678910111213141516171819 0 1 2 ... 6 7 80 0.785217 0.862609 0.828406 ... 0.874493 0.879130 0.8820291 0.789143 0.824000 0.843429 ... 0.844952 0.845714 0.8478102 0.834667 0.866286 0.857714 ... 0.848381 0.853524 0.8603813 0.881538 0.890000 0.886154 ... 0.881795 0.864615 0.8987184 0.601373 0.694902 0.687745 ... 0.756569 0.765588 0.7683335 0.754366 0.805540 0.804131 ... 0.850704 0.847512 0.8277936 0.615450 0.674597 0.664171 ... 0.706161 0.702749 0.7157357 0.754732 0.831122 0.803415 ... 0.840293 0.824195 0.8459518 0.811746 0.826984 0.831429 ... 0.822751 0.834921 0.8443399 0.915749 0.928309 0.927246 ... 0.941739 0.935556 0.93874410 0.535238 0.640173 0.591602 ... 0.674026 0.670216 0.66952411 0.695733 0.780800 0.759822 ... 0.809689 0.798489 0.79528912 0.640356 0.700889 0.687911 ... 0.690844 0.696978 0.70542213 0.694667 0.804148 0.751852 ... 0.786519 0.801037 0.81155614 0.803824 0.833137 0.834608 ... 0.841373 0.833529 0.85039215 0.646479 0.679531 0.723192 ... 0.772582 0.776901 0.80347416 0.682636 0.745271 0.743101 ... 0.760930 0.770078 0.75814017 0.668372 0.708837 0.700465 ... 0.719535 0.696744 0.721395 如下表所示，有些列的数据对应起来就并不好，先基于平均值然后再去筛选为什么为地域80%的原因，找单独的数据序列，去对应查看其中的影响因素。 12345678910111213141516171819 0 1 2 ... 6 7 80 0.721449 0.851304 0.764348 ... 0.848116 0.836232 0.8515941 0.712571 0.770095 0.768381 ... 0.808571 0.814476 0.7697142 0.806476 0.858286 0.844000 ... 0.837524 0.842095 0.8619053 0.818205 0.846154 0.870513 ... 0.854103 0.851538 0.8564104 0.495882 0.645000 0.575392 ... 0.700294 0.696961 0.6820595 0.720845 0.784695 0.757934 ... 0.818592 0.814554 0.7642256 0.521991 0.613175 0.576967 ... 0.637820 0.638768 0.6357357 0.676488 0.782634 0.677366 ... 0.799707 0.803220 0.8079028 0.782540 0.819153 0.817460 ... 0.810794 0.820106 0.8326989 0.906377 0.917005 0.916908 ... 0.920000 0.916908 0.92048310 0.484762 0.586667 0.511688 ... 0.642511 0.638182 0.61497811 0.683378 0.739111 0.730667 ... 0.785156 0.779111 0.75822212 0.637956 0.688356 0.688267 ... 0.670578 0.679467 0.68853313 0.528741 0.705778 0.642519 ... 0.723852 0.733333 0.69051914 0.736569 0.810686 0.774216 ... 0.818431 0.817647 0.81911815 0.490704 0.595869 0.573052 ... 0.724413 0.706291 0.63953116 0.666977 0.746202 0.727907 ... 0.754884 0.753488 0.76031017 0.595814 0.668372 0.650233 ... 0.676279 0.657209 0.696279 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# -*- coding: utf-8 -*-# @Time : 2020/6/24# @Author : esyimport numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport warnings# 忽略警告warnings.filterwarnings(\"ignore\")# 最高准确率时对应特征数，对应的分类准确率feature = pd.read_excel('E:/feature section' + '/feature_section_class' + '%s' % 1 + '.xlsx')data = pd.get_dummies(feature.iloc[0:len(feature), 1:])data.rename(columns=&#123;0: 'SGD', 1: 'SVM', 2: 'LSVM', 3: 'LR', 4: 'KNN', 5: 'DT', 6: 'RF', 7: 'GBT', 8: 'NN'&#125;, inplace=True)# 经过1%牺牲后的分类准确率section = pd.read_excel('E:/feature section' + '/features_section_class' + '%s' % 1 + '.xlsx')df = pd.get_dummies(section.iloc[0:len(section), 1:])df.rename(columns=&#123;0: 'SGD', 1: 'SVM', 2: 'LSVM', 3: 'LR', 4: 'KNN', 5: 'DT', 6: 'RF', 7: 'GBT', 8: 'NN'&#125;, inplace=True)x = np.arange(9)y1 = [(np.array([np.array(data).tolist()[i][j] * 100 for i in range(18)])).mean() for j in range(9)]y2 = [(np.array([np.array(df).tolist()[i][j] * 100 for i in range(18)])).mean() for j in range(9)]width = 0.4plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']plt.rcParams['axes.unicode_minus'] = Falsefig, ax = plt.subplots(figsize=(7, 5))rects1 = ax.bar(x - width/2, y1, width, color='SkyBlue', label='Before dimensionality reduction')rects2 = ax.bar(x + width/2, y2, width, color='IndianRed', label='After dimensionality reduction')plt.xticks(x, (df.keys()), fontsize=10, rotation=0)plt.ylabel('Average Accuracy/%', fontsize=15)ax.set_title('DLRW主题下降维前后准确率对比', fontsize=15)ax.legend()plt.ylim((60, 95))new_ticks = np.linspace(60, 95, 5)plt.yticks(new_ticks, fontsize=10)for y in rects1+rects2: h = y.get_height() ax.text(y.get_x()+y.get_width()/2, h, '%.1f' % h, ha='center', va='bottom', fontsize=10)plt.show()fig.savefig('feature_class4_number.png', dpi=1600, bbox_inches='tight') 感觉效果并不好，考虑下一个步骤","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"特征数的确定","slug":"sleep apnea and sleep stage/特征数的确定","date":"2020-06-24T01:42:09.000Z","updated":"2020-06-24T01:42:09.000Z","comments":true,"path":"2020/06/24/sleep apnea and sleep stage/特征数的确定/","link":"","permalink":"https://esyyes.github.io/2020/06/24/sleep%20apnea%20and%20sleep%20stage/%E7%89%B9%E5%BE%81%E6%95%B0%E7%9A%84%E7%A1%AE%E5%AE%9A/","excerpt":"","text":"特征数的确定经过50次平均值筛选后，可看出对应3分期时，特征数为15,4、5分期的特征数都为23，此时为最高的特征值。 为了确定特征数对准确率的影响，第一个方案 选择(10-22)个特征，将每个特征都用于分类，然后将对比看看分类的结果 特征缩减12345678910111213141516171819202122232425262728293031323334353637383940414243# -*- coding: utf-8 -*-# @Time : 2020/6/17# @Author : esyfrom data_preprocessing import *from sklearn.model_selection import train_test_splitfrom classifiers import *import warningswarnings.filterwarnings(\"ignore\")for index in range(10, 22): class_scores = [] kappa_scores = [] for i in range(1, 19): feature = pd.read_excel('D:/zccode/all_feature' + '/features' + '%s' % i + '.xlsx') data = pd.get_dummies(feature.iloc[0:len(feature), 1:]) note = pd.read_excel('D:/zccode/all_note' + '/note' + '%s' % i + '.xlsx') tag = pd.get_dummies(note.iloc[0:len(data), 1:]) # 选定固定的特征值 feature_import = pd.read_excel('D:/zccode' + '/feature_important' + '%s' % 2 + '.xlsx') df = pd.get_dummies(feature_import.iloc[0:len(feature_import), 1:index]) std_data = data_pre(data[df.keys()]) label = pd.get_dummies(tag.iloc[0:len(data), 1:2]) class_score = [] kappa_score = [] for x in range(50): X_train, X_test, y_train, y_test = train_test_split(std_data, label, test_size=0.3) score = run_classifiers(X_train, X_test, y_train, y_test) class_score.append(score[0]) kappa_score.append(score[1]) class_scores.append([(np.array([class_score[a][k] for a in range(50)])).mean() for k in range(9)]) kappa_scores.append([(np.array([kappa_score[a][k] for a in range(50)])).mean() for k in range(9)]) print(f'已经运行&#123;i&#125;次') class_total = pd.DataFrame(class_scores) kappa_total = pd.DataFrame(kappa_scores) class_total.to_excel('no RFE classf' + '%d' % index + \".xlsx\") kappa_total.to_excel('no RFE kappaf' + '%d' % index + \".xlsx\") 此次方案，在进行分类时，直接选用的是固定的特征，即迭代50次特征贡献度，平均后的结果，用固定特征对应的特征数，去进行分类。 分类模型123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115# -*- coding: utf-8 -*-# @Time : 2020/6/15# @Author : esyfrom sklearn.ensemble import RandomForestClassifierfrom sklearn.ensemble import GradientBoostingClassifierfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.tree import DecisionTreeClassifierfrom sklearn.svm import SVCfrom sklearn.svm import LinearSVCfrom sklearn.linear_model import LogisticRegressionfrom sklearn.neural_network import MLPClassifierfrom sklearn.linear_model import SGDClassifierfrom sklearn.metrics import accuracy_scorefrom sklearn.metrics import cohen_kappa_scoredef run_rf(train_x, test_x, train_y, test_y): clf = RandomForestClassifier() clf.fit(train_x, train_y) pred_y = clf.predict(test_x) acr = accuracy_score(test_y, pred_y) kappa = cohen_kappa_score(test_y, pred_y) return [acr, kappa]def run_gbt(train_x, test_x, train_y, test_y): clf = GradientBoostingClassifier() clf.fit(train_x, train_y) pred_y = clf.predict(test_x) acr = accuracy_score(test_y, pred_y) kappa = cohen_kappa_score(test_y, pred_y) return [acr, kappa]def run_knn(train_x, test_x, train_y, test_y): clf = KNeighborsClassifier() clf.fit(train_x, train_y) pred_y = clf.predict(test_x) acr = accuracy_score(test_y, pred_y) kappa = cohen_kappa_score(test_y, pred_y) return [acr, kappa]def run_dt(train_x, test_x, train_y, test_y): clf = DecisionTreeClassifier() clf.fit(train_x, train_y) pred_y = clf.predict(test_x) acr = accuracy_score(test_y, pred_y) kappa = cohen_kappa_score(test_y, pred_y) return [acr, kappa]def run_svm(train_x, test_x, train_y, test_y): clf = SVC() clf.fit(train_x, train_y) pred_y = clf.predict(test_x) acr = accuracy_score(test_y, pred_y) kappa = cohen_kappa_score(test_y, pred_y) return [acr, kappa]def run_lsvm(train_x, test_x, train_y, test_y): clf = LinearSVC() clf.fit(train_x, train_y) pred_y = clf.predict(test_x) acr = accuracy_score(test_y, pred_y) kappa = cohen_kappa_score(test_y, pred_y) return [acr, kappa]def run_lr(train_x, test_x, train_y, test_y): clf = LogisticRegression() clf.fit(train_x, train_y) pred_y = clf.predict(test_x) acr = accuracy_score(test_y, pred_y) kappa = cohen_kappa_score(test_y, pred_y) return [acr, kappa]def run_ml(train_x, test_x, train_y, test_y): clf = MLPClassifier() clf.fit(train_x, train_y) pred_y = clf.predict(test_x) acr = accuracy_score(test_y, pred_y) kappa = cohen_kappa_score(test_y, pred_y) return [acr, kappa]def run_sgd(train_x, test_x, train_y, test_y): clf = SGDClassifier() clf.fit(train_x, train_y) pred_y = clf.predict(test_x) acr = accuracy_score(test_y, pred_y) kappa = cohen_kappa_score(test_y, pred_y) return [acr, kappa]# 直接运行结果def run_classifiers(train_x, test_x, train_y, test_y): rf = run_rf(train_x, test_x, train_y, test_y) gbt = run_gbt(train_x, test_x, train_y, test_y) knn = run_knn(train_x, test_x, train_y, test_y) dt = run_dt(train_x, test_x, train_y, test_y) svm = run_svm(train_x, test_x, train_y, test_y) lsvm = run_lsvm(train_x, test_x, train_y, test_y) lr = run_lr(train_x, test_x, train_y, test_y) ml = run_ml(train_x, test_x, train_y, test_y) sgd = run_sgd(train_x, test_x, train_y, test_y) class_s = [sgd[0], svm[0], lsvm[0], lr[0], knn[0], dt[0], rf[0], gbt[0], ml[0]] kappa_s = [sgd[1], svm[1], lsvm[1], lr[1], knn[1], dt[1], rf[1], gbt[1], ml[1]] return [class_s, kappa_s] 分类模型对应的为以下9种，并分别计算出的kappa值 1[sgd[0], svm[0], lsvm[0], lr[0], knn[0], dt[0], rf[0], gbt[0], ml[0]] 文件保存为： E:\\sleep_stage 例如：no RFE class10.xlsx 10其实对应的是9，在index中，而且不一定对应的是9还可能是对应的8，这点待会儿还需要检验下，直接进行最高的和牺牲对比的 总结对比结果发现，特征越多，准确率越高，在其他分类模型中，随机森林相对变化不大 方案二最大准确率虽然此时的max对应的特征数已经确定，但是可以明显看出，从特征数7-9这些开始已经没有太多的明显变化 所以为了进一步的缩减特征值，在此次方案中采取牺牲1%的准确率，来降低特征数的方针。 123456789101112131415161718192021222324252627# -*- coding: utf-8 -*-# @Time : 2020/6/24# @Author : esyimport pandas as pdimport numpy as npimport warnings# 忽略警告warnings.filterwarnings(\"ignore\")all_section = []for q in range(3): data = pd.read_excel('E:/features' + '/themes' + '%s' % q + '.xlsx') train_data = np.array(data).tolist() list_mean = [[np.array([eval(train_data[i][k])[j] for k in range(50)]).mean() for j in range(25)] for i in range(18)] feature_section = [np.array([list_mean[j][i] * 100 for j in range(18)]).mean() for i in range(25)] all_section.append(feature_section)x = np.arange(1, 26)class_5 = all_section[0]class_4 = all_section[1]class_3 = all_section[2]class_num = [x[all_section[i].index(max(all_section[i]))] for i in range(3)]class_max = [max(all_section[i]) for i in range(3)] 先找到对应的最大值对应的位置class_num和值class_max [23, 23, 15] [79.64724146295774, 86.40048338502821, 89.03929260177847] 来个制表符，直接输出，让他看起来好看点 1234for i in range(3): print(f'分期为&#123;5-i&#125;时', end='\\t') print(f'最高准确率为%.2f%%' % max(all_section[i]), end='\\t') print(f'特征数为&#123;x[all_section[i].index(max(all_section[i]))]&#125;') 输出要%时，即为%% 123分期为5时 最高准确率为79.65% 特征数为23分期为4时 最高准确率为86.40% 特征数为23分期为3时 最高准确率为89.04% 特征数为15 降低1%后对应结果12345678910print(f'准确率降低1%后对应的特征数')for i in range(3): print(f'分期为&#123;5-i&#125;时', end='\\t') print(f'最高准确率为%.2f%%' % max(all_section[i]), end='\\t') print(f'最高准确率降低1%%后为%.2f%%' % (max(all_section[i]) * 0.99), end='\\t') for j in range(len(all_section[i])): if (max(all_section[i]) * 0.99) &lt; all_section[i][j]: print(f'比较筛选的准确率为%.2f%%' % (all_section[i][j]), end='\\t') break print(f'特征数为&#123;x[all_section[i].index(all_section[i][j])]&#125;') 12345678最大准确率时对应的特征数分期为5时 最高准确率为79.65% 特征数为23分期为4时 最高准确率为86.40% 特征数为23分期为3时 最高准确率为89.04% 特征数为15准确率降低1%后对应的特征数分期为5时 最高准确率为79.65% 最高准确率降低1%后为78.85% 比较筛选的准确率为78.86% 特征数为9分期为4时 最高准确率为86.40% 最高准确率降低1%后为85.54% 比较筛选的准确率为85.66% 特征数为8分期为3时 最高准确率为89.04% 最高准确率降低1%后为88.15% 比较筛选的准确率为88.22% 特征数为7","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"绘制特征重要度筛选结果","slug":"sleep apnea and sleep stage/绘制特征重要度筛选结果","date":"2020-06-24T00:59:32.000Z","updated":"2020-06-24T00:59:32.000Z","comments":true,"path":"2020/06/24/sleep apnea and sleep stage/绘制特征重要度筛选结果/","link":"","permalink":"https://esyyes.github.io/2020/06/24/sleep%20apnea%20and%20sleep%20stage/%E7%BB%98%E5%88%B6%E7%89%B9%E5%BE%81%E9%87%8D%E8%A6%81%E5%BA%A6%E7%AD%9B%E9%80%89%E7%BB%93%E6%9E%9C/","excerpt":"","text":"绘制特征重要度筛选结果基于全部特征的提取和标签处理，初步设定RFE-RF筛选特征时，设定的重要度中的特征个数index为26，即在25个特征之间进行排查。 输出特征重要度12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# -*- coding: utf-8 -*-# @Time : 2020/6/12# @Author : esyfrom data_preprocessing import *from sklearn.model_selection import train_test_splitfrom sklearn.ensemble import RandomForestClassifierfrom sklearn.feature_selection import RFEfrom sklearn.metrics import accuracy_scoreimport warningswarnings.filterwarnings(\"ignore\")def run_rf(xtrain, xtest, ytrain, ytest): clf = RandomForestClassifier() clf.fit(xtrain, ytrain) ypred = clf.predict(xtest) sad = accuracy_score(ytest, ypred) return sadfor k in range(3): print(f'在标签&#123;k&#125;下的特征文件') se = [] for i in range(1, 19): feature = pd.read_excel('D:/zccode/all_feature' + '/features' + '%s' % i + '.xlsx') data = pd.get_dummies(feature.iloc[0:len(feature), 1:]) note = pd.read_excel('D:/zccode/all_note' + '/note' + '%s' % i + '.xlsx') tag = pd.get_dummies(note.iloc[0:len(data), 1:]) df = data_pre(data) label = pd.get_dummies(tag.iloc[0:len(data), k:k+1]) acr = [] for j in range(50): X_train, X_test, y_train, y_test = train_test_split(df, label, test_size=0.3) score = [] for index in range(1, 26): sel = RFE(RandomForestClassifier(random_state=0), n_features_to_select=index) sel.fit(X_train, y_train) X_train_rfe = sel.transform(X_train) X_test_rfe = sel.transform(X_test) score.append(run_rf(X_train_rfe, X_test_rfe, y_train, y_test)) acr.append(score) print(f'检测文件数为：%2d' % i, end='\\t') se.append(acr) print() sea = pd.DataFrame(se) sea.to_excel('themes' + '%d' % k + \".xlsx\") print(f'运行主题&#123;k&#125;次') 这个区间就为(1, 26) 进行了50次循环筛选，然后保存为文件为themes012,对应为分期结果543 保存在： E:\\features\\themes012 绘制50次平均重要度对应准确率1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# -*- coding: utf-8 -*-# @Time : 2020/6/18# @Author : esyimport pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport warnings# 忽略警告warnings.filterwarnings(\"ignore\")all_section = []for q in range(3): data = pd.read_excel('E:/features' + '/themes' + '%s' % q + '.xlsx') train_data = np.array(data).tolist() list_mean = [[np.array([eval(train_data[i][k])[j] for k in range(50)]).mean() for j in range(25)] for i in range(18)] feature_section = [np.array([list_mean[j][i] * 100 for j in range(18)]).mean() for i in range(25)] all_section.append(feature_section)x = np.arange(1, 26)class_5 = all_section[0]class_4 = all_section[1]class_3 = all_section[2]fig = plt.figure(figsize=(7, 4))# 解决中文显示问题plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']plt.rcParams['axes.unicode_minus'] = Falseplt.xticks(x)plt.plot(x, class_5, \"k*--\", linewidth=1, label='class_5')plt.plot(x, class_4, \"bo--\", linewidth=1, label='class_5')plt.plot(x, class_3, \"ro--\", linewidth=1, label='class_5')for i in range(3): plt.scatter(x[all_section[i].index(max(all_section[i]))], max(all_section[i]), s=100, color='r') plt.text(x[all_section[i].index(max(all_section[i]))], max(all_section[i])-2, r's', fontdict=&#123;'size': '10', 'color': 'k'&#125;)plt.xlabel(\"Number of Features\", fontsize=10)plt.xticks(fontsize=8)plt.ylabel(\"Average Accuracy of RF/%\", fontsize=10)plt.yticks(fontsize=8)plt.legend()ax = plt.gca()ax.spines['right'].set_color('none')ax.spines['top'].set_color('none')plt.show()fig.savefig('features_section.png', dpi=1980, bbox_inches='tight')# dpi可以控制图象的分辨率,bbox_inches可以剪除图表的空白部分 经过50次平均值筛选后，可看出对应3分期时，特征数为15,4、5分期的特征数都为23，此时为最高的特征值。 hexo 插入本地图片!【】用这个形式，但是根目录和插入的目录的不能再进行重叠，且斜杠为/images/features_section.png 用这个形式相同的道理，上面那个好用点 ！【】（http://pic1.win4000.com/wallpaper/1/5993ff70bfac7.jpg）","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"重要特征查看","slug":"sleep apnea and sleep stage/重要特征查看","date":"2020-06-18T08:24:02.000Z","updated":"2020-06-18T08:24:02.000Z","comments":true,"path":"2020/06/18/sleep apnea and sleep stage/重要特征查看/","link":"","permalink":"https://esyyes.github.io/2020/06/18/sleep%20apnea%20and%20sleep%20stage/%E9%87%8D%E8%A6%81%E7%89%B9%E5%BE%81%E6%9F%A5%E7%9C%8B/","excerpt":"","text":"重要特征查看目的：将睡眠分期中的345阶段的睡眠分期结果进行比较，查看特征对睡眠分期的影响, 筛选出特征贡献度最高的那几个，进行查看 程序：利用表格形式输出特征的排序 12345678910111213141516171819202122232425# -*- coding: utf-8 -*-# @Time : 2020/6/18# @Author : esy# 选定固定的特征值import pandas as pdimport warnings# 忽略警告warnings.filterwarnings(\"ignore\")for h in range(1, 4): feature_import = pd.read_excel('E:/features' + '/feature_important' + '%s' % h + '.xlsx') df = pd.get_dummies(feature_import.iloc[0:len(feature_import), 1:23]) data = df.T print(f'列写特征重要度排序', end='\\t') print() print(f'序号', end='\\t\\t') print(f'特征', end='\\t\\t') print(f'重要度') for i in range(22): print(f'%2d' % i, end='\\t') print(f'%10s' % df.keys()[i], end='\\t') print(f'%0.3f' % data[0][i]) 1234567891011121314151617181920212223序号 特征 重要度 0 5pNN20 0.021 1 5NN20 0.021 2 5pNN50 0.019 3 5NN50 0.019 4 5p_RMSSD 0.018 5 5p_var 0.018 6 5csi50 0.017 7 5csi30 0.017 8 5csi10 0.017 9 5HF 0.01710 5p_skew 0.01711 5p_SDNN 0.01712 5p_median 0.01713 5R_mean 0.01614 5HR_mean 0.01615 5p_RMS 0.01516 5p_mean 0.01517 5p_max 0.01418 5R_median 0.01419 5apen 0.01420 5p_peak_factor 0.01421 5csi100 0.014 1234567891011121314151617181920212223序号 特征 重要度 0 5NN20 0.024 1 5pNN20 0.023 2 5pNN50 0.023 3 5NN50 0.022 4 5p_skew 0.020 5 5HF 0.018 6 5p_median 0.017 7 5R_mean 0.016 8 5p_SDNN 0.016 9 5p_var 0.01610 5p_RMS 0.01611 5csi10 0.01612 5p_RMSSD 0.01613 5R_CVSD 0.01614 5p_max 0.01615 5csi50 0.01616 5R_SDSD 0.01517 5p_mean 0.01518 5sd1 0.01519 5R_RMSSD 0.01520 5HR_min 0.01521 5apen 0.015 1234567891011121314151617181920212223序号 特征 重要度 0 5pNN20 0.026 1 5NN20 0.025 2 5pNN50 0.023 3 5NN50 0.021 4 5R_mean 0.019 5 5p_skew 0.019 6 5HF 0.018 7 5HR_min 0.017 8 5p_median 0.017 9 5R_median 0.01710 5apen 0.01711 5HR_mean 0.01712 5p_RMSSD 0.01613 5R_CVSD 0.01614 5csi10 0.01615 5p_SDNN 0.01616 5p_RMS 0.01617 5p_max 0.01618 5p_var 0.01519 5p_mean 0.01520 5R_SDSD 0.01521 5R_RMSSD 0.015 排序顺序为543分类 直接用一个行表格不就行了嘛。。。 123456789101112131415161718192021222324252627282930313233# -*- coding: utf-8 -*-# @Time : 2020/6/18# @Author : esy# 选定固定的特征值import pandas as pdimport warnings# 忽略警告warnings.filterwarnings(\"ignore\")# for h in range(1, 4):# feature_import = pd.read_excel('E:/features' + '/feature_important' + '%s' % h + '.xlsx')# df = pd.get_dummies(feature_import.iloc[0:len(feature_import), 1:23])# data = df.T# print(f'列写特征重要度排序', end='\\t')# print()# print(f'序号', end='\\t\\t')# print(f'特征', end='\\t\\t')# print(f'重要度')# for i in range(22):# print(f'%2d' % i, end='\\t')# print(f'%10s' % df.keys()[i], end='\\t')# print(f'%0.3f' % data[0][i])for i in range(22): for h in range(1, 4): feature_import = pd.read_excel('E:/features' + '/feature_important' + '%s' % h + '.xlsx') df = pd.get_dummies(feature_import.iloc[0:len(feature_import), 1:23]) data = df.T print(f'%15s' % df.keys()[i], end='\\t') print() 1234567891011121314151617181920212223 5期 4期 3期 5pNN20 5NN20 5pNN20 5NN20 5pNN20 5NN20 5pNN50 5pNN50 5pNN50 5NN50 5NN50 5NN50 5p_RMSSD 5p_skew 5R_mean 5p_var 5HF 5p_skew 5csi50 5p_median 5HF 5csi30 5R_mean 5HR_min 5csi10 5p_SDNN 5p_median 5HF 5p_var 5R_median 5p_skew 5p_RMS 5apen 5p_SDNN 5csi10 5HR_mean 5p_median 5p_RMSSD 5p_RMSSD 5R_mean 5R_CVSD 5R_CVSD 5HR_mean 5p_max 5csi10 5p_RMS 5csi50 5p_SDNN 5p_mean 5R_SDSD 5p_RMS 5p_max 5p_mean 5p_max 5R_median 5sd1 5p_var 5apen 5R_RMSSD 5p_mean 5p_peak_factor 5HR_min 5R_SDSD 5csi100 5apen 5R_RMSSD","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"全部特征的提取和标签处理","slug":"sleep apnea and sleep stage/全部特征的提取和标签处理","date":"2020-06-11T08:49:41.000Z","updated":"2020-06-11T08:49:41.000Z","comments":true,"path":"2020/06/11/sleep apnea and sleep stage/全部特征的提取和标签处理/","link":"","permalink":"https://esyyes.github.io/2020/06/11/sleep%20apnea%20and%20sleep%20stage/%E5%85%A8%E9%83%A8%E7%89%B9%E5%BE%81%E7%9A%84%E6%8F%90%E5%8F%96%E5%92%8C%E6%A0%87%E7%AD%BE%E5%A4%84%E7%90%86/","excerpt":"","text":"全部特征的提取和标签处理提取5分钟片段的特征，并进行滑窗切片，以30s为窗口，5min为步长 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# -*- coding: utf-8 -*-# @Time : 2020/6/11# @Author : esy# 将5分钟的数据进行30s窗口的滑窗切片，然后进行输出为list# 5min的进行单独的分析，然后进行时频域和非线性的分析import wfdbfrom wfdb import processing# import numpy as npimport warningsfrom peaks_time_features import *from time_domain import *from frequency_domain import *from HRV_interp1 import *from nonliner_domain import *from eliminate_outliers import *# 忽略警告warnings.filterwarnings(\"ignore\")test = 'slp01a'record = wfdb.rdrecord('F:/slpdb_data/mitdata' + '/%s' % test, channels=[0])annotation = wfdb.rdann('F:/slpdb_data/mitdata' + '/%s' % test, 'ecg')ecg_signal = record.p_signalecg_locs = annotation.sample.tolist()ecg_locs.pop(0)min_bpm = 40max_bpm = 200search_radius = int(record.fs * 60 / max_bpm)ecg_r_locs1 = processing.correct_peaks(ecg_signal[:, 0], peak_inds=ecg_locs, search_radius=search_radius, smooth_window_size=100)# ecg_r_locs异常点处理ecg_r_locs = eliminate(ecg_r_locs1)# ecg_r_peaks峰值点获取ecg_r_peaks = [ecg_signal[int(ecg_r_locs[i])][0] for i in range(len(ecg_r_locs))]all_RR_5m = []all_locs_5m = []all_peaks_5m = []for i in range(int(record.sig_len/record.fs/30 - 11)): RR_300s = [] locs_300s = [] peaks_300s = [] for j in range(len(ecg_r_locs)): if (30*record.fs*i) &lt;= ecg_r_locs[j] &lt;= (30*record.fs*(i+10)): locs_300s.append(ecg_r_locs[j]) RR_300s.append((ecg_r_locs[j+1] - ecg_r_locs[j]) * 4) peaks_300s.append(ecg_r_peaks[j][0]) else: pass RR_300s.pop() all_RR_5m.append(RR_300s) all_locs_5m.append(locs_300s) all_peaks_5m.append(peaks_300s)# ECG_Rpeaks_features = [peaks_time_feature(all_peaks_300s[i]) for i in range(len(all_peaks_300s))]# HRVhrv_time = [time_features(all_RR_300s[i]) for i in range(len(all_RR_300s))]hrv_freq = [getfreq(resample(hrv_interp1(all_locs_300s[i], all_RR_300s[i], 1), 250, 4)) for i in range(len(all_RR_300s))]hrv_nonl = [non_linear(np.array(all_RR_300s[i])) for i in range(len(all_RR_30s))]features = [peaks_features[i] + hrv_time[i] + hrv_freq[i] + hrv_nonl[i] for i in range(len(all_RR_300s))] 特征重要度123456789101112131415161718192021222324252627282930# -*- coding: utf-8 -*-# @Time : 2020/6/11# @Author : esyfrom data_preprocessing import *from sklearn.model_selection import train_test_splitfrom sklearn.ensemble import RandomForestClassifierfrom sklearn.feature_selection import SelectFromModelimport warningswarnings.filterwarnings(\"ignore\")for i in range(1, 19): feature = pd.read_excel('F:/py/python-ECG信号处理/all_feature' + '/features' + '%s' % i + '.xlsx') data = pd.get_dummies(feature.iloc[0:len(feature), 1:]) note = pd.read_excel('F:/py/python-ECG信号处理/all_note' + '/note' + '%s' % i + '.xlsx') tag = pd.get_dummies(note.iloc[0:len(data), 1:]) # 数据预处理 df = data_pre(data) label = pd.get_dummies(tag.iloc[0:len(data), -2:-1]) X = df Y = label X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3) sel = SelectFromModel(RandomForestClassifier(n_jobs=-1)) sel.fit(X_train, y_train) features = X_train.columns[sel.get_support()] print(f'%2d 重要特征数为：&#123;len(features)&#125;' %i, end='\\t') print() 1 重要特征数为：26 2 重要特征数为：30 3 重要特征数为：24 4 重要特征数为：34 5 重要特征数为：42 6 重要特征数为：32 7 重要特征数为：40 8 重要特征数为：34 9 重要特征数为：2110 重要特征数为：2511 重要特征数为：4112 重要特征数为：2913 重要特征数为：2614 重要特征数为：3215 重要特征数为：3016 重要特征数为：3717 重要特征数为：2118 重要特征数为：27 还是选择25个作为特征重要度筛选","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"hexo相关学习","slug":"hexo/hexo相关学习","date":"2020-06-10T06:45:26.000Z","updated":"2020-06-10T06:45:26.000Z","comments":true,"path":"2020/06/10/hexo/hexo相关学习/","link":"","permalink":"https://esyyes.github.io/2020/06/10/hexo/hexo%E7%9B%B8%E5%85%B3%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"hexo相关学习hexo -主题切换 https://github.com/ZEROKISEKI/hexo-theme-gal 看中了gal这个主题 下载放入themes文件夹下,更名为gai hexo s,查看效果","categories":[{"name":"hexo","slug":"hexo","permalink":"https://esyyes.github.io/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://esyyes.github.io/tags/hexo/"}]},{"title":"hexo-无法登陆github","slug":"hexo/hexo-无法登陆github","date":"2020-06-10T01:16:51.000Z","updated":"2020-06-10T01:16:51.000Z","comments":true,"path":"2020/06/10/hexo/hexo-无法登陆github/","link":"","permalink":"https://esyyes.github.io/2020/06/10/hexo/hexo-%E6%97%A0%E6%B3%95%E7%99%BB%E9%99%86github/","excerpt":"","text":"hexo-无法登陆githubTypora进入全屏模式按F11进入和退出 hexo无法上传博客github无法访问主要修改host文件，去访问IP 直接C盘输入 C:\\Windows\\System32\\drivers\\etc 找hosts文件 检测DNS所在地的IP http://tool.chinaz.com/dns?type=1&amp;host=github.com&amp;ip= 在hosts文件中输入ip响应的ip地址加github.com 192.30.253.112 github.com 13.229.188.59 github.com 140.82.114.4 github.com","categories":[{"name":"hexo","slug":"hexo","permalink":"https://esyyes.github.io/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://esyyes.github.io/tags/hexo/"}]},{"title":"数据预处理","slug":"sleep apnea and sleep stage/数据预处理","date":"2020-06-09T02:48:46.000Z","updated":"2020-06-09T02:48:46.000Z","comments":true,"path":"2020/06/09/sleep apnea and sleep stage/数据预处理/","link":"","permalink":"https://esyyes.github.io/2020/06/09/sleep%20apnea%20and%20sleep%20stage/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/","excerpt":"","text":"数据预处理对特征数据进行预处理，首先进行缺省值插补，然后再进行标准化 缺省值插补首先将inf数据转换为nan 12# 将inf数据转换为nandf = data.replace([np.inf, -np.inf], np.nan) pd直接将空格转换为nan所以只需要将nan转换为均值中值等就行 12# 查看每一列缺失值的数量num = df.isnull().sum() 采用均值插补 1234567for i in range(len(num)): if num[i] &gt; 0: # 就需要进行均值填充 values = df[df.keys()[i]].mean() df[df.keys()[i]].fillna(value=values, inplace=True) else: pass 123456789101112131415161718192021222324252627282930313233343536# 查看每一列数据量和数据类型# df.info()# def fillna(# self,# value=None,# method=None,# axis=None,# inplace=False,# limit=None,# downcast=None,# **kwargs# ):# return super().fillna(# value=value,# method=method,# axis=axis,# inplace=inplace,# limit=limit,# downcast=downcast,# **kwargs# )# https://blog.csdn.net/qq_43542339/article/details/105098235?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase# df['列名1'].fillna(value = 30，inplace=True)# # value = 30，用30填补空值# # value = df['列名1'].mean() 均值填充# # value = df['列名1'].median() 中位数填充# # value = df.Mer_min_distance.mode()[0] 众数填充# df['列名1'].fillna(method = 'pad',inplace=True)# method参数取值：&#123;‘pad’, ‘ffill’,‘backfill’, ‘bfill’, None&#125;，使用过程中因为对ipad很熟悉，故常常用 'pad’填充## ‘pad’ or ‘ffill’ : 用前一个非缺失值填充# ‘backfill’ or ‘bfill’：用后一个非缺失值填充# ‘None’ or default : 默认采用固定值填充 1234# 将缺省值值替换为nan# 转换和均值，需要一个数据来进行参考，没办法直接进行运行，所以还是采用fillna进行# imp = SimpleImputer(missing_values=np.nan, strategy='mean')# data = imp.fit(df) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117# -*- coding: utf-8 -*-# @Time : 2020/6/9# @Author : esy\"\"\"对inf,nan数据采用均值插补缺省值插补，然后再进行z-score\"\"\"import pandas as pdimport numpy as np# 缺失值插补# from sklearn.impute import SimpleImputerfrom sklearn import preprocessingimport warningswarnings.filterwarnings(\"ignore\")feature = pd.read_excel('F:/py/python-ECG信号处理/features_data' + '/slp' + '%s' % 1 + '.xlsx')data = pd.get_dummies(feature.iloc[0:len(feature), 1:])# 缺省值插补，采用均值插补\"\"\"1.数据中有inf数据，将其转换为nan,然后用均值插补2.将nan和遗失数据用均值插补# 缺失值插补，用这个库from sklearn.impute import SimpleImputerSimpleImputer(add_indicator=False, copy=True, fill_value=None, missing_values=nan, strategy='mean', verbose=0) missing_values=nan可以用自己想要的填充 strategy='mean' 缺省值插补填充的内容：mean median, most_frequent数据是连续型，用均值填充数据是分类型，用纵数填充利用ctrl+tab再点击函数查看函数\"\"\"\"\"\"预处理方法：https://blog.csdn.net/Bryan__/article/details/51228971https://blog.csdn.net/luanpeng825485697/article/details/79845629?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase\"\"\"# Series和DataFrame都会自动把None转换成NaN 然后 运算的时候会把NaN当成0,直接进行了填充，然后首先将inf转换为nan就行# 将inf数据转换为nandf = data.replace([np.inf, -np.inf], np.nan)# 其他意见自动填充为nan，空格缺省直接填充nan# 用fillna直接进行填充# data.fillna()# df['列名1'].fillna(value = 30，inplace=True)# df.fillna(value=, axis=1)# 查看每一列缺失值的数量num = df.isnull().sum()for i in range(len(num)): if num[i] &gt; 0: # 就需要进行均值填充 values = df[df.keys()[i]].mean() df[df.keys()[i]].fillna(value=values, inplace=True) else: pass# z-score标准化std = preprocessing.scale(df)print(f'均值为：&#123;std.mean()&#125;')print(f'标准差为：&#123;std.std()&#125;')print(f'列均值为：&#123;std.mean(axis=0)&#125;')print(f'列标准差为：&#123;std.std(axis=0)&#125;')# 查看每一列数据量和数据类型# df.info()# def fillna(# self,# value=None,# method=None,# axis=None,# inplace=False,# limit=None,# downcast=None,# **kwargs# ):# return super().fillna(# value=value,# method=method,# axis=axis,# inplace=inplace,# limit=limit,# downcast=downcast,# **kwargs# )# https://blog.csdn.net/qq_43542339/article/details/105098235?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase# df['列名1'].fillna(value = 30，inplace=True)# # value = 30，用30填补空值# # value = df['列名1'].mean() 均值填充# # value = df['列名1'].median() 中位数填充# # value = df.Mer_min_distance.mode()[0] 众数填充# df['列名1'].fillna(method = 'pad',inplace=True)# method参数取值：&#123;‘pad’, ‘ffill’,‘backfill’, ‘bfill’, None&#125;，使用过程中因为对ipad很熟悉，故常常用 'pad’填充## ‘pad’ or ‘ffill’ : 用前一个非缺失值填充# ‘backfill’ or ‘bfill’：用后一个非缺失值填充# ‘None’ or default : 默认采用固定值填充# 将缺省值值替换为nan# 转换和均值，需要一个数据来进行参考，没办法直接进行运行，所以还是采用fillna进行# imp = SimpleImputer(missing_values=np.nan, strategy='mean')# data = imp.fit(df)# # 正则化，标准化 标准化123456# z-score标准化std = preprocessing.scale(df)print(f'均值为：&#123;std.mean()&#125;')print(f'标准差为：&#123;std.std()&#125;')print(f'列均值为：&#123;std.mean(axis=0)&#125;')print(f'列标准差为：&#123;std.std(axis=0)&#125;') 函数形式版1234567891011121314151617181920# -*- coding: utf-8 -*-# @Time : 2020/6/9# @Author : esy\"\"\"均值插补缺省值z-score标准化\"\"\"import numpy as npfrom sklearn import preprocessingdef data_pre(data): df = data.replace([np.inf, -np.inf], np.nan) num = df.isnull().sum() [df[df.keys()[i]].fillna(value=df[df.keys()[i]].mean(), inplace=True) for i in range(len(num)) if num[i] &gt; 0] df_scale = preprocessing.scale(df) return df_scale","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"标签和特征长度处理","slug":"sleep apnea and sleep stage/标签和特征长度处理","date":"2020-06-08T11:16:50.000Z","updated":"2020-06-08T11:16:50.000Z","comments":true,"path":"2020/06/08/sleep apnea and sleep stage/标签和特征长度处理/","link":"","permalink":"https://esyyes.github.io/2020/06/08/sleep%20apnea%20and%20sleep%20stage/%E6%A0%87%E7%AD%BE%E5%92%8C%E7%89%B9%E5%BE%81%E9%95%BF%E5%BA%A6%E5%A4%84%E7%90%86/","excerpt":"","text":"标签和特征长度处理在进行机器学习之前需要查看标签和特征的长度，判断是否相等，数据比标签少30s 12345678910111213141516171819202122232425# -*- coding: utf-8 -*-# @Time : 2020/6/8# @Author : esy\"\"\"判断：读取注释和特征查看长度是否相等\"\"\"import pandas as pdimport warnings# 忽略警告warnings.filterwarnings(\"ignore\")for i in range(1, 19): feature = pd.read_excel('F:/py/python-ECG信号处理/features_data' + '/slp' + '%s' % i + '.xlsx') data = pd.get_dummies(feature.iloc[0:len(feature), 1:]) note = pd.read_excel('F:/py/python-ECG信号处理/note_data' + '/%s' % i + '.xlsx') tag = pd.get_dummies(note.iloc[0:len(note)-1, -1:]) if len(data) == len(tag): pass else: print(f'数据slp&#123;i&#125;不相等') print(f'特征长度&#123;len(data)&#125;, 标签长度‘&#123;len(tag)&#125;')else: print(f'检测完毕') 检测结果123456789数据slp5不相等 特征长度700 标签长度719数据slp7不相等 特征长度719 标签长度713数据slp8不相等 特征长度719 标签长度693数据slp10不相等 特征长度699 标签长度697数据slp14不相等 特征长度479 标签长度457数据slp15不相等 特征长度699 标签长度719数据slp16不相等 特征长度739 标签长度719数据slp17不相等 特征长度439 标签长度438检测完毕 数据处理slp5和slp15为slp03和slp60，只清除了AHI标签，没有清理睡眠标签 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# -*- coding: utf-8 -*-# @Time : 2020/6/8# @Author : esyimport wfdbimport pandas as pdimport warnings# 忽略警告warnings.filterwarnings(\"ignore\")# 读取st文件# test = input(\"请输入想读取的文件名： \")# test = 'slp03'test = 'slp60'annotation = wfdb.rdann('F:/slpdb_data/mitdata' + '/%s' % test, 'st')aux = annotation.aux_note# record = wfdb.rdrecord('F:/slpdb_data/mitdata' + '/%s' % test, sampfrom=1222500, sampto=1237500, channels=[3])# ecg_signal = record.p_signal# 查看低通气和osa阻塞性呼吸暂停的ecg信号取别# 对标签进行处理。分为2个类别,就是正常和低通气。把osa判定为低通气tag1 = []tag2 = []tag3 = []for i in range(len(aux)): if 538 &lt; i &lt; 549: pass else: if (aux[i][0] == '4') or (aux[i][0] == '3'): tag1.append(1) tag2.append(1) tag3.append(1) elif aux[i][0] == '2': tag1.append(2) tag2.append(2) tag3.append(1) elif aux[i][0] == '1': tag1.append(3) tag2.append(2) tag3.append(1) elif aux[i][0] == 'R': tag1.append(4) tag2.append(3) tag3.append(2) else: tag1.append(5) tag2.append(4) tag3.append(3)# 即aux[i][2]:为低通气这些的判定，如果没有则认定为正常，有就进行判定tag4 = []for i in range(len(aux)): # slp03 # if 174 &lt; i &lt; 194: if 538 &lt; i &lt; 549: # slp60 pass else: if len(aux[i]) == 1 or len(aux[i]) == 2: tag4.append(0) elif len(aux[i]) &gt;= 3: if (aux[i][2] == 'H') or (aux[i][2] == 'X') or (aux[i][2] == 'O') or (aux[i][2] == 'C'): tag4.append(1) else: tag4.append(0)label1 = pd.DataFrame(tag1, columns=['N321RW'])label2 = pd.DataFrame(tag2, columns=['DLRW'])label3 = pd.DataFrame(tag3, columns=['NRW'])label4 = pd.DataFrame(tag4, columns=['AHI'])label = pd.concat([label1, label2, label3, label4], axis=1)num = int(input(\"输入保存的文件名： \"))label.to_excel('%d' % num + \".xlsx\") 再次检测1234567数据slp7不相等 特征长度719 标签长度713数据slp8不相等 特征长度719 标签长度693数据slp10不相等 特征长度699 标签长度697数据slp14不相等 特征长度479 标签长度457数据slp16不相等 特征长度739 标签长度719数据slp17不相等 特征长度439 标签长度438检测完毕 数据查看slp7即为slp14 1234567891011121314151617import wfdbimport pandas as pdimport warnings# 忽略警告warnings.filterwarnings(\"ignore\")# 读取st文件# test = input(\"请输入想读取的文件名： \")test = 'slp14'annotation = wfdb.rdann('F:/slpdb_data/mitdata' + '/%s' % test, 'st')aux = annotation.aux_notesample_min = annotation.sample.min()sample_max = annotation.sample.max()print(f'起始位置为&#123;sample_min&#125;, 终止位置为&#123;sample_max&#125;')起始位置为45000, 终止位置为5392500 slp8:slp16 起始位置为195000, 终止位置为5392500 1for i in range(int(195000/record.fs/30), int(record.sig_len/record.fs/30 - 1)): slp10:slp37 数据slp10不相等 特征长度699 标签长度697 起始位置为15000, 终止位置为5242500 slp14:slp59 起始位置为165000, 终止位置为3592500 slp16:slp61 数据slp16不相等 特征长度739 标签长度719 起始位置为150000, 终止位置为5542500 slp17:slp66 数据slp17不相等 特征长度439 标签长度438 起始位置为1, 终止位置为3285000 数据检测完毕以后5分钟的数据片段还是要经过这个处理，标签缺失","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"HRV的30s特征提取","slug":"sleep apnea and sleep stage/HRV的30s特征提取","date":"2020-06-08T09:50:09.000Z","updated":"2020-06-08T09:50:09.000Z","comments":true,"path":"2020/06/08/sleep apnea and sleep stage/HRV的30s特征提取/","link":"","permalink":"https://esyyes.github.io/2020/06/08/sleep%20apnea%20and%20sleep%20stage/HRV%E7%9A%8430s%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/","excerpt":"","text":"HRV的30s特征提取 slp03和slp60数据中有一段数据遗失了ecg——r, slp03消除174-194之间的数据 slp60消除538 &lt; i &lt; 549之间的数据 标签这一部分全是w，可以删除 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677# -*- coding: utf-8 -*-# @Time : 2020/6/2# @Author : esy# slp60数据到时需要加0.7或者其他左右，没有经过预处理后，就不会出现复数，所以peaks中就不需要abs，加起也好import wfdbfrom wfdb import processing# import numpy as npimport pandas as pdimport warningsfrom peaks_time_features import *from time_domain import *from frequency_domain import *from HRV_interp1 import *from nonliner_domain import *from eliminate_outliers import *# 忽略警告warnings.filterwarnings(\"ignore\")test = input('请输入文件名：')# test = 'slp03'record = wfdb.rdrecord('F:/slpdb_data/mitdata' + '/%s' % test, channels=[0])annotation = wfdb.rdann('F:/slpdb_data/mitdata' + '/%s' % test, 'ecg')ecg_signal = record.p_signalecg_locs = annotation.sample.tolist()ecg_locs.pop(0)min_bpm = 40max_bpm = 200search_radius = int(record.fs * 60 / max_bpm)ecg_r_locs1 = processing.correct_peaks(ecg_signal[:, 0], peak_inds=ecg_locs, search_radius=search_radius, smooth_window_size=100)# ecg_r_locs异常点处理ecg_r_locs = eliminate(ecg_r_locs1)# ecg_r_peaks峰值点获取ecg_r_peaks = [ecg_signal[int(ecg_r_locs[i])][0] for i in range(len(ecg_r_locs))]all_RR_30s = []all_locs_30s = []all_peaks_30s = []for i in range(int(record.sig_len/record.fs/30 - 1)): RR_30s = [] locs_30s = [] peaks_30s = [] for j in range(len(ecg_r_locs)): if (30*record.fs*i) &lt;= ecg_r_locs[j] &lt;= (30*record.fs*(i+1)): locs_30s.append(ecg_r_locs[j]) RR_30s.append((ecg_r_locs[j+1] - ecg_r_locs[j]) * 4) peaks_30s.append(ecg_r_peaks[j]) else: pass RR_30s.pop() all_RR_30s.append(RR_30s) del locs_30s[0] all_locs_30s.append(locs_30s) all_peaks_30s.append(peaks_30s)# ECG_Rpeaks_features = [peaks_time_feature(all_peaks_30s[i]) for i in range(len(all_peaks_30s))]# HRVhrv_time = [time_features(all_RR_30s[i]) for i in range(len(all_RR_30s))]hrv_freq = [getfreq(resample(hrv_interp1(all_locs_30s[i], all_RR_30s[i], 1), 250, 4)) for i in range(len(all_RR_30s))]hrv_nonl = [non_linear(np.array(all_RR_30s[i])) for i in range(len(all_RR_30s))]features = [peaks_features[i] + hrv_time[i] + hrv_freq[i] + hrv_nonl[i] for i in range(len(all_RR_30s))]# 保存为excelfeature = pd.DataFrame(features, columns=['p_max', 'p_min', 'p_mean', 'p_median', 'p_SDNN', 'p_var', 'p_Peaks', 'p_RMSSD', 'p_kurt', 'p_skew', 'p_wave_factor', 'p_peak_factor', 'p_Impulse_factor', 'p_Margin_factor', 'p_RMS', 'R_mean', 'R_SDNN', 'R_SDSD', 'NN50', 'pNN50', 'NN20', 'pNN20', 'R_RMSSD', 'R_median', 'R_NUM', 'R_CVSD', 'R_CV', 'HR_mean', 'HR_max', 'HR_min', 'HR_std', 'LF', 'HF', 'LF_HF', 'LFnu', 'HFnu', 'total', ' VLF', 'sd1', 'sd2', 'sd2/sd1', 'csi10', 'cvi', 'Modified_CSI10', 'apen', 'spen', 'lle', 'sampen'])num = int(input('请输入特征的名字:'))feature.to_excel('slp' + '%d' % num + \".xlsx\") 123456789101112131415161718192021all_peaks_30s = []for i in range(int(record.sig_len/record.fs/30 - 1)): if 538 &lt; i &lt; 549:slp60 174-194 slp03 pass else: RR_30s = [] locs_30s = [] peaks_30s = [] for j in range(len(ecg_r_locs)): if (30*record.fs*i) &lt;= ecg_r_locs[j] &lt;= (30*record.fs*(i+1)): locs_30s.append(ecg_r_locs[j]) RR_30s.append((ecg_r_locs[j+1] - ecg_r_locs[j]) * 4) peaks_30s.append(ecg_r_peaks[j]) else: pass RR_30s.pop() all_RR_30s.append(RR_30s) del locs_30s[0] all_locs_30s.append(locs_30s) all_peaks_30s.append(peaks_30s) 消除异常点123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127# -*- coding: utf-8 -*-# @Time : 2020/6/8# @Author : esyimport numpy as np# RR间期获取def RR_rr(locs1): return [locs1[i+1]-locs1[i] for i in range(len(locs1) - 1)]# 得到19个RR间期的均值def MRR(x): return [np.mean(x[i:i+19]) for i in range(len(x) - 19)]# 消除过检def Eliminate_check(locs1): RR_lou = [] num = 0 RR_locs_lou = [] RR = RR_rr(locs1) mRR = MRR(RR) for i in range(len(RR)): if i &lt; 10: if RR[i] &lt; (0.55 * mRR[0]): RR2 = RR[i] + RR[i-1] num += 1 RR_lou.pop(i - num) locs2 = locs1[i + 1] RR_locs_lou.pop(i - num) else: RR2 = RR[i] locs2 = locs1[i + 1] elif i &gt; (len(RR) - 10): if RR[i] &lt; (0.55 * mRR[len(mRR) - 1]): RR2 = RR[i] + RR[i - 1] num = num + 1 locs2 = locs1[i + 1] RR_lou.pop(i - num) RR_locs_lou.pop(i - num) else: RR2 = RR[i] locs2 = locs1[i + 1] else: if RR[i] &lt; (0.55 * mRR[i - 10]): RR2 = RR[i] + RR[i - 1] num = num + 1 RR_lou.pop(i - num) locs2 = locs1[i + 1] RR_locs_lou.pop(i - num) else: RR2 = RR[i] locs2 = locs1[i + 1] RR_lou.append(RR2) RR_locs_lou.append(locs2) RR_locs_lou.insert(0, locs1[0]) return RR_locs_lou# 消除漏检def Eliminate_LOW(locs): locs1 = Eliminate_check(locs) RR = RR_rr(locs1) mRR = MRR(RR) i = 0 k = 0 RR_guo = [] RR_locs_guo = [] while i &lt; len(RR): if i &lt; 10: if RR[i] &gt; (1.55 * mRR[0]): m = int(round(RR[i] / mRR[0])) RR3 = RR[i] / m RR_guo[(i + k):(i + k)] = (m - 1) * [RR3] cs = [] for j in range(m - 1): cs1 = locs1[i] + (j + 1) * RR3 cs.append(cs1) RR_locs_guo.extend(cs) locs2 = locs1[i + 1] k = k + m else: RR3 = RR[i] locs2 = locs1[i + 1] elif i &gt; (len(RR) - 10): if RR[i] &gt; (1.55 * mRR[len(mRR) - 1]): m = int(round(RR[i] / mRR[len(mRR) - 1])) RR3 = RR[i] / m RR_guo[(i + k):(i + k)] = (m - 1) * [RR3] cs = [] for j in range(m - 1): cs1 = locs1[i] + (j + 1) * RR3 cs.append(cs1) RR_locs_guo.extend(cs) locs2 = locs1[i + 1] k = k + m else: RR3 = RR[i] locs2 = locs1[i + 1] else: if RR[i] &gt; (1.55 * mRR[i - 10]): m = int(round(RR[i] / mRR[i])) RR3 = RR[i] / m RR_guo[(i + k):(i + k)] = (m - 1) * [RR3] cs = [] for j in range(m - 1): cs1 = locs1[i] + (j + 1) * RR3 cs.append(cs1) RR_locs_guo.extend(cs) locs2 = locs1[i + 1] k = k + m else: RR3 = RR[i] locs2 = locs1[i + 1] i += 1 RR_locs_guo.append(locs2) RR_guo.append(RR3) RR_locs_guo.insert(0, locs1[0]) return RR_locs_guodef eliminate(locs1): c = Eliminate_LOW(Eliminate_check(locs1)) return c peaks的时域特征12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182# -*- coding: utf-8 -*-# @Time : 2020/6/3# @Author : esy# R峰值的时域特征分析import mathimport numpy as npfrom scipy import stats# 裕度因子def margin_factor(x): sum = 0 for i in range(len(x) - 1): sum += math.sqrt(x[i]) mean = np.mean(sum) return mean**2# 差值均方根def get_RMSSD(x): sum = 0 for i in range(len(x) - 1): sum += (x[i+1] - x[i])**2 return math.sqrt(sum/(len(x) - 1))# 均方根def get_rms(x): sum = 0 for i in range(len(x) - 1): sum += (x[i])**2 return math.sqrt(sum / (len(x)-1))def peaks_time_feature(f): x = abs(np.array(f)) # 最大值 p_max = x.max() # 最小值 p_min = x.min() # 均值： p_mean = x.mean() # 中位数 p_median = np.median(x) # 标准差 SDNN = x.std() # 方差 p_var = x.var() # 峰峰值 p_peaks = p_max - p_min # 差值均方根 RMSSD = get_RMSSD(x) # 峭度/峰度 p_kurt = stats.kurtosis(x) # 偏度 p_skew = stats.skew(x) # 波形因子 p_wave_factor = RMSSD / p_mean # 峰值因子 p_peak_factor = p_peaks / RMSSD # 脉冲因子 p_impulse_factor = p_peaks / p_mean # 裕度因子 p_margin_factor = p_peaks / margin_factor(x) # 均方根 p_RMS = get_rms(x) list_time_features = [p_max, p_min, p_mean, p_median, SDNN, p_var, p_peaks, RMSSD, p_kurt, p_skew, p_wave_factor, p_peak_factor, p_impulse_factor, p_margin_factor, p_RMS] return list_time_features HRV的时域特征123456789101112131415161718192021222324252627# -*- coding: utf-8 -*-# @Time : 2020/6/8# @Author : esyfrom hrvanalysis import get_time_domain_featuresdef time_features(x): A = get_time_domain_features(x) RR_mean = A['mean_nni'] SDNN = A['sdnn'] SDSD = A['sdsd'] NN50 = A['nni_50'] PNN50 = A['pnni_50'] NN20 = A['nni_20'] PNN20 = A['pnni_20'] RMSSD = A['rmssd'] RR_median = A['median_nni'] NUM = A['range_nni'] CVSD = A['cvsd'] RR_CV = A['cvnni'] HR_mean = A['mean_hr'] HR_max = A['max_hr'] HR_min = A['min_hr'] HR_std = A['std_hr'] ALL = [RR_mean, SDNN, SDSD, NN50, PNN50, NN20, PNN20, RMSSD, RR_median, NUM, CVSD, RR_CV, HR_mean, HR_max, HR_min, HR_std] return ALL 插值并重采样123456789101112131415161718192021222324252627282930313233# -*- coding: utf-8 -*-# @Time : 2020/6/8# @Author : esyimport numpy as npimport scipy.interpolate as spi# 插值def hrv_interp1(x, y, s): x_new = np.linspace(x[0], x[len(x) - 1], 7500 * s) # 新的插值区间及其点的个数 ipo3 = spi.splrep(x, y, k=3) # 样本点导入，生成参数 hrv_interpolation = spi.splev(x_new, ipo3) # 根据观测点和样条参数，生成插值 return hrv_interpolation# 重采样def resample(input_signal, src_fs, tar_fs): \"\"\" :param input_signal:输入信号 :param src_fs:输入信号采样率 :param tar_fs:输出信号采样率 :return:输出信号 \"\"\" dtype = input_signal.dtype audio_len = len(input_signal) audio_time_max = 1.0 * audio_len / src_fs src_time = 1.0 * np.linspace(0, audio_len, audio_len) / src_fs tar_time = 1.0 * np.linspace(0, np.int(audio_time_max*tar_fs), np.int(audio_time_max*tar_fs)) / tar_fs output_signal = np.interp(tar_time, src_time, input_signal).astype(dtype) return output_signal HRV的频域特征12345678910111213141516# -*- coding: utf-8 -*-# @Time : 2020/6/8# @Author : esyfrom hrvanalysis import get_frequency_domain_featuresdef getfreq(x): all = get_frequency_domain_features(x) LF = all['lf'] HF = all['hf'] LF_HF = all['lf_hf_ratio'] LFnu = all['lfnu'] HFnu = all['hfnu'] total = all['total_power'] VLF = all['vlf'] freqs = [LF, HF, LF_HF, LFnu, HFnu, total, VLF] return freqs HRV的非线性特征1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# -*- coding: utf-8 -*-# @Time : 2020/6/8# @Author : esyfrom hrvanalysis import *from non_features import *def SD1(x): sd = [x[i+1] - x[i] for i in range(len(x)-1)] return np.std(sd) / np.sqrt(2)def SD2(x): sd = [x[i+1] + x[i] for i in range(len(x)-1)] return np.std(sd) / np.sqrt(2)def non_linear5(x): RR_sd1 = SD1(x) RR_sd2 = SD2(x) RR_csi10 = csi(x, 10) RR_csi30 = csi(x, 30) RR_csi50 = csi(x, 50) RR_csi100 = csi(x, 100) RR_cvi = get_csi_cvi_features(x)['cvi'] Modified_CSI10 = Modified_csi(x, 10) Modified_CSI30 = Modified_csi(x, 30) Modified_CSI50 = Modified_csi(x, 50) Modified_CSI100 = Modified_csi(x, 100) RR_apen = apen(x, m=2, r=0.6) RR_spen = spen(x) A = get_sampen(x) RR_sampen = A['sampen'] RR_lle = lle(x) ALL_5 = [RR_sd1, RR_sd2, RR_sd2/RR_sd1, RR_csi10, RR_csi30, RR_csi50, RR_csi100, RR_cvi, Modified_CSI10, Modified_CSI30, Modified_CSI50, Modified_CSI100, RR_apen, RR_spen, RR_sampen, RR_lle] return ALL_5def non_linear(x): RR_sd1 = SD1(x) RR_sd2 = SD2(x) RR_csi10 = csi(x, 10) RR_cvi = get_csi_cvi_features(x)['cvi'] Modified_CSI10 = Modified_csi(x, 10) RR_apen = apen(x, m=2, r=0.6) RR_spen = spen(x) RR_lle = lle(x) RR_sampen = get_sampen(x)['sampen'] ALL_30 = [RR_sd1, RR_sd2, RR_sd2/RR_sd1, RR_csi10, RR_cvi, Modified_CSI10, RR_apen, RR_spen, RR_lle, RR_sampen] return ALL_30 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239# -*- coding: utf-8 -*-# @Time : 2020/6/8# @Author : esy\"\"\"Provides the non-linear functions for processing ECGs. Signals should be inputas an np.array of R-R intervals. Arrays can be multi-dimensional as long asaxis 1 moves through time (i.e. inputs should have shapes (n,) or (m, n)).Includes function: csi (cardiac sympathatic index) apen (approximate entropy),spen (spectral entropy), lle (largest Lypunov exponent).\"\"\"import numpy as npfrom scipy.fftpack import fft, ifftdef csi(intervals, num_points): \"\"\" From Geometry of the Poincare plot of RR intervals and its asymmetry in healthy adults, J. Piskorski and P. Guzik; and A new method of assessing cardiac autonomic function and its comparison with spectral analysis and coefficient of variation of R--R interval, Motomi Toichi, Takeshi Sugiura Toshiya Murai, and Akira Sengoku. Cardiac Sympathetic Index (CSI). The poincare plot is method for visualizing chaotic signals by plotting the peaks of a signal against the same peaks delayed by one, for use with heart rate the peaks used are the R-R intervals. This produces a ellipse aligned along the line x=y with major and minor axes 4*SD2 and 4*SD1 respectively. The minor axis represents variation between consecutive beats while the major axis represents total beat difference. The CSI is given by SD2/SD1. Large CSI values indicate relatively large inter-beat variation. Parameters: num_points (positive integer): The number of datapoints used to calculate the CSI. Used as a window so the output will be of length len(intervals) - num_points + 1. \"\"\" sd1, sd2 = _sd(intervals, num_points) sd2[sd1 == 0] = 1 sd1[sd1 == 0] = 1 CSI = (sd2 / sd1).T# 心交感指数CSI# 庞加莱曲线图是一种将混沌信号可视化的方法，方法是将信号的峰值与延迟1的相同峰值相对照，用于心率。使用的峰值是R-R间隔。这会产生一个沿线x=y对齐的椭圆，长轴和短轴分别为4*sd2和4*sd1。短轴表示连续拍子之间的变化，而长轴表示总拍子差# 找出最大的庞加莱曲线图 return CSI.mean()def Modified_csi(intervals, num_points): sd1, sd2 = _sd(intervals, num_points) sd2[sd1 == 0] = 1 sd1[sd1 == 0] = 1 Modified_CSI = ((sd2 ** 2) / sd1).T return Modified_CSI.mean()def _sd(intervals, num_points): axis = _function_dimension(intervals) signal_length = intervals.shape[axis] n = signal_length - num_points + 1 indices = np.sum(np.mgrid[0:n, 0:num_points], axis=0) if axis == 0: windowed_intervals = intervals[indices] else: windowed_intervals = intervals.swapaxes(0, axis)[indices] x = windowed_intervals[:-1] y = windowed_intervals[1:] def _means(x, y): mean_x = x.mean(axis=1) mean_y = y.mean(axis=1) return(mean_x, mean_y) def _transpose(vals): if axis == 0: return vals.T else: return vals.swapaxes(0, axis) mean_x, mean_y = _means(x, y) def _sd1(): mean = _transpose(np.array([mean_y - mean_x])) sd1 = np.std((x - y) + mean, axis=1) / (2.0 ** 0.5) return sd1 def _sd2(): mean = _transpose(np.array([mean_x + mean_y])) sd2 = np.std((x + y) - mean, axis=1) / (2.0 ** 0.5) return sd2 return(_sd1(), _sd2())def apen(intervals, m=2, r=0.6): \"\"\" Approximate Entropy (ApEn) as described in \"Physiological time-series analysis what does regularity quantify?\" by Steven M. Pingus And Ary L. Goldberger. Vector x_i contains the ith heart rate to the (i + m - 1)th heart rate. The distance between two vectors, x_i and x_j, is greater than r if abs(x_i[k] - x_j[k]) &gt; r for any k = 0 ... (m - 1). A pair of vectors (or groups), x_i and x_j, are said to be close if the distance between them is less than r. C_i is the number of close groups of length m + 1 divided by the number of close groups of length m. Based on the definition of distance if the ith and jth group are close when using length m + 1 then they must also be close when using a length of only m. Therefore C is the probability heart rate i + m is close to heart rate j + m given all m heart rates in groups i and j are also close. ApEn = phi^(m+1)(r) - phi^m(r) where phi^m(r) is the average of natural log C_i, for all i groups, calculated using a group size of m. Parameters: m (positive int): group lengths. r (float): max distance between close groups. \"\"\" heart_rates = 1 / intervals.astype(np.float32) num_close_groups_m = _find_num_close_groups(heart_rates, m, r) num_close_groups_m_plus_1 = _find_num_close_groups(heart_rates, m+1, r) num_close_groups_m_plus_2 = _find_num_close_groups(heart_rates, m+2, r) C_m = num_close_groups_m_plus_1 / num_close_groups_m[:-1] C_m_plus_1 = num_close_groups_m_plus_2 / num_close_groups_m_plus_1[:-1] phi = lambda C: np.nanmean(np.log(C), axis=0) return phi(C_m_plus_1) - phi(C_m)def _find_num_close_groups(heart_rates, m, r): dim = _function_dimension(heart_rates) err_msg = 'Group lengths must be smaller than the signal length' assert m &lt; heart_rates.shape[dim], err_msg if dim == 0: dist_mat = _one_dim_distance_matrix(heart_rates) else: dist_mat = _multi_dim_distance_matrix(heart_rates) far_vals = np.logical_or(np.greater(dist_mat, r), np.less(dist_mat, -r)) return _sum_num_close_groups(far_vals, m).astype(np.float32)def _function_dimension(x): if len(x.shape) &gt; 1: return 1 return 0def _one_dim_distance_matrix(vals): repeats = np.tile(vals, (vals.shape[0], 1)) return repeats - repeats.Tdef _multi_dim_distance_matrix(vals): vals = _rotate_and_repeat(vals) return vals - np.swapaxes(vals, 0, 1)def _rotate_and_repeat(vals): vals = np.swapaxes(np.array([vals]), 1, 2) size = vals.shape new_size = (size[1],) + size[1:] return np.broadcast_to(vals, new_size)def _sum_num_close_groups(group_dist_mat, m): return np.sum(_is_group_close(group_dist_mat, m), axis=0)def _is_group_close(far_vals, m): close_groups = 0 for str_idx in range(m): end_idx = m - str_idx close_groups += far_vals[str_idx:-end_idx, str_idx:-end_idx] return close_groups == 0def spen(intervals): \"\"\" Spectral Entropy (SpEn) is a measure of entropy based on the probability mass distribution of the discreate Fourier transformation. If a few frequencies dominate a signal the signal is predictable and thus has a low entropy. SpEn uses log based 2 and can therefore be interpreted as the min number of bits needed to encode the signals power spectrum. Because of this length of the signal can affect the outcome. \"\"\" axis = _function_dimension(intervals) spectrum = np.abs(fft(intervals)) ** 2 probs = spectrum / np.array([spectrum.sum(axis=axis)]).T return - np.sum(probs * np.log2(probs), axis=axis)def lle(intervals): \"\"\" Largest Lypunov exponent (LLE) is a measure chaos within a signal. If the LLE of a signal is positive the signal is determined to be chaotic. The Lypunov exponent of each dimension represents how quickly two initially close points move apart from one another. This method of calculating the LLE is based on M. Rosenstein, J. Collins, and C. De Luca's method from \"A practical method for calculating largest Lypunov exponents from small data sets\". \"\"\" dim = _function_dimension(intervals) j = _calc_j_from_autocorr(intervals, dim) return jdef _calc_j_from_autocorr(intervals, axis): Intervals = fft(intervals, axis=axis) Corr = np.abs(Intervals ** 2) corr = ifft(Corr, axis=axis).real if axis is 0: corr = corr[:int(len(corr) / 2)] / corr[0] else: corr = corr[:, :corr.shape[1] / 2] / np.array([corr[:, 0]]).T diminish_factor = 1 - 1/np.exp(1) lag_vals = np.abs(corr - diminish_factor) min_val = np.argmin(lag_vals, axis=axis) return min_val","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"ECG_RR间期预处理","slug":"sleep apnea and sleep stage/ECG-RR间期预处理","date":"2020-06-08T09:46:48.000Z","updated":"2020-06-08T09:46:48.000Z","comments":true,"path":"2020/06/08/sleep apnea and sleep stage/ECG-RR间期预处理/","link":"","permalink":"https://esyyes.github.io/2020/06/08/sleep%20apnea%20and%20sleep%20stage/ECG-RR%E9%97%B4%E6%9C%9F%E9%A2%84%E5%A4%84%E7%90%86/","excerpt":"","text":"ECG_RR间期预处理还是要用矫正后的R进行读取，所以第一个点进行查看用矫正后的R间期序列，第一个点，就直接按照标注结果进行标注，直接不要第一个点，数据点很多，而且分析的时候，第一个30s并没有进行分析 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# -*- coding: utf-8 -*-# @Time : 2020/6/2# @Author : esy\"\"\"还是要用矫正后的R进行读取，所以第一个点进行查看用矫正后的R间期序列，第一个点，就直接按照标注结果进行标注，直接不要第一个点，数据点很多，而且分析的时候，第一个30s并没有进行分析\"\"\"import wfdbfrom wfdb import processingimport warnings# 忽略警告warnings.filterwarnings(\"ignore\")test = 'slp01b'record = wfdb.rdrecord('F:/slpdb_data/mitdata' + '/%s' % test, channels=[0])# 读取心电数据库的R峰值点annotation = wfdb.rdann('F:/slpdb_data/mitdata' + '/%s' % test, 'ecg')ecg_signal = record.p_signalecg_locs = annotation.sample.tolist()ecg_locs.pop(0)# Correct the peaks shifting them to local maximamin_bpm = 40max_bpm = 200# Use the maximum possible bpm as the search radius,进行平滑校准到峰值点位置search_radius = int(record.fs * 60 / max_bpm)# 进行矫正后的峰值点信号坐标，用这个来进行后续的分析，虽然RR间期没什么影响，但是峰值点的值有很大的影响ecg_r_locs = processing.correct_peaks(ecg_signal[:, 0], peak_inds=ecg_locs, search_radius=search_radius, smooth_window_size=100)# 峰值信号ecg_r_peaks = ecg_signal[ecg_r_locs].tolist()# 异常点处理，感觉可以不写，毕竟写了会出现R峰值无法对应的现象，会报错，到时可以写这个步骤，但是，没必要在程序中书写# 30s切片# for i in range(record.sig_len/record.fs/30 - 1):RR_30s = []locs_30s = []for i in range(30*record.fs): if ecg_r_locs[i] &lt;= 30*record.fs: locs_30s.append(ecg_r_locs[i]) RR_30s.append(ecg_r_locs[i+1] - ecg_r_locs[i]) else: pass# 删除RR间期的最后一个，i+1数据超出了范围RR_30s.pop()# 删除locs对应的第一个坐标，因为是用后面的R峰值点的坐标去对应RR波形del locs_30s[0] 将30s的数据进行循环切片，然后进行输出为list30s的和5min的进行单独的分析，然后进行时频域和非线性的分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# -*- coding: utf-8 -*-# @Time : 2020/6/2# @Author : esy# 将30s的数据进行循环切片，然后进行输出为list# 30s的和5min的进行单独的分析，然后进行时频域和非线性的分析import wfdbfrom wfdb import processing# import numpy as npimport warnings# 忽略警告warnings.filterwarnings(\"ignore\")test = 'slp01a'record = wfdb.rdrecord('F:/slpdb_data/mitdata' + '/%s' % test, channels=[0])annotation = wfdb.rdann('F:/slpdb_data/mitdata' + '/%s' % test, 'ecg')ecg_signal = record.p_signalecg_locs = annotation.sample.tolist()ecg_locs.pop(0)min_bpm = 40max_bpm = 200search_radius = int(record.fs * 60 / max_bpm)ecg_r_locs = processing.correct_peaks(ecg_signal[:, 0], peak_inds=ecg_locs, search_radius=search_radius, smooth_window_size=100)# 峰值信号ecg_r_peaks = ecg_signal[ecg_r_locs].tolist()all_RR_30s = []all_locs_30s = []all_peaks_30s = []for i in range(int(record.sig_len/record.fs/30 - 1)): RR_30s = [] locs_30s = [] peaks_30s = [] for j in range(len(ecg_r_locs)): if (30*record.fs*i) &lt;= ecg_r_locs[j] &lt;= (30*record.fs*(i+1)): locs_30s.append(ecg_r_locs[j]) RR_30s.append((ecg_r_locs[j+1] - ecg_r_locs[j]) * 4) peaks_30s.append(ecg_r_peaks[j][0]) else: pass RR_30s.pop() all_RR_30s.append(RR_30s) all_locs_30s.append(locs_30s) all_peaks_30s.append(peaks_30s)","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"ECG信号读取","slug":"sleep apnea and sleep stage/ECG信号读取","date":"2020-06-08T09:42:03.000Z","updated":"2020-06-08T09:42:03.000Z","comments":true,"path":"2020/06/08/sleep apnea and sleep stage/ECG信号读取/","link":"","permalink":"https://esyyes.github.io/2020/06/08/sleep%20apnea%20and%20sleep%20stage/ECG%E4%BF%A1%E5%8F%B7%E8%AF%BB%E5%8F%96/","excerpt":"","text":"ECG信号读取读取RR和st中的注释程序 1234567891011121314151617181920212223242526# -*- coding: utf-8 -*-# @Time : 2020/5/29# @Author : esy# 利用wfdb读取ECG数据import wfdb as wfdb# 读取slp01a的数据，sampfrom：起始位置，sampto：结束位置，即可写做# record = wfdb.rdrecord('F:/slpdb_data/mitdata/slp02a', sampfrom=0, sampto=1500, channels=[0])# 相当于已经把这个写成了一个类别，然后进行读取时，读取相关的属性就可以了。面向对象类别record.p_signal即为相关信号# 读取注释文件annotation = wfdb.rdann('F:/slpdb_data/mitdata/slp14', 'st')aux = annotation.aux_note# 直接读取注释的信息，然后进行判断即可，所以就可以不需要txt。直接用[][0]来进行判断睡眠分期# 用【】【2】来判定是否是呼吸暂停# aux[16][0]# Out[13]: '1'# aux[67][0]# Out[14]: 'M'# aux[63][3]# Out[15]: 'A'# aux[63][2]# Out[16]: 'H'# aux[55][2] 标签处理12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667# -*- coding: utf-8 -*-# @Time : 2020/5/31# @Author : esyimport wfdbimport pandas as pdimport warnings# 忽略警告warnings.filterwarnings(\"ignore\")# 读取st文件test = input(\"请输入想读取的文件名： \")# test = 'slp14'annotation = wfdb.rdann('F:/slpdb_data/mitdata' + '/%s' % test, 'st')aux = annotation.aux_note# record = wfdb.rdrecord('F:/slpdb_data/mitdata' + '/%s' % test, sampfrom=1222500, sampto=1237500, channels=[3])# ecg_signal = record.p_signal# 查看低通气和osa阻塞性呼吸暂停的ecg信号取别# 对标签进行处理。分为2个类别,就是正常和低通气。把osa判定为低通气tag1 = []tag2 = []tag3 = []for i in range(len(aux)): if (aux[i][0] == '4') or (aux[i][0] == '3'): tag1.append(1) tag2.append(1) tag3.append(1) elif aux[i][0] == '2': tag1.append(2) tag2.append(2) tag3.append(1) elif aux[i][0] == '1': tag1.append(3) tag2.append(2) tag3.append(1) elif aux[i][0] == 'R': tag1.append(4) tag2.append(3) tag3.append(2) else: tag1.append(5) tag2.append(4) tag3.append(3)# 即aux[i][2]:为低通气这些的判定，如果没有则认定为正常，有就进行判定tag4 = []for i in range(len(aux)): if len(aux[i]) == 1 or len(aux[i]) == 2: tag4.append(0) elif len(aux[i]) &gt;= 3: if (aux[i][2] == 'H') or (aux[i][2] == 'X') or (aux[i][2] == 'O') or (aux[i][2] == 'C'): tag4.append(1) else: tag4.append(0)label1 = pd.DataFrame(tag1, columns=['N321RW'])label2 = pd.DataFrame(tag2, columns=['DLRW'])label4 = pd.DataFrame(tag4, columns=['AHI'])label3 = pd.DataFrame(tag3, columns=['NRW'])label = pd.concat([label1, label2, label3, label4], axis=1)num = int(input(\"输入保存的文件名： \"))label.to_excel('%d' % num + \".xlsx\") 12345678910111213141516# 即aux[i][2]:为低通气这些的判定，如果没有则认定为正常，有就进行判定tag4 = []for i in range(len(aux)):# slp30和60有数据缺失 # if 174 &lt; i &lt; 194: # slp03 if 538 &lt; i &lt; 549: # slp60 pass else: if len(aux[i]) == 1 or len(aux[i]) == 2: tag4.append(0) elif len(aux[i]) &gt;= 3: if (aux[i][2] == 'H') or (aux[i][2] == 'X') or (aux[i][2] == 'O') or (aux[i][2] == 'C'): tag4.append(1) else: tag4.append(0)","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"sleep apnea","slug":"sleep apnea and sleep stage/sleep-apnea","date":"2020-05-31T07:43:01.000Z","updated":"2020-05-31T07:43:01.000Z","comments":true,"path":"2020/05/31/sleep apnea and sleep stage/sleep-apnea/","link":"","permalink":"https://esyyes.github.io/2020/05/31/sleep%20apnea%20and%20sleep%20stage/sleep-apnea/","excerpt":"","text":"sleep apnea诊断OSAS时,对有鼻炎、打鼾、张口呼吸、睡时慢性咳嗽、睡眠不安等高危症状的儿童,应给予高度重视。根据北京儿童医院睡眠中心推荐的儿童OSAS诊断标准,呼吸暂停为呼吸停止≥5秒或2个呼吸周期、暂停指数AI≥1次/小时;低通气指口鼻气流振幅较基线(气流停止或下降之前至少2分钟或3个呼吸周期的平均呼吸幅度)下降50%或持续2个呼吸周期以上,伴血氧饱和度降低3%以上或觉醒;呼吸暂停低通气指数AHI≥5次/小时可诊断为儿童OSAS,该指数510为轻度,1020为中度,20以上为重度。通过病史、临床表现、放射学检查以及多导睡眠检测等方法,诊断OSAS并不困难,但要注意与原发性鼾症鉴别诊断,后者无频繁觉醒,也无明确梗阻性睡眠呼吸暂停或气体交换异常。 成年人的睡眠呼吸暂停判定： AHI(次数、小时) 轻度：AHI 5-14 中度： 15-29 重度： ≥30 直接根据AHI的平均值进行判定，只考虑AHI,OS这些全部判定为AHI。即可，直接先用这个特征进行提取，然后再考虑其他心电关于呼吸暂停的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667# -*- coding: utf-8 -*-# @Time : 2020/5/31# @Author : esyimport wfdbimport pandas as pdimport warnings# 忽略警告warnings.filterwarnings(\"ignore\")# 读取st文件test = input(\"请输入想读取的文件名： \")num = int(input(\"输入保存的文件名： \"))# test = 'slp14'annotation = wfdb.rdann('F:/slpdb_data/mitdata' + '/%s' % test, 'st')aux = annotation.aux_note# record = wfdb.rdrecord('F:/slpdb_data/mitdata' + '/%s' % test, sampfrom=1222500, sampto=1237500, channels=[3])# ecg_signal = record.p_signal# 查看低通气和osa阻塞性呼吸暂停的ecg信号取别# 对标签进行处理。分为2个类别,就是正常和低通气。把osa判定为低通气tag1 = []tag2 = []tag3 = []for i in range(len(aux)): if (aux[i][0] == '4') or (aux[i][0] == '3'): tag1.append(1) tag2.append(1) tag3.append(1) elif aux[i][0] == '2': tag1.append(2) tag2.append(2) tag3.append(1) elif aux[i][0] == '1': tag1.append(3) tag2.append(2) tag3.append(1) elif aux[i][0] == 'R': tag1.append(4) tag2.append(3) tag3.append(2) else: tag1.append(5) tag2.append(4) tag3.append(3)# 即aux[i][2]:为低通气这些的判定，如果没有则认定为正常，有就进行判定tag4 = []for i in range(len(aux)): if len(aux[i]) == 1 or len(aux[i]) == 2: tag4.append(0) elif len(aux[i]) &gt;= 3: if (aux[i][2] == 'H') or (aux[i][2] == 'X') or (aux[i][2] == 'O') or (aux[i][2] == 'C'): tag4.append(1) else: tag4.append(0)label1 = pd.DataFrame(tag1, columns=['N321RW'])label2 = pd.DataFrame(tag2, columns=['DLRW'])label3 = pd.DataFrame(tag3, columns=['NRW'])label4 = pd.DataFrame(tag4, columns=['AHI'])label = pd.concat([label1, label2, label3, label4], axis=1)label.to_excel('%d' % num + \".xlsx\") 首先对标签进行处理，睡眠分为3大主题。低通气和正常分为一类。 slp03和slp60丢失了一段数据 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273# -*- coding: utf-8 -*-# @Time : 2020/6/8# @Author : esyimport wfdbimport pandas as pdimport warnings# 忽略警告warnings.filterwarnings(\"ignore\")# 读取st文件# test = input(\"请输入想读取的文件名： \")test = 'slp03'# test = 'slp60'annotation = wfdb.rdann('F:/slpdb_data/mitdata' + '/%s' % test, 'st')aux = annotation.aux_note# record = wfdb.rdrecord('F:/slpdb_data/mitdata' + '/%s' % test, sampfrom=1222500, sampto=1237500, channels=[3])# ecg_signal = record.p_signal# 查看低通气和osa阻塞性呼吸暂停的ecg信号取别# 对标签进行处理。分为2个类别,就是正常和低通气。把osa判定为低通气tag1 = []tag2 = []tag3 = []for i in range(len(aux)): if (aux[i][0] == '4') or (aux[i][0] == '3'): tag1.append(1) tag2.append(1) tag3.append(1) elif aux[i][0] == '2': tag1.append(2) tag2.append(2) tag3.append(1) elif aux[i][0] == '1': tag1.append(3) tag2.append(2) tag3.append(1) elif aux[i][0] == 'R': tag1.append(4) tag2.append(3) tag3.append(2) else: tag1.append(5) tag2.append(4) tag3.append(3)# 即aux[i][2]:为低通气这些的判定，如果没有则认定为正常，有就进行判定tag4 = []for i in range(len(aux)): # if 174 &lt; i &lt; 194: # slp03 if 538 &lt; i &lt; 549: # slp60 pass else: if len(aux[i]) == 1 or len(aux[i]) == 2: tag4.append(0) elif len(aux[i]) &gt;= 3: if (aux[i][2] == 'H') or (aux[i][2] == 'X') or (aux[i][2] == 'O') or (aux[i][2] == 'C'): tag4.append(1) else: tag4.append(0)label1 = pd.DataFrame(tag1, columns=['N321RW'])label2 = pd.DataFrame(tag2, columns=['DLRW'])label4 = pd.DataFrame(tag4, columns=['AHI'])label3 = pd.DataFrame(tag3, columns=['NRW'])label = pd.concat([label1, label2, label3, label4], axis=1)num = int(input(\"输入保存的文件名： \"))label.to_excel('%d' % num + \".xlsx\")","categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"}]},{"title":"面向对象版学员管理系统","slug":"python/面向对象版学员管理系统","date":"2020-05-28T11:58:57.000Z","updated":"2020-05-28T11:58:57.000Z","comments":true,"path":"2020/05/28/python/面向对象版学员管理系统/","link":"","permalink":"https://esyyes.github.io/2020/05/28/python/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%89%88%E5%AD%A6%E5%91%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"面向对象版学员管理系统123456789101112131415161718192021222324252627282930313233343536373839# -*- coding: utf-8 -*-# @Time : 2020/5/27# @Author : esy\"\"\"## 3.1 student.py需求：- 学员信息包含：姓名、性别、手机号；- 添加`__str__`魔法方法，方便查看学员对象信息\"\"\"\"\"\"分析：1.生成学生这个类别2.这个类别中的属性有 姓名、性别、手机号3.可以用__str__这个来进行赋值\"\"\"# 生成学生这个类别class student(object): # 初始化对象，设定对象带的属性，用__init__设置带类的对象的属性，self就是student def __init__(self, name, gender, tel): # self.name就是带的小属性，name即可定义参数 self.name = name self.gender = gender self.tel = tel # def __str__(self): # 当使用print输出对象的时候，默认打印对象的内存地址。 # 如果类定义了`__str__`方法，那么就会打印从在这个方法中 return 的数据。 # 便于直接打印出内部的文件信息 def __str__(self): # 返回的是要打印的内容 return f\"学生姓名：&#123;self.name&#125;, 性别：&#123;self.gender&#125;, 手机号：&#123;self.tel&#125;\"# 重命名时不能命名为类的名字# student1 = student('zc', 'man', '111')# print(student1) 生成管理系统这个类别：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261# -*- coding: utf-8 -*-# @Time : 2020/5/28# @Author : esyfrom student import student\"\"\"## ManagerSystem.py需求：- 存储数据的位置：文件(student.csv) - 加载文件数据 - 修改数据后保存到文件- 存储数据的形式：列表存储学员对象- 系统功能 - 添加学员 - 删除学员 - 修改学员 - 查询学员信息 - 显示所有学员信息 - 保存学员信息 - 退出系统\"\"\"\"\"\"需求：系统功能循环使用，用户输入不同的功能序号执行不同的功能。- 步骤 - 定义程序入口函数 - 加载数据 - 显示功能菜单 - 用户输入功能序号 - 根据用户输入的功能序号执行不同的功能 - 定义系统功能函数，添加、删除学员等\"\"\"\"\"\"分析：1. 加载data文件需要对文件进行修改和保存2. 修改数据后保存到文件\"\"\"class MangerSystem(object): def __init__(self): # 列表存储学员对象 self.student_list = [] def run(self): # 程序开始运行，进入界面 # 加载student.data文件 self.load_student() # while True 语句中一定要有结束该循环的break语句，否则会一直循环下去的。 # 这是一个死循环，所以每次循环后输入都要去显示页面 # 采用while True循环语句： # 根据输入的功能序号进行判断，然后运行功能 while True: # 显示界面的功能 self.show_menu() # 利用数字筛选系统的功能，供选择系统的功能，首先要确定你输入的数字是什么 # 用int转换为整数形式，将这个功能赋值给菜单，然后用菜单里的内容进行比较，输入菜单的功能 menu_num = int(input('请输入你需要的功能序号：')) if menu_num == 1: # 1- 添加学员 self.add_student() elif menu_num == 2: # 2- 删除学员 self.del_student() elif menu_num == 3: # 3 - 修改学员 self.modify_student() elif menu_num == 4: # 4 - 查询学员信息 self.search_student() elif menu_num == 5: # 5 - 显示所有学员信息 self.show_student() elif menu_num == 6: # 6 - 保存学员信息 self.save_student() elif menu_num == 7: # 7 - 退出系统 # 跳出循环即可 break # 显示菜单的功能，将对应序号表现出来，以供选择，静态的 # 当方法中 **既不需要使用实例对象**(如实例对象，实例属性)，**也不需要使用类对象** # (如类属性、类方法、创建实例等)时，定义为静态方法 # 用@staticmethod修饰 @staticmethod def show_menu(): print(f'请选择以下功能： ') print(f'1: 添加学员') print(f'2: 删除学员') print(f'3: 修改学员信息') print(f'4: 查询学员信息') print(f'5: 显示所有学员信息') print(f'6: 保存学员信息') print(f'7: 退出系统') # 读取student中的数据 def load_student(self): try: f = open('student.data', 'r') print(f'成功打开文件') except: f = open('student.data', 'w') print(f'没有该文件') else: data = f.read() data_list = eval(data) # 将学生的数据放入学生的类别中，student.py,参数写入student的属性('name', 'gender', 'tel')，将其赋值，并保存为list形式 # 需要与student.py文件结合起来,需要导入那个文件中的student模块，类别 self.student_list = [student(i['name'], i['gender'], i['tel']) for i in data_list] finally: f.close() # 1-添加学员 def add_student(self): # 输入name gender tel name = input(\"请输入学员的姓名：\") gender = input(\"请输入学员的性别： \") tel = input(\"请输入学员的电话号码： \") # 将name gender tel放入student这个类别里面，作为一个字典，然后再叠加到student_list这个列表里面 student_in = student(name, gender, tel) self.student_list.append(student_in) # 查看字典和列表 print(student_in) print(self.student_list) # 2-删除学员 def del_student(self): # 输入你想删除学员的名字 del_name = input(\"请输入你想删除的学员的名字： \") # 查找这个学员的名字在哪,用循环遍历出这个学员的所在 # 然后删除这个学员的name gender tel，即在list中直接移除这个字典 # 遍历出的每个字典都是student_in = student(name, gender, tel)，所以这个字典中的名字即可为i.name for i in self.student_list: if del_name == i.name: self.student_list.remove(i) break else: # 如果没有这个名字就输出这个 print('没有这个学员') # 再打印出这个列表的值 print(self.student_list) # 3- 修改学员信息 def modify_student(self): # 输入你想修改的学员的名字,进行查找,然后修改里面的name,gender,tel modify_name = input(\"请输入你想修改的学员的名字： \") for i in self.student_list: if modify_name == i.name: i.name = input(\"姓名修改：\") i.gender = input(\"性别修改：\") i.tel = input(\"电话修改为：\") print(f'学员信息修改完毕。 姓名为&#123;i.name&#125;, 性别为：&#123;i.gender&#125;, 电话为：&#123;i.tel&#125;') break else: # 如果没有这个名字就输出这个 print('没有这个学员') # 4 - 查询学员信息 def search_student(self): # 输入你想查询的学员的名字,进行查找 search_name = input(\"请输入你想查找的的学员的名字： \") for i in self.student_list: if search_name == i.name: print(f'姓名：&#123;i.name&#125;, 性别：&#123;i.gender&#125;, 电话：&#123;i.tel&#125;') break else: # 如果没有这个名字就输出这个 print('没有这个学员') # 5- 显示所有学员信息 def show_student(self): # 用表格的形式展示 # 打印表头 print(f'姓名\\t性别\\t电话') for i in self.student_list: # 打印出表格内容 print(f'&#123;i.name&#125;\\t&#123;i.gender&#125;\\t&#123;i.tel&#125;') # 6- 保存学员信息 # 即将学员的信息写入student.data文件中 def save_student(self): f = open('student.data', 'w') # 将student_list中的内容更改后写入程序 # 写入的内容必须是字符串 # 直接写入的列表将会是一个字符串形式，但是不会进行单排的分页，所以需要将它一个一个的展开 # new_list = [] # for i in self.student_list: # new_list.append(i.__dict__) new_list = [i.__dict__ for i in self.student_list] f.write(str(new_list)) f.close()# 这个符号的意思# __dict__?直接调用类别中的那列的字典# 1. 定义类# class A(object):# a = 0## def __init__(self):# self.b = 1### # 2. 创建对象# aa = A()## # 3. 调用__dict__# print(A.__dict__)## print(aa.__dict__)\"\"\"try: # 用只读的形式打开文件 f = open('student.data', 'r') print(f'文件夹中有该文件')except: # 如果发生了异常，则在文件夹中创建一个新的文件，用w写入文件 f = open('student.data', 'w') print(f'创建一个新的文件')else: # 没有异常才执行的语句，try能够运行才执行的语句 # f.read()读取文件夹中的参数，内容 data = f.read() # 查看data内的参数内容 print(type(data)) # '[&#123;'name': 'aaa', 'gender': 'nan', 'tel': '11111111'&#125;]' # data是字符串形式，去除[]列表外的'',使用eval，转换为list data_list = eval(data) print(f'将字符串&#123;type(data)&#125;转换为列表&#123;type(data_list)&#125;:&#123;data_list&#125;') print(f'字典的key:&#123;data_list[0].keys()&#125;, 字典的values: &#123;data_list[0].values()&#125;') name = data_list[0]['name'] gender = data_list[0]['gender'] tel = data_list[0]['tel']finally: # 不管成功与否，关闭文件夹 f.close()for i in data_list: print(i) print(1) self.student_list = [Student(i['name'], i['gender'], i['tel']) for i in new_list] 生成一个字典i: dict, &#123;'name': 'aaa', 'gender': 'nan', 'tel': '11111111'&#125; i['name'] = value # 然后将其赋值到student的属性里面\"\"\" 生成一个主程序进行运行1234567891011121314151617181920# -*- coding: utf-8 -*-# @Time : 2020/5/28# @Author : esy# 生成一个主程序进行运行from MangerSystem import *# 已经在MangerSystem进行了调用# from student import *# 2. 启动管理系统# 保证是当前文件运行才启动管理系统：if --创建对象并调用run方法# 每个python模块（python文件，也就是此处的 test.py 和 import_test.py）都包含内置的变量# __name__，当该模块被直接执行的时候，__name__ 等于文件名（包含后缀 .py ）；# 如果该模块 import 到其他模块中，则该模块的 __name__ 等于模块名称（不包含后缀.py）。# 而 “__main__” 始终指当前执行模块的名称（包含后缀.py）。进而当模块被直接执行时，__name__ == 'main' 结果为真。if __name__ == '__main__': student_manager = MangerSystem() student_manager.run() 生成的界面：12345678910成功打开文件请选择以下功能： 1: 添加学员2: 删除学员3: 修改学员信息4: 查询学员信息5: 显示所有学员信息 不能进行break,要不然会导致添加后跳出循环，无法查找到6: 保存学员信息7: 退出系统请输入你需要的功能序号：","categories":[{"name":"python","slug":"python","permalink":"https://esyyes.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://esyyes.github.io/tags/python/"}]},{"title":"python-入门复习之模块和包","slug":"python/python-入门复习之模块和包","date":"2020-05-26T10:43:10.000Z","updated":"2020-05-26T10:43:10.000Z","comments":true,"path":"2020/05/26/python/python-入门复习之模块和包/","link":"","permalink":"https://esyyes.github.io/2020/05/26/python/python-%E5%85%A5%E9%97%A8%E5%A4%8D%E4%B9%A0%E4%B9%8B%E6%A8%A1%E5%9D%97%E5%92%8C%E5%8C%85/","excerpt":"","text":"python-入门复习之模块和包123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118# -*- coding: utf-8 -*-# @Time : 2020/5/26# @Author : esy\"\"\"模块Python 模块(Module)，是一个 Python 文件，以 .py 结尾，包含了 Python 对象定义和Python语句。模块能定义函数，类和变量，模块里也能包含可执行的代码。### 导入模块的方式- import 模块名- from 模块名 import 功能名- from 模块名 import *- import 模块名 as 别名- from 模块名 import 功能名 as 别名# 1. 导入模块import 模块名import 模块名1, 模块名2...# 2. 调用功能模块名.功能名()#### 1.1.2.2 from..import..- 语法``` pythonfrom 模块名 import 功能1, 功能2, 功能3...```- 体验``` pythonfrom math import sqrtprint(sqrt(9))```#### 1.1.2.3 from .. import *- 语法``` pythonfrom 模块名 import *```- 体验``` pythonfrom math import *print(sqrt(9))```#### 1.1.2.4 as定义别名- 语法``` python# 模块定义别名import 模块名 as 别名# 功能定义别名from 模块名 import 功能 as 别名```- 体验``` python# 模块别名import time as tttt.sleep(2)print('hello')# 功能别名from time import sleep as slsl(2)print('hello')```包将有联系的模块组织在一起，即放到同一个文件夹下，并且在这个文件夹创建一个名字为`__init__.py` 文件，那么这个文件夹就称之为包。## 2.1 制作包[New] — [Python Package] — 输入包名 — [OK] — 新建功能模块(有联系的模块)。注意：新建包后，包内部会自动创建`__init__.py`文件，这个文件控制着包的导入行为。import包名.模块名包名.模块名.目标必须在`__init__.py`文件中添加`__all__ = []`，控制允许导入的模块列表。- 导入模块方法``` pythonimport 模块名from 模块名 import 目标from 模块名 import *```- 导入包``` pythonimport 包名.模块名from 包名 import *```- `__all__ = []` ：允许导入的模块或功能列表\"\"\"","categories":[{"name":"python","slug":"python","permalink":"https://esyyes.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://esyyes.github.io/tags/python/"}]},{"title":"python-入门复习之异常","slug":"python/python-入门复习之异常","date":"2020-05-26T10:38:15.000Z","updated":"2020-05-26T10:38:15.000Z","comments":true,"path":"2020/05/26/python/python-入门复习之异常/","link":"","permalink":"https://esyyes.github.io/2020/05/26/python/python-%E5%85%A5%E9%97%A8%E5%A4%8D%E4%B9%A0%E4%B9%8B%E5%BC%82%E5%B8%B8/","excerpt":"","text":"python-入门复习之异常12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394# -*- coding: utf-8 -*-# @Time : 2020/5/26# @Author : esy\"\"\"当检测到一个错误时，解释器就无法继续执行了，反而出现了一些错误的提示，这就是所谓的\"异常\"。异常的写法try: 可能发生错误的代码except: 如果出现异常执行的代码捕获指定异常try: 可能发生错误的代码except 异常类型: 如果捕获到该异常类型执行的代码try: print(num)except NameError: print('有错误')注意：1. 如果尝试执行的代码的异常类型和要捕获的异常类型不一致，则无法捕获异常。2. 一般try下方只放一行尝试执行的代码。当捕获多个异常时，可以把要捕获的异常类型的名字，放到except 后，并使用元组的方式进行书写。try: print(1/0)except (NameError, ZeroDivisionError): print('有错误')捕获异常描述信息try: print(num)except (NameError, ZeroDivisionError) as result: print(result)捕获所有异常Exception是所有程序异常类的父类。try: print(num)except Exception as result: print(result)else表示的是如果没有异常要执行的代码。try: print(1)except Exception as result: print(result)else: print('我是else，是没有异常的时候执行的代码')finally表示的是无论是否异常都要执行的代码\"\"\"\"\"\"异常语法try: 可能发生异常的代码except: 如果出现异常执行的代码else: 没有异常执行的代码finally: 无论是否异常都要执行的代码捕获异常 except 异常类型: 代码except 异常类型 as xx: 代码自定义异常# 1. 自定义异常类class 异常类类名(Exception): 代码 # 设置抛出异常的描述信息 def __str__(self): return ...# 2. 抛出异常raise 异常类名()# 捕获异常except Exception...\"\"\"","categories":[{"name":"python","slug":"python","permalink":"https://esyyes.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://esyyes.github.io/tags/python/"}]},{"title":"python-入门复习面向对象","slug":"python/python-入门复习面向对象","date":"2020-05-26T08:45:05.000Z","updated":"2020-05-26T08:45:05.000Z","comments":true,"path":"2020/05/26/python/python-入门复习面向对象/","link":"","permalink":"https://esyyes.github.io/2020/05/26/python/python-%E5%85%A5%E9%97%A8%E5%A4%8D%E4%B9%A0%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","excerpt":"","text":"python-入门复习面向对象很类似于数据库slpdb 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594# -*- coding: utf-8 -*-# @Time : 2020/5/26# @Author : esy\"\"\"面向对象基础==面向对象就是将编程当成是一个事物，对外界来说，事物是直接使用的，不用去管他内部的情况。而编程就是设置事物能够做什么事。==类和对象的关系：用类去创建一个对象。类是对一系列具有相同==特征==和==行为==的事物的统称，是一个==抽象的概念==，不是真实存在的事物。- 特征即是属性- 行为即是方法对象是类创建出来的真实存在的事物 定义类Python2中类分为：经典类 和 新式类class 类名(): 代码 ......注意：类名要满足标识符命名规则，同时遵循==大驼峰命名习惯==。class Washer(): def wash(self): print('我会洗衣服')不由任意内置类型派生出的类，称之为经典类class 类名: 代码 ......创建对象对象又名实例。- 语法对象名 = 类名()# 创建对象haier1 = Washer()# &lt;__main__.Washer object at 0x0000018B7B224240&gt;print(haier1)# haier对象调用实例方法haier1.wash()self指的是调用该函数的对象。# 1. 定义类class Washer(): def wash(self): print('我会洗衣服') # &lt;__main__.Washer object at 0x0000024BA2B34240&gt; print(self)# 2. 创建对象haier1 = Washer()# &lt;__main__.Washer object at 0x0000018B7B224240&gt;print(haier1)# haier1对象调用实例方法haier1.wash()haier2 = Washer()# &lt;__main__.Washer object at 0x0000022005857EF0&gt;print(haier2)打印对象和self得到的结果是一致的，都是当前对象的内存中存储地址。对象名.属性名 = 值对象名.属性名print(f'haier1洗衣机的宽度是&#123;haier1.width&#125;')print(f'haier1洗衣机的高度是&#123;haier1.height&#125;')self.属性名# 定义类class Washer(): def print_info(self): # 类里面获取实例属性 print(f'haier1洗衣机的宽度是&#123;self.width&#125;') print(f'haier1洗衣机的高度是&#123;self.height&#125;')# 创建对象haier1 = Washer()# 添加实例属性haier1.width = 500haier1.height = 800haier1.print_info()\"\"\"\"\"\"在Python中，`__xx__()`的函数叫做魔法方法，指的是具有特殊功能的函数。==`__init__()`方法的作用：初始化对象。==class Washer(): # 定义初始化功能的函数 def __init__(self): # 添加实例属性 self.width = 500 self.height = 800 def print_info(self): # 类里面调用实例属性 print(f'洗衣机的宽度是&#123;self.width&#125;, 高度是&#123;self.height&#125;')haier1 = Washer()haier1.print_info()注意：- `__init__()`方法，在创建一个对象时默认被调用，不需要手动调用- `__init__(self)`中的self参数，不需要开发者传递，python解释器会自动把当前的对象引用传递过去。一个类可以创建多个对象，如何对不同的对象设置不同的初始化属性呢？class Washer(): def __init__(self, width, height): self.width = width self.height = height def print_info(self): print(f'洗衣机的宽度是&#123;self.width&#125;') print(f'洗衣机的高度是&#123;self.height&#125;')haier1 = Washer(10, 20)haier1.print_info()haier2 = Washer(30, 40)haier2.print_info()当使用print输出对象的时候，默认打印对象的内存地址。如果类定义了`__str__`方法，那么就会打印从在这个方法中 return 的数据。class Washer(): def __init__(self, width, height): self.width = width self.height = height def __str__(self): return '这是海尔洗衣机的说明书'haier1 = Washer(10, 20)# 这是海尔洗衣机的说明书print(haier1)当删除对象时，python解释器也会默认调用`__del__()`方法。\"\"\"\"\"\"# 总结- 面向对象重要组成部分 - 类 - 创建类 ``` python class 类名(): 代码 ``` - 对象 ``` python 对象名 = 类名() ```- 添加对象属性 - 类外面 ``` python 对象名.属性名 = 值 ``` - 类里面 ``` python self.属性名 = 值 ```- 获取对象属性 - 类外面 ``` python 对象名.属性名 ``` - 类里面 ``` python self.属性名 ```- 魔法方法 - `__init__()`: 初始化 - `__str__()`:输出对象信息 - `__del__()`:删除对象时调用\"\"\"\"\"\"class 类名(object): 代码# 父类Aclass A(object): def __init__(self): self.num = 1 def info_print(self): print(self.num)# 子类Bclass B(A): passresult = B()result.info_print() # 1在Python中，所有类默认继承object类，object类是顶级类或基类；其他子类叫做派生类注意：当一个类有多个父类的时候，默认使用第一个父类的同名属性和方法。\"\"\"\"\"\"单继承# 1. 师父类class Master(object): def __init__(self): self.kongfu = '[古法煎饼果子配方]' def make_cake(self): print(f'运用&#123;self.kongfu&#125;制作煎饼果子') # 2. 徒弟类class Prentice(Master): pass# 3. 创建对象daqiudaqiu = Prentice()# 4. 对象访问实例属性print(daqiu.kongfu)# 5. 对象调用实例方法daqiu.make_cake()\"\"\"\"\"\" 多继承class Master(object): def __init__(self): self.kongfu = '[古法煎饼果子配方]' def make_cake(self): print(f'运用&#123;self.kongfu&#125;制作煎饼果子')# 创建学校类class School(object): def __init__(self): self.kongfu = '[黑马煎饼果子配方]' def make_cake(self): print(f'运用&#123;self.kongfu&#125;制作煎饼果子')class Prentice(School, Master): passdaqiu = Prentice()print(daqiu.kongfu)daqiu.make_cake()注意：当一个类有多个父类的时候，默认使用第一个父类的同名属性和方法。\"\"\"\"\"\"子类重写父类同名方法和属性class Master(object): def __init__(self): self.kongfu = '[古法煎饼果子配方]' def make_cake(self): print(f'运用&#123;self.kongfu&#125;制作煎饼果子')class School(object): def __init__(self): self.kongfu = '[黑马煎饼果子配方]' def make_cake(self): print(f'运用&#123;self.kongfu&#125;制作煎饼果子')# 独创配方class Prentice(School, Master): def __init__(self): self.kongfu = '[独创煎饼果子配方]' def make_cake(self): print(f'运用&#123;self.kongfu&#125;制作煎饼果子')daqiu = Prentice()print(daqiu.kongfu)daqiu.make_cake()print(Prentice.__mro__)子类和父类具有同名属性和方法，默认使用子类的同名属性和方法。\"\"\"\"\"\"子类调用父类的同名方法和属性class Master(object): def __init__(self): self.kongfu = '[古法煎饼果子配方]' def make_cake(self): print(f'运用&#123;self.kongfu&#125;制作煎饼果子')class School(object): def __init__(self): self.kongfu = '[黑马煎饼果子配方]' def make_cake(self): print(f'运用&#123;self.kongfu&#125;制作煎饼果子')class Prentice(School, Master): def __init__(self): self.kongfu = '[独创煎饼果子配方]' def make_cake(self): # 如果是先调用了父类的属性和方法，父类属性会覆盖子类属性，故在调用属性前，先调用自己子类的初始化 self.__init__() print(f'运用&#123;self.kongfu&#125;制作煎饼果子') # 调用父类方法，但是为保证调用到的也是父类的属性，必须在调用方法前调用父类的初始化 def make_master_cake(self): Master.__init__(self) Master.make_cake(self) def make_school_cake(self): School.__init__(self) School.make_cake(self)daqiu = Prentice()daqiu.make_cake()daqiu.make_master_cake()daqiu.make_school_cake()daqiu.make_cake()\"\"\"\"\"\"&gt; 使用super() 可以自动查找父类。调用顺序遵循 `__mro__` 类属性的顺序。比较适合单继承使用。class Master(object): def __init__(self): self.kongfu = '[古法煎饼果子配方]' def make_cake(self): print(f'运用&#123;self.kongfu&#125;制作煎饼果子')class School(Master): def __init__(self): self.kongfu = '[黑马煎饼果子配方]' def make_cake(self): print(f'运用&#123;self.kongfu&#125;制作煎饼果子') # 方法2.1 # super(School, self).__init__() # super(School, self).make_cake() # 方法2.2 super().__init__() super().make_cake()class Prentice(School): def __init__(self): self.kongfu = '[独创煎饼果子技术]' def make_cake(self): self.__init__() print(f'运用&#123;self.kongfu&#125;制作煎饼果子') # 子类调用父类的同名方法和属性：把父类的同名属性和方法再次封装 def make_master_cake(self): Master.__init__(self) Master.make_cake(self) def make_school_cake(self): School.__init__(self) School.make_cake(self) # 一次性调用父类的同名属性和方法 def make_old_cake(self): # 方法一：代码冗余；父类类名如果变化，这里代码需要频繁修改 # Master.__init__(self) # Master.make_cake(self) # School.__init__(self) # School.make_cake(self) # 方法二: super() # 方法2.1 super(当前类名, self).函数() # super(Prentice, self).__init__() # super(Prentice, self).make_cake() # 方法2.2 super().函数() super().__init__() super().make_cake()daqiu = Prentice()daqiu.make_old_cake()\"\"\"\"\"\"- 继承的特点 - 子类默认拥有父类的所有属性和方法 - 子类重写父类同名方法和属性 - 子类调用父类同名方法和属性- super()方法快速调用父类方法- 私有权限 - 不能继承给子类的属性和方法需要添加私有权限 - 语法class 类名(): # 私有属性 __属性名 = 值 # 私有方法 def __函数名(self): 代码\"\"\"\"\"\"- 封装 - 将属性和方法书写到类的里面的操作即为封装 - 封装可以为属性和方法添加私有权限- 继承 - 子类默认继承父类的所有属性和方法 - 子类可以重写父类属性和方法- 多态 - 传入不同的对象，产生不同的结果\"\"\"'''多态指的是一类事物有多种形态，（一个抽象类有多个子类，因而多态的概念依赖于继承）。- 定义：多态是一种使用对象的方式，子类重写父类方法，调用不同子类对象的相同父类方法，可以产生不同的执行结果- 好处：调用灵活，有了多态，更容易编写出通用的代码，做出通用的编程，以适应需求的不断变化！- 实现步骤： - 定义父类，并提供公共方法 - 定义子类，并重写父类方法 - 传递子类对象给调用者，可以看到不同子类执行效果不同class Dog(object): def work(self): # 父类提供统一的方法，哪怕是空方法 print('指哪打哪...')class ArmyDog(Dog): # 继承Dog类 def work(self): # 子类重写父类同名方法 print('追击敌人...')class DrugDog(Dog): def work(self): print('追查毒品...')class Person(object): def work_with_dog(self, dog): # 传入不同的对象，执行不同的代码，即不同的work函数 dog.work()ad = ArmyDog()dd = DrugDog()daqiu = Person()daqiu.work_with_dog(ad)daqiu.work_with_dog(dd)'''\"\"\"### 设置和访问类属性- 类属性就是 **类对象** 所拥有的属性，它被 **该类的所有实例对象 所共有**。- 类属性可以使用 **类对象** 或 **实例对象** 访问。class Dog(object): tooth = 10wangcai = Dog()xiaohei = Dog()print(Dog.tooth) # 10print(wangcai.tooth) # 10print(xiaohei.tooth) # 10类属性的优点- **记录的某项数据 始终保持一致时**，则定义类属性。- **实例属性** 要求 **每个对象** 为其 **单独开辟一份内存空间** 来记录数据，而 **类属性** 为全类所共有 ，**仅占用一份内存**，**更加节省内存空间**。\"\"\"\"\"\"类属性只能通过类对象修改，不能通过实例对象修改，如果通过实例对象修改类属性，表示的是创建了一个实例属性。\"\"\"# 需要用装饰器`@classmethod`来标识其为类方法，对于类方法，**第一个参数必须是类对象**，一般以`cls`作为第一个参数。'''### 类方法使用场景- 当方法中 **需要使用类对象** (如访问私有类属性等)时，定义类方法- 类方法一般和类属性配合使用'''\"\"\"### 静态方法特点- 需要通过装饰器`@staticmethod`来进行修饰，**静态方法既不需要传递类对象也不需要传递实例对象（形参没有self/cls）**。- 静态方法 也能够通过 **实例对象** 和 **类对象** 去访问。静态方法使用场景- 当方法中 **既不需要使用实例对象**(如实例对象，实例属性)，**也不需要使用类对象** (如类属性、类方法、创建实例等)时，定义静态方法- **取消不需要的参数传递**，有利于 **减少不必要的内存占用和性能消耗**\"\"\"\"\"\"class Dog(object): @staticmethod def info_print(): print('这是一个狗类，用于创建狗实例....')wangcai = Dog()# 静态方法既可以使用对象访问又可以使用类访问wangcai.info_print()Dog.info_print()\"\"\"\"\"\"- 面向对象三大特性 - 封装 - 继承 - 多态- 类属性 - 归属于类对象的属性，所有对象共有的属性- 实例属性- 类方法@classmethoddef xx(): 代码 静态方法@staticmethoddef xx(): 代码\"\"\"","categories":[{"name":"python","slug":"python","permalink":"https://esyyes.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://esyyes.github.io/tags/python/"}]},{"title":"python_入门复习之文件读取","slug":"python/python-入门复习之文件读取","date":"2020-05-26T05:55:41.000Z","updated":"2020-05-26T05:55:41.000Z","comments":true,"path":"2020/05/26/python/python-入门复习之文件读取/","link":"","permalink":"https://esyyes.github.io/2020/05/26/python/python-%E5%85%A5%E9%97%A8%E5%A4%8D%E4%B9%A0%E4%B9%8B%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96/","excerpt":"","text":"python-文件读取123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197 # -*- coding: utf-8 -*-# @Time : 2020/5/26# @Author : esy\"\"\"文件的基本操作 - 打开- 读写- 关闭打开：在python，使用open函数，可以打开一个已经存在的文件，或者创建一个新文件，语法如下：open(name, mode)name：是要打开的目标文件名的字符串(可以包含文件所在的具体路径)。mode：设置打开文件的模式(访问模式)：只读、写入、追加等。| 模式 | 描述 || :--: | ------------------------------------------------------------ || r | 以只读方式打开文件。文件的指针将会放在文件的开头。这是默认模式。 || rb | 以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。这是默认模式。 || r+ | 打开一个文件用于读写。文件指针将会放在文件的开头。 || rb+ | 以二进制格式打开一个文件用于读写。文件指针将会放在文件的开头。 || w | 打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。 || wb | 以二进制格式打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。 || w+ | 打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。 || wb+ | 以二进制格式打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。 || a | 打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 || ab | 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 || a+ | 打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。 || ab+ | 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写。 |f = open('test.txt', 'w')# 1. 打开文件f = open('test.txt', 'w')# 2.文件写入f.write('hello world')# 3. 关闭文件f.close()注意：1. `w `和`a`模式：如果文件不存在则创建该文件；如果文件存在，`w`模式先清空再写入，`a`模式直接末尾追加。2. `r`模式：如果文件不存在则报错。文件对象.read(num)&gt; num表示要从文件中读取的数据的长度（单位是字节），如果没有传入num，那么就表示读取文件中所有的数据。readlines可以按照行的方式把整个文件中的内容进行一次性读取，并且返回的是一个列表，其中每一行的数据为一个元素f = open('test.txt')content = f.readlines()# ['hello world\\n', 'abcdefg\\n', 'aaa\\n', 'bbb\\n', 'ccc']print(content)# 关闭文件f.close()readline()一次读取一行内容。文件对象.seek(偏移量, 起始位置)起始位置：- 0：文件开头- 1：当前位置- 2：文件结尾关闭文件对象.close()\"\"\"\"\"\"在Python中文件和文件夹的操作要借助os模块里面的相关功能，具体步骤如下：导入os模块import os使用`os`模块相关功能os.函数名()文件重命名os.rename(目标文件名, 新文件名)删除文件os.remove(目标文件名)创建文件夹os.mkdir(文件夹名字)删除文件夹os.rmdir(文件夹名字)获取当前目录os.getcwd()改变默认目录os.chdir(目录)获取目录列表os.listdir(目录)\"\"\"\"\"\"需求：批量修改文件名，既可添加指定字符串，又能删除指定字符串。- 步骤1. 设置添加删除字符串的的标识2. 获取指定目录的所有文件3. 将原有文件名添加/删除指定字符串，构造新名字4. os.rename()重命名import os# 设置重命名标识：如果为1则添加指定字符，flag取值为2则删除指定字符flag = 1# 获取指定目录dir_name = './'# 获取指定目录的文件列表file_list = os.listdir(dir_name)# print(file_list)# 遍历文件列表内的文件for name in file_list: # 添加指定字符 if flag == 1: new_name = 'Python-' + name # 删除指定字符 elif flag == 2: num = len('Python-') new_name = name[num:] # 打印新文件名，测试程序正确性 print(new_name) # 重命名 os.rename(dir_name+name, dir_name+new_name)\"\"\"\"\"\"# 六. 总结- 文件操作步骤 - 打开 ``` python 文件对象 = open(目标文件, 访问模式) ``` - 操作 - 读 ``` python 文件对象.read() 文件对象.readlines() 文件对象.readline() ``` - 写 ``` python 文件对象.write() ``` - seek() - 关闭 ``` python 文件对象.close() ```- 主访问模式 - w：写，文件不存在则新建该文件 - r：读，文件不存在则报错 - a：追加- 文件和文件夹操作 - 重命名：os.rename() - 获取当前目录：os.getcwd() - 获取目录列表：os.listdir()\"\"\"","categories":[{"name":"python","slug":"python","permalink":"https://esyyes.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://esyyes.github.io/tags/python/"}]},{"title":"python_入门复习之函数","slug":"python/python-入门复习之函数","date":"2020-05-26T05:50:42.000Z","updated":"2020-05-26T05:50:42.000Z","comments":true,"path":"2020/05/26/python/python-入门复习之函数/","link":"","permalink":"https://esyyes.github.io/2020/05/26/python/python-%E5%85%A5%E9%97%A8%E5%A4%8D%E4%B9%A0%E4%B9%8B%E5%87%BD%E6%95%B0/","excerpt":"","text":"python-函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290# -*- coding: utf-8 -*-# @Time : 2020/5/26# @Author : esy'''函数复习：&gt; 函数在开发过程中，可以更高效的实现==代码重用==。定义函数：def 函数名(参数): 代码1 代码2. ......调用函数：函数名(参数)1. 不同的需求，参数可有可无。2. 在Python中，函数必须==先定义后使用==。定义函数的说明文档def 函数名(参数): \"\"\" 说明文档的位置 \"\"\" 代码 ......查看函数的说明文档help(函数名)def sum_num(a, b): \"\"\" 求和函数 \"\"\" return a + bhelp(sum_num)- 函数的参数：函数调用的时候可以传入真实数据，增大函数的使用的灵活性 - 形参：函数定义时书写的参数(非真实数据) - 实参：函数调用时书写的参数(真实数据)- 函数的返回值 - 作用：函数调用后，返回需要的计算结果 - 写法return 表达式- 函数的说明文档 - 作用：保存函数解释说明的信息 - 写法 ``` python def 函数名(): \"\"\" 函数说明文档 \"\"\" ```- 函数嵌套调用：一个函数内部嵌套调用另外一个函数'''\"\"\"变量作用域变量作用域指的是变量生效的范围，主要分为两类：==局部变量==和==全局变量==。所谓局部变量是定义在函数体内部的变量，即只在函数体内部生效。局部变量的作用：在函数体内部，临时保存数据，即当函数调用完成后，则销毁局部变量。- 全局变量所谓全局变量，指的是在函数体内、外都能生效的变量。 # global 关键字声明a是全局变量def return_num(): return 1 return 2result = return_num()print(result) # 1只执行了第一个return，原因是因为return可以退出当前函数，导致return下方的代码不执行。`return a, b`写法，返回多个数据的时候，默认是元组类型。&gt; 1. return后面可以连接列表、元组或字典，以返回多个值。调用函数时根据函数定义的参数位置来传递参数。传递和定义参数的顺序及个数必须一致。**函数调用时，如果有位置参数时，位置参数必须在关键字参数的前面，但关键字参数之间不存在先后顺序。**函数调用时，如果为缺省参数传值则修改默认参数值；否则使用这个默认值。不定长参数也叫可变参数。用于不确定调用的时候会传递多少个参数(不传参也可以)的场景。此时，可用包裹(packing)位置参数，或者包裹关键字参数，来进行参数传递，会显得非常方便。包裹位置传递def user_info(*args): print(args)# ('TOM',)user_info('TOM')# ('TOM', 18)user_info('TOM', 18)传进的所有参数都会被args变量收集，它会根据传进参数的位置合并为一个元组(tuple)，args是元组类型，这就是包裹位置传递。包裹关键字传递def user_info(**kwargs): print(kwargs)# &#123;'name': 'TOM', 'age': 18, 'id': 110&#125;user_info(name='TOM', age=18, id=110)无论是包裹位置传递还是包裹关键字传递，都是一个组包的过程。\"\"\"def user_info(name, age, gender): print(f'您的名字是&#123;name&#125;, 年龄是&#123;age&#125;, 性别是&#123;gender&#125;')user_info('Rose', age=20, gender='女')user_info('小明', gender='男', age=16)# 拆包：元组def return_num(): return 100, 200num1, num2 = return_num()print(num1) # 100print(num2) # 200# 拆包：字典dict1 = &#123;'name': 'TOM', 'age': 18&#125;a, b = dict1# 对字典进行拆包，取出来的是字典的keyprint(a) # nameprint(b) # ageprint(dict1[a]) # TOMprint(dict1[b]) # 18'''**我们可以用`id()`来判断两个变量是否为同一个值的引用。** 我们可以将id值理解为那块内存的地址标识。'''# 1. int类型a = 1b = aprint(b) # 1print(id(a)) # 140708464157520print(id(b)) # 140708464157520a = 2print(b) # 1,说明int类型为不可变类型print(id(a)) # 140708464157552，此时得到是的数据2的内存地址print(id(b)) # 140708464157520# 2. 列表aa = [10, 20]bb = aaprint(id(aa)) # 2325297783432print(id(bb)) # 2325297783432aa.append(30)print(bb) # [10, 20, 30], 列表为可变类型print(id(aa)) # 2325297783432print(id(bb)) # 2325297783432\"\"\"所谓可变类型与不可变类型是指：数据能够直接进行修改，如果能直接修改那么就是可变，否则是不可变.- 可变类型 - 列表 - 字典 - 集合- 不可变类型 - 整型 - 浮点型 - 字符串 - 元组\"\"\"\"\"\"- 变量作用域 - 全局：函数体内外都能生效 - 局部：当前函数体内部生效- 函数多返回值写法``` pythonreturn 表达式1, 表达式2...```- 函数的参数 - 位置参数 - 形参和实参的个数和书写顺序必须一致 - 关键字参数 - 写法： `key=value` - 特点：形参和实参的书写顺序可以不一致；关键字参数必须书写在位置参数的后面 - 缺省参数 - 缺省参数就是默认参数 - 写法：`key=vlaue` - 不定长位置参数 - 收集所有位置参数，返回一个元组 - 不定长关键字参数 - 收集所有关键字参数，返回一个字典- 引用：Python中，数据的传递都是通过引用\"\"\"\"\"\"`abs()`函数可以完成对数字求绝对值计算。`round()`函数可以完成对数字的四舍五入计算。\"\"\"\"\"\"- 递归 - 函数内部自己调用自己 - 必须有出口- lambda - 语法 ``` python lambda 参数列表: 表达式 ``` - lambda的参数形式 - 无参数 ``` python lambda: 表达式 ``` - 一个参数 ``` python lambda 参数: 表达式 ``` - 默认参数 ``` python lambda key=value: 表达式 ``` - 不定长位置参数 ``` python lambda *args: 表达式 ``` - 不定长关键字参数 ``` python lambda **kwargs: 表达式 ```- 高阶函数 - 作用：把函数作为参数传入，化简代码 - 内置高阶函数 - map() - reduce() - filter()strip()函数用于移除字符串头尾指定的字符（默认为空格或换行符）或字符序列。rstrip()函数移除末尾指定字符，默认为空格\"\"\"","categories":[{"name":"python","slug":"python","permalink":"https://esyyes.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://esyyes.github.io/tags/python/"}]},{"title":"python--入门复习推导式","slug":"python/python-入门复习推导式","date":"2020-05-25T12:00:32.000Z","updated":"2020-05-25T12:00:32.000Z","comments":true,"path":"2020/05/25/python/python-入门复习推导式/","link":"","permalink":"https://esyyes.github.io/2020/05/25/python/python-%E5%85%A5%E9%97%A8%E5%A4%8D%E4%B9%A0%E6%8E%A8%E5%AF%BC%E5%BC%8F/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596# -*- coding: utf-8 -*-# @Time : 2020/5/25# @Author : esy\"\"\"推导式- 列表推导式作用：用一个表达式创建一个有规律的列表或控制一个有规律列表。列表推导式又叫列表生成式。- 字典推导式字典推导式作用：快速合并列表为字典或提取字典中目标数据。- 集合推导式创建一个集合，数据为下方列表的2次方。- 推导式的作用：简化代码- 推导式写法# 列表推导式[xx for xx in range()]# 字典推导式&#123;xx1: xx2 for ... in ...&#125;# 集合推导式&#123;xx for xx in ...&#125;\"\"\"\"\"\"列表推导式:需求创建一个0-10的列表。- while循环实现\"\"\"list1 = []# 2. 书写循环，依次追加数字到空列表list1中i = 0while i &lt; 10: list1.append(i) i += 1print(list1)list1 = []for i in range(10): list1.append(i)print(list1)# 列表推导式实现list1 = [i for i in range(10)]print(list1)# 需求：创建0-10的偶数列表## - 方法一：range()步长实现list1 = [i for i in range(0, 10, 2)]print(list1)# if实现list1 = [i for i in range(10) if i % 2 == 0]print(list1)a = [(1, 0), (1, 1), (1, 2), (2, 0), (2, 1), (2, 2)]a = [(i, j) for i in range(1, 3) for j in range(3)]print(a)# 创建一个字典：字典key是1-5数字，value是这个数字的2次方dict1 = &#123;i: i**2 for i in range(1, 5)&#125;print(dict1) # &#123;1: 1, 2: 4, 3: 9, 4: 16&#125;# 将两个列表合并为一个字典list1 = ['name', 'age', 'gender']list2 = ['Tom', 20, 'man']dict1 = &#123;list1[i]: list2[i] for i in range(len(list1))&#125;print(dict1)# 提取字典中目标数据counts = &#123;'MBP': 268, 'HP': 125, 'DELL': 201, 'Lenovo': 199, 'acer': 99&#125;# 需求：提取上述电脑数量大于等于200的字典数据count1 = &#123;key: value for key, value in counts.items() if value &gt;= 200&#125;print(count1) # &#123;'MBP': 268, 'DELL': 201&#125;# 集合推导式# 需求：创建一个集合，数据为下方列表的2次方。list1 = [1, 1, 2]set1 = &#123;i ** 2 for i in list1&#125;print(set1) # &#123;1, 4&#125;# 集合有数据去重功能。","categories":[],"tags":[]},{"title":"python——入门复习数据序列","slug":"python/python——入门复习数据序列","date":"2020-05-25T11:57:35.000Z","updated":"2020-05-25T11:57:35.000Z","comments":true,"path":"2020/05/25/python/python——入门复习数据序列/","link":"","permalink":"https://esyyes.github.io/2020/05/25/python/python%E2%80%94%E2%80%94%E5%85%A5%E9%97%A8%E5%A4%8D%E4%B9%A0%E6%95%B0%E6%8D%AE%E5%BA%8F%E5%88%97/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315# -*- coding: utf-8 -*-# @Time : 2020/5/25# @Author : esy# 字符串'''数据类型为str(字符串)三引号形式的字符串支持换行。'''c = \"I'm Tom\"d = 'I\\'m Tom'print(c)print(d)'''切片是指对操作的对象截取其中一部分的操作。**字符串、列表、元组**都支持切片操作。序列[开始位置下标:结束位置下标:步长]步长是选取间隔，正负整数均可，默认步长为1。左闭右开'''name = \"abcdefg\"print(name[2:5:1]) # cdeprint(name[2:5]) # cdeprint(name[:5]) # abcdeprint(name[1:]) # bcdefgprint(name[:]) # abcdefgprint(name[::2]) # acegprint(name[:-1]) # abcdef, 负1表示倒数第一个数据print(name[-4:-1]) # defprint(name[::-1]) # gfedcba'''find()：检测某个子串是否包含在这个字符串中，如果在返回这个子串开始的位置下标，否则则返回-1。字符串序列.find(子串, 开始位置下标, 结束位置下标)'''mystr = \"hello world and itcast and itheima and Python\"print(mystr.find('and')) # 12print(mystr.find('and', 15, 30)) # 23print(mystr.find('ands')) # -1'''index()：检测某个子串是否包含在这个字符串中，如果在返回这个子串开始的位置下标，否则则报异常。开始和结束位置下标可以省略，表示在整个字符串序列中查找。'''mystr = \"hello world and itcast and itheima and Python\"print(mystr.index('and')) # 12print(mystr.index('and', 15, 30)) # 23print(mystr.index('ands')) # 报错'''所谓修改字符串，指的就是通过函数的形式修改字符串中的数据。字符串序列.replace(旧子串, 新子串, 替换次数)'''# 结果：hello world he itcast he itheima he Pythonprint(mystr.replace('and', 'he', 10))\"\"\"- 下标 - 计算机为数据序列中每个元素分配的从0开始的编号- 切片``` python序列名[开始位置下标:结束位置下标:步长]```- 常用操作方法 - find() - index()\"\"\"\"\"\"列表：[数据1, 数据2, 数据3, 数据4......]列表的作用是一次性存储多个数据，程序员可以对这些数据进行的操作有：增、删、改、查。\"\"\"name_list = ['Tom', 'Lily', 'Rose']print(name_list[0]) # Tomprint(name_list[1]) # Lilyprint(name_list[2]) # Rose# index()：返回指定数据所在位置的下标 。# 列表序列.index(数据, 开始位置下标, 结束位置下标)print(name_list.index('Lily', 0, 2)) # 1# count()：统计指定数据在当前列表中出现的次数。print(name_list.count('Lily')) # 1# len()：访问列表长度，即列表中数据的个数。print(len(name_list)) # 3# append()：列表结尾追加数据。name_list.append('xiaoming')# 结果：['Tom', 'Lily', 'Rose', 'xiaoming']print(name_list)# 如果append()追加的数据是一个序列，则追加整个序列到列表# extend()：列表结尾追加数据，如果数据是一个序列，则将这个序列的数据逐一添加到列表。name_list = ['Tom', 'Lily', 'Rose']name_list.extend('xiaoming')# 结果：['Tom', 'Lily', 'Rose', 'x', 'i', 'a', 'o', 'm', 'i', 'n', 'g']print(name_list)name_list.extend(['xiaoming'])print(name_list)# insert()：指定位置新增数据。# 列表序列.insert(位置下标, 数据)name_list = ['Tom', 'Lily', 'Rose']name_list.insert(1, 'xiaoming')# 结果：['Tom', 'xiaoming', 'Lily', 'Rose']print(name_list)# 删除# del 目标name_list = ['Tom', 'Lily', 'Rose']# 结果：报错提示：name 'name_list' is not defineddel name_listprint(name_list)name_list = ['Tom', 'Lily', 'Rose']# 删除指定数据del name_list[0]# 结果：['Lily', 'Rose']print(name_list)# pop()：删除指定下标的数据(默认为最后一个)，并返回该数据。# 列表序列.pop(下标)name_list = ['Tom', 'Lily', 'Rose']del_name = name_list.pop(1)# 结果：Lilyprint(del_name)# 结果：['Tom', 'Rose']print(name_list)# 列表序列.sort( key=None, reverse=False)'''列表序列.sort( key=None, reverse=False)如果定义的元组只有一个数据，那么这个数据后面也好添加逗号，否则数据类型为唯一的这个数据的数据类型元组数据不支持修改，只支持查找index()：查找某个数据，如果数据存在返回对应的下标，否则报错，语法和列表、字符串的index方法相同count()：统计某个数据在当前元组出现的次数。len()：统计元组中数据的个数。 '''# 多个数据元组t1 = (10, 20, 30)# 单个数据元组t2 = (10,)'''字典特点：- 符号为==大括号==- 数据为==键值对==形式出现- 各个键值对之间用==逗号==隔开一般称冒号前面的为键(key)，简称k；冒号后面的为值(value)，简称v。&gt; 字典为可变类型。del() / del：删除字典或删除字典中指定键值对。clear()：清空字典'''# 有数据字典dict1 = &#123;'name': 'Tom', 'age': 20, 'gender': '男'&#125;# 空字典dict2 = &#123;&#125;dict3 = dict()dict1['name'] = 'Rose'# 结果：&#123;'name': 'Rose', 'age': 20, 'gender': '男'&#125;print(dict1)dict1['id'] = 110# &#123;'name': 'Rose', 'age': 20, 'gender': '男', 'id': 110&#125;print(dict1)'''字典序列.get(key, 默认值)如果当前查找的key不存在则返回第二个参数(默认值)，如果省略第二个参数，则返回None。'''dict1 = &#123;'name': 'Tom', 'age': 20, 'gender': '男'&#125;print(dict1.get('name')) # Tomprint(dict1.get('id', 110)) # 110print(dict1.get('id')) # None# keys()dict1 = &#123;'name': 'Tom', 'age': 20, 'gender': '男'&#125;print(dict1.keys()) # dict_keys(['name', 'age', 'gender'])# values()print(dict1.values()) # dict_values(['Tom', 20, '男'])dict1 = &#123;'name': 'Tom', 'age': 20, 'gender': '男'&#125;print(dict1.items()) # dict_items([('name', 'Tom'), ('age', 20), ('gender', '男')])'''创建集合使用`&#123;&#125;`或`set()`， 但是如果要创建空集合只能使用`set()`，因为`&#123;&#125;`用来创建空字典。'''s3 = set('abcdefg')print(s3)\"\"\"1. 集合可以去掉重复数据；2. 集合数据是无序的，故不支持下标增加数据add()\"\"\"s1 = &#123;10, 20&#125;s1.add(100)s1.add(10)print(s1) # &#123;100, 10, 20&#125;# 因为集合有去重功能，所以，当向集合内追加的数据是当前集合已有数据的话，则不进行任何操作。# update(), 追加的数据是序列。s1 = &#123;10, 20&#125;# s1.update(100) # 报错s1.update([100, 200])s1.update('abc')print(s1)# remove()，删除集合中的指定数据，如果数据不存在则报错。# discard()，删除集合中的指定数据，如果数据不存在也不会报错。# pop()，随机删除集合中的某个数据，并返回这个数据。s1 = &#123;10, 20, 30, 40, 50&#125;del_num = s1.pop()print(del_num)print(s1)\"\"\"常见操作- 增加数据 - add() - update()- 删除数据 - remove() - discard()\"\"\"\"\"\"| 运算符 | 描述 | 支持的容器类型 || :----: | :------------: | :----------------------: || + | 合并 | 字符串、列表、元组 || * | 复制 | 字符串、列表、元组 || in | 元素是否存在 | 字符串、列表、元组、字典 || not in | 元素是否不存在 | 字符串、列表、元组、字典 |\"\"\"# 1. 字符串str1 = 'aa'str2 = 'bb'str3 = str1 + str2print(str3) # aabb# 2. 列表list1 = [1, 2]list2 = [10, 20]list3 = list1 + list2print(list3) # [1, 2, 10, 20]# 3. 元组t1 = (1, 2)t2 = (10, 20)t3 = t1 + t2print(t3) # (10, 20, 100, 200)# 1. 字符串print('-' * 10) # ----------# 2. 列表list1 = ['hello']print(list1 * 4) # ['hello', 'hello', 'hello', 'hello']# 3. 元组t1 = ('world',)print(t1 * 4) # ('world', 'world', 'world', 'world')\"\"\"len()计算容器中元素个数del 或 del()删除max()返回容器中元素最大值min()返回容器中元素最小值\"\"\"\"\"\"数据类型转换- tuple()- list()- set()\"\"\"","categories":[],"tags":[]},{"title":"python_入门复习","slug":"python/python-入门复习","date":"2020-05-21T08:28:34.000Z","updated":"2020-05-25T08:23:33.525Z","comments":true,"path":"2020/05/21/python/python-入门复习/","link":"","permalink":"https://esyyes.github.io/2020/05/21/python/python-%E5%85%A5%E9%97%A8%E5%A4%8D%E4%B9%A0/","excerpt":"","text":"python入门复习_变量—循环—条件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397# -*- coding: utf-8 -*-# @Time : 2020/5/21# @Author : esy# python 入门复习\"\"\"注释文件: 多行注释：‘’‘ 。。。’‘’或者“”“。。。”“” 单行注释：# 快捷键 ：ctrl + /\"\"\"'''标识符命名规则是Python中定义各种名字的时候的统一规范，具体如下：- 由数字、字母、下划线组成- 不能数字开头- 不能使用内置关键字- 严格区分大小写变量命名习惯- 大驼峰：即每个单词首字母都大写，例如：`MyName`。- 小驼峰：第二个（含）以后的单词首字母大写，例如：`myName`。- 下划线：例如：`my_name`。''''''Debug工具是PyCharm IDE中集成 用来调试程序的工具，在这里程序员可以查看程序的执行细节和流程或者调解bug。Debug工具使用步骤：1. 打断点2. Debug调试'''\"\"\"检测数据类型的方法：`type()`数据类型- 整型：int- 浮点型：float- 字符串：str- 布尔型：bool- 元组：tuple- 集合：set- 字典：dict\"\"\"\"\"\"- 格式化输出 - 格式化符号 - f-字符串- print的结束符所谓的格式化输出即按照一定的格式输出内容| 格式符号 | 转换 | :------: | :--------------------: | ==%s== | 字符串 | ==%d== | 有符号的十进制整数 | ==%f== | 浮点数 | %c | 字符 | %u | 无符号十进制整数 | %o | 八进制整数 | %x | 十六进制整数（小写ox） | %X | 十六进制整数（大写OX） | %e | 科学计数法（小写'e'） | %E | 科学计数法（大写'E'） | %g | %f和%e的简写 | %G | %f和%E的简写 - %06d，表示输出的整数显示位数，不足以0补全，超出当前位数则原样输出- %.2f，表示小数点后显示的小数位数。格式化字符串除了%s，还可以写为`f'&#123;表达式&#125;'`\"\"\"# print('') or print(\"\")print('hello Python')print(\"hello Python\")# hello Python# hello Pythonage = 18name = 'TOM'weight = 75.5student_id = 1# 我的名字是TOMprint('我的名字是%s' % name)# 我的学号是0001print('我的学号是%4d' % student_id)# 我的体重是75.50公斤print('我的体重是%.2f公斤' % weight)# 我的名字是TOM，今年18岁了print('我的名字是%s，今年%d岁了' % (name, age))# 我的名字是TOM，明年19岁了print('我的名字是%s，明年%d岁了' % (name, age + 1))# 我的名字是TOM，明年19岁了print(f'我的名字是&#123;name&#125;, 明年&#123;age + 1&#125;岁了')\"\"\"- 转义字符 - \\n：换行 - \\t：制表符- print结束符print('内容', end=\"\")\"\"\"\"\"\"输出的 print 函数总结：1. 字符串和数值类型可以直接输出2.变量无论什么类型，数值，布尔，列表，字典...都可以直接输出(1). %字符：标记转换说明符的开始(2). 转换标志：-表示左对齐；+表示在转换值之前要加上正负号；“”（空白字符）表示正数之前保留空格；0表示转换值若位数不够则用0填充(3). 最小字段宽度：转换后的字符串至少应该具有该值指定的宽度。如果是*，则宽度会从值元组中读出。(4). 点(.)后跟精度值：如果转换的是实数，精度值就表示出现在小数点后的位数。如果转换的是字符串，那么该数字就表示最大字段宽度。如果是*，那么精度将从元组中读出 (5).字符串格式化转换类型\"\"\"for x in range(0, 10): print(x, end='\\t')\"\"\"abs(number)，返回数字的绝对值cmath.sqrt(number)，返回平方根，也可以应用于负数float(object)，把字符串和数字转换为浮点数help()，提供交互式帮助input(prompt)，获取用户输入int(object)，把字符串和数字转换为整数math.ceil(number)，返回数的上入整数，返回值的类型为浮点数math.floor(number)，返回数的下舍整数，返回值的类型为浮点数math.sqrt(number)，返回平方根不适用于负数pow(x,y[.z]),返回X的y次幂（有z则对z取模）repr(object)，返回值的字符串标示形式round(number[.ndigits])，根据给定的精度对数字进行四舍五入str(object),把值转换为字符串\"\"\"\"\"\"- 输入功能 - input('提示文字')- 输入的特点 - 一般将input接收的数据存储到变量 - input接收的任何数据默认都是字符串数据类型\"\"\"k = input(\"请输入你的账号：\")print(\"tom的年龄:\", 15 + 5)print('我的名字是%s' % name)\"\"\"转换数据类型常用的函数- int()- float()- str()- list()- tuple()- eval() eval() -- 将字符串中的数据转换成Python表达式原本类型\"\"\"str1 = '10'str2 = '[1, 2, 3]'str3 = '(1000, 2000, 3000)'print(eval(str1))print(eval(str2))print(eval(str3))print(type(eval(str1)))print(type(eval(str2)))print(type(eval(str3)))\"\"\"10[1, 2, 3](1000, 2000, 3000)用eval将数据转换为原有形式，去除两边的''在数据转换中可以用到\"\"\"'''算数运算符| 运算符 | 描述 | 实例 || :----: | :----: | ----------------------------------------------------|| + | 加 | 1 + 1 输出结果为 2 || - | 减 | 1-1 输出结果为 0 || * | 乘 | 2 * 2 输出结果为 4 || / | 除 | 10 / 2 输出结果为 5 || // | 整除 | 9 // 4 输出结果为2 || % | 取余 | 9 % 4 输出结果为 1 || ** | 指数 | 2 ** 4 输出结果为 16，即 2 * 2 * 2 * 2 || () | 小括号 | 小括号用来提高运算优先级，即 (1 + 2) * 3 输出结果为 9 |混合运算优先级顺序：`()`高于 `**` 高于 `*` `/` `//` `%` 高于 `+` `-`复合赋值运算符 | 运算符 | 描述 | 实例 || ------ | -------------- | -------------------------- || += | 加法赋值运算符 | c += a 等价于 c = c + a || -= | 减法赋值运算符 | c -= a 等价于 c = c- a || *= | 乘法赋值运算符 | c *= a 等价于 c = c * a || /= | 除法赋值运算符 | c /= a 等价于 c = c / a || //= | 整除赋值运算符 | c //= a 等价于 c = c // a || %= | 取余赋值运算符 | c %= a 等价于 c = c % a || **= | 幂赋值运算符 | c ** = a 等价于 c = c ** a |比较运算符| 运算符 | 描述 | 实例 || ------ | ------------------------------------------------------------ | -------------------------------------|| == | 判断相等。如果两个操作数的结果相等，则条件结果为真(True)，否则条件结果为假(False) | 如a=3,b=3，则（a == b) 为 True || != | 不等于 。如果两个操作数的结果不相等，则条件为真(True)，否则条件结果为假(False) | 如a=3,b=3，则（a == b) 为 True如a=1,b=3，则(a != b) 为 True || &gt; | 运算符左侧操作数结果是否大于右侧操作数结果，如果大于，则条件为真，否则为假 | 如a=7,b=3，则(a &gt; b) 为 True || &lt; | 运算符左侧操作数结果是否小于右侧操作数结果，如果小于，则条件为真，否则为假 | 如a=7,b=3，则(a &lt; b) 为 False || &gt;= | 运算符左侧操作数结果是否大于等于右侧操作数结果，如果大于，则条件为真，否则为假 | 如a=7,b=3，则(a &lt; b) 为 False如a=3,b=3，则(a &gt;= b) 为 True || &lt;= | 运算符左侧操作数结果是否小于等于右侧操作数结果，如果小于，则条件为真，否则为假 | 如a=3,b=3，则(a &lt;= b) 为 True |逻辑运算符| 运算符 | 逻辑表达式 | 描述 | 实例 || ------ | ---------- | ------------------------------------------------------------ | ------------------ || and | x and y | 布尔\"与\"：如果 x 为 False，x and y 返回 False，否则它返回 y 的值。 | True and False， 返回 False。 || or | x or y | 布尔\"或\"：如果 x 是 True，它返回 True，否则它返回 y 的值。 | False or True， 返回 True。 || not | not x | 布尔\"非\"：如果 x 为 True，返回 False 。如果 x 为 False，它返回 True。 | not True 返回 False, not False 返回 True |'''# 数字之间的逻辑运算a = 0b = 1c = 2# and运算符，只要有一个值为0，则结果为0，否则结果为最后一个非0数字print(a and b) # 0print(b and a) # 0print(a and c) # 0print(c and a) # 0print(b and c) # 2print(c and b) # 1# or运算符，只有所有值为0结果才为0，否则结果为第一个非0数字print(a or b) # 1print(a or c) # 2print(b or c) # 1'''总结：- 算数运算的优先级 - 混合运算优先级顺序：`()`高于 `**` 高于 `*` `/` `//` `%` 高于 `+` `-`- 赋值运算符 - =- 复合赋值运算符 - += - -= - 优先级 1. 先算复合赋值运算符右侧的表达式 2. 再算复合赋值运算的算数运算 3. 最后算赋值运算- 比较运算符 - 判断相等： == - 大于等于： &gt;= - 小于等于：&lt;= - 不等于： !=- 逻辑运算符 - 与： and - 或：or - 非：not'''# round()函数，4舍5入print(f'round(5.3)') # 5print(f'我的名字是&#123;name&#125;, 明年&#123;age + 1&#125;岁了')'''if 条件1: 条件1成立执行的代码elif 条件2: 条件2成立执行的代码else: 以上条件都不成立执行的代码'''age = int(input('请输入您的年龄：'))if age &lt; 18: print(f'您的年龄是&#123;age&#125;,童工一枚')# elif (age &gt;= 18) and (age &lt;= 60):elif 18 &lt;= age &lt;= 60: print(f'您的年龄是&#123;age&#125;,合法工龄')elif age &gt; 60: print(f'您的年龄是&#123;age&#125;,可以退休')# age &gt;= 18 and age &lt;= 60`可以化简为`18 &lt;= age &lt;= 60`。'''随机做法：1. 导出random模块2. random.randint(开始,结束)'''\"\"\"三目运算符也叫三元运算符。# 值1 if 条件 else 值2\"\"\"a = 1b = 2c = a if a &gt; b else bprint(c)# ctrl + c 停止运行# ctrl + d 复制上一行\"\"\"while的语法必须加: i += 1- break退出整个循环- continue退出本次循环，继续执行下一次重复执行的代码- else - while和for都可以配合else使用 - else下方缩进的代码含义：当循环正常结束后执行的代码 - break终止循环不会执行else下方缩进的代码 - continue退出循环的方式执行else下方缩进的代码 for 临时变量 in 序列: 重复执行的代码1 重复执行的代码2 ......while 条件1: 条件1成立执行的代码 ...... while 条件2: 条件2成立执行的代码 ......\"\"\"i = 1result = 0while i &lt;= 100: result += i i += 1# 输出5050print(result)# 重复打印5行星星j = 0while j &lt;= 4: # 一行星星的打印 i = 0 while i &lt;= 4: # 一行内的星星不能换行，取消print默认结束符\\n print('*', end='') i += 1 # 每行结束要换行，这里借助一个空的print，利用print默认结束符换行 print() j += 1# 重复打印5行星星# j表示行号j = 0while j &lt;= 4: # 一行星星的打印 i = 0 # i表示每行里面星星的个数，这个数字要和行号相等所以i要和j联动 while i &lt;= j: print('*', end='') i += 1 print() j += 1# 重复打印9行表达式j = 1while j &lt;= 9: # 打印一行里面的表达式 a * b = a*b i = 1 while i &lt;= j: print(f'&#123;i&#125;*&#123;j&#125;=&#123;j*i&#125;', end='\\t') # end='\\t'制表符 i += 1 print() # 换行 j += 1# 所谓else指的是循环正常结束之后要执行的代码，即如果是break终止循环的情况，else下方缩进的代码将不执行# &gt; 因为continue是退出当前一次循环，继续下一次循环，所以该循环在continue控制下是可以正常结束的，当循环结束后，则执行了else缩进的代码。","categories":[],"tags":[]},{"title":"VF基础知识","slug":"matlab/VF/VF基础知识","date":"2020-05-18T07:17:42.000Z","updated":"2020-05-18T07:17:42.000Z","comments":true,"path":"2020/05/18/matlab/VF/VF基础知识/","link":"","permalink":"https://esyyes.github.io/2020/05/18/matlab/VF/VF%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","excerpt":"","text":"心室纤颤(Ventricular Fibrillation ，VF)心室纤颤(Ventricular Fibrillation ，VF)特点： QRS-T波群完全消失，代之以形态不同、大小各异间距极不匀齐的颤动波(f波)，频率为250～500次/分钟，颤动波之间无等电线。 心室扑动典型的心电图特点 连续而规则、宽大、畸形的QRS波，即心室扑动波。QRS波的时限长，在0.12s以上，QRS波呈向上向下的波幅似正弦样曲线与T波无法分开，QRS波之间无等电线。QRS波频率多在180～250次/分钟，有时可低达150次/分钟或高达300次/分钟。P波消失。 心室纤颤的数据库： 数据长短： 总结：直接选择数据库为VFDB，室颤的，然后根据标签选择室颤的信号，筛选10个的样子，每个10s，然后生成excel表格，再选择正常的数据10段，最后来区分，利用利用python直接来读取数据，然后生成数据组合!再进行预处理。最后筛选出一个算法进行进行分类，并有个准确率输出。 VF数据库含有室颤的数据有：424,426,430 数据长短为：2100s，35min 采样率为：250 首先确定VF和VFIB的位置，将其生成excel文档，10s长短，即2500数据点， python-wfdb截取数据12345678910111213141516171819202122232425262728293031323334# -*- coding: utf-8 -*-# @Time : 2020/5/19# @Author : esyimport wfdb as wfdbimport pandas as pdimport matplotlib.pyplot as pltimport warnings# 忽略警告warnings.filterwarnings(\"ignore\")# 根据标签筛选出室颤信号record = wfdb.rdrecord('F:/VF/VFDB/424', channels=[0], sampfrom=314749, sampto=341173)VF = record.p_signalvf = []for i in range(record.sig_len): vf.append(VF[i][0])vf = vf[5000:7500]fig = plt.figure(figsize=(7, 4))plt.plot(vf, linewidth=1)plt.ylabel(\"U/mv\", fontsize=10)plt.xticks(fontsize=8)plt.xlabel(\"time/s\", fontsize=10)plt.yticks(fontsize=8)plt.show()data = pd.DataFrame(vf)data.to_excel(\"vf1.xlsx\") 筛选10个数据片段 筛选正常数据 下一步就是用算法将其判断出来，写个循环看看，Ndata数据的效果，用pt算法，另外一个也试试 数据片段的筛选，重新保存筛选，先选择算法进行分析。 TCI算法： https://link.springer.com/article/10.1186/1475-925X-4-60 随便设定一个大于250和小于250就行了 纪念下人生第一单哈哈哈 1234567891011121314151617181920212223242526272829303132333435363738394041424344clc;clear;close all% 读取室颤数据data = xlsread(&apos;F:\\VF\\VFdata\\0.xlsx&apos;);% 读取正常数据% data = xlsread(&apos;F:\\VF\\Ndata\\0.xlsx&apos;);% 采样频率fs = 250;% 想要采样的时间长度为10s，所以数据长短通通为2500vf = data(2:2501, 2);% 将采样点的横坐标转换为sN = length(vf);m = 0 : N-1;t = m / fs;% 绘制出原始数据subplot(2,1,1)plot(t,vf,&apos;b&apos;);title(&apos;原始信号&apos;);xlabel(&apos;time/s&apos;);ylabel(&apos;U/mV&apos;);% 可要可不要这一步将数据平滑一下subplot(2,1,2)df = smooth(vf,3);plot(t,df);title(&apos;平滑后的信号&apos;);xlabel(&apos;time/s&apos;);ylabel(&apos;U/mV&apos;);% 利用TCI (Threshold crossing intervals)算法对TCI值进行判断% verbose = 0数据直接输出8个3s窗口的平均值，verbose = 1，进入调试界面verbose = 1;tci = VF_TCI(vf,fs,10,verbose);% VF的频率为250～500次/分钟，转换为ms为120-240ms，即可判定为室颤if (tci &gt;= 120) &amp;&amp; (tci &lt;= 240) disp(&apos;该信号为室颤信号&apos;)else disp(&apos;该信号为正常信号&apos;)end 读取单个的图 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748clc;clear;close all% 数据标签，将VF数据判定为1，正常的判定为0tag = [];for i = 0 : 31 if i &lt;= 18 tag(i+1,1) = 0; else tag(i+1,1) = 1; endend% 循环读取数据，将VF数据判定为1，正常的判定为0num_vf = 0;num_n = 0;all = [];TCI = [];for i = 0 : 31 data = xlsread(['F:\\VF\\all_data\\', num2str(i), '.xlsx']); fs = 250; vf = data(2:2501, 2); tci = VF_TCI(vf,fs,10,0); TCI(i+1,1) = tci; if (tci &gt;= 120) &amp;&amp; (tci &lt;= 240) num_vf = num_vf + 1; all(i+1,1) = 1; else num_n = num_n + 1; all(i+1,1) = 0; endend% 进行比较，用标签和这个你判定的数据进行比较ALL = 32;True = 0;F = 0;for i = 0 : 31 if all(i+1,1) == tag(i+1,1) True = True + 1; else F = F + 1; end end% 输出得到判定准确的值，差不多准确率就基本可以了，毕竟100%了，再转换为百分数ACR = True / ALL;accuracy = strcat(num2str(ACR * 100),'%');disp(['准确率为:',accuracy]); 输出为准确率 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123function tci = VF_TCI(xf,fs,wL,verbose)% INPUT:% - xf: ecg signal (preprocessed)% - fs: sampling frequency% - wL: window length, in seconds % - verbose: debugging variable (1: plot; 0: default, not ploting)%% OUTPUT% - tci parameterwl = 1*fs; % 1-sec window sampleswa = 3*fs; % 3-sec window samplesL = wL-3+1; % number of 3-sec windows in wl segment %becg = zeros(1,wa);becg1 = zeros(1,wl);becg2 = zeros(1,wl);becg3 = zeros(1,wl);tci6 = zeros(1,L);for j=0:L-1 wsamples1 = j*wl+1:(j+1)*wl; wsamples2 = (j+1)*wl+1:(j+2)*wl; wsamples3 = (j+2)*wl+1:(j+3)*wl; stage1 = xf(wsamples1)-mean(xf(wsamples1)); maxv = max(stage1); th1 = 0.2*maxv; becg1(stage1&gt;th1) = 1; stage2 = xf(wsamples2)-mean(xf(wsamples2)); maxv = max(stage2); th2 = 0.2*maxv; becg2(stage2&gt;th2) = 1; stage3 = xf(wsamples3)-mean(xf(wsamples3)); maxv = max(stage3); th3 = 0.2*maxv; becg3(stage3&gt;th3) = 1; becg = [becg1 becg2 becg3]; aux = [0 diff(becg)]; s1 = find(aux(1:wl)==-1); if isempty(s1) t1 = 1; else t1 = (wl-s1(end))/fs; end index = find(aux(wl+1:2*wl)); s2 = aux(wl+1:2*wl); pulses = s2(index); if pulses(1) == -1 &amp;&amp; pulses(end) == -1 t2 = 0; t3 = (wl-index(end))/fs; N = (length(pulses)+1)/2; elseif pulses(1) == 1 &amp;&amp; pulses(end) == 1 t2 = index(1)/fs; t3 = 0; N = (length(pulses)+1)/2; elseif pulses(1) == -1 &amp;&amp; pulses(end) == 1 t2 = 0; t3 = 0; N = (length(pulses)+2)/2; elseif pulses(1) == 1 &amp;&amp; pulses(end) == -1 t2 = index(1)/fs; t3 = (wl-index(end))/fs; N = (length(pulses))/2; else disp('This should not be happening!') keyboard; %better to debug end s4 = find(aux(2*wl+1:3*wl)==1); if isempty(s4) t4 = 1; else t4 = s4(1)/fs; end tci6(j+1) = 1000/((N-1)+(t2/(t1+t2))+(t3/(t3+t4))); %Plot data if verbose f = figure; t = [wsamples1 wsamples2 wsamples3]/fs; stage = [stage1' stage2' stage3']; subplot(211) plot(t,stage); hold on; plot(t,[th1*ones(1,wl) th2*ones(1,wl) th3*ones(1,wl)],'r'); xlabel('time/s'); ylabel('ECG and threshold'); subplot(212); plot(t,becg,'k'); hold on; stem(t,aux,'r'); hold on; line([j+1 j+1],[-1.2 1.2]);line([j+2 j+2],[-1.2 1.2]); axis([t(1) t(end) -1.2 1.2]) xlabel('time/s'); ylabel('pulses'); msg = sprintf('t_1=%2.2f\\t\\t t_2=%2.2f\\t\\t t_3=%2.2f\\t\\t t_4=%2.2f',... t1,t2,t3,t4); title(msg) text(j+1.2,-0.5,['TCI = ' num2str(tci6(j+1))]) hold off % 是否进行调试，观看效果 keyboard; close(f); end becg1 = zeros(1,wa/3); becg2 = zeros(1,wa/3); becg3 = zeros(1,wa/3); endtci = mean(tci6); TCI算法 准确率为100%结束","categories":[],"tags":[]},{"title":"图像识别的目标","slug":"opencv/图像识别的目标","date":"2020-05-05T13:54:25.000Z","updated":"2020-05-05T13:54:25.000Z","comments":true,"path":"2020/05/05/opencv/图像识别的目标/","link":"","permalink":"https://esyyes.github.io/2020/05/05/opencv/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E7%9A%84%E7%9B%AE%E6%A0%87/","excerpt":"","text":"图像识别的学习目标 写一篇专利 专利：利用图像识别技术，识别QRS波形的R波 写一个小论文 利用图像识别来对睡眠进行分类，或者区分是否是OSA和健康人群 把现在这篇小论文写完，然后重新学下数据处理方向的知识，图像处理还是要先理解 5月中旬争取写完小论文","categories":[],"tags":[]},{"title":"python-opencv基础入门","slug":"opencv/python-opencv基础入门","date":"2020-05-05T12:47:17.000Z","updated":"2020-05-05T12:47:17.000Z","comments":true,"path":"2020/05/05/opencv/python-opencv基础入门/","link":"","permalink":"https://esyyes.github.io/2020/05/05/opencv/python-opencv%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"python-Matplotlib视频讲解版","slug":"python/python-Matplotlib视频讲解版","date":"2020-04-12T04:22:04.000Z","updated":"2020-04-12T04:22:04.000Z","comments":true,"path":"2020/04/12/python/python-Matplotlib视频讲解版/","link":"","permalink":"https://esyyes.github.io/2020/04/12/python/python-Matplotlib%E8%A7%86%E9%A2%91%E8%AE%B2%E8%A7%A3%E7%89%88/","excerpt":"","text":"python-Matplotlib视频讲解版视频连接 https://www.bilibili.com/video/BV1tt411e7zF?p=1 1234567891011121314151617181920212223242526# 绘制成一条线形式fig, ax = plt.subplots(figsize=(7, 4))# xy范围plt.ylim((80,100))# 设定xy的尺度大小new_ticks = np.linspace(80, 100, 6)# yticks改变坐标轴的大小plt.yticks(new_ticks, fontsize=8)# 改变标签注释的大小plt.ylabel('Average Accuracy/%', fontsize=10)# 更改横坐标的标签和字体大小，以及转换方向plt.xticks(x,(df.keys()), fontsize=8, rotation=0)l1, = ax.plot(x,y1,color='red',linewidth=1.0,linestyle='--')l2, = ax.plot(x,y2,color='blue',linewidth=3.0,linestyle='--')# 标准图例plt.legend(handles=[l1,l2],labels=['Original model','Optimization model'],loc='best')# shift+tab可以查看图中函数的设置# 改变图的边框颜色ax = plt.gca()ax.spines['right'].set_color('none')ax.spines['top'].set_color('blue')plt.show() https://jishuin.proginn.com/p/7056.html 这个链接中描述了很多绘制 多用shift+tab加来查看函数的说明","categories":[],"tags":[]},{"title":"python_可视化之seaborn","slug":"python/python-可视化之seaborn","date":"2020-03-26T13:16:31.000Z","updated":"2020-03-26T13:16:31.000Z","comments":true,"path":"2020/03/26/python/python-可视化之seaborn/","link":"","permalink":"https://esyyes.github.io/2020/03/26/python/python-%E5%8F%AF%E8%A7%86%E5%8C%96%E4%B9%8Bseaborn/","excerpt":"","text":"python_可视化之seaborn1import seaborn as sns 主题修改： https://matplotlib.org/tutorials/introductory/customizing.html 将自己的主题设定为： 12# 设置风格sns.set_style(\"whitegrid\") https://www.cntofu.com/book/172/docs/20.md 后面还是参考上面网址进行学习，基本已经理清seaborn怎么绘制。 好吧还是使用这个！ https://www.jb51.net/article/104924.htm","categories":[],"tags":[]},{"title":"python——读取excel文件之奇葩数据","slug":"python/python——读取excel文件之奇葩数据","date":"2020-03-25T14:16:10.000Z","updated":"2020-03-25T14:16:10.000Z","comments":true,"path":"2020/03/25/python/python——读取excel文件之奇葩数据/","link":"","permalink":"https://esyyes.github.io/2020/03/25/python/python%E2%80%94%E2%80%94%E8%AF%BB%E5%8F%96excel%E6%96%87%E4%BB%B6%E4%B9%8B%E5%A5%87%E8%91%A9%E6%95%B0%E6%8D%AE/","excerpt":"","text":"python——读取excel文件对应3-25 RFE-RF特征选择进行绘图读取程序12345678# 读取excel表格import pandas as pdimport numpy as np from matplotlib import pyplot as pltdata = pd.read_excel('E:/features/%s.xlsx'%1)data.head()数据如下表所示，在生成excel的时候，直接存的列表，纯属失误 0 1 0 [0.9420289855072463, 0.9710144927536232, 0.956… [0.9710144927536232, 0.9565217391304348, 0.956… 1 [0.7523809523809524, 0.7142857142857143, 0.742… [0.6285714285714286, 0.780952380952381, 0.7523… 2 [0.6761904761904762, 0.819047619047619, 0.9047… [0.7333333333333333, 0.7714285714285715, 0.847… 3 [0.7692307692307693, 0.8717948717948718, 0.910… [0.7307692307692307, 0.8846153846153846, 0.871… 4 [0.7230046948356808, 0.7981220657276995, 0.807… [0.6619718309859155, 0.7417840375586855, 0.737… 一个空格中有运行的25个数据。需要将18个数据组，每个数据运行两次，25个数据，分别取对应的行进行求平均值。 1234train_data = np.array(data)train_x_list = train_data.tolist() #listtrain_x_list[0][0]'[0.9420289855072463, 0.9710144927536232, 0.9565217391304348, 0.9710144927536232, 0.9565217391304348, 0.9565217391304348, 0.9565217391304348, 0.9710144927536232, 0.9710144927536232, 0.9710144927536232, 0.9420289855072463, 0.9565217391304348, 0.9710144927536232, 0.9710144927536232, 0.9565217391304348, 0.9565217391304348, 0.9710144927536232, 0.9565217391304348, 0.9420289855072463, 0.9565217391304348, 0.9420289855072463, 0.9565217391304348, 0.9710144927536232, 0.9565217391304348, 0.9420289855072463]' 先转换为列表，问题1，它表达的是字符串，要先去掉’’ 12eval(train_x_list[0][1])# 转换为列表。用eval()函数 12345678list_mean = []for i in range(18): list_x = eval(train_x_list[i][0]) list_y = eval(train_x_list[i][1]) list_m = [] for j in range(len(list_x)): list_m.append((list_x[j] + list_y[j])/2) list_mean.append(list_m) 生成一个含有18个小列表，已经求了一次平均，每个小列表里面有25个数据组 参考 1234567list_f = []for j in range(25): s = [] for i in range(18): s.append(list_mean[i][j]) c = (np.array(s)).mean() list_f.append(c) 均值化，只有一个25数据的列表 根据这个画图即可 参考 3-19 绘制特征选择曲线 程序","categories":[],"tags":[]},{"title":"python_Accuracy,Precison,Recall,F1 score","slug":"python/python-Accuracy-Precison-Recall-F1-score","date":"2020-03-22T13:31:12.000Z","updated":"2020-03-22T13:31:12.000Z","comments":true,"path":"2020/03/22/python/python-Accuracy-Precison-Recall-F1-score/","link":"","permalink":"https://esyyes.github.io/2020/03/22/python/python-Accuracy-Precison-Recall-F1-score/","excerpt":"","text":"Accuracy,Precison,Recall,F1 score主要参考这两篇博文 https://blog.csdn.net/u014380165/article/details/77493978 https://www.cnblogs.com/laozhanghahaha/p/12374027.html 假设一个二分类问题，样本有正负两个类别。那么模型预测的结果和真实标签的组合就有4种：TP，FP，FN，TN，如下图所示。这4个分别表示：实际为正样本你预测为正样本，实际为负样本你预测为正样本，实际为正样本你预测为负样本，实际为负样本你预测为负样本。 TP(True Positive) － 被正确预测的正例．表示真实值为正，同时也被正确的预测为正； TN(True Negative) －被正确预测的反例．表示真实值为反例，也被正确的预测为反例； FP(False Positive) － 表示真实值为负例，被错误的预测为正例； FN(False Negative)－表示真实值为正例，被错误的预测为反例； 那么Precision和Recall表示什么意思？一般Precision和Recall都是针对某个类而言的，比如正类别的Recall，负类别的Recall等。如果你是10分类，那么可以有1这个类别的Precision，2这个类别的Precision，3这个类别的Recall等。而没有类似全部数据集的Recall或Precision这种说法。 Precison,Recall都对应的2分类，是单独一个类别的准确率 Precision适用场景:当反例被错误的预测为正例（假正例）产生的代价很高的时候，适合用查准率，因为高查准率意味着低假正率/假阳性．比如在垃圾邮件检测中，假正例意味着非垃圾邮件（实际为负）被错误的预测为垃圾邮件（预测为正）．如果一个垃圾邮件监测系统的查准率不高导致很多非垃圾邮件被归到垃圾邮箱里去，那么邮箱用户可能会丢失或者漏看一些很重要的邮件． Recall使用场景:当正例被错误的预测为反例（假反例）产生很高的代价时，用查全率，因为高查全率意味着低假反率/假阴性．比如说在银行的欺诈检测或医院的病患者检测中，如果将欺诈性交易（实际为正）预测为非欺诈性交易（预测为负），则可能会给银行带来非常严重的损失。再比如以最近的新冠疫情为例，如果一个患病者（实际为正）经过试剂检测被预测为没有患病（预测为负），这样的假反例或者说假阴性产生的风险就非常大． 还有一个概念：Accuracy，表示你有多少比例的样本预测对了，公式如下，分母永远是全部样本的数量，很好理解。很容易扩展到多类别的情况，比如10分类，那么分子就是第一个类别预测对了多少个+第二个类别预测对了多少个+…+第十个类别预测对了多少个。 所以用Accuracy来进行判断分类的准确率 F1score的计算是这样的：1/F1score = 1/2(1/recall + 1/precision)*，简单换算后就成了：F1score=2recallprecision/(recall+precision)。同样F1score也是针对某个样本而言的。一般而言F1score用来综合precision和recall作为一个评价指标。还有F1score的变形，主要是添加一个权重系数可以根据需要对recall和precision赋予不同的权重。","categories":[],"tags":[]},{"title":"python_随机森林参数设置","slug":"python/python-随机森林参数设置","date":"2020-03-22T05:37:20.000Z","updated":"2020-03-22T05:37:20.000Z","comments":true,"path":"2020/03/22/python/python-随机森林参数设置/","link":"","permalink":"https://esyyes.github.io/2020/03/22/python/python-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE/","excerpt":"","text":"随机森林参数设置随机森林介绍随机森林定义在机器学习中，随机森林是一个包含多个决策树的分类器， 并且其输出的类别是由个别树输出的类别的众数而定。 Leo Breiman和Adele Cutler发展出推论出随机森林的算法。 而 “Random Forests” 是他们的商标。 这个术语是1995年由贝尔实验室的Tin Kam Ho所提出的随机决策森林（random decision forests）而来的。这个方法则是结合 Breimans 的 “Bootstrap aggregating” 想法和 Ho 的”random subspace method”以建造决策树的集合。 随机森林参数定义https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html https://blog.csdn.net/Longtermevolution/article/details/100919721 n_estimators： 森林中数的个数。这个属性是典型的模型表现与模型效率成反比的影响因子，即便如此，你还是应该尽可能提高这个数字，以让你的模型更准确更稳定。 criterion ： 度量分裂的标准。可选值：“mse”，均方差（mean squared error）；“mae”，平均绝对值误差（mean absolute error） 支持的标准是基尼杂质的“gini（基尼）”和信息增益的“entropy（熵）”。注意：此参数是特定于树的。默认是基尼 max_features ： 寻找最佳分裂点时考虑的特征数目。可选值，int（具体的数目），float（数目的百分比），string（“auto”， “sqrt”，“log2”）.这一属性是对单个树来设置的，通常来讲，这个值越大单棵树可以考虑的属性越多，则模型的表现就越好。但是这也不是肯定的，不过有一点是肯定的，增加这个值会导致算法运行速度变慢，所以需要我们考虑去达到一个平衡。 max_depth :integer或者None。树的最大深度，如果None，节点扩展直到所有叶子是纯的或者所有叶子节点包含的样例数小于min_samples_split min_samples_split ： 分裂内部节点需要的最少样例数。int(具体数目),float(数目的百分比) min_samples_leaf ：叶子节点上应有的最少样例数。int(具体数目),float(数目的百分比)。更少的节点数使得模型更容易遭受noise data的影响，我通常设置这个值大于50，但是你需要寻找最适合你的数值。 min_weight_fraction_leaf ： max_leaf_nodes ：以”最优优先方式”(best-first fashion),最优节点定义为:纯度的相对减少.如果None则不限制叶子节点个数;[float]min_impurity_split : 树增长提前结束的阈值.对于当前节点,大于这个阈值将分裂,否则就看做叶子节点; [float]min_impurity_decrease ：一个阈值,表示一个节点分裂的条件是:如果这次分裂纯度的减少大于等于这这个值.bootstrap ：构建数是不是采用有放回样本的方式(bootstrap samples); [True/False]oob_score ：交叉验证相关的属性。n_jobs ：设定fit和predict阶段并列执行的任务个数,如果设置为-1表示并行执行的任务数等于计算级核数; [integer, optional (default=1)]random_state ：如果是int数值表示它就是随机数产生器的种子.如果指定RandomState实例,它就是随机产生器的种子.如果是None,随机数产生器是np.random所用的RandomState实例; [int, RandomState instance or None, optional (default=None)]verbose ：控制构建数过程的冗长度; [int, optional (default=0)]warm_start ：当设置为True,重新使用之前的结构去拟合样例并且加入更多的估计器(estimators,在这里就是随机树)到组合器中; [True/False]class_weight: “banlanced”模式是根据y标签值自动调整权值与输入数据的类频率成反比,计算公式是:n_samples / (n_classes np.bincount(y)).“balanced_subsample”模式的与”balanced模式相同,只不过在每一次树增长过程中权值的计算是根据有放回样本的. 模型调参利器 gridSearchCV（网格搜索）GridSearchCV，它存在的意义就是自动调参，只要把参数输进去，就能给出最优化的结果和参数。但是这个方法适合于小数据集，一旦数据的量级上去了，很难得出结果。这个时候就是需要动脑筋了。数据量比较大的时候可以使用一个快速调优的方法——坐标下降。它其实是一种贪心算法：拿当前对模型影响最大的参数调优，直到最优化；再拿下一个影响最大的参数调优，如此下去，直到所有的参数调整完毕。这个方法的缺点就是可能会调到局部最优而不是全局最优，但是省时间省力，巨大的优势面前，还是试一试吧，后续可以再拿bagging再优化。 2.参数说明class sklearn.model_selection.GridSearchCV(estimator, param_grid, scoring=None, fit_params=None, n_jobs=1, iid=True, refit=True, cv=None, verbose=0, pre_dispatch=‘2*n_jobs’, error_score=’raise’, return_train_score=’warn’) （1） estimator\\ 选择使用的分类器，并且传入除需要确定最佳的参数之外的其他参数。每一个分类器都需要一个scoring参数，或者score方法：estimator=RandomForestClassifier(min_samples_split=100,min_samples_leaf=20,max_depth=8,max_features=’sqrt’,random_state=10), （2） param_grid\\ 需要最优化的参数的取值，值为字典或者列表，例如：param_grid =param_test1，param_test1 = {‘n_estimators’:range(10,71,10)}。 （3） scoring=None\\ 模型评价标准，默认None,这时需要使用score函数；或者如scoring=’roc_auc’，根据所选模型不同，评价准则不同。字符串（函数名），或是可调用对象，需要其函数签名形如：scorer(estimator, X, y)；如果是None，则使用estimator的误差估计函数。具体值的选取看本篇第三节内容。 （4） fit_params=None\\ （5） n_jobs=1\\ n_jobs: 并行数，int：个数,-1：跟CPU核数一致, 1:默认值 （6） iid=True\\ iid:默认True,为True时，默认为各个样本fold概率分布一致，误差估计为所有样本之和，而非各个fold的平均。 （7） refit=True\\ 默认为True,程序将会以交叉验证训练集得到的最佳参数，重新对所有可用的训练集与开发集进行，作为最终用于性能评估的最佳模型参数。即在搜索参数结束后，用最佳参数结果再次fit一遍全部数据集。 （8） cv=None\\ 交叉验证参数，默认None，使用三折交叉验证。指定fold数量，默认为3，也可以是yield训练/测试数据的生成器。 （9） verbose=0\\, *scoring=None* verbose：日志冗长度，int：冗长度，0：不输出训练过程，1：偶尔输出，&gt;1：对每个子模型都输出。 （10） pre_dispatch=‘2*n_jobs’\\ 指定总共分发的并行任务数。当n_jobs大于1时，数据将在每个运行点进行复制，这可能导致OOM，而设置pre_dispatch参数，则可以预先划分总共的job数量，使数据最多被复制pre_dispatch次 （11） error_score=’raise’\\ （12） return_train_score=’warn’\\ 如果“False”，cv_results_属性将不包括训练分数 回到sklearn里面的GridSearchCV，GridSearchCV用于系统地遍历多种参数组合，通过交叉验证确定最佳效果参数。 打算使用网格搜索对模型进行调优，然后再进行交叉验证！ 步骤实现： 想让树的数目从10到100 生成一个10,100的列表 list(range(10,100)) 构建循环 实现代码 12345678910111213# 初始化模型rfc = RandomForestClassifier()tuned_parameter = [&#123; 'n_estimators':list(range(10, 100))&#125;]对模型进行交叉验证，# 将训练/测试数据集划分10个互斥子集# kflod = StratifiedKFold(n_splits=10, shuffle = True,random_state=7)# 将模型进行网格搜索调优clf = GridSearchCV(estimator=rfc,param_grid=tuned_parameter, cv=kflod, n_jobs=1)clf.fit(X_train, y_train)# 将模型进行网格搜索调优print(\"Best: %f using %s\" % (clf.best_score_,clf.best_params_))out： Best: 0.912500 using &#123;'n_estimators': 28&#125; 没啥必要循环了，每次都在变，选个最高的模型越复杂越好，就选14的倍数，28 参考博客参考这篇对模型进行优化，还可以用下这个模型 https://blog.csdn.net/weixin_41988628/article/details/83098130 123456789101112131415161718192021222324252627282930313233343536373839import pandas as pd # 数据科学计算工具import numpy as np # 数值计算工具import matplotlib.pyplot as plt # 可视化import seaborn as sns # matplotlib的高级APIfrom sklearn.model_selection import StratifiedKFold #交叉验证from sklearn.model_selection import GridSearchCV #网格搜索from sklearn.model_selection import train_test_split #将数据集分开成训练集和测试集from xgboost import XGBClassifier #xgboostpima = pd.read_csv(\"pima_indians-diabetes.csv\")print(pima.head())x = pima.iloc[:,0:8]y = pima.iloc[:,8]seed = 7 #重现随机生成的训练test_size = 0.33 #33%测试，67%训练X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=test_size, random_state=seedmodel = XGBClassifier() learning_rate = [0.0001,0.001,0.01,0.1,0.2,0.3] #学习率gamma = [1, 0.1, 0.01, 0.001]param_grid = dict(learning_rate = learning_rate,gamma = gamma)#转化为字典格式，网络搜索要求kflod = StratifiedKFold(n_splits=10, shuffle = True,random_state=7)#将训练/测试数据集划分10个互斥子集，grid_search = GridSearchCV(model,param_grid,scoring = 'neg_log_loss',n_jobs = -1,cv = kflod)#scoring指定损失函数类型，n_jobs指定全部cpu跑，cv指定交叉验证grid_result = grid_search.fit(X_train, Y_train) #运行网格搜索print(\"Best: %f using %s\" % (grid_result.best_score_,grid_search.best_params_))#grid_scores_：给出不同参数情况下的评价结果。best_params_：描述了已取得最佳结果的参数的组合#best_score_：成员提供优化过程期间观察到的最好的评分#具有键作为列标题和值作为列的dict，可以导入到DataFrame中。#注意，“params”键用于存储所有参数候选项的参数设置列表。means = grid_result.cv_results_['mean_test_score']params = grid_result.cv_results_['params']for mean,param in zip(means,params): print(\"%f with: %r\" % (mean,param)) 忽略警告每次都会出现一大堆的红字，看到就不舒服，以后将这个作为第一个 12import warningswarnings.filterwarnings(\"ignore\") 在PyCharm中提示shadows name ‘xxxx’ from outer scope，当你在外部有个相同名称的变量在方法内部被重新指定了新的值，也就是说你在外部的相同名称的变量压根就没有任何作用。所以PyCharm就回提示这个信息。这个时候就需要我们去调整具体代码了。 意思就是在pycharm中，函数中的变量最好跟外部的变量不一样，要不然就会警告","categories":[],"tags":[]},{"title":"python_文件存取操作","slug":"python/python-文件存取操作","date":"2020-03-21T06:50:12.000Z","updated":"2020-03-21T06:50:12.000Z","comments":true,"path":"2020/03/21/python/python-文件存取操作/","link":"","permalink":"https://esyyes.github.io/2020/03/21/python/python-%E6%96%87%E4%BB%B6%E5%AD%98%E5%8F%96%E6%93%8D%E4%BD%9C/","excerpt":"","text":"python_文件存取操作123456789# 读取第一个数据f = open(r'E:/test.txt', 'r')result = []for line in f.readlines(): result.append(list(map(str, line.split(','))))# 将列表中的数据从第5列后开始删除for i in range(len(result)): del result[i][4:] 删除列表后面的几列 1del result[i][4:] [‘1729162717’, ‘2169702956’, ‘57181’, ‘59445’] 删除引号 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# -*- coding: utf-8 -*-# @Time : 2020/3/21# @Author : esyimport pandas as pdimport numpy as np# 读取txt文件f = open(r'E:/test.txt', 'r')result = []for line in f.readlines(): result.append(list(map(str, line.split(','))))# 删除指定的列for i in range(len(result)): del result[i][-2:-1]data2 = result# # 将str数据转换为整数# data2 = []# for j in range(len(result)):# list2 = []# for i in range(len(result[j])):# list2.append(int(result[j][i]))# data2.append(list2)# 读取xlsx文件，是转换为datarafmedf = pd.read_excel('E:/tt.xlsx')data = pd.get_dummies(df.iloc[0:])# 0插补data = data.fillna(0)# 将其转换为数组train_data = np.array(data)# 将其转换为列表train_x_list = train_data.tolist() #list# 将列表叠加到后面去data1 = []for j in range(len(train_x_list)): list1 = [] for i in range(len(train_x_list[j])): list1.append(int(train_x_list[j][i])) data1.append(list1)# 批量保存文件now = []for j in range(90): shu = [] for i in range(len(data1)): # 指定列进行添加数据 data2[i].insert(7, int(data1[i][j])) shu.append(data2[i]) now.append(shu) # 保存文件 np.savetxt(\"E:/3211/%s.txt\"%j, now[j], fmt='%s', delimiter=',') for s in range(len(data2)): del data2[s][-2:-1]print(\"1\") 其实根本没必要删除引号，再进行保存文件时，就已经删除了引号","categories":[],"tags":[]},{"title":"python_Matplotlib","slug":"python/python-Matplotlib","date":"2020-03-19T07:38:53.000Z","updated":"2020-03-19T07:38:53.000Z","comments":true,"path":"2020/03/19/python/python-Matplotlib/","link":"","permalink":"https://esyyes.github.io/2020/03/19/python/python-Matplotlib/","excerpt":"","text":"python_Matplotlib参考这个即可 https://www.jb51.net/article/168302.htm 1from matplotlib import pyplot as plt 横纵坐标的确定，以绘制特征选择曲线为例。 1234import numpy as np from matplotlib import pyplot as pltx = np.arange(1, 25)y为N123RW,DLRW,SRW 绘制最简单的图像 1234x = np.arange(1, 25)y1 = N123RWy2 = DLRWy3 = SRW 12345plt.plot(x,y1) plt.xlabel(\"Characteristic number\") plt.ylabel(\"Accuracy of RF\")plt.title(\"Feature elimination based on DBT and RFE\")plt.show() 对点进行标记1234plt.plot(x,y1,\"*r\")# 只有点plt.plot(x,y1,\"*r--\")# 带虚线的点 &#39;-&#39; 实线样式 &#39;--&#39; 短横线样式 &#39;-.&#39; 点划线样式 &#39;:&#39; 虚线样式 &#39;.&#39; 点标记 &#39;,&#39; 像素标记 &#39;o&#39; 圆标记 &#39;v&#39; 倒三角标记 &#39;^&#39; 正三角标记 &#39;&lt;&#39; 左三角标记 &#39;&gt;&#39; 右三角标记 &#39;1&#39; 下箭头标记 &#39;2&#39; 上箭头标记 &#39;3&#39; 左箭头标记 &#39;4&#39; 右箭头标记 &#39;s&#39; 正方形标记 &#39;p&#39; 五边形标记 &#39;*&#39; 星形标记 &#39;h&#39; 六边形标记 1 &#39;H&#39; 六边形标记 2 &#39;+&#39; 加号标记 &#39;x&#39; X 标记 &#39;D&#39; 菱形标记 &#39;d&#39; 窄菱形标记 `’ ‘` &#39;_&#39; 水平线标记 字符 颜色 &#39;b&#39; 蓝色 &#39;g&#39; 绿色 &#39;r&#39; 红色 &#39;c&#39; 青色 &#39;m&#39; 品红色 &#39;y&#39; 黄色 &#39;k&#39; 黑色 &#39;w&#39; 白色 问题图像不清晰，横坐标想用12345-25表示，字体太小 123456789101112131415161718192021222324252627282930313233属性 值类型alpha 浮点值animated [True / False]antialiased or aa [True / False]clip_box matplotlib.transform.Bbox 实例clip_on [True / False]clip_path Path 实例， Transform，以及Patch实例color or c 任何 matplotlib 颜色contains 命中测试函数dash_capstyle ['butt' / 'round' / 'projecting']dash_joinstyle ['miter' / 'round' / 'bevel']dashes 以点为单位的连接/断开墨水序列data (np.array xdata, np.array ydata)figure matplotlib.figure.Figure 实例label 任何字符串linestyle or ls [ '-' / '--' / '-.' / ':' / 'steps' / ...]linewidth or lw 以点为单位的浮点值lod [True / False]marker [ '+' / ',' / '.' / '1' / '2' / '3' / '4' ]markeredgecolor or mec 任何 matplotlib 颜色markeredgewidth or mew 以点为单位的浮点值markerfacecolor or mfc 任何 matplotlib 颜色markersize or ms 浮点值markevery [ None / 整数值 / (startind, stride) ]picker 用于交互式线条选择pickradius 线条的拾取选择半径solid_capstyle ['butt' / 'round' / 'projecting']solid_joinstyle ['miter' / 'round' / 'bevel']transform matplotlib.transforms.Transform 实例visible [True / False]xdata np.arrayydata np.arrayzorder 任何数值 123# 显示中文mpl.rcParams['font.sans-serif'] = ['FangSong'] # 指定默认字体 mpl.rcParams['axes.unicode_minus'] = False # 解决保存图像是负号'-'显示为方块的问题 黑体 SimHei 微软雅黑 Microsoft YaHei 微软正黑体 Microsoft JhengHei 新宋体 NSimSun 新细明体 PMingLiU 细明体 MingLiU 标楷体 DFKai-SB 仿宋 FangSong 楷体 KaiTi 仿宋_GB2312 FangSong_GB2312 楷体_GB2312 KaiTi_GB2312 1234#颜色、标记和线型plt.figure()##linestyle设置线型，color设置颜色,marker设置设置连接点plt.plot(numpy.random.randn(30).cumsum(),linestyle='--',color='g',marker='o') 参考这个 https://www.jb51.net/article/168302.htm 123456789#设置标题、轴标签，刻度以及刻度标签fig = plt.figure() #创建figure对象ax = fig.add_subplot(1,1,1) #获得Axes对象ax.plot(numpy.random.randn(1000).cumsum()) #生成随机数ax.set_xticks([0,250,500,750,1000]) #设置x轴刻度ax.set_yticks([-20,-10,0,10,20]) #设置y轴刻度ax.set_title('My first matplotlib plot') #设置标题ax.set_xlabel('Xtages') #设置x轴标签ax.set_ylabel('Ytages') #设置y轴标签 123plt.annotate(\"Important value\", (55,20), xycoords='data', #添加注释的方法 xytext=(5, 38), arrowprops=dict(arrowstyle='-&gt;')) 1234567891011121314151617181920212223# 调整图像的大小fig = plt.figure(figsize=(12,6))#解决中文显示问题plt.rcParams['font.sans-serif']=['Microsoft YaHei']plt.rcParams['axes.unicode_minus'] = False# 标记图的序号# fig.suptitle('1') # 改变横纵坐标plt.xticks(x)# 绘制图像，r*--颜色，点的标记，线段模式，label标签的名字，linewidth线的宽度plt.plot(x,y1,\"r*--\", label='N123RW',linewidth=0.25 )plt.plot(x,y2,\"ks--\", label='DLRW',linewidth=0.25)plt.plot(x,y3,\"gp--\", label='SRW',linewidth=0.25)# 显示标签，默认为axis=0左上角plt.legend()# fontsize字体大小plt.xlabel(\"Characteristic number\", fontsize = 15) plt.xticks(fontsize=10)plt.ylabel(\"Accuracy of RF\", fontsize = 15)plt.yticks(fontsize=10)plt.title(\"Feature elimination based on DBT and RFE\", fontsize = 15)plt.show()fig.savefig('features.png',dpi = 400,bbox_inches='tight')","categories":[],"tags":[]},{"title":"python——OpenCV初接触","slug":"opencv/python——OpenCV初接触","date":"2020-03-08T13:43:17.000Z","updated":"2020-03-08T13:43:17.000Z","comments":true,"path":"2020/03/08/opencv/python——OpenCV初接触/","link":"","permalink":"https://esyyes.github.io/2020/03/08/opencv/python%E2%80%94%E2%80%94OpenCV%E5%88%9D%E6%8E%A5%E8%A7%A6/","excerpt":"","text":"OpenCV初接触 github问题解决github出问题了公共秘钥的问题,不能进行打开和下载，而且github也出现问题，各种不显示。 已经解决： 对浏览器进行删除浏览记录，消除cookie;然后可以正常进行登录了。 问题2，登录慢；ping github.com请求超时的问题；https://www.cnblogs.com/findview/p/11720245.html opencv-python下载pip insatll opencv-python pip install opencv-contrib-python pip install ptesseract 首先进行安装，实在是慢，我先看下文献；希望别出错！！！ opencv-python安装python版本：3.7.5 1.进入清华镜像 https://blog.csdn.net/qq_38327353/article/details/88847694?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task 2.下载opencv-python对应的版本，whl文件 3.用pip install (whl)文件进行安装 4.以后下载安装还是直接找包或者镜像，要不然国外的太慢。 opencv-python测试import cv2 测试成功。 opencv-python图片读取问题opencv读取的图片格式cv2读取的图片通道是按照BGR排列的，而非RGB顺序。因此工程中opencv库与其他库混用的时候要注意，可以使用img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) 貌似图片都可以读取 利用jupyter读取图片，毕竟这个可以保存。 opencv读取图片图片的样子 1234import cv2 as cvimg = cv.imread(\"C:/Users/86184/Desktop/111.jfif\") cv.imshow(\"miao\",img)cv.waitKey() #在imshow之后如果没有waitkey语句则不会正常显示图像","categories":[],"tags":[]},{"title":"2-28汇报","slug":"hexo/2-28汇报","date":"2020-02-28T02:31:53.000Z","updated":"2020-02-28T02:31:53.000Z","comments":true,"path":"2020/02/28/hexo/2-28汇报/","link":"","permalink":"https://esyyes.github.io/2020/02/28/hexo/2-28%E6%B1%87%E6%8A%A5/","excerpt":"","text":"2-28汇报 按照AASM分期标准，以30s为一个分期间隔，而心率变异性按照（Heart rate variability：Standards of measurement, physiological interpretation, and clinical use）标准是5分钟为一个分析阶段，大部分文献都是直接将5分钟来替换对应的30s分期标准来进行特征分析，打算将对应的分期标签和5min和30s都进行分析特征，进行对比效果。 为了消除异常值的影响，将每个RR值与以测试值为中心的21点矩形窗口内的平均值(MRR)进行比较。如果RR小于0.5MRR或大于1.5MRR，则替换为MRR创新点：即可描述为19个，小于0.55，大于1.55，将其进行比较，如果小于0.55，则判定为过检，则叠加到前一个数据，相应的删除对应的R峰值点的坐标如果大于1.55，则判定为漏检，则将RR/MRR=m,取整m,再将RR分为m份，相应的横坐标locs则叠加mRR。 根据这个（Sleep stages classification based on heart rate variability and random forest） 文献说法： 为了消除异常值的影响，将每个RR值与以测试值为中心的21点矩形窗口内的平均值(MRR)进行比较。如果RR小于0.5MRR*或大于*1.5MRR，则替换为MRR 自己处理：即可描述为19个，小于0.55，大于1.55，将其进行比较，如果小于0.55，则判定为过检，则叠加到前一个数据，相应的删除对应的R峰值点的坐标 如果大于1.55，则判定为漏检，则将RR/MRR=m,取整m,再将RR分为m份，相应的横坐标locs则叠加mRR。 总结7806个数据点，用算法提取到的是7810个，消除了4个，可以忽略不计，时频域的特征提取效果差别不大。","categories":[],"tags":[]},{"title":"python","slug":"python/python——呼吸音特征","date":"2020-02-26T12:58:00.000Z","updated":"2020-02-26T12:58:00.000Z","comments":true,"path":"2020/02/26/python/python——呼吸音特征/","link":"","permalink":"https://esyyes.github.io/2020/02/26/python/python%E2%80%94%E2%80%94%E5%91%BC%E5%90%B8%E9%9F%B3%E7%89%B9%E5%BE%81/","excerpt":"","text":"找到呼吸音的特征。已经ECG信号滤波为呼吸信号，这两个的特征，还有R峰值的信号点的特征","categories":[],"tags":[]},{"title":"python——特征选择和优化","slug":"python/python——特征选择和优化","date":"2020-02-26T07:33:12.000Z","updated":"2020-02-26T07:33:12.000Z","comments":true,"path":"2020/02/26/python/python——特征选择和优化/","link":"","permalink":"https://esyyes.github.io/2020/02/26/python/python%E2%80%94%E2%80%94%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E5%92%8C%E4%BC%98%E5%8C%96/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"python_wfdb使用","slug":"python/python-wfdb使用","date":"2020-02-15T14:42:29.000Z","updated":"2020-02-15T14:42:29.000Z","comments":true,"path":"2020/02/15/python/python-wfdb使用/","link":"","permalink":"https://esyyes.github.io/2020/02/15/python/python-wfdb%E4%BD%BF%E7%94%A8/","excerpt":"","text":"python_wfdb使用","categories":[],"tags":[]},{"title":"python模块的构建和调用","slug":"python/python模块的构建和调用","date":"2020-02-09T08:55:02.000Z","updated":"2020-02-09T08:55:02.000Z","comments":true,"path":"2020/02/09/python/python模块的构建和调用/","link":"","permalink":"https://esyyes.github.io/2020/02/09/python/python%E6%A8%A1%E5%9D%97%E7%9A%84%E6%9E%84%E5%BB%BA%E5%92%8C%E8%B0%83%E7%94%A8/","excerpt":"","text":"python模块的构建和调用代码运行出来太大了，看起来没那么好看，所以，需要进行处理，异常点还是要处理下，毕竟还可以得到一个时域特征。 异常点处理还是需要考虑到漏点这些情况，在这个里面就不需要了，但是在其他程序里面还是需要，因此找下相关的R峰值点查找的问题。 模块又要考虑两个问题，一个函数的构建，一个事模块的构建和调用。先看下别人的博客，关于时频域特征的提取问题前面不是看到个。 1.heartpy库https://blog.csdn.net/weixin_45414380/article/details/100084696 直接对其进行应用 https://github.com/paulvangentcom/heartrate_analysis_python 查看heartpy库的说明。 https://python-heart-rate-analysis-toolkit.readthedocs.io/en/latest/ 有点不想看了。明天再说。 安装起了，把包都升级下","categories":[],"tags":[]},{"title":"python——滑动切片之数组","slug":"python/python——滑动切片之数组","date":"2020-02-08T05:45:57.000Z","updated":"2020-02-08T05:45:57.000Z","comments":true,"path":"2020/02/08/python/python——滑动切片之数组/","link":"","permalink":"https://esyyes.github.io/2020/02/08/python/python%E2%80%94%E2%80%94%E6%BB%91%E5%8A%A8%E5%88%87%E7%89%87%E4%B9%8B%E6%95%B0%E7%BB%84/","excerpt":"","text":"属性 说明 ndarray.ndim 秩，即轴的数量或维度的数量 ndarray.shape 数组的维度，对于矩阵，n 行 m 列 ndarray.size 数组元素的总个数，相当于 .shape 中 n*m 的值 ndarray.dtype ndarray 对象的元素类型 ndarray.itemsize ndarray 对象中每个元素的大小，以字节为单位 ndarray.flags ndarray 对象的内存信息 ndarray.real ndarray元素的实部 ndarray.imag ndarray 元素的虚部 ndarray.data 包含实际数组元素的缓冲区，由于一般通过数组的索引获取元素，所以通常不需要使用这个属性。 数组的切片： ndarray对象的内容可以通过索引或切片来访问和修改，与 Python 中 list 的切片操作一样。 ndarray 数组可以基于 0 - n 的下标进行索引，切片对象可以通过内置的 slice 函数，并设置 start, stop 及 step 参数进行，从原数组中切割出一个新数组。 12345import numpy as np a = np.arange(10) b = a[2:7:2] # 从索引 2 开始到索引 7 停止，间隔为 2print(b) 数组的详细介绍 https://www.runoob.com/numpy/numpy-ndexing-and-slicing.html 还是需要用到循环结果 进行30s切片，并得到RR系列： 12345678910i = 0locs_30s = []RR = []while locs[i] &lt; 7500: locs_30s.append(locs[i]) RR.append(locs[i+1] - locs[i]) i += 1RR.pop()print(RR)[215, 223, 230, 224, 226, 223, 221, 227, 221, 215, 216, 213, 217, 227, 237, 245, 242, 239, 247, 249, 246, 239, 231, 234, 235, 237, 236, 226, 222, 224, 228, 226] 循环切片先不管RR系列 12345678910111213141516171819202122232425# 考虑它的片段个数240# 先考虑ECG片段的分段，分为240个30s的数据，毕竟这个为等距离的，列表里面放列表# 建立一个空元组tuple1 = []i = 0while i &lt; (ECG_LEN / 250 / 30) - 1: j = 0 locs_30s = []# RR = [] while locs[j] &lt; 7500 * (i + 1): if locs[j] &gt;= 7500 * i: locs_30s.append(locs[j])# C = locs[j+1] - locs[j]# RR.append(C) j+=1 print(locs_30s) tuple1.append(locs_30s) i += 1print(i)print(tuple1)[19, 234, 457, 687, 911, 1137, 1360, 1581, 1808, 2029, 2244, 2460, 2673, 2890, 3117, 3354, 3599, 3841, 4080, 4327, 4576, 4822, 5061, 5292, 5526, 5761, 5998, 6234, 6460, 6682, 6906, 7134, 7360][7578, 7787, 7993, 8202, 8418, 8643, 8874, 9104, 9352, 9606, 9857, 10106, 10343, 10577, 10808, 11038, 11268, 11490, 11710, 11933, 12165, 12407, 12647, 12873, 13093, 13306, 13520, 13736, 13954, 14176, 14414, 14664, 14912][15159, 15400, 15634, 15875, 16114, 16352, 16583, 16809, 17038, 17266, 17497, 17728, 17946, 18159, 18368, 18575, 18787, 19007, 19230, 19455, 19691, 19934, 20178, 20416, 20654, 20898, 21143, 21387, 21619, 21845, 22071, 22301][22532, 22757, 22968, 23180, 23393, 23612, 23842, 24077, 24325, 24582, 24846, 25109, 25362, 25608, 25856, 26106, 26356, 26598, 26830, 27055, 27280, 27498, 27710, 27921, 28133, 28352, 28585, 28819, 29057, 29306, 29554, 29798][30054, 30314, 30573, 30824, 31070, 31313, 31555, 31793, 32029, 32258, 32490, 32727, 32961, 33195, 33425, 33652, 33880, 34110, 34337, 34562, 34782, 35007, 35236, 35473, 35710, 35943, 36174, 36409, 36653, 36899, 37138, 37369] 得到一个大的列表，里面包含很多个小的列表， while i &lt; (ECG_LEN / 250 / 30) - 1:在编写时，一定要考虑i的区间范围，要不然会超出范围，导致程序出错，虽然有结果，但是无法正常运行，在进行时通过计算-1可得到完整的数据，毕竟后面有个 while locs[j] &lt; 7500 * (i + 1): 123456789101112131415161718192021list_RR = []i = 0while i &lt; (ECG_LEN / 250 / 30) - 1: j = 0 locs_30s = [] RR = [] while locs[j] &lt; 7500 * (i + 1): if locs[j] &gt;= 7500 * i: locs_30s.append(locs[j]) C = locs[j+1] - locs[j] RR.append(C) j+=1 print(RR) list_RR.append(RR) i += 1print(i)print(list_RR)[215, 223, 230, 224, 226, 223, 221, 227, 221, 215, 216, 213, 217, 227, 237, 245, 242, 239, 247, 249, 246, 239, 231, 234, 235, 237, 236, 226, 222, 224, 228, 226, 218][209, 206, 209, 216, 225, 231, 230, 248, 254, 251, 249, 237, 234, 231, 230, 230, 222, 220, 223, 232, 242, 240, 226, 220, 213, 214, 216, 218, 222, 238, 250, 248, 247][241, 234, 241, 239, 238, 231, 226, 229, 228, 231, 231, 218, 213, 209, 207, 212, 220, 223, 225, 236, 243, 244, 238, 238, 244, 245, 244, 232, 226, 226, 230, 231][225, 211, 212, 213, 219, 230, 235, 248, 257, 264, 263, 253, 246, 248, 250, 250, 242, 232, 225, 225, 218, 212, 211, 212, 219, 233, 234, 238, 249, 248, 244, 256] 得到以5分钟为片段的30s滑窗的矩阵 123456789101112131415161718list_RR = []i = 0while i &lt; (ECG_LEN / 250 / 30) - 11: j = 0 locs_300s = [] RR = [] while locs[j] &lt; 75000 + 7500 * i: if locs[j] &gt;= 7500 * i: locs_30s.append(locs[j]) C = locs[j+1] - locs[j] RR.append(C) j+=1 RR.pop() # 删除列表的最后一个，毕竟将数据多加了一个1，进行了运算 print(RR) list_RR.append(RR) # 将每个运行的列表叠加在一个列表上，构成一个大的列表 i += 1print(list_RR)[215, 223, 230, 224, 226, 223, 221, 227, 221, 215, 216, 213, 217, 227, 237, 245, 242, 239, 247, 249, 246, 239, 231, 234, 235, 237, 236, 226, 222, 224, 228, 226, 218, 209, 206, 209, 216, 225, 231, 230, 248, 254, 251, 249, 237, 234, 231, 230, 230, 222, 220, 223, 232, 242, 240, 226, 220, 213, 214, 216, 218, 222, 238, 250, 248, 247, 241, 234, 241, 239, 238, 231, 226, 229, 228, 231, 231, 218, 213, 209, 207, 212, 220, 223, 225, 236, 243, 244, 238, 238, 244, 245, 244, 232, 226, 226, 230, 231, 225, 211, 212, 213, 219, 230, 235, 248, 257, 264, 263, 253, 246, 248, 250, 250, 242, 232, 225, 225, 218, 212, 211, 212, 219, 233, 234, 238, 249, 248, 244, 256, 260, 259, 251, 246, 243, 242, 238, 236, 229, 232, 237, 234, 234, 230, 227, 228, 230, 227, 225, 220, 225, 229, 237, 237, 233, 231, 235, 244, 246, 239, 231, 231, 229, 228, 226, 222, 226, 224, 214, 215, 212, 216, 223, 232, 236, 238, 232, 240, 244, 248, 239, 232, 231, 231, 232, 230, 227, 226, 235, 238, 238, 233, 227, 223, 214, 207, 202, 204, 210, 227, 245, 258, 254, 251, 255, 246, 248, 237, 227, 230, 227, 227, 230, 229, 232, 237, 239, 237, 230, 227, 235, 237, 234, 228, 230, 221, 222, 220, 221, 234, 244, 250, 247, 242, 247, 248, 247, 242, 231, 230, 232, 233, 233, 228, 227, 228, 229, 229, 217, 207, 207, 207, 213, 221, 227, 227, 228, 234, 238, 237, 230, 231, 234, 234, 232, 225, 222, 224, 229, 233, 225, 226, 228, 231, 234, 224, 217, 225, 231, 240, 246, 241, 240, 247, 254, 249, 234, 237, 236, 242, 241, 234, 227, 223, 214, 209, 208, 207, 210, 219, 227, 234, 235, 231, 238, 237, 238, 236, 231, 224, 226, 222, 214, 207, 206, 212, 220, 230, 233, 233, 236, 243, 246, 244] 两种情况都得到结果 下一步：得到RR序列，首先查看，那个库，然后进行时频域分析，我觉得还是要消除异常点，毕竟为了后面做准备，还可以将其作为一个时域特征。","categories":[],"tags":[]},{"title":"python__滑动切片","slug":"python/python-滑动切片","date":"2020-02-08T02:33:27.000Z","updated":"2020-02-08T02:33:27.000Z","comments":true,"path":"2020/02/08/python/python-滑动切片/","link":"","permalink":"https://esyyes.github.io/2020/02/08/python/python-%E6%BB%91%E5%8A%A8%E5%88%87%E7%89%87/","excerpt":"","text":"PYTHON——滑动切片需求：1.所需要的数据是以5分钟为短程分析 2.注释是以30秒为一个间期 3.以5分钟为片段，30秒为滑动窗口，考虑样本采样率为250，滑动的间隔为250*30=7500个数据点 4.直接用采样峰值点来进行切片，最后放入一个（）中，每个间隔为小矩阵 若为了好写的话，可以直接在python里面找pt算法，在找异常点，在循环，按照matlab的步骤 后面分析的还是这个公开数据库的数据，所以我可以直接按照峰值点来进行计算。 数据样本直接按照读取的峰值点进行提取即可。 1.选取5分钟作为切片首先判定里面数据的类型 1234567891011print(type(locs))print(type(ECG))[[0.085] [0.08 ] [0.125] ... [0.23 ] [0.235] [0.225]]&lt;class 'numpy.ndarray'&gt;&lt;class 'numpy.ndarray'&gt; 1.1 数据系列复习下1.1.1字符串字符串是 Python 中最常用的数据类型。我们一般使用引号来创建字符串。name1 = ‘Tom’ 控制台显示结果为&lt;class &#39;str&#39;&gt;， 即数据类型为str(字符串)。 1234567name = input('请输入您的名字：')print(f'您输入的名字是&#123;name&#125;')print(type(name))password = input('请输入您的密码：')print(f'您输入的密码是&#123;password&#125;')print(type(password)) 1.1.2 下标12345name = \"abcdef\"取到不同下标对应的数据print(name[1])print(name[0])print(name[2]) 1.1.3 切片1序列[开始位置下标:结束位置下标:步长] 注意 1. 不包含结束位置下标对应的数据， 正负整数均可； 2. 步长是选取间隔，正负整数均可，默认步长为1。1234567891011name = \"abcdefg\"print(name[2:5:1]) # cdeprint(name[2:5]) # cdeprint(name[:5]) # abcdeprint(name[1:]) # bcdefgprint(name[:]) # abcdefgprint(name[::2]) # acegprint(name[:-1]) # abcdef, 负1表示倒数第一个数据print(name[-4:-1]) # defprint(name[::-1]) # gfedcba 1.1.4查找所谓字符串查找方法即是查找子串在字符串中的位置或出现的次数。 find()：检测某个子串是否包含在这个字符串中，如果在返回这个子串开始的位置下标，否则则返回-1。 1字符串序列.find(子串, 开始位置下标, 结束位置下标) 注意：开始和结束位置下标可以省略，表示在整个字符串序列中查找。 12345mystr = \"hello world and itcast and itheima and Python\"print(mystr.find('and')) # 12print(mystr.find('and', 15, 30)) # 23print(mystr.find('ands')) # -1 index()：检测某个子串是否包含在这个字符串中，如果在返回这个子串开始的位置下标，否则则报异常。 count()：返回某个子串在字符串中出现的次数 下标 计算机为数据序列中每个元素分配的从0开始的编号 切片 1序列名[开始位置下标:结束位置下标:步长] 常用操作方法 find() index() 1.1.2列表12345678910111213141516L.append(var) #追加元素L.insert(index,var)L.pop(var) #返回最后一个元素，并从list中删除之L.remove(var) #删除第一次出现的该元素L.count(var) #该元素在列表中出现的个数L.index(var) #该元素的位置,无则抛异常L.extend(list6) #追加list６，即合并list到L上,这里注意，使用extend函数可以一次在一个列表中插入任意多个值，而不必须每次只使用append()一次一值的插入L.sort() #排序L.reverse() #倒序del L[1] #删除指定下标的元素del L[1:3] #删除指定下标范围的元素#复制list:L1 = L #L1为L的别名，用C来说就是指针地址相同，对L1操作即对L操作。L1 = L[:] #L1为L的克隆，即另一个拷贝。https://blog.csdn.net/liuyanfeier/article/details/53731239 1[数据1, 数据2, 数据3, 数据4......] 列表可以一次性存储多个数据，且可以为不同数据类型。 1.1.2.1 下标12345name_list = ['Tom', 'Lily', 'Rose']print(name_list[0]) # Tomprint(name_list[1]) # Lilyprint(name_list[2]) # Rose 1.1.2.2 函数 index()：返回指定数据所在位置的下标 。 语法 1列表序列.index(数据, 开始位置下标, 结束位置下标) 快速体验 123name_list = ['Tom', 'Lily', 'Rose']print(name_list.index('Lily', 0, 2)) # 1 注意：如果查找的数据不存在则报错。 count()：统计指定数据在当前列表中出现的次数。 123name_list = ['Tom', 'Lily', 'Rose']print(name_list.count('Lily')) # 1 len()：访问列表长度，即列表中数据的个数。 123name_list = ['Tom', 'Lily', 'Rose']print(len(name_list)) # 3 1.1.2.3 增加作用：增加指定数据到列表中。 append()：列表结尾追加数据。 语法 1列表序列.append(数据) 体验 123456name_list = ['Tom', 'Lily', 'Rose']name_list.append('xiaoming')# 结果：['Tom', 'Lily', 'Rose', 'xiaoming']print(name_list) 列表追加数据的时候，直接在原列表里面追加了指定数据，即修改了原列表，故列表为可变类型数据。 注意点 如果append()追加的数据是一个序列，则追加整个序列到列表 123456name_list = ['Tom', 'Lily', 'Rose']name_list.append(['xiaoming', 'xiaohong'])# 结果：['Tom', 'Lily', 'Rose', ['xiaoming', 'xiaohong']]print(name_list) extend()：列表结尾追加数据，如果数据是一个序列，则将这个序列的数据逐一添加到列表。 语法 1列表序列.extend(数据) 快速体验 2.1 单个数据 123456name_list = ['Tom', 'Lily', 'Rose']name_list.extend('xiaoming')# 结果：['Tom', 'Lily', 'Rose', 'x', 'i', 'a', 'o', 'm', 'i', 'n', 'g']print(name_list) ​ 2.2 序列数据 123456name_list = ['Tom', 'Lily', 'Rose']name_list.extend(['xiaoming', 'xiaohong'])# 结果：['Tom', 'Lily', 'Rose', 'xiaoming', 'xiaohong']print(name_list) insert()：指定位置新增数据。 语法 1列表序列.insert(位置下标, 数据) 快速体验 123456name_list = ['Tom', 'Lily', 'Rose']name_list.insert(1, 'xiaoming')# 结果：['Tom', 'xiaoming', 'Lily', 'Rose']print(name_list) 1.1.2.4 删除 del 语法 1del 目标 快速体验 2.1 删除列表 12345name_list = ['Tom', 'Lily', 'Rose']# 结果：报错提示：name 'name_list' is not defineddel name_listprint(name_list) ​ 2.2 删除指定数据 123456name_list = ['Tom', 'Lily', 'Rose']del name_list[0]# 结果：['Lily', 'Rose']print(name_list) pop()：删除指定下标的数据(默认为最后一个)，并返回该数据。 语法 1列表序列.pop(下标) 快速体验 123456789name_list = ['Tom', 'Lily', 'Rose']del_name = name_list.pop(1)# 结果：Lilyprint(del_name)# 结果：['Tom', 'Rose']print(name_list) remove()：移除列表中某个数据的第一个匹配项。 语法 1列表序列.remove(数据) 快速体验 123456name_list = ['Tom', 'Lily', 'Rose']name_list.remove('Rose')# 结果：['Tom', 'Lily']print(name_list) clear()：清空列表 1234name_list = ['Tom', 'Lily', 'Rose']name_list.clear()print(name_list) # 结果： [] 1.1.2.5 修改 修改指定下标数据 123456name_list = ['Tom', 'Lily', 'Rose']name_list[0] = 'aaa'# 结果：['aaa', 'Lily', 'Rose']print(name_list) 逆置：reverse() 123456num_list = [1, 5, 2, 3, 6, 8]num_list.reverse()# 结果：[8, 6, 3, 2, 5, 1]print(num_list) 1.1.2.6 列表的循环遍历需求：依次打印列表中的各个数据。 while 代码 123456name_list = ['Tom', 'Lily', 'Rose']i = 0while i &lt; len(name_list): print(name_list[i]) i += 1 执行结果 for 代码 1234name_list = ['Tom', 'Lily', 'Rose']for i in name_list: print(i) 执行结果 列表嵌套所谓列表嵌套指的就是一个列表里面包含了其他的子列表。 应用场景：要存储班级一、二、三三个班级学生姓名，且每个班级的学生姓名在一个列表。 1name_list = [['小明', '小红', '小绿'], ['Tom', 'Lily', 'Rose'], ['张三', '李四', '王五']] 思考： 如何查找到数据”李四”？ 12345# 第一步：按下标查找到李四所在的列表print(name_list[2])# 第二步：从李四所在的列表里面，再按下标找到数据李四print(name_list[2][1]) 总结 列表的格式 1[数据1, 数据2, 数据3] 常用操作方法 index() len() append() pop() remove() 列表嵌套 12name_list = [['小明', '小红', '小绿'], ['Tom', 'Lily', 'Rose'], ['张三', '李四', '王五']]name_list[2][1] 总结反应过来了这是一个数组，我需要将他切片放进列表中，太久没学习了脑壳疼。","categories":[],"tags":[]},{"title":"python__获取MIT数据","slug":"python/python-获取MIT数据","date":"2020-02-07T06:06:46.000Z","updated":"2020-02-07T06:06:46.000Z","comments":true,"path":"2020/02/07/python/python-获取MIT数据/","link":"","permalink":"https://esyyes.github.io/2020/02/07/python/python-%E8%8E%B7%E5%8F%96MIT%E6%95%B0%E6%8D%AE/","excerpt":"","text":"python__获取MIT数据1.数据库所在位置：F:\\MITDAT 2.数据保存格式：st,dat,ecg,hea 3.利用pycharm读取dat数据，并且存为可读格式 123456789101112131415161718192021222324252627282930313233343536373839# 下载对应的数据库数据，保存位置：F:\\MITDAT# 读取对应数据库的dat数据import wfdb as wfdbimport numpy as np'''读取心电信号文件sampfrom: 设置读取心电信号的 起始位置，sampfrom=0表示从0开始读取，默认从0开始sampto：设置读取心电信号的 结束位置，sampto = 1500表示从1500出结束，默认读到文件末尾channel_names：设置设置读取心电信号名字，必须是列表，channel_names=['MLII']表示读取MLII导联线channels：设置读取第几个心电信号，必须是列表，channels=[0, 3]表示读取第0和第3个信号，注意信号数不确定:return:'''# record = wfdb.rdrecord('F:/MITDAT/slp01a', sampfrom=0, sampto = 1500)# record = wfdb.rdrecord('F:/MITDAT/slp01a', sampfrom=0, sampto = 1500)# 仅仅读取“ECG”信号# record = wfdb.rdrecord('F:/MITDAT/slp01a', sampto=1500, channel_names=['ECG'])# 仅仅读取第0个信号（ECG）# record = wfdb.rdrecord('F:/MITDAT/slp01a', sampfrom=0, channels=[0])# 读取slp01a的数据，sampfrom：起始位置，sampto：结束位置，即可写做record = wfdb.rdrecord('F:/MITDAT/slp01a')# 查看record类型print(type(record))# 查看类中的方法和属性# print(dir(record))# 获得心电导联线信号，本文获得是4通道的信号print(record.p_signal)# 输出4通道的信号print(np.shape(record.p_signal))# 查看导联线信号长度print(record.sig_len)# 查看文件名print(record.record_name)# 查看导联线条数，本文为导联线条数4print(record.n_sig)# 查看信号名称（列表），本文导联线名称['ECG', 'BP', 'EEG (C4-A1)', 'Resp (sum)']print(record.sig_name)# 查看采用率print(record.fs) 结果如下： 暂时只需要ECG信号，即第一个客户端的数据 1234567891011121314151617# 只获取ECG对应的信号import wfdb as wfdbimport numpy as nprecord = wfdb.rdrecord('F:/MITDAT/slp01a', channels=[0])print(record.p_signal)# 输出4通道的信号print(np.shape(record.p_signal))# 查看导联线信号长度print(record.sig_len)# 查看文件名print(record.record_name)# 查看导联线条数，本文为导联线条数4print(record.n_sig)# 查看信号名称（列表），本文导联线名称['ECG', 'BP', 'EEG (C4-A1)', 'Resp (sum)']print(record.sig_name)# 查看采用率print(record.fs) 即所需的数据为： 12345import wfdb as wfdbrecord = wfdb.rdrecord('F:/MITDAT/slp01a', channels=[0])# 输出ECG通道的信号ECG = record.p_signalprint(ECG) 读取R峰值点 1234567import wfdb as wfdb# 读取心电数据库的R峰值点annotation = wfdb.rdann('F:/MITDAT/slp01a', 'ecg')# 标注每一个心拍的R波的尖锋位置，与心电信号对应print(annotation.sample)#symbol对应标签,sample为R峰所在位置，sig为R峰值# print(annotation.symbol) 提取注释信息！可以暂时不用管理，到时重新导出注释信号。 下一步。利用PT算法，读取峰值点，在python里面读取 不过已经直接读取出R峰值点，暂时可不考虑。pt算法。 切片循环和导出峰值，提取时域。","categories":[],"tags":[]},{"title":"matlab中的滑动窗口","slug":"matlab/matlab中的滑动窗口","date":"2020-01-07T02:47:29.000Z","updated":"2020-01-07T02:47:29.000Z","comments":true,"path":"2020/01/07/matlab/matlab中的滑动窗口/","link":"","permalink":"https://esyyes.github.io/2020/01/07/matlab/matlab%E4%B8%AD%E7%9A%84%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/","excerpt":"","text":"进行滑动加窗Kubios HRV分析的信号在加载时会漏掉后续20秒的数据，想要完整的5分钟数据，因此输出的信号即为6分钟，保持连贯性，即选取6分钟的窗口，以5分钟为步长进行移动分析。 sliding Windows 滑动窗口：滑动窗口由固定的窗口长度和滑动间隔组成。 特点：窗口长度固定，有重叠。 滑动窗口大小：5分钟即：75000 总结：笨。。。 批量保存txt文件1.放在一个矩阵中，会出现维度不同的报错问题 2.综合考虑放在一个cell元包数组中，或者结构体中 3.在考虑批量保存 元胞数组：特点： 1.可以存储大小不同的矩阵序列 2.检索内容时，使用大括号下标进行索引，A{1} 3.包含其他数组的副本，而不包含指向这些数组的指针，即修改原值，元胞里的内容不变 结构体：结构体是多维 MATLAB 数组，包含可按文本字段标志符访问的元素。 cell（1，1）是查看大小和样式 cell{1 . 1}是读取全部的数 123456789101112131415161718192021while i &lt;= m [QRS_pks, QRS_locs, delay] = pan_tompkin(ECG(i, :), fs, 0); [RR] = HRV(QRS_locs);% 得到HRV信号 [QRS_locs, RR] = Eliminate_outliers(QRS_locs, RR);% 消除HRV中的RR异常值 cell_RR(i, 1) = &#123;RR&#125;; i = i + 1; end332x1 double341x1 double331x1 double321x1 double315x1 double315x1 double301x1 double306x1 double303x1 double305x1 double305x1 double320x1 double322x1 double 两个分析的软件都只能读取txt文件。因此需要进行批量保存为txt文件。","categories":[{"name":"matlab","slug":"matlab","permalink":"https://esyyes.github.io/categories/matlab/"}],"tags":[]},{"title":"去趋势波动分析DFA","slug":"python/去趋势波动分析DFA","date":"2019-12-26T06:34:05.000Z","updated":"2019-12-26T06:34:05.000Z","comments":true,"path":"2019/12/26/python/去趋势波动分析DFA/","link":"","permalink":"https://esyyes.github.io/2019/12/26/python/%E5%8E%BB%E8%B6%8B%E5%8A%BF%E6%B3%A2%E5%8A%A8%E5%88%86%E6%9E%90DFA/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"LV-3","slug":"python/python调用wfdb","date":"2019-12-26T02:33:29.000Z","updated":"2019-12-26T02:33:29.000Z","comments":true,"path":"2019/12/26/python/python调用wfdb/","link":"","permalink":"https://esyyes.github.io/2019/12/26/python/python%E8%B0%83%E7%94%A8wfdb/","excerpt":"","text":"python中的WFDB库使用1.获取MIT——PhysioNet数据库的所有库名称1234import wfdb as wfdbdbs = wfdb.get_dbs()print(dbs) 获取PhysioNet所有库的名称列表： [[‘adfecgdb’, ‘Abdominal and Direct Fetal ECG Database’], [‘aftdb’, ‘AF Termination Challenge Database’], [‘ahadb’, ‘AHA Database [sample excluded record]’], [‘aami-ec13’, ‘ANSI/AAMI EC13 Test Waveforms’], [‘apnea-ecg’, ‘Apnea-ECG Database’], [‘chfdb’, ‘BIDMC Congestive Heart Failure Database’], [‘bidmc’, ‘BIDMC PPG and Respiration Dataset’], [‘bpssrat’, ‘Blood Pressure in Salt-Sensitive Dahl Rats’], [‘capslpdb’, ‘CAP Sleep Database’], [‘crisdb’, ‘CAST RR Interval Sub-Study Database’], [‘cves’, ‘Cerebral Vasoregulation in Elderly with Stroke’], [‘challenge/2009/test-set-a’, ‘Challenge 2009 Test Set A’], [‘challenge/2009/test-set-b’, ‘Challenge 2009 Test Set B’], [‘challenge/2010/set-a’, ‘Challenge 2010 Training Set A’], [‘challenge/2010/set-b’, ‘Challenge 2010 Test Set B’], [‘challenge/2010/set-c’, ‘Challenge 2010 Test Set C’], [‘challenge/2011/sim’, ‘Challenge 2011 Pilot Set’], [‘challenge/2011/set-a’, ‘Challenge 2011 Training Set A’], [‘challenge/2011/set-b’, ‘Challenge 2011 Test Set B’], [‘challenge/2013/set-a’, ‘Challenge 2013 Training Set A’], [‘challenge/2013/set-b’, ‘Challenge 2013 Test Set B’], [‘challenge/2014/set-p2’, ‘Challenge 2014 Extended Training Set’], [‘challenge/2014/set-p’, ‘Challenge 2014 Training Set’], [‘challenge/2015/training’, ‘Challenge 2015 Training Set’], [‘challenge/2016/training-a’, ‘Challenge 2016 Training Set A’], [‘challenge/2016/training-b’, ‘Challenge 2016 Training Set B’], [‘challenge/2016/training-c’, ‘Challenge 2016 Training Set C’], [‘challenge/2016/training-d’, ‘Challenge 2016 Training Set D’], [‘challenge/2016/training-e’, ‘Challenge 2016 Training Set E’], [‘challenge/2016/training-f’, ‘Challenge 2016 Training Set F’], [‘challenge/2017/training’, ‘Challenge 2017 Training Set’], [‘challenge/2018/training’, ‘Challenge 2018 Training Set’], [‘challenge/2018/test’, ‘Challenge 2018 Test Set’], [‘charisdb’, ‘CHARIS database’], [‘chbmit’, ‘CHB-MIT Scalp EEG Database’], [‘cebsdb’, ‘Combined measurement of ECG, Breathing and Seismocardiograms’], [‘culm’, ‘Complex Upper-Limb Movements’], [‘chf2db’, ‘Congestive Heart Failure RR Interval Database’], [‘ctu-uhb-ctgdb’, ‘CTU-CHB Intrapartum Cardiotocography Database’], [‘cudb’, ‘CU Ventricular Tachyarrhythmia Database’], [‘ecgdmmld’, ‘ECG Effects of Dofetilide, Moxifloxacin, Dofetilide+Mexiletine, Dofetilide+Lidocaine and Moxifloxacin+Diltiazem’], [‘ecgcipa’, ‘CiPA ECG Validation Study’], [‘ecgrdvq’, ‘ECG Effects of Ranolazine, Dofetilide, Verapamil, and Quinidine’], [‘ecgiddb’, ‘ECG-ID Database’], [‘eegmat’, ‘EEG During Mental Arithmetic Tasks’], [‘eegmmidb’, ‘EEG Motor Movement/Imagery Dataset’], [‘ltrsvp’, ‘EEG Signals from an RSVP Task’], [‘erpbci’, ‘ERP-based Brain-Computer Interface recordings’], [‘edb’, ‘European ST-T Database’], [‘earh’, ‘Evoked Auditory Responses in Heading Impaired’], [‘earndb’, ‘Evoked Auditory Responses in Normals’], [‘emgdb’, ‘Examples of Electromyograms’], [‘fantasia’, ‘Fantasia Database’], [‘fecgsyndb’, ‘Fetal ECG Synthetic Database’], [‘fpcgdb’, ‘Fetal PCG Database’], [‘gaitdb’, ‘Gait in Aging and Disease Database’], [‘gaitndd’, ‘Gait in Neurodegenerative Disease Database’], [‘gait-maturation-db/data’, ‘Gait Maturation Database’], [‘meditation/data’, ‘Heart Rate Oscillations during Meditation’], [‘hbedb’, ‘Human Balance Evaluation Database’], [‘ehgdb’, ‘Icelandic 16-electrode Electrohysterogram Database’], [‘iafdb’, ‘Intracardiac Atrial Fibrillation Database’], [‘ltafdb’, ‘Long Term AF Database’], [‘ltstdb’, ‘Long Term ST Database’], [‘mssvepdb’, ‘MAMEM SSVEP Database’], [‘mghdb’, ‘MGH/MF Waveform Database’], [‘mimicdb’, ‘MIMIC Database’], [‘mimicdb/numerics’, ‘MIMIC Database Numerics’], [‘mimic2cdb’, ‘MIMIC II Clinical Database Public Subset’], [‘mimic2wdb/30’, ‘MIMIC II/III Waveform Database, part 0’], [‘mimic2wdb/31’, ‘MIMIC II/III Waveform Database, part 1’], [‘mimic2wdb/32’, ‘MIMIC II/III Waveform Database, part 2’], [‘mimic2wdb/33’, ‘MIMIC II/III Waveform Database, part 3’], [‘mimic2wdb/34’, ‘MIMIC II/III Waveform Database, part 4’], [‘mimic2wdb/35’, ‘MIMIC II/III Waveform Database, part 5’], [‘mimic2wdb/36’, ‘MIMIC II/III Waveform Database, part 6’], [‘mimic2wdb/37’, ‘MIMIC II/III Waveform Database, part 7’], [‘mimic2wdb/38’, ‘MIMIC II/III Waveform Database, part 8’], [‘mimic2wdb/39’, ‘MIMIC II/III Waveform Database, part 9’], [‘mimic2wdb/matched’, ‘MIMIC II Waveform Database Matched Subset’], [‘mimic3wdb/matched’, ‘MIMIC III Waveform Database Matched Subset’], [‘mitdb’, ‘MIT-BIH Arrhythmia Database’], [‘pwave’, ‘MIT-BIH Arrhythmia Database P-Wave Annotations’], [‘afdb’, ‘MIT-BIH Atrial Fibrillation Database’], [‘cdb’, ‘MIT-BIH ECG Compression Test Database’], [‘ltdb’, ‘MIT-BIH Long-Term ECG Database’], [‘vfdb’, ‘MIT-BIH Malignant Ventricular Ectopy Database’], [‘nstdb’, ‘MIT-BIH Noise Stress Test Database’], [‘nsrdb’, ‘MIT-BIH Normal Sinus Rhythm Database’], [‘excluded’, ‘… [Recordings excluded from the NSR DB]’], [‘slpdb’, ‘MIT-BIH Polysomnographic Database’], [‘stdb’, ‘MIT-BIH ST Change Database’], [‘svdb’, ‘MIT-BIH Supraventricular Arrhythmia Database’], [‘mmgdb’, ‘MMG Database’], [‘macecgdb’, ‘Motion Artifact Contaminated ECG Database’], [‘motion-artifact’, ‘Motion Artifact Contaminated fNIRS and EEG Data’], [‘noneeg’, ‘Non-EEG Dataset for Assessment of Neurological Status’], [‘nifecgdb’, ‘Non-Invasive Fetal ECG Database’], [‘nifeadb’, ‘Non-Invasive Fetal ECG Arrhythmia Database’], [‘nsr2db’, ‘Normal Sinus Rhythm RR Interval Database’], [‘ob1db’, ‘OB-1 Fetal ECG Database [sample record]’], [‘afpdb’, ‘PAF Prediction Challenge Database’], [‘osv’, ‘Pattern Analysis of Oxygen Saturation Variability’], [‘prcp’, ‘Physiologic Response to Changes in Posture’], [‘szdb’, ‘Post-Ictal Heart Rate Oscillations in Partial Epilepsy’], [‘picsdb’, ‘Preterm Infant Cardio-Respiratory Signals Database’], [‘ptbdb’, ‘PTB Diagnostic ECG Database’], [‘qtdb’, ‘QT Database’], [‘rvmh1’, ‘Response to Valsalva Maneuver in Humans’], [‘sufhsdb’, ‘Shiraz University Fetal Heart Sounds Database’], [‘simfpcgdb’, ‘Simulated Fetal Phonocardiograms’], [‘sleepbrl’, ‘Sleep Bioradiolocation Database’], [‘sleep-edfx’, ‘Sleep-EDF Database [Expanded]’], [‘shhpsgdb’, ‘Sleep Heart Health Study PSG Database [sample record]’], [‘shareedb’, ‘Smart Health for Assessing the Risk of Events via ECG Database’], [‘mvtdb/data’, ‘Spontaneous Ventricular Tachyarrhythmia Database’], [‘sgamp’, ‘Squid Giant Axon Membrane Potential’], [‘incartdb’, ‘St Petersburg INCART 12-lead Arrhythmia Database’], [‘staffiii’, ‘STAFF III Database’], [‘drivedb’, ‘Stress Recognition in Automobile Drivers’], [‘sddb’, ‘Sudden Cardiac Death Holter Database’], [‘twadb’, ‘T-Wave Alternans Challenge Database’], [‘taichidb’, ‘Tai Chi, Physiological Complexity, and Healthy Aging - Gait’], [‘tpehgdb’, ‘Term-Preterm EHG Database’], [‘tpehgt’, ‘Term-Preterm EHG DataSet with Tocogram (TPEHGT DS)’], [‘ucddb’, ‘UCD Sleep Apnea Database’], [‘unicaprop’, ‘UniCA ElectroTastegram Database (PROP)’], [‘videopulse’, ‘Video Pulse Signals in Stationary and Motion Conditions’], [‘voiced’, ‘VOice ICar fEDerico II Database’], [‘wrist’, ‘Wrist PPG During Exercise’], [‘mimic2db’, ‘MIMIC II Waveform DB, v2 [deprecated, use v3]’], [‘mimic2db/numerics’, ‘MIMIC II Waveform DB, v2 Numerics [deprecated, use v3]’], [‘sleep-edf’, ‘Sleep-EDF Database, v1 [deprecated, use sleep-edfx]’]] 这个列表其实在网站https://physionet.org/physiobank/database/中也可以查看查看 找到想要分析的睡眠数据库： [‘slpdb’, ‘MIT-BIH Polysomnographic Database’] 2.获取想要的睡眠数据库的所有信号记录列表由第一个库知道， [‘slpdb’, ‘MIT-BIH Polysomnographic Database’]，对应的数据库就为slpdb，获取里面所有数据集的列表： 12recs_list = wfdb.get_record_list('slpdb')print(recs_list) [‘slp01a’, ‘slp01b’, ‘slp02a’, ‘slp02b’, ‘slp03’, ‘slp04’, ‘slp14’, ‘slp16’, ‘slp32’, ‘slp37’, ‘slp41’, ‘slp45’, ‘slp48’, ‘slp59’, ‘slp60’, ‘slp61’, ‘slp66’, ‘slp67x’] 3.获取对应的数据库里面的内容","categories":[],"tags":[]},{"title":"matlab中的插值","slug":"matlab/matlab中的插值","date":"2019-12-18T00:50:08.000Z","updated":"2019-12-18T00:50:08.000Z","comments":true,"path":"2019/12/18/matlab/matlab中的插值/","link":"","permalink":"https://esyyes.github.io/2019/12/18/matlab/matlab%E4%B8%AD%E7%9A%84%E6%8F%92%E5%80%BC/","excerpt":"","text":"Matlab中的插值函数 # interp1 一维数据插值（表查找） 语法1234567vq = interp1(x,v,xq)vq = interp1(x,v,xq,method)vq = interp1(x,v,xq,method,extrapolation)vq = interp1(v,xq)vq = interp1(v,xq,method)vq = interp1(v,xq,method,extrapolation)pp = interp1(x,v,method,'pp') 说明vq = interp1(x,v,xq) 使用线性插值返回一维函数在特定查询点的插入值。向量 x 包含样本点，v 包含对应值 v(x)。向量 xq 包含查询点的坐标。 如果您有多个在同一点坐标采样的数据集，则可以将 v 以数组的形式进行传递。数组 v 的每一列都包含一组不同的一维样本值。 vq = interp1(x,v,xq,method) 指定备选插值方法：&#39;linear&#39;、&#39;nearest&#39;、&#39;next&#39;、&#39;previous&#39;、&#39;pchip&#39;、&#39;cubic&#39;、&#39;v5cubic&#39;、&#39;makima&#39; 或 &#39;spline&#39;。默认方法为 &#39;linear&#39;。 vq = interp1(x,v,xq,method,extrapolation) 用于指定外插策略，来计算落在 x 域范围外的点。如果希望使用 method 算法进行外插，可将 extrapolation 设置为 &#39;extrap&#39;。您也可以指定一个标量值，这种情况下，interp1 将为所有落在 x 域范围外的点返回该标量值。 vq = interp1(v,xq) 返回插入的值，并假定一个样本点坐标默认集。默认点是从 1 到 n 的数字序列，其中 n取决于 v 的形状： 当 v 是向量时，默认点是 1:length(v)。 当 v 是数组时，默认点是 1:size(v,1)。 如果您不在意点之间的绝对距离，则可使用此语法。 vq = interp1(v,xq,method) 指定备选插值方法中的任意一种，并使用默认样本点。 vq = interp1(v,xq,method,extrapolation) 指定外插策略，并使用默认样本点。 pp = interp1(x,v,method,&#39;pp&#39;) 使用 method 算法返回分段多项式形式的 v(x)。 根据需求确定的语法： 1vq = interp1(x,v,xq,method) 输入参数x :样本点**** x :样本点，指定为一行或一列实数向量。x 中的值必须各不相同。x 的长度必须符合以下要求之一： 如果 v 为向量，则 length(x) 必须等于 length(v)。 如果 v 为数组，则 length(x) 必须等于 size(v,1) V:样本值 样本值，指定为实数/复数向量、矩阵或数组。如果 v 是矩阵或数组，则每列包含单独的一组一维值。 如果 v 包含复数，则 interp1 将分别插入实部和虚部。 xq: 查询点 查询点，指定为实数标量、向量、矩阵或数组。 method- 插值方法 方法 说明 连续性 注释 &#39;linear&#39; 线性插值。在查询点插入的值基于各维中邻点网格点处数值的线性插值。这是默认插值方法。 C0 需要至少 2 个点。比最近邻点插值需要更多内存和计算时间。 &#39;nearest&#39; 最近邻点插值。在查询点插入的值是距样本网格点最近的值。 不连续 需要至少 2 个点。最低内存要求最快计算时间 &#39;next&#39; 下一个邻点插值。在查询点插入的值是下一个抽样网格点的值。 不连续 需要至少 2 个点。内存要求和计算时间与 &#39;nearest&#39; 相同 &#39;previous&#39; 上一个邻点插值。在查询点插入的值是上一个抽样网格点的值。 不连续 需要至少 2 个点。内存要求和计算时间与 &#39;nearest&#39; 相同 &#39;pchip&#39; 保形分段三次插值。在查询点插入的值基于邻点网格点处数值的保形分段三次插值。 C1 需要至少 4 个点。比 &#39;linear&#39; 需要更多内存和计算时间 &#39;cubic&#39;注意interp1(...,&#39;cubic&#39;)的行为在以后的版本中会有所变化。在以后的版本中，此方法将执行三次卷积。 与 &#39;pchip&#39; 相同。 C1 此方法目前返回与 &#39;pchip&#39; 相同的结果。 &#39;v5cubic&#39; 用于 MATLAB® 5 的三次卷积。 C1 点之间的间距必须均匀。&#39;cubic&#39; 将在以后的版本中替代 &#39;v5cubic&#39;。 &#39;makima&#39; 修改后的 Akima 三次 Hermite 插值。在查询点插入的值基于次数最大为 3 的多项式的分段函数。为防过冲，已改进 Akima 公式。 C1 需要至少 2 个点。产生的波动比 &#39;spline&#39; 小，但不像 &#39;pchip&#39; 那样急剧变平计算成本高于 &#39;pchip&#39;，但通常低于 &#39;spline&#39;内存要求与 &#39;spline&#39; 类似 &#39;spline&#39; 使用非结终止条件的样条插值。在查询点插入的值基于各维中邻点网格点处数值的三次插值。 C2 需要至少 4 个点。比 &#39;pchip&#39; 需要更多内存和计算时间 选择spline。参考文献：基于时频分析的心率变异性研究 输出函数vq- 输出的插值 插入的值，以标量、向量、矩阵或数组的形式返回。vq 的大小取决于 v 和 xq 的形状。 v 的形状 xq 的形状 Vq 的大小 示例 向量 向量 size(xq) 如果 size(v) = [1 100] 且 size(xq) = [1 500]， 则 size(vq) = [1 500]。 向量 矩阵 或 N 维数组 size(xq) 如果 size(v) = [1 100] 且 size(xq) = [50 30]， 则 size(vq) = [50 30]。 矩阵 或 N 维数组 向量 [length(xq) size(v,2),...,size(v,n)] 如果 size(v) = [100 3] 且 size(xq) = [1 500]， 则 size(vq) = [500 3]。 矩阵 或 N 维数组 矩阵 或 N 维数组 [size(xq,1),...,size(xq,n),... size(v,2),...,size(v,m)] 如果 size(v) = [4 5 6] 且 size(xq) = [2 3 7]， 则 size(vq) = [2 3 7 5 6]。 http://www.360doc.com/content/18/0201/11/12548572_726900990.shtml 参考代码：12345678910111213141516171819load ekg.mat; %读入ecg信号[map,r,delay]=pan_tompkin(ecg,fs,0);% 利用pan_tomkin算法找到R点[a,l]=size(r);for i=2:l;t(i-1)=r(i)-r(i-1); %求出R-R间的时间值，即使HRVendx=r(2:19);y=interp1(x,t,r(2):1:r(19),'spline'); %利用插值法求出以原ecg信号的采样率fs的拟合函数plot(y);hold on,scatter(r(2:19)-r(2),t(1:18)); 进行插值并实现重采样，代码如下：12345678910111213141516171819202122232425262728293031%对其进行三次样本插值sRR = interp1(locs(2:length(locs),1),RR, locs(2):1:locs(length(locs)), 'spline');%利用散点图将图像进行标记figure(5)plot(sRR);hold onscatter(locs(2:length(locs),1) - locs(2),RR(1:length(locs)-1));%原来的采样率为250Hz,进行重采样为2.4Hz，%输出为等间隔的数据信号VRR = resample(sRR, 720, 74651);VRR = VRR';Fs = 2.4;N_RR = length(VRR);%采样数fen1 = N_RR / (60 * Fs);m = 1 : N_RR;t = m / Fs;figure(6)plot(t, VRR);%对数据进行切片30SXRR = [];i = 1;while i &lt;= 10j = 1; while j &lt;= 72 XRR(j, i) = VRR(j * i, 1); j = j + 1; end i = i +1;end","categories":[{"name":"-工作 -matlab","slug":"工作-matlab","permalink":"https://esyyes.github.io/categories/%E5%B7%A5%E4%BD%9C-matlab/"}],"tags":[]},{"title":"matlab中的重采样","slug":"matlab/matlab中的重采样","date":"2019-12-17T06:14:28.000Z","updated":"2019-12-17T06:14:28.000Z","comments":true,"path":"2019/12/17/matlab/matlab中的重采样/","link":"","permalink":"https://esyyes.github.io/2019/12/17/matlab/matlab%E4%B8%AD%E7%9A%84%E9%87%8D%E9%87%87%E6%A0%B7/","excerpt":"","text":"## Matlab中的重采样 选取3条插值重采样 重采样函数Resample：将统一或非统一数据重新采样为新的固定速率 语法： y = resample(x, p, q) y = resample(x, tx, __, method) 指定插值方法以及该组中以前语法中的任何参数。内插方法可以是&#39;linear&#39;，&#39;pchip&#39;，或&#39;spline&#39;。 注： 如果x没有变化缓慢，可以考虑使用interp1与&#39;pchip&#39;插值方法。 输入参数输入信号，指定为矢量或矩阵。如果x是矩阵，则将其列视为独立通道。x可以包含NaN。NaN将s视为丢失的数据，并从重采样中排除。double p, q:重采样因子，指定为正整数。如需要原采样频率的1/5,即p=1,q=5 n— 相邻词号 10（默认）| 正整数邻居项号，指定为正整数。如果n = 0，则执行最近邻插值。抗混叠FIR滤波器的长度与成正比。较大的值提供更好的精度，但要花费更多的计算时间。resample``n``n 资料类型： double Kaiser窗口5的 Shape参数（默认）| 正实标量Kaiser窗口的Shape参数，指定为正实标量。增大beta加宽用于设计抗混叠滤波器的窗口的主瓣，并减小窗口旁瓣的幅度。 资料类型： `double b— FIR滤波器系数 矢量FIR滤波器系数，指定为矢量。默认情况下，使用Kaiser窗口设计过滤器。补偿延迟时，假定具有奇数长度和线性相位。resamplefirlsresample``b 示例：fir1(4,0.5)指定一个四阶低通滤波器，其归一化截止频率为0.5πrad /样本。 资料类型： double tx— 时间瞬间 非负实矢量 | datetime数组时间瞬间，指定为非负实向量或datetime数组。tx必须单调增加，但不必均匀间隔。tx可以包含NaN或NaT。这些值被视为丢失的数据，并从重新采样中排除。 数据类型：double |datetime fs— 采样率 正标量采样率，指定为正标量。采样率是每单位时间的采样数。如果时间单位是秒，则采样率以Hz为单位。 资料类型： double method— 插值方法 &#39;linear&#39;（默认）| &#39;pchip&#39;|&#39;spline&#39;插值方法，规定为一个&#39;linear&#39;，&#39;pchip&#39;或&#39;spline&#39;： &#39;linear&#39; - 线性插值。 &#39;pchip&#39; —保形分段三次插值。 &#39;spline&#39; —使用非终止条件进行样条插值。 输出参数y— 重采样的信号 向量| 矩阵重新采样的信号，以向量或矩阵形式返回。如果x是的长度的信号Ñ并指定p和 q，然后y是长度⌈ Ñ × p/ q⌉。 b— FIR滤波器系数 矢量FIR滤波器系数，以向量形式返回。 ty—输出瞬间 非负实矢量输出瞬间，作为非负实向量返回。 需求： 1.将信号采样为2Hz 2.用3次插值 3.等间隔 method: “pchip”三次插值 是先插值，再重采样！！！！！！！","categories":[{"name":"-工作 -matlab","slug":"工作-matlab","permalink":"https://esyyes.github.io/categories/%E5%B7%A5%E4%BD%9C-matlab/"}],"tags":[{"name":"-malab -毕业","slug":"malab-毕业","permalink":"https://esyyes.github.io/tags/malab-%E6%AF%95%E4%B8%9A/"}]},{"title":"心率变异性","slug":"hexo/心率变异性","date":"2019-12-16T13:31:31.000Z","updated":"2019-12-16T13:31:31.000Z","comments":true,"path":"2019/12/16/hexo/心率变异性/","link":"","permalink":"https://esyyes.github.io/2019/12/16/hexo/%E5%BF%83%E7%8E%87%E5%8F%98%E5%BC%82%E6%80%A7/","excerpt":"","text":"心率变异性心率变异性(heart rate variability, HRV),即指连续两次心跳时间间隔的微小变化，HRV 产生于自主神经系统（Autonomic Nervous System ，ANS）对心脏窦房结的调制，使得心搏间期一般存在几十毫秒的差异或波动，HRV 是了解 ANS 状态的有用信号，心率（Heart Rate, HR）的正常变异是由于心脏和循环系统的自主神经调节。 目前，HRV 分析方法主要分为三类，即时域分析法、频域分析法和非线性分析法。其中，时域分析和频域分析法是线性分析，计算简单且各项指标的含义明确。 时域分析法是基于统计学原理来量化 RR 间期序列以及心率序列的变化差异，主要是计算各项统计指标。 频域分析法是将 RR 间期序列通过傅里叶变换或小波变换的方法由时域转换到频率域上，计算各频段的频谱功率。频域分析法通常采用快速傅里叶变换法(FFT)或小波变换来计算 HRV 的功率谱密度及各频段的频谱功率。 文献中常用的方法是试图使用从混沌理论或分形过程得出的非线性统计指标来量化心率的复杂性，如去趋势波动分析、Poincare 散点图、李雅普诺夫指数、相关维度、近似熵、样本熵、多尺度熵、复杂度等。","categories":[{"name":"-工作","slug":"工作","permalink":"https://esyyes.github.io/categories/%E5%B7%A5%E4%BD%9C/"}],"tags":[]},{"title":"matplotlib图像绘制学习","slug":"python/matplotlib图像绘制学习","date":"2019-12-10T14:37:17.000Z","updated":"2019-12-10T14:37:17.000Z","comments":true,"path":"2019/12/10/python/matplotlib图像绘制学习/","link":"","permalink":"https://esyyes.github.io/2019/12/10/python/matplotlib%E5%9B%BE%E5%83%8F%E7%BB%98%E5%88%B6%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"1234567891011121314151617181920212223# -*- coding: utf-8 -*-# @Time : 2019/12/10# @Author : esy# 坐标名称图像绘制还有标题 import matplotlib.pyplot as pltx = [1, 2, 3]y = [5, 7, 4]x1 = [1, 2, 3]y1 = [15, 17, 14]# 定义线段的名字可以在后面加label=‘’，即为legend效果plt.plot(x, y, label='First Line')plt.plot(x1, y1, label='Second Line')plt.xlabel('plot xnumber')plt.ylabel('plot ynumber')plt.title('plot tu\\ncheck it out')plt.legend()# 展示图像plt.show() 绘制图像，同理在python中bar是直方图 加颜色： 12plt.plot(x, y, label='First Line', color='r')plt.plot(x1, y1, label='Second Line', color='b') 在pycharm中还是直接运行，当需要查看变量时，点击下面的Python Console,可在里面查看变量值。 点击run file in console,即可运行到console中，可查看变量。","categories":[],"tags":[]},{"title":"升级conda","slug":"hexo/升级conda","date":"2019-12-10T02:54:05.000Z","updated":"2019-12-10T02:54:05.000Z","comments":true,"path":"2019/12/10/hexo/升级conda/","link":"","permalink":"https://esyyes.github.io/2019/12/10/hexo/%E5%8D%87%E7%BA%A7conda/","excerpt":"","text":"python conda 软件包升级 conda: 运行Anaconda Prompt 升级conda(升级Anaconda前需要先升级conda)：conda update conda 升级anaconda：conda update anaconda 升级spyder：conda update spyder 更新所有包：conda update –all 安装包：conda install package 更新包：conda update package 查询某个conda指令使用-h后缀，如conda update -h 因为是用Prcharm调用anaconda里面的python的库函数，一般情况下，升级python还有IPython即可 pip: 升级pip python -m pip install –upgrade pip pip升级包 pip install –upgrade 要升级的包名 Commands: install 安装包. uninstall 卸载包. freeze 按着一定格式输出已安装包列表 list 列出已安装包. show 显示包详细信息. search 搜索包，类似yum里的search. wheel Buildwheelsfromyourrequirements. zip 不推荐.Zipindividualpackages. unzip 不推荐.Unzipindividualpackages. bundle 不推荐.Createpybundles. help 当前帮助. pip list –outdate 查看可以升级的包 总结： 我也想要小爱心点击效果","categories":[{"name":"-升级conda","slug":"升级conda","permalink":"https://esyyes.github.io/categories/%E5%8D%87%E7%BA%A7conda/"}],"tags":[{"name":"-python","slug":"python","permalink":"https://esyyes.github.io/tags/python/"}]},{"title":"LV-2","slug":"python/python基础之列表","date":"2019-12-08T13:00:32.000Z","updated":"2019-12-08T13:00:32.000Z","comments":true,"path":"2019/12/08/python/python基础之列表/","link":"","permalink":"https://esyyes.github.io/2019/12/08/python/python%E5%9F%BA%E7%A1%80%E4%B9%8B%E5%88%97%E8%A1%A8/","excerpt":"","text":"# 转移程序时遇到的问题 1.列表只提取一部分数据：即切片序列[开始位置下标:结束位置下标:步长] 注意 不包含结束位置下标对应的数据， 正负整数均可； 步长是选取间隔，正负整数均可，默认步长为1。 1234567891011name = \"abcdefg\"print(name[2:5:1]) # cdeprint(name[2:5]) # cdeprint(name[:5]) # abcdeprint(name[1:]) # bcdefgprint(name[:]) # abcdefgprint(name[::2]) # acegprint(name[:-1]) # abcdef, 负1表示倒数第一个数据print(name[-4:-1]) # defprint(name[::-1]) # gfedcba 所谓字符串查找方法即是查找子串在字符串中的位置或出现的次数。 find()：检测某个子串是否包含在这个字符串中，如果在返回这个子串开始的位置下标，否则则返回-1。 语法 1字符串序列.find(子串, 开始位置下标, 结束位置下标) 注意：开始和结束位置下标可以省略，表示在整个字符串序列中查找。 下标 计算机为数据序列中每个元素分配的从0开始的编号 切片 1序列名[开始位置下标:结束位置下标:步长] 常用操作方法 find() index() python切片，一切取单个值，即data[i]下标即可，可用负数查找 切取完整的对象：data[:],从左往右，data[::],从左往右，data[::-1],从右往左 data[1:6],数值即为12345,左闭右开， 2.列表进行倒置1# 将数据进行转置ecg = ecg.transpose() 并没有把行数据转换为列数据 python中的行数据和列数据的形式？感觉没啥用 一直觉得图错了，原来是在列表查找时设置的是data[1] 12345# 查找data字典中的valkey值data = data['val']# 读取第一个列表data = data[0]print(data) 读取的是列表的第二个，导致图像一直错误！！！ (～￣(OO)￣)ブ 1.列表1.1列表的格式[数据1, 数据2, 数据3, 数据4……] 列表可以一次性存储多个数据，且可以为不同数据类型。 1.列表的行和列的区别？ 2.列表中的行绘制和列绘制的区别","categories":[],"tags":[]},{"title":"matlab中的function函数","slug":"matlab/matlab中的function函数","date":"2019-12-04T08:46:53.000Z","updated":"2019-12-04T08:46:53.000Z","comments":true,"path":"2019/12/04/matlab/matlab中的function函数/","link":"","permalink":"https://esyyes.github.io/2019/12/04/matlab/matlab%E4%B8%AD%E7%9A%84function%E5%87%BD%E6%95%B0/","excerpt":"","text":"matlab中的function函数1.function函数在matlab中的构建funciton: 声明函数名称、输入和输出 在matlab中，新建 - 函数，即为一个函数样本。 123456function [outputArg1,outputArg2] = untitled2(inputArg1,inputArg2)%UNTITLED2 此处显示有关此函数的摘要% 此处显示详细说明outputArg1 = inputArg1;outputArg2 = inputArg2;end 12说明：function [outputArg1,outputArg2] = untitled2(inputArg1,inputArg2) 声明名为 untitled2 的函数,即文件的取名封装名，此声明语句必须是函数的第一个可执行代码行。有效的函数名称以字母字符开头，并且可以包含字母、数字或下划线。 可以将函数保存在以下位置： 只包含函数定义的函数文件中。文件的名称应与文件中其函数的名称一致。 包含命令和函数定义的脚本文件中。函数必须位于该文件的末尾。脚本文件不能与文件中的函数具有相同的名称。R2016b 或更高版本的脚本中支持函数。 文件可以包含多个局部函数或嵌套函数。为提高可读性，可使用 end关键字来表示文件中每个函数的末尾。以下情况下需要end关键字: 文件中有任意函数包含嵌套函数。 该函数是函数文件中的局部函数，并且文件中有局部函数使用 end关键字。 该函数是脚本文件内的局部函数。 2.构建一个多输入，多输出的函数输入： a b 输出： jia jie cheng chu 函数命名为： jibenyunsuan 12345678function [jia, jian, cheng, chu] = jibenyunsuan(a, b)%jibenyunsuan 此处显示有关此函数的摘要:% 完成函数的加减乘除运算jia = a + b;jian = a - b;cheng = a * b;chu = a / b; end 函数名字最好跟文件名字一样好找，输出结果也最好能直接好理解的； 在别的文件夹下运算： 123a = 60;b = 2;[jia, jian, cheng, chu] = jibenyunsuan(a, b)； 直接调用函数即可，输出的前面最好按照好理解的方式定义名字。 前面的命名是否可更改？ 可以进行更改，前面的命名是按照自我的定义，是输出，自己改动，前面的function里面的输出定义项也会相继改动。 主函数只能有一个，其余的函数均为子函数。 3.构建一个循环的函数构建一个NN50特征 123456789101112131415161718function [NN50q, NN50h, PNN50q, PNN50h] = NN50tezheng(a)%UNTITLED5 此处显示有关此函数的摘要% 相邻RR间期大于50ms的RR期数量，NN50q前面大于后面,NN50后面大于前面% PNN50为分别占总的RR间期的百分比i = 1;NN50q = 0;NN50h = 0;while i &lt; length(a) if a(i) - a(i+1) &gt; 50 NN50q = NN50q + 1; elseif a(i+1) - a(i) &gt; 50 NN50h = NN50h + 1; end i = i +1;endPNN50q = NN50q / length(a);PNN50h = NN50h / length(a);end","categories":[{"name":"-matlab -工作","slug":"matlab-工作","permalink":"https://esyyes.github.io/categories/matlab-%E5%B7%A5%E4%BD%9C/"}],"tags":[{"name":"-malab -毕业","slug":"malab-毕业","permalink":"https://esyyes.github.io/tags/malab-%E6%AF%95%E4%B8%9A/"}]},{"title":"hexo学习","slug":"hexo/hexo学习","date":"2019-12-03T05:42:05.000Z","updated":"2019-12-03T05:42:05.000Z","comments":true,"path":"2019/12/03/hexo/hexo学习/","link":"","permalink":"https://esyyes.github.io/2019/12/03/hexo/hexo%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"hexo学习1.hexo书写123456categories: -分类1 -分类2tags: -标签1 -标签2 按照上述方式进行分类和标签，一直没进行标签和分类的整理。 1.1 hexo的字体、颜色、字号、位置p align=”right”&gt;font face=”微软雅黑” color=”red” size=”28”&gt;字体颜色大小 字体颜色大小 2.配置hexo里面的插入图片2.1插入本地图片方式1： 必须在source文件夹下建立一个空的文件，其实必须是/斜杠才能读取地址 格式为![] (/images/图片名字)【】里面的内容为取名 可以img但是要改方向 方式2： 使用img src=”” alt=”” 还是跟上面的加入/images/图片名字。alt= “”来命名 也可以直接插入但是要换斜杠的方向 2.2插入网络图片在网上找到图片，直接复制图片的地址， 使用img src=”加入链接” alt=”” alt= “”来命名 直接在![](后面加链接 3.在hexo里面的插入视频先上传，在网页视频上，在通过分享视频，点击分享，找到嵌入代码，复制粘贴即可。 ## 4.在hexo里面插入音频 在网易云里面进行插入。 首先：选择插入网页版； ？？？？由于版权保护无法生成什么鬼 解决办法https://www.shknn.com/music-163-gedan.html 1.点开歌单，找到生成外链，右击找到检查； 2.接着找到生成外链播放器这段文字直接双击复制前面/outchain/0/2945719972/，就是外链的复制id 3.然后直接将/outchain/0/2945719972/放到网站后面直接打开即可 https://music.163.com/ #/outchain/0/2945719972/ 歌单全部生成外链，单独的直接点开生成即可。选择直接播放，就可以每次打开就有一首。 直接复制代码进来即可，跟视频放入一样。 ## 5.更改博客背景音乐 打开主题下的_config.yml文件，有mp3歌曲 该歌曲是与直接插入不同，是通过外链转换为mp3进行切换 在网易云找到想听的歌，通过https://link.hhtjim.com/网站将其转换为mp3文件，复制进行即可 6.默认文章封面图的切换需求：发现每篇文章的封面图都为一样，想每篇换个封面","categories":[{"name":"-hexo完善","slug":"hexo完善","permalink":"https://esyyes.github.io/categories/hexo%E5%AE%8C%E5%96%84/"}],"tags":[{"name":"-个人博客搭建","slug":"个人博客搭建","permalink":"https://esyyes.github.io/tags/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"}]},{"title":"LV-1.3","slug":"hexo/hexo的使用","date":"2019-12-02T01:25:52.000Z","updated":"2019-12-04T03:04:01.075Z","comments":true,"path":"2019/12/02/hexo/hexo的使用/","link":"","permalink":"https://esyyes.github.io/2019/12/02/hexo/hexo%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"安装配置破解专业版的Pycharm1.对图像进行绘制12345678910111213141516171819202122232425import scipy.io as scoimport numpy as npfrom matplotlib import pyplot as pl# 定位mat所在dataFile = 'F://MITPSG//slp01am.mat'# 使用loadmat函数进行读取data = sco.loadmat(dataFile)# 查找data字典中的valkey值data = data['val']# 读取第一个列表data = data[1]# 中文显示，为了标记横纵坐标pl.rcParams['font.sans-serif'] = ['SimHei']pl.rcParams['axes.unicode_minus'] = False# 绘制图像pl.xlabel(u\"时间\")pl.ylabel(u\"幅值\")pl.title(u\"心电信号\")pl.plot(data)# 必须加show()才会出现图像pl.show() 2.配置hexo里面的插入图片2.1插入本地图片方式1： 必须在source文件夹下建立一个空的文件，其实必须是/斜杠才能读取地址 格式为![] (/images/图片名字)【】里面的内容为取名 可以img但是要改方向 方式2： 使用img src=”” alt=”” 还是跟上面的加入/images/图片名字。alt= “”来命名 也可以直接插入但是要换斜杠的方向 2.2插入网络图片在网上找到图片，直接复制图片的地址， 使用img src=”加入链接” alt=”” alt= “”来命名 直接在![](后面加链接","categories":[{"name":"随笔","slug":"随笔","permalink":"https://esyyes.github.io/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[]},{"title":"LV-1","slug":"python/python基础之绘制列表文件","date":"2019-12-01T11:56:29.000Z","updated":"2019-12-02T12:47:02.281Z","comments":true,"path":"2019/12/01/python/python基础之绘制列表文件/","link":"","permalink":"https://esyyes.github.io/2019/12/01/python/python%E5%9F%BA%E7%A1%80%E4%B9%8B%E7%BB%98%E5%88%B6%E5%88%97%E8%A1%A8%E6%96%87%E4%BB%B6/","excerpt":"","text":"绘制LV-0中的data列表数据1. import numpy as np由于机器学习算法在数据处理过程中大都涉及线性代数的知识，需要用到矩阵操作，Python本身没有处理矩阵的数据类型，因此需要使用附加的函数库。 NumPy函数库是Python开发环境的一个独立模块，是Python的一种开源的数值计算扩展工具。 这种工具可以用来存储和处理大型多维矩阵，比Python自身的列表结构要高效的多。尽管Python的list类型已经提供了类似于矩阵的表示形式，但是NumPy提供了更多的科学计算函数。 NumPy被定位为数学基础库，属于比较底层的Python库，其地位趋向于成为一个被其它库调用的核心库。 在使用NumPy库之前，首先必须导入该函数库，导入方式如下：import numpy as np# import 模块名 as 别名 2.matplotlib绘图Matplotlib 是 Python 的绘图库。 它可与 NumPy 一起使用，提供了一种有效的 MatLab 开源替代方案。 它也可以和图形工具包一起使用，如 PyQt 和 wxPython。 Matplotlib 默认情况不支持中文 123# 为了显示中文，目的：标记横纵坐标pl.rcParams['font.sans-serif']=['SimHei']pl.rcParams['axes.unicode_minus'] = False 参考如下对matplotlib绘制的讲解 https://blog.csdn.net/gaotihong/article/details/80983937 pylab 是 matplotlib 面向对象绘图库的一个接口，它的语法和 Matlab 十分相近，主要的绘图命令和 Matlab 对应的命令有相似的参数 暂时不对Matplotlib进行了解，初步选用pylab函数。 3.pylab和pyplot函数pylab 模块是一款由python提供的可以绘制二维，三维数据的工具模块，其中包括了绘图软件包 matplotlib,其可以生成matab绘图库的图像。 pylab将所有的功能函数（pyplot状态机函数，大部分时numpy里面的函数）全部导入其单独的命名空间内。为什么要这样做，是因为这样可以很好地与ipython（或者类似的IDE，比如pycharm）实现很好的交互模式，这个就和MATLAB差不多。 pylab和pyplot的区别是，前者将numpy导入了其命名空间中。这样会使pylab表现的和matlab更加相似。现在来说我们经常使用pyplot，因为pyplot相比pylab更加纯粹。 总结：使用的只是pylab里面的plot功能，暂时先直接使用pyplot函数。 matplotlib.pyplot：提供一个类似matlab的绘图框架。 pylab将pyplot与numpy合并为一个命名空间。这对于交互式工作很方便，但是对于编程来说，建议将名称空间分开. 3.1 pyplot函数Matplotlib.pyplot 常用方法（一）: https://blog.csdn.net/sinat_34022298/article/details/76348969 绘图函数是直接作用于当前axes（matplotlib中的专有名词，图形中组成部分，不是数学中的坐标系。 重大发现： 为啥我的pycharm好多功能没有！！！！！！！！！ PyCharm 在2017.3版本之后加入了Scientific Mode 2019版社区版为啥很多功能没有呢，社区版这么不给力嘛。。。下载破解版 对电脑访问权限的更改，明日任务，菜鸡问题多呀 总结就是问题一大堆，明天继续弄，速度过度到python","categories":[{"name":"游戏人生","slug":"游戏人生","permalink":"https://esyyes.github.io/categories/%E6%B8%B8%E6%88%8F%E4%BA%BA%E7%94%9F/"}],"tags":[]},{"title":"LV.0","slug":"python/python基础之读取mat文件","date":"2019-12-01T04:21:31.000Z","updated":"2019-12-02T12:48:43.770Z","comments":true,"path":"2019/12/01/python/python基础之读取mat文件/","link":"","permalink":"https://esyyes.github.io/2019/12/01/python/python%E5%9F%BA%E7%A1%80%E4%B9%8B%E8%AF%BB%E5%8F%96mat%E6%96%87%E4%BB%B6/","excerpt":"","text":"对MIT数据库中的mat文件进行读取1.MIT数据库数据数据库：MIT-BIH Polysomnographic Database 数据来源：https://archive.physionet.org/cgi-bin/atm/ATM MIT-BIH多导睡眠图数据库是睡眠期间多种生理信号记录的集合。在波士顿的贝思以色列医院睡眠实验室对受试者进行了监测，以评估慢性阻塞性睡眠呼吸暂停综合症，并测试恒定的气道正压通气（CPAP）的效果，气道正压通气是一种标准的治疗手段，通常可预防或大幅减少这些患者的气道阻塞。该数据库包含价值超过80小时的四通道，六通道和七通道多导睡眠图记录，每条记录的心电图信号逐节拍，以及关于睡眠阶段和呼吸暂停的EEG和呼吸信号。 2.数据下载及保存2.1 数据类型及说明.st文件为数据的注释文件，对睡眠/呼吸暂停进行注释； .ecg文件为数据的心电节拍注释文件，即心率ECG的R峰值点 .dat文件为4个通道的所有数据文件 .hea文件为文件的标头 主要参考利用ATM下载的mat文件 主要需要读取的文件格式 .txt .dat .mat .xls 2.2 数据保存位置F:\\MITPSG 例如文件：F:\\py\\读取.py 3 对.mat进行读取3.1 mat文件mat数据格式是Matlab的数据存储的标准格式。在Matlab中主要使用load()函数导入一个mat文件，使用save()函数保存一个mat文件。 在MATLAB中导入slp01am.mat文件：程序：F:\\matlabchengxu\\clus1.m 1load('slp01am.mat') 生成一个val变量，该变量为一个4*900,000数组，只需要对1-ECG和4-resq信号进行处理 3.2 在python中导入mat文件 在python中可以使用scipy.io中的函数loadmat()读取mat文件，函数savemat保存文件。 3.2.1 调用函数模块12import scipy.io as sci# import 模块名 as 别名 3.2.2 读取mat文件文件保存位置：F:\\MITPSG\\slp01am.mat 123import scipy.io as scodataFile = 'F://MITPSG//slp01am.mat'data = sco.loadmat(dataFile) 3.3 在Pycharm中查看变量 在需要查看那一行进行断点标记 运行debug Variables窗口中的变量可以右击，Add to Watches，然后在Watches窗口中可以看到所选数据的具体信息，包括数值。 12345# 打印data文件查看其形式print(data)# data文件是字典形式&#123;中间有hea文件开头&#125;# 在matlab中自动省去开头文件没有进行提取，所以是个字典形式print(type(data)) 3.4 读取val变量中的1.4列表12345# 查找data字典中的valkey值data = data[&apos;val&apos;]# 读取第一个列表data = data[1]print(data) 3.5 字典的读取字典特点： 符号为==大括号== 数据为==键值对==形式出现 各个键值对之间用==逗号==隔开 123dict1 = &#123;&apos;name&apos;: &apos;Tom&apos;, &apos;age&apos;: 20, &apos;gender&apos;: &apos;男&apos;&#125;print(dict1[&apos;name&apos;]) # Tomprint(dict1[&apos;id&apos;]) # 报错 总结： 初步完成了mat文件的读取 调用python的库时遇到各种奇奇怪怪的问题，还有些未解决，暂时现在py文件夹进行处理 pycharm里面的字典、列表等需要随时查看，不能直接套用matlab的经验 同理val：4即为呼吸的数据 下一步对列表数据进行处理 小菜鸡加油","categories":[{"name":"游戏人生","slug":"游戏人生","permalink":"https://esyyes.github.io/categories/%E6%B8%B8%E6%88%8F%E4%BA%BA%E7%94%9F/"}],"tags":[]},{"title":"pyhon基础--函数","slug":"python/pyhon基础-函数","date":"2019-11-24T12:57:32.000Z","updated":"2019-12-05T02:28:35.447Z","comments":true,"path":"2019/11/24/python/pyhon基础-函数/","link":"","permalink":"https://esyyes.github.io/2019/11/24/python/pyhon%E5%9F%BA%E7%A1%80-%E5%87%BD%E6%95%B0/","excerpt":"","text":"函数1.函数基本操作1234def 函数名(参数): 代码1 代码2 ..... 注意： 1. 不同的需求，参数可有可无。 2. 在Python中，函数必须==先定义后使用==。完成需求如下：一个函数完成两个数1和2的加法运算 12345678# 定义函数def add_num1(): result = 1 + 2 print(result)# 调用函数add_num1() 用户要在调用函数的时候指定具体数字，那么在定义函数的时候就需要接收用户指定的数字。函数调用时候指定的数字和定义函数时候接收的数字即是函数的参数。 12345678# 定义函数时同时定义了接收用户数据的参数a和b，a和b是形参def add_num2(a, b): result = a + b print(result)# 调用函数时传入了真实的数据10 和 20，真实数据为实参add_num2(10, 20) 需求：制作一个计算器，计算任意两数字之和，并保存结果。 1234567def sum_num(a, b): return a + b# 用result变量保存函数返回值result = sum_num(1, 2)print(result) 定义函数的说明文档 1234def 函数名(参数): \"\"\" 说明文档的位置 \"\"\" 代码 ...... 查看函数的说明文档 1help(函数名) 求三个数之和 12345def sum_num(a, b, c): return a + b + cresult = sum_num(1, 2, 3)print(result) # 6 函数的返回值 作用：函数调用后，返回需要的计算结果 写法 1return 表达式 函数的说明文档 作用：保存函数解释说明的信息 写法 12def 函数名(): &quot;&quot;&quot; 函数说明文档 &quot;&quot;&quot; 函数嵌套调用：一个函数内部嵌套调用另外一个函数 2.函数的参数12# global 关键字声明a是全局变量global a 传递和定义参数的顺序及个数必须一致。 函数调用，通过“键=值”形式加以指定。可以让函数更加清晰、容易使用，同时也清除了参数的顺序需求。 123456def user_info(name, age, gender): print(f'您的名字是&#123;name&#125;, 年龄是&#123;age&#125;, 性别是&#123;gender&#125;')user_info('Rose', age=20, gender='女')user_info('小明', gender='男', age=16) 注意：函数调用时，如果有位置参数时，位置参数必须在关键字参数的前面，但关键字参数之间不存在先后顺序。 缺省参数也叫默认参数，用于定义函数，为参数提供默认值，调用函数时可不传该默认参数的值（注意：所有位置参数必须出现在默认参数前，包括函数定义和调用）。 12345def user_info(name, age, gender='男'): print(f'您的名字是&#123;name&#125;, 年龄是&#123;age&#125;, 性别是&#123;gender&#125;')user_info('TOM', 20)user_info('Rose', 18, '女') 注意：函数调用时，如果为缺省参数传值则修改默认参数值；否则使用这个默认值。 不定长参数也叫可变参数。用于不确定调用的时候会传递多少个参数(不传参也可以)的场景。此时，可用包裹(packing)位置参数，或者包裹关键字参数，来进行参数传递，会显得非常方便。 123456def user_info(*args): print(args)# ('TOM',)user_info('TOM')# ('TOM', 18)user_info('TOM', 18) 注意：传进的所有参数都会被args变量收集，它会根据传进参数的位置合并为一个元组(tuple)，args是元组类型，这就是包裹位置传递。 包裹关键字传递 123456def user_info(**kwargs): print(kwargs)# &#123;'name': 'TOM', 'age': 18, 'id': 110&#125;user_info(name='TOM', age=18, id=110) 综上：无论是包裹位置传递还是包裹关键字传递，都是一个组包的过程。 拆包：元组 1234567def return_num(): return 100, 200num1, num2 = return_num()print(num1) # 100print(num2) # 200 拆包：字典 12345678910dict1 = &#123;'name': 'TOM', 'age': 18&#125;a, b = dict1# 对字典进行拆包，取出来的是字典的keyprint(a) # nameprint(b) # ageprint(dict1[a]) # TOMprint(dict1[b]) # 18 所谓可变类型与不可变类型是指：数据能够直接进行修改，如果能直接修改那么就是可变，否则是不可变. 可变类型 列表 字典 集合 不可变类型 整型 浮点型 字符串 元组 总结 变量作用域 全局：函数体内外都能生效 局部：当前函数体内部生效 函数多返回值写法 1return 表达式1, 表达式2... 函数的参数 位置参数 形参和实参的个数和书写顺序必须一致 关键字参数 写法： key=value 特点：形参和实参的书写顺序可以不一致；关键字参数必须书写在位置参数的后面 缺省参数 缺省参数就是默认参数 写法：key=vlaue 不定长位置参数 收集所有位置参数，返回一个元组 不定长关键字参数 收集所有关键字参数，返回一个字典 引用：Python中，数据的传递都是通过引用 三. lambda 表达式3.1 lambda的应用场景如果一个函数有一个返回值，并且只有一句代码，可以使用 lambda简化。 3.2 lambda语法1lambda 参数列表 ： 表达式 注意 lambda表达式的参数可有可无，函数的参数在lambda表达式中完全适用。 lambda表达式能接收任何数量的参数但只能返回一个表达式的值。 快速入门12345678910111213# 函数def fn1(): return 200print(fn1)print(fn1())# lambda表达式fn2 = lambda: 100print(fn2)print(fn2()) 注意：直接打印lambda表达式，输出的是此lambda的内存地址 3.3 示例：计算a + b3.3.1 函数实现123456def add(a, b): return a + bresult = add(1, 2)print(result) 思考：需求简单，是否代码多？ 3.3.2 lambda实现12fn1 = lambda a, b: a + bprint(fn1(1, 2)) 3.4 lambda的参数形式3.4.1.无参数12fn1 = lambda: 100print(fn1()) 3.4.2.一个参数12fn1 = lambda a: aprint(fn1('hello world')) 3.4.3.默认参数12fn1 = lambda a, b, c=100: a + b + cprint(fn1(10, 20)) 3.4.4.可变参数：*args12fn1 = lambda *args: argsprint(fn1(10, 20, 30)) 注意：这里的可变参数传入到lambda之后，返回值为元组。 3.4.5.可变参数：**kwargs12fn1 = lambda **kwargs: kwargsprint(fn1(name='python', age=20)) 3.5 lambda的应用3.5.1. 带判断的lambda12fn1 = lambda a, b: a if a &gt; b else bprint(fn1(1000, 500)) 3.5.2. 列表数据按字典key的值排序1234567891011121314151617students = [ &#123;'name': 'TOM', 'age': 20&#125;, &#123;'name': 'ROSE', 'age': 19&#125;, &#123;'name': 'Jack', 'age': 22&#125;]# 按name值升序排列students.sort(key=lambda x: x['name'])print(students)# 按name值降序排列students.sort(key=lambda x: x['name'], reverse=True)print(students)# 按age值升序排列students.sort(key=lambda x: x['age'])print(students) 四. 高阶函数==把函数作为参数传入==，这样的函数称为高阶函数，高阶函数是函数式编程的体现。函数式编程就是指这种高度抽象的编程范式。 4.1 体验高阶函数在Python中，abs()函数可以完成对数字求绝对值计算。 1abs(-10) # 10 round()函数可以完成对数字的四舍五入计算。 12round(1.2) # 1round(1.9) # 2 需求：任意两个数字，按照指定要求整理数字后再进行求和计算。 方法1 123456def add_num(a, b): return abs(a) + abs(b)result = add_num(-1, 2)print(result) # 3 方法2 123456def sum_num(a, b, f): return f(a) + f(b)result = sum_num(-1, 2, abs)print(result) # 3 注意：两种方法对比之后，发现，方法2的代码会更加简洁，函数灵活性更高。 函数式编程大量使用函数，减少了代码的重复，因此程序比较短，开发速度较快。 4.2 内置高阶函数4.2.1 map()map(func, lst)，将传入的函数变量func作用到lst变量的每个元素中，并将结果组成新的列表(Python2)/迭代器(Python3)返回。 需求：计算list1序列中各个数字的2次方。 1234567891011list1 = [1, 2, 3, 4, 5]def func(x): return x ** 2result = map(func, list1)print(result) # &lt;map object at 0x0000013769653198&gt;print(list(result)) # [1, 4, 9, 16, 25] 4.2.2 reduce()reduce(func，lst)，其中func必须有两个参数。每次func计算的结果继续和序列的下一个元素做累积计算。 注意：reduce()传入的参数func必须接收2个参数。 需求：计算list1序列中各个数字的累加和。 123456789101112import functoolslist1 = [1, 2, 3, 4, 5]def func(a, b): return a + bresult = functools.reduce(func, list1)print(result) # 15 4.2.3 filter()filter(func, lst)函数用于过滤序列, 过滤掉不符合条件的元素, 返回一个 filter 对象。如果要转换为列表, 可以使用 list() 来转换。 1234567891011list1 = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]def func(x): return x % 2 == 0result = filter(func, list1)print(result) # &lt;filter object at 0x0000017AF9DC3198&gt;print(list(result)) # [2, 4, 6, 8, 10] 总结 递归 函数内部自己调用自己 必须有出口 lambda 语法 1lambda 参数列表: 表达式 lambda的参数形式 无参数 1lambda: 表达式 一个参数 1lambda 参数: 表达式 默认参数 1lambda key=value: 表达式 不定长位置参数 1lambda *args: 表达式 不定长关键字参数 1lambda **kwargs: 表达式 高阶函数 作用：把函数作为参数传入，化简代码 内置高阶函数 map() reduce() filter()","categories":[{"name":"-python基础","slug":"python基础","permalink":"https://esyyes.github.io/categories/python%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"-python -人工智能","slug":"python-人工智能","permalink":"https://esyyes.github.io/tags/python-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}]},{"title":"pyhon基础--模块","slug":"python/pyhon基础-模块","date":"2019-11-24T12:12:54.000Z","updated":"2019-11-24T12:51:10.591Z","comments":true,"path":"2019/11/24/python/pyhon基础-模块/","link":"","permalink":"https://esyyes.github.io/2019/11/24/python/pyhon%E5%9F%BA%E7%A1%80-%E6%A8%A1%E5%9D%97/","excerpt":"","text":"模块和包一. 模块Python 模块(Module)，是一个 Python 文件，以 .py 结尾，包含了 Python 对象定义和Python语句。 模块能定义函数，类和变量，模块里也能包含可执行的代码。 1.1. 导入模块1.1.1 导入模块的方式 import 模块名 from 模块名 import 功能名 from 模块名 import * import 模块名 as 别名 from 模块名 import 功能名 as 别名 1.1.2 导入方式详解1.1.2.1 import语法 12345678# 1. 导入模块import 模块名import 模块名1, 模块名2...# 2. 调用功能模块名.功能名() 12import mathprint(math.sqrt(36)) 1.1.2.2 from..import..from 模块名 import 功能1, 功能2, 功能3… 12from math import sqrtprint(sqrt(36)) 1.1.2.3 from .. import *from 模块名 import * # *指代所有 12from math import *print(sqrt(36)) 1.1.2.4 as定义别名12345# 模块定义别名 ：即改名字import 模块名 as 别名# 功能定义别名from 模块名 import 功能 as 别名 1.2. 制作模块在Python中，每个Python文件都可以作为一个模块，模块的名字就是文件的名字。也就是说自定义模块名必须要符合标识符命名规则。 1.2.1 定义模块新建一个Python文件，命名为my_module1.py，并定义testA函数。 12345# 完成加法运算def testA(a, b): print(a + b)# 测试信息testA(1, 11) 此时，无论是当前文件，还是其他已经导入了该模块的文件，在运行的时候都会自动执行testA函数的调用。 123456def testA(a, b): print(a + b)# 只在当前文件中调用该函数，其他导入的文件内不符合该条件，则不执行testA函数调用if __name__ == &apos;__main__&apos;: testA(1, 11) 123# 调用import my_modulemy_module.testA(4, 6) 如果使用from .. import ..或from .. import *导入多个模块的时候，且模块内有同名功能。当调用这个同名功能的时候，调用到的是后面导入的模块的功能。 1.3. 模块定位顺序当导入一个模块，Python解析器对模块位置的搜索顺序是： 当前目录 如果不在当前目录，Python则搜索在shell变量PYTHONPATH下的每个目录。 如果都找不到，Python会察看默认路径。UNIX下，默认路径一般为/usr/local/lib/python/ 模块搜索路径存储在system模块的sys.path变量中。变量里包含当前目录，PYTHONPATH和由安装过程决定的默认目录。 1.4. __all__如果一个模块文件中有__all__变量，当使用from xxx import *导入时，只能导入这个列表中的元素。 二. 包包将有联系的模块组织在一起，即放到同一个文件夹下，并且在这个文件夹创建一个名字为__init__.py 文件，那么这个文件夹就称之为包。 2.1 制作包[New] — [Python Package] — 输入包名 — [OK] — 新建功能模块(有联系的模块)。 注意：新建包后，包内部会自动创建__init__.py文件，这个文件控制着包的导入行为。 2.1.1 快速体验 新建包mypackage 新建包内模块：my_module1 和 my_module2 模块内代码如下 123456# my_module1print(1)def info_print1(): print('my_module1') 123456# my_module2print(2)def info_print2(): print('my_module2') 2.2 导入包2.2.1 方法一123import 包名.模块名包名.模块名.目标 2.2.1.1 体验123import my_package.my_module1my_package.my_module1.info_print1() 2.2.2 方法二注意：必须在__init__.py文件中添加__all__ = []，控制允许导入的模块列表。 12from 包名 import *模块名.目标 2.2.2.1 体验123from my_package import *my_module1.info_print1() 三. 总结 导入模块方法 12345import 模块名from 模块名 import 目标from 模块名 import * 导入包 123import 包名.模块名from 包名 import * __all__ = [] ：允许导入的模块或功能列表","categories":[],"tags":[]},{"title":"python2","slug":"python/python基础--异常","date":"2019-11-20T13:59:36.000Z","updated":"2019-11-24T12:11:33.132Z","comments":true,"path":"2019/11/20/python/python基础--异常/","link":"","permalink":"https://esyyes.github.io/2019/11/20/python/python%E5%9F%BA%E7%A1%80--%E5%BC%82%E5%B8%B8/","excerpt":"","text":"一.异常当检测到一个错误时，解释器就无法继续执行了，反而出现了一些错误的提示，这就是所谓的”异常”。 二. 异常的写法2.1 语法1234try: 可能发生错误的代码except: 如果出现异常执行的代码 2.2 捕获指定异常2.2.1 语法1234try: 可能发生错误的代码except 异常类型: 如果捕获到该异常类型执行的代码 1234try: print(num)except NameError: print(&apos;有错误&apos;) 注意： 如果尝试执行的代码的异常类型和要捕获的异常类型不一致，则无法捕获异常。 一般try下方只放一行尝试执行的代码。 2.2.2 捕获多个指定异常当捕获多个异常时，可以把要捕获的异常类型的名字，放到except 后，并使用元组的方式进行书写。 12345try: print(1/0)except (NameError, ZeroDivisionError): print(&apos;有错误&apos;) 2.2.3 捕获异常描述信息1234try: print(num)except (NameError, ZeroDivisionError) as result: print(result) 2.2.4 捕获所有异常Exception是所有程序异常类的父类。 1234try: print(num)except Exception as result: print(result) 2.3 异常的elseelse表示的是如果没有异常要执行的代码。 123456try: print(1)except Exception as result: print(result)else: print(&apos;我是else，是没有异常的时候执行的代码&apos;) 2.4 异常的finallyfinally表示的是无论是否异常都要执行的代码 2.5 自定义异常在Python中，抛出自定义异常的语法为raise 异常类对象。 三. 总结异常语法 12345678try: 可能发生异常的代码except: 如果出现异常执行的代码else: 没有异常执行的代码finally: 无论是否异常都要执行的代码 捕获异常 12345except 异常类型: 代码except 异常类型 as xx: 代码 自定义异常 123456789101112131415161718# 1. 自定义异常类class 异常类类名(Exception): 代码 # 设置抛出异常的描述信息 def __str__(self): return ...# 2. 抛出异常raise 异常类名()# 捕获异常except Exception...","categories":[{"name":"python基础","slug":"python基础","permalink":"https://esyyes.github.io/categories/python%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"https://esyyes.github.io/tags/python/"}]},{"title":"python1","slug":"python/python基础--推导式","date":"2019-11-20T08:29:46.000Z","updated":"2019-11-21T01:11:50.373Z","comments":true,"path":"2019/11/20/python/python基础--推导式/","link":"","permalink":"https://esyyes.github.io/2019/11/20/python/python%E5%9F%BA%E7%A1%80--%E6%8E%A8%E5%AF%BC%E5%BC%8F/","excerpt":"","text":"PYTHON基础学习–推导式⼀. 列表推导式作⽤：⽤⼀个表达式创建⼀个有规律的列表或控制⼀个有规律列表。 列表推导式⼜叫列表⽣成式。 1.1 while循环实现123456list1 = []i = 0while i &lt; 10: list1.append(i) i += 1print(list1) 1.2 for循环实现1234list1 = []for i in range(10): list1.append(i)print(list1) 1.3 list推导式12list1 = [i for i in range(10)]print(list1) 1.4 带if的列表推导式需求：创建0-10的偶数列表 range()步长实现：range左闭右开 12list1 = [i for i in range(0, 10, 2)]print(list1) if实现推导式 12list1 = [i for i in range(0, 10) if i % 2 == 0]print(list1) 1.5 多个for循环推导式需求：创建列表如下： 1[(1, 0), (1, 1), (1, 2), (2, 0), (2, 1), (2, 2)] 代码如下： 123for i in range(1, 3): for j in range(3): print((i, j), end=&apos;&apos;) 推导式： 12list1 =[(i, j) for i in range(1, 3) for j in range(3)]print(list1) 总结推导式的作⽤：简化代码 推导式写法 123456# 列表推导式[xx for xx in range()]# 字典推导式&#123;xx1: xx2 for ... in ...&#125;# 集合推导式&#123;xx for xx in ...&#125;","categories":[{"name":"python基础","slug":"python基础","permalink":"https://esyyes.github.io/categories/python%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"https://esyyes.github.io/tags/python/"}]}],"categories":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/categories/work/"},{"name":"hexo","slug":"hexo","permalink":"https://esyyes.github.io/categories/hexo/"},{"name":"python","slug":"python","permalink":"https://esyyes.github.io/categories/python/"},{"name":"matlab","slug":"matlab","permalink":"https://esyyes.github.io/categories/matlab/"},{"name":"-工作 -matlab","slug":"工作-matlab","permalink":"https://esyyes.github.io/categories/%E5%B7%A5%E4%BD%9C-matlab/"},{"name":"-工作","slug":"工作","permalink":"https://esyyes.github.io/categories/%E5%B7%A5%E4%BD%9C/"},{"name":"-升级conda","slug":"升级conda","permalink":"https://esyyes.github.io/categories/%E5%8D%87%E7%BA%A7conda/"},{"name":"-matlab -工作","slug":"matlab-工作","permalink":"https://esyyes.github.io/categories/matlab-%E5%B7%A5%E4%BD%9C/"},{"name":"-hexo完善","slug":"hexo完善","permalink":"https://esyyes.github.io/categories/hexo%E5%AE%8C%E5%96%84/"},{"name":"随笔","slug":"随笔","permalink":"https://esyyes.github.io/categories/%E9%9A%8F%E7%AC%94/"},{"name":"游戏人生","slug":"游戏人生","permalink":"https://esyyes.github.io/categories/%E6%B8%B8%E6%88%8F%E4%BA%BA%E7%94%9F/"},{"name":"-python基础","slug":"python基础","permalink":"https://esyyes.github.io/categories/python%E5%9F%BA%E7%A1%80/"},{"name":"python基础","slug":"python基础","permalink":"https://esyyes.github.io/categories/python%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"work","slug":"work","permalink":"https://esyyes.github.io/tags/work/"},{"name":"hexo","slug":"hexo","permalink":"https://esyyes.github.io/tags/hexo/"},{"name":"python","slug":"python","permalink":"https://esyyes.github.io/tags/python/"},{"name":"-malab -毕业","slug":"malab-毕业","permalink":"https://esyyes.github.io/tags/malab-%E6%AF%95%E4%B8%9A/"},{"name":"-python","slug":"python","permalink":"https://esyyes.github.io/tags/python/"},{"name":"-个人博客搭建","slug":"个人博客搭建","permalink":"https://esyyes.github.io/tags/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"},{"name":"-python -人工智能","slug":"python-人工智能","permalink":"https://esyyes.github.io/tags/python-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}]}