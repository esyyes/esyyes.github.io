<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>python_随机森林参数设置 | ESY</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="随机森林参数设置随机森林介绍随机森林定义在机器学习中，**随机森林是一个包含多个决策树的分类器**， 并且其输出的类别是由个别树输出的类别的众数而定。 Leo Breiman和Adele Cutler发展出推论出随机森林的算法。 而 “Random Forests” 是他们的商标。 这个术语是1995年由贝尔实验室的Tin Kam Ho所提出的随机决策森林（random decision fo">
<meta property="og:type" content="article">
<meta property="og:title" content="python_随机森林参数设置">
<meta property="og:url" content="https://esyyes.github.io/2020/03/22/python-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE/index.html">
<meta property="og:site_name" content="ESY">
<meta property="og:description" content="随机森林参数设置随机森林介绍随机森林定义在机器学习中，**随机森林是一个包含多个决策树的分类器**， 并且其输出的类别是由个别树输出的类别的众数而定。 Leo Breiman和Adele Cutler发展出推论出随机森林的算法。 而 “Random Forests” 是他们的商标。 这个术语是1995年由贝尔实验室的Tin Kam Ho所提出的随机决策森林（random decision fo">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://i0.hdslb.com/bfs/archive/f252847e6071d16bf5f9b423d759b2c8a0c6eb3d.jpg">
<meta property="og:image" content="http://i2.hdslb.com/bfs/archive/2c891439af62694315487dc640d3beb6d5709593.jpg">
<meta property="article:published_time" content="2020-03-22T05:37:20.000Z">
<meta property="article:modified_time" content="2020-03-22T05:37:20.000Z">
<meta property="article:author" content="esy">
<meta property="article:tag" content="python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://i0.hdslb.com/bfs/archive/f252847e6071d16bf5f9b423d759b2c8a0c6eb3d.jpg">
  
    <link rel="alternate" href="/atom.xml" title="ESY" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">ESY</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://esyyes.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-python-随机森林参数设置" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/03/22/python-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE/" class="article-date">
  <time datetime="2020-03-22T05:37:20.000Z" itemprop="datePublished">2020-03-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      python_随机森林参数设置
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="http://i0.hdslb.com/bfs/archive/f252847e6071d16bf5f9b423d759b2c8a0c6eb3d.jpg"></p>
<p><img src="http://i2.hdslb.com/bfs/archive/2c891439af62694315487dc640d3beb6d5709593.jpg"></p>
<h1 id="随机森林参数设置"><a href="#随机森林参数设置" class="headerlink" title="随机森林参数设置"></a>随机森林参数设置</h1><h2 id="随机森林介绍"><a href="#随机森林介绍" class="headerlink" title="随机森林介绍"></a>随机森林介绍</h2><h3 id="随机森林定义"><a href="#随机森林定义" class="headerlink" title="随机森林定义"></a>随机森林定义</h3><p>在<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>中，**随机森林是一个包含多个决策树的<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E5%88%86%E7%B1%BB%E5%99%A8">分类器</a>**， 并且其输出的类别是由个别树输出的类别的众数而定。 Leo Breiman和Adele Cutler发展出推论出随机森林的算法。 而 “Random Forests” 是他们的<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E5%95%86%E6%A0%87">商标</a>。 这个术语是1995年由贝尔实验室的Tin Kam Ho所提出的随机决策森林（random decision forests）而来的。这个方法则是结合 Breimans 的 “Bootstrap aggregating” 想法和 Ho 的”random subspace method”以建造<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E5%86%B3%E7%AD%96%E6%A0%91">决策树</a>的集合。</p>
<h3 id="随机森林参数定义"><a href="#随机森林参数定义" class="headerlink" title="随机森林参数定义"></a>随机森林参数定义</h3><p><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Longtermevolution/article/details/100919721">https://blog.csdn.net/Longtermevolution/article/details/100919721</a></p>
<p><strong>n_estimators：</strong></p>
<p>森林中数的个数。<br>这个属性是典型的<strong>模型表现与模型效率成反比的影响因子</strong>，即便如此，你还是应该尽可能提高这个数字，以让你的模型更准确更稳定。</p>
<p><strong>criterion ：</strong></p>
<p>度量分裂的标准。可选值：“mse”，均方差（mean squared error）；“mae”，平均绝对值误差（mean absolute error） 支持的标准是基尼杂质的“<strong>gini（基尼）</strong>”和<strong>信息增益的“entropy（熵</strong>）”。注意：此参数是特定于树的。<strong>默认是基尼</strong></p>
<p><strong>max_features</strong> ：</p>
<p>寻找<strong>最佳分裂点时考虑的特征数目</strong>。可选值，int（具体的数目），float（数目的百分比），string（“auto”， “sqrt”，“log2”）.<br>这一属性是对单个树来设置的，通常来讲，<strong>这个值越大单棵树可以考虑的属性越多，则模型的表现就越好</strong>。但是这也不是肯定的，不过有一点是肯定的，增加这个值会导致算法运行速度变慢，所以需要我们考虑去达到一个平衡。</p>
<p>**max_depth :**integer或者None。树的最大深度，如果None，节点扩展直到所有叶子是纯的或者所有叶子节点包含的样例数小于min_samples_split </p>
<p><strong>min_samples_split</strong> ： 分裂内部节点需要的最少样例数。int(具体数目),float(数目的百分比) </p>
<p><strong>min_samples_leaf</strong> ：叶子节点上应有的最少样例数。int(具体数目),float(数目的百分比)。<br>更少的节点数使得模型更容易遭受noise data的影响，我通常设置这个值大于50，但是你需要寻找最适合你的数值。 </p>
<p><strong>min_weight_fraction_leaf ：</strong> </p>
<p><strong>max_leaf_nodes ：</strong>以”最优优先方式”(best-first fashion),最优节点定义为:纯度的相对减少.如果None则不限制叶子节点个数;[float]<br><strong>min_impurity_split :</strong> 树增长提前结束的阈值.对于当前节点,大于这个阈值将分裂,否则就看做叶子节点; [float]<br><strong>min_impurity_decrease ：</strong>一个阈值,表示一个节点分裂的条件是:如果这次分裂纯度的减少大于等于这这个值.<br><strong>bootstrap</strong> ：构建数是不是采用有放回样本的方式(bootstrap samples); [True/False]<br><strong>oob_score ：</strong>交叉验证相关的属性。<br><strong>n_jobs ：</strong>设定fit和predict阶段并列执行的任务个数,<strong>如果设置为-1表示并行执行的任务数等于计算级核数</strong>; [integer, optional (default=1)]<br><strong>random_state</strong> ：如果是<strong>int数值表示它就是随机数产生器的种子</strong>.如果指定RandomState实例,它就是随机产生器的种子.如果是None,随机数产生器是np.random所用的RandomState实例; [int, RandomState instance or None, optional (default=None)]<br><strong>verbose ：</strong>控制<strong>构建数过程的冗长度</strong>; [int, optional (default=0)]<br><strong>warm_start ：</strong>当设置为True,重新使用之前的结构去拟合样例并且加入更多的估计器(estimators,在这里就是随机树)到组合器中; [True/False]<br><strong>class_weight: “</strong>banlanced”模式是根据y标签值自动调整权值与输入数据的类频率成反比,计算公式是:n_samples / (n_classes np.bincount(y)).“balanced_subsample”模式的与”balanced模式相同,只<strong>不过在每一次树增长过程中权值的计算是根据有放回样本的</strong>.</p>
<h2 id="模型调参利器-gridSearchCV（网格搜索）"><a href="#模型调参利器-gridSearchCV（网格搜索）" class="headerlink" title="模型调参利器 gridSearchCV（网格搜索）"></a>模型调参利器 gridSearchCV（网格搜索）</h2><p>GridSearchCV，它存在的意义就是<strong>自动调参</strong>，只要把参数输进去，就能给出<strong>最优化的结果和参数</strong>。但是这个方法适合于<strong>小数据集</strong>，一旦数据的量级上去了，很难得出结果。这个时候就是需要动脑筋了。数据量比较大的时候可以使用一个快速调优的方法——坐标下降。它其实是一种<strong>贪心算法</strong>：<strong>拿当前对模型影响最大的参数调优，直到最优化；再拿下一个影响最大的参数调优</strong>，如此下去，直到所有的参数调整完毕。这个方法的缺点就是可能会调到局部最优而不是全局最优，但是省时间省力，巨大的优势面前，还是试一试吧，后续可以再拿bagging再优化。</p>
<h2 id="2-参数说明"><a href="#2-参数说明" class="headerlink" title="2.参数说明"></a>2.参数说明</h2><p><em>class sklearn.model_selection.<strong>GridSearchCV</strong>(estimator, param_grid, scoring=None, fit_params=None, n_jobs=1, iid=True, refit=True, cv=None, verbose=0, pre_dispatch=‘2\</em>n_jobs’, error_score=’raise’, return_train_score=’warn’)*</p>
<p><strong>（1）</strong>    <strong><em>estimator\</em></strong></p>
<p>选择使用的分类器，并且传入除需要确定最佳的参数之外的其他参数。每一个分类器都需要一个scoring参数，或者score方法：estimator=RandomForestClassifier(min_samples_split=100,min_samples_leaf=20,max_depth=8,max_features=’sqrt’,random_state=10),</p>
<p><strong>（2）</strong>    <strong><em>param_grid\</em></strong></p>
<p>需要最优化的参数的取值，值为字典或者列表，例如：param_grid =param_test1，param_test1 = {‘n_estimators’:range(10,71,10)}。</p>
<p><strong>（3）</strong>    <strong><em>scoring=None\</em></strong></p>
<p>模型评价标准，默认None,这时需要使用score函数；或者如scoring=’roc_auc’，根据所选模型不同，评价准则不同。字符串（函数名），或是可调用对象，需要其函数签名形如：scorer(estimator, X, y)；如果是None，则使用estimator的误差估计函数。具体值的选取看本篇第三节内容。</p>
<p><strong>（4）</strong>    <strong><em>fit_params=None\</em></strong></p>
<p><strong>（5）</strong>    <strong><em>n_jobs=1\</em></strong></p>
<p>n_jobs: 并行数，int：个数,-1：跟CPU核数一致, 1:默认值</p>
<p><strong>（6）</strong>    <strong><em>iid=True\</em></strong></p>
<p><strong>iid</strong>:默认True,为True时，默认为各个样本fold概率分布一致，误差估计为所有样本之和，而非各个fold的平均。</p>
<p><strong>（7）</strong>    <strong><em>refit=True\</em></strong></p>
<p>默认为True,程序将会以交叉验证训练集得到的最佳参数，重新对所有可用的训练集与开发集进行，作为最终用于性能评估的最佳模型参数。即在搜索参数结束后，用最佳参数结果再次fit一遍全部数据集。</p>
<p><strong>（8）</strong>    <strong><em>cv=None\</em></strong></p>
<p>交叉验证参数，默认None，使用三折交叉验证。指定fold数量，默认为3，也可以是yield训练/测试数据的生成器。</p>
<p><strong>（9）</strong>    <strong><em>verbose=0\</em>, *scoring=None*</strong></p>
<p><strong>verbose</strong>：日志冗长度，int：冗长度，0：不输出训练过程，1：偶尔输出，&gt;1：对每个子模型都输出。</p>
<p><strong>（10）</strong>  <strong><em>pre_dispatch=‘2\</em>n_jobs’*</strong></p>
<p>指定总共分发的并行任务数。当n_jobs大于1时，数据将在每个运行点进行复制，这可能导致OOM，而设置pre_dispatch参数，则可以预先划分总共的job数量，使数据最多被复制pre_dispatch次</p>
<p><strong>（11）</strong>  <strong><em>error_score=’raise’\</em></strong></p>
<p><strong>（12）</strong>  <strong><em>return_train_score=’warn’\</em></strong></p>
<p>如果“False”，cv_results_属性将不包括训练分数</p>
<p>回到sklearn里面的GridSearchCV，GridSearchCV用于系统地遍历多种参数组合，通过交叉验证确定最佳效果参数。</p>
<p><strong>打算使用网格搜索对模型进行调优，然后再进行交叉验证！</strong></p>
<h2 id="步骤实现："><a href="#步骤实现：" class="headerlink" title="步骤实现："></a>步骤实现：</h2><ol>
<li>想让树的数目从10到100</li>
</ol>
<p>生成一个10,100的列表</p>
<p>list(range(10,100))</p>
<ol start="2">
<li>构建循环</li>
<li>实现代码</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化模型</span></span><br><span class="line">rfc = RandomForestClassifier()</span><br><span class="line"></span><br><span class="line">tuned_parameter = [&#123; <span class="string">&#x27;n_estimators&#x27;</span>:<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">10</span>, <span class="number">100</span>))&#125;]</span><br><span class="line">对模型进行交叉验证，<span class="comment"># 将训练/测试数据集划分10个互斥子集</span></span><br><span class="line"><span class="comment"># kflod = StratifiedKFold(n_splits=10, shuffle = True,random_state=7)</span></span><br><span class="line"><span class="comment"># 将模型进行网格搜索调优</span></span><br><span class="line">clf = GridSearchCV(estimator=rfc,param_grid=tuned_parameter, cv=kflod, n_jobs=<span class="number">1</span>)</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 将模型进行网格搜索调优</span></span><br><span class="line">print(<span class="string">&quot;Best: %f using %s&quot;</span> % (clf.best_score_,clf.best_params_))</span><br><span class="line">out：</span><br><span class="line">	Best: <span class="number">0.912500</span> using &#123;<span class="string">&#x27;n_estimators&#x27;</span>: <span class="number">28</span>&#125;</span><br></pre></td></tr></table></figure>

<p>没啥必要循环了，每次都在变，选个最高的模型越复杂越好，就选14的倍数，<strong>28</strong></p>
<h2 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a><strong>参考博客</strong></h2><p>参考这篇对模型进行优化，还可以用下这个模型</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_41988628/article/details/83098130">https://blog.csdn.net/weixin_41988628/article/details/83098130</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># 数据科学计算工具</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># 数值计算工具</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># 可视化</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns <span class="comment"># matplotlib的高级API</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold <span class="comment">#交叉验证</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV <span class="comment">#网格搜索</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split <span class="comment">#将数据集分开成训练集和测试集</span></span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier                     <span class="comment">#xgboost</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pima = pd.read_csv(<span class="string">&quot;pima_indians-diabetes.csv&quot;</span>)</span><br><span class="line">print(pima.head())</span><br><span class="line"></span><br><span class="line">x = pima.iloc[:,<span class="number">0</span>:<span class="number">8</span>]</span><br><span class="line">y = pima.iloc[:,<span class="number">8</span>]</span><br><span class="line"></span><br><span class="line">seed = <span class="number">7</span> <span class="comment">#重现随机生成的训练</span></span><br><span class="line">test_size = <span class="number">0.33</span> <span class="comment">#33%测试，67%训练</span></span><br><span class="line">X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=test_size, random_state=seed</span><br><span class="line">model = XGBClassifier()               </span><br><span class="line">learning_rate = [<span class="number">0.0001</span>,<span class="number">0.001</span>,<span class="number">0.01</span>,<span class="number">0.1</span>,<span class="number">0.2</span>,<span class="number">0.3</span>] <span class="comment">#学习率</span></span><br><span class="line">gamma = [<span class="number">1</span>, <span class="number">0.1</span>, <span class="number">0.01</span>, <span class="number">0.001</span>]</span><br><span class="line"></span><br><span class="line">param_grid = <span class="built_in">dict</span>(learning_rate = learning_rate,gamma = gamma)<span class="comment">#转化为字典格式，网络搜索要求</span></span><br><span class="line"></span><br><span class="line">kflod = StratifiedKFold(n_splits=<span class="number">10</span>, shuffle = <span class="literal">True</span>,random_state=<span class="number">7</span>)<span class="comment">#将训练/测试数据集划分10个互斥子集，</span></span><br><span class="line"></span><br><span class="line">grid_search = GridSearchCV(model,param_grid,scoring = <span class="string">&#x27;neg_log_loss&#x27;</span>,n_jobs = <span class="number">-1</span>,cv = kflod)</span><br><span class="line"><span class="comment">#scoring指定损失函数类型，n_jobs指定全部cpu跑，cv指定交叉验证</span></span><br><span class="line">grid_result = grid_search.fit(X_train, Y_train) <span class="comment">#运行网格搜索</span></span><br><span class="line">print(<span class="string">&quot;Best: %f using %s&quot;</span> % (grid_result.best_score_,grid_search.best_params_))</span><br><span class="line"><span class="comment">#grid_scores_：给出不同参数情况下的评价结果。best_params_：描述了已取得最佳结果的参数的组合</span></span><br><span class="line"><span class="comment">#best_score_：成员提供优化过程期间观察到的最好的评分</span></span><br><span class="line"><span class="comment">#具有键作为列标题和值作为列的dict，可以导入到DataFrame中。</span></span><br><span class="line"><span class="comment">#注意，“params”键用于存储所有参数候选项的参数设置列表。</span></span><br><span class="line">means = grid_result.cv_results_[<span class="string">&#x27;mean_test_score&#x27;</span>]</span><br><span class="line">params = grid_result.cv_results_[<span class="string">&#x27;params&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> mean,param <span class="keyword">in</span> <span class="built_in">zip</span>(means,params):</span><br><span class="line">    print(<span class="string">&quot;%f  with:   %r&quot;</span> % (mean,param))</span><br></pre></td></tr></table></figure>

<h1 id="忽略警告"><a href="#忽略警告" class="headerlink" title="忽略警告"></a>忽略警告</h1><p>每次都会出现一大堆的红字，看到就不舒服，以后将这个作为第一个</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>在PyCharm中提示shadows name ‘xxxx’ from outer scope，当你在外部有个相同名称的变量在方法内部被重新指定了新的值，也就是说你在外部的相同名称的变量压根就没有任何作用。所以PyCharm就回提示这个信息。这个时候就需要我们去调整具体代码了。</p>
<p>意思就是在pycharm中，函数中的变量最好跟外部的变量不一样，要不然就会警告</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://esyyes.github.io/2020/03/22/python-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE/" data-id="ckh4h5f60003zisue41fq0810" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/03/22/python-Accuracy-Precison-Recall-F1-score/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          python_Accuracy,Precison,Recall,F1 score
        
      </div>
    </a>
  
  
    <a href="/2020/03/21/python-%E6%96%87%E4%BB%B6%E5%AD%98%E5%8F%96%E6%93%8D%E4%BD%9C/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">python_文件存取操作</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/hexo%E5%AE%8C%E5%96%84/">-hexo完善</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/matlab-%E5%B7%A5%E4%BD%9C/">-matlab -工作</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python%E5%9F%BA%E7%A1%80/">-python基础</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%8D%87%E7%BA%A7conda/">-升级conda</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E4%BD%9C/">-工作</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E4%BD%9C-matlab/">-工作 -matlab</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Graduation-work/">Graduation work</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/mathematical-modeling/">mathematical modeling</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/matlab/">matlab</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/nlp/">nlp</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/py-study/">py_study</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python%E5%9F%BA%E7%A1%80/">python基础</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/work/">work</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B8%B8%E6%88%8F%E4%BA%BA%E7%94%9F/">游戏人生</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%9A%8F%E7%AC%94/">随笔</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/malab-%E6%AF%95%E4%B8%9A/" rel="tag">-malab -毕业</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">-python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" rel="tag">-python -人工智能</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/" rel="tag">-个人博客搭建</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Graduation-work/" rel="tag">Graduation work</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/" rel="tag">hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mathematical-modeling/" rel="tag">mathematical modeling</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nlp/" rel="tag">nlp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/py-study/" rel="tag">py_study</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/work/" rel="tag">work</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/malab-%E6%AF%95%E4%B8%9A/" style="font-size: 12px;">-malab -毕业</a> <a href="/tags/python/" style="font-size: 10px;">-python</a> <a href="/tags/python-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" style="font-size: 10px;">-python -人工智能</a> <a href="/tags/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/" style="font-size: 10px;">-个人博客搭建</a> <a href="/tags/Graduation-work/" style="font-size: 14px;">Graduation work</a> <a href="/tags/hexo/" style="font-size: 12px;">hexo</a> <a href="/tags/mathematical-modeling/" style="font-size: 16px;">mathematical modeling</a> <a href="/tags/nlp/" style="font-size: 12px;">nlp</a> <a href="/tags/py-study/" style="font-size: 10px;">py_study</a> <a href="/tags/python/" style="font-size: 18px;">python</a> <a href="/tags/work/" style="font-size: 20px;">work</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">十一月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">十月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">九月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">八月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">七月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">六月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">五月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">四月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">三月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">一月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">十二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/11/04/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2020/11/03/%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/">分类模型的评估指标</a>
          </li>
        
          <li>
            <a href="/2020/10/21/10-21-%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/">10-21 爬虫基础</a>
          </li>
        
          <li>
            <a href="/2020/09/25/CRF%E7%9A%84%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B%E7%BB%93%E6%9E%9C/">CRF的整体流程结果</a>
          </li>
        
          <li>
            <a href="/2020/09/25/nlp-crf%E6%A8%A1%E5%9E%8B/">nlp_crf模型</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 esy<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>