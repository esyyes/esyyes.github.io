
<!DOCTYPE html>
<html lang="zh-CN" class="loading">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>python_随机森林参数设置 - ESY</title>
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate" />
    <meta name="keywords" content="ESY,"> 
    <meta name="description" content="mengxin,

随机森林参数设置随机森林介绍随机森林定义在机器学习中，随机森林是一个包含多个决策树的分类器， 并且其输出的类别是由个别树输出的类别的众数而定。 Leo Breiman和Adele Cutler发,"> 
    <meta name="author" content="esy"> 
    <link rel="alternative" href="atom.xml" title="ESY" type="application/atom+xml"> 
    <link rel="icon" href="/img/hhh.png"> 
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
    <link rel="stylesheet" href="/css/diaspora.css">
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({
              google_ad_client: "ca-pub-8691406134231910",
              enable_page_level_ads: true
         });
    </script>
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
</head>

<body class="loading">
    <span id="config-title" style="display:none">ESY</span>
    <div id="loader"></div>
​    <div id="single">
    <div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <a class="icon-home image-icon" href="javascript:;" target="_blank" rel="noopener" data-url="https://esyyes.github.io"></a>
    <div title="播放/暂停" class="icon-play"></div>
    <h3 class="subtitle">python_随机森林参数设置</h3>
    <div class="social">
        <!--<div class="like-icon">-->
            <!--<a href="javascript:;" target="_blank" rel="noopener" class="likeThis active"><span class="icon-like"></span><span class="count">76</span></a>-->
        <!--</div>-->
        <div>
            <div class="share">
                <a title="获取二维码" class="icon-scan" href="javascript:;" target="_blank" rel="noopener"></a>
            </div>
            <div id="qr"></div>
        </div>
    </div>
    <div class="scrollbar"></div>
</div>

    <div class="section">
        <div class="article">
    <div class='main'>
        <h1 class="title">python_随机森林参数设置</h1>
        <div class="stuff">
            <span>三月 22, 2020</span>
            

        </div>
        <div class="content markdown">
            <p><img src="http://i0.hdslb.com/bfs/archive/f252847e6071d16bf5f9b423d759b2c8a0c6eb3d.jpg" alt=""></p>
<p><img src="http://i2.hdslb.com/bfs/archive/2c891439af62694315487dc640d3beb6d5709593.jpg" alt=""></p>
<h1 id="随机森林参数设置"><a href="#随机森林参数设置" class="headerlink" title="随机森林参数设置"></a>随机森林参数设置</h1><h2 id="随机森林介绍"><a href="#随机森林介绍" class="headerlink" title="随机森林介绍"></a>随机森林介绍</h2><h3 id="随机森林定义"><a href="#随机森林定义" class="headerlink" title="随机森林定义"></a>随机森林定义</h3><p>在<a href="https://baike.baidu.com/item/机器学习" target="_blank" rel="noopener">机器学习</a>中，<strong>随机森林是一个包含多个决策树的<a href="https://baike.baidu.com/item/分类器" target="_blank" rel="noopener">分类器</a></strong>， 并且其输出的类别是由个别树输出的类别的众数而定。 Leo Breiman和Adele Cutler发展出推论出随机森林的算法。 而 “Random Forests” 是他们的<a href="https://baike.baidu.com/item/商标" target="_blank" rel="noopener">商标</a>。 这个术语是1995年由贝尔实验室的Tin Kam Ho所提出的随机决策森林（random decision forests）而来的。这个方法则是结合 Breimans 的 “Bootstrap aggregating” 想法和 Ho 的”random subspace method”以建造<a href="https://baike.baidu.com/item/决策树" target="_blank" rel="noopener">决策树</a>的集合。</p>
<h3 id="随机森林参数定义"><a href="#随机森林参数定义" class="headerlink" title="随机森林参数定义"></a>随机森林参数定义</h3><p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" target="_blank" rel="noopener">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html</a></p>
<p><a href="https://blog.csdn.net/Longtermevolution/article/details/100919721" target="_blank" rel="noopener">https://blog.csdn.net/Longtermevolution/article/details/100919721</a></p>
<p><strong>n_estimators：</strong></p>
<p>森林中数的个数。<br>这个属性是典型的<strong>模型表现与模型效率成反比的影响因子</strong>，即便如此，你还是应该尽可能提高这个数字，以让你的模型更准确更稳定。</p>
<p><strong>criterion ：</strong></p>
<p>度量分裂的标准。可选值：“mse”，均方差（mean squared error）；“mae”，平均绝对值误差（mean absolute error） 支持的标准是基尼杂质的“<strong>gini（基尼）</strong>”和<strong>信息增益的“entropy（熵</strong>）”。注意：此参数是特定于树的。<strong>默认是基尼</strong></p>
<p><strong>max_features</strong> ：</p>
<p>寻找<strong>最佳分裂点时考虑的特征数目</strong>。可选值，int（具体的数目），float（数目的百分比），string（“auto”， “sqrt”，“log2”）.<br>这一属性是对单个树来设置的，通常来讲，<strong>这个值越大单棵树可以考虑的属性越多，则模型的表现就越好</strong>。但是这也不是肯定的，不过有一点是肯定的，增加这个值会导致算法运行速度变慢，所以需要我们考虑去达到一个平衡。</p>
<p><strong>max_depth :</strong>integer或者None。树的最大深度，如果None，节点扩展直到所有叶子是纯的或者所有叶子节点包含的样例数小于min_samples_split </p>
<p><strong>min_samples_split</strong> ： 分裂内部节点需要的最少样例数。int(具体数目),float(数目的百分比) </p>
<p><strong>min_samples_leaf</strong> ：叶子节点上应有的最少样例数。int(具体数目),float(数目的百分比)。<br>更少的节点数使得模型更容易遭受noise data的影响，我通常设置这个值大于50，但是你需要寻找最适合你的数值。 </p>
<p><strong>min_weight_fraction_leaf ：</strong> </p>
<p><strong>max_leaf_nodes ：</strong>以”最优优先方式”(best-first fashion),最优节点定义为:纯度的相对减少.如果None则不限制叶子节点个数;[float]<br><strong>min_impurity_split :</strong> 树增长提前结束的阈值.对于当前节点,大于这个阈值将分裂,否则就看做叶子节点; [float]<br><strong>min_impurity_decrease ：</strong>一个阈值,表示一个节点分裂的条件是:如果这次分裂纯度的减少大于等于这这个值.<br><strong>bootstrap</strong> ：构建数是不是采用有放回样本的方式(bootstrap samples); [True/False]<br><strong>oob_score ：</strong>交叉验证相关的属性。<br><strong>n_jobs ：</strong>设定fit和predict阶段并列执行的任务个数,<strong>如果设置为-1表示并行执行的任务数等于计算级核数</strong>; [integer, optional (default=1)]<br><strong>random_state</strong> ：如果是<strong>int数值表示它就是随机数产生器的种子</strong>.如果指定RandomState实例,它就是随机产生器的种子.如果是None,随机数产生器是np.random所用的RandomState实例; [int, RandomState instance or None, optional (default=None)]<br><strong>verbose ：</strong>控制<strong>构建数过程的冗长度</strong>; [int, optional (default=0)]<br><strong>warm_start ：</strong>当设置为True,重新使用之前的结构去拟合样例并且加入更多的估计器(estimators,在这里就是随机树)到组合器中; [True/False]<br><strong>class_weight: “</strong>banlanced”模式是根据y标签值自动调整权值与输入数据的类频率成反比,计算公式是:n_samples / (n_classes np.bincount(y)).“balanced_subsample”模式的与”balanced模式相同,只<strong>不过在每一次树增长过程中权值的计算是根据有放回样本的</strong>.</p>
<h2 id="模型调参利器-gridSearchCV（网格搜索）"><a href="#模型调参利器-gridSearchCV（网格搜索）" class="headerlink" title="模型调参利器 gridSearchCV（网格搜索）"></a>模型调参利器 gridSearchCV（网格搜索）</h2><p>GridSearchCV，它存在的意义就是<strong>自动调参</strong>，只要把参数输进去，就能给出<strong>最优化的结果和参数</strong>。但是这个方法适合于<strong>小数据集</strong>，一旦数据的量级上去了，很难得出结果。这个时候就是需要动脑筋了。数据量比较大的时候可以使用一个快速调优的方法——坐标下降。它其实是一种<strong>贪心算法</strong>：<strong>拿当前对模型影响最大的参数调优，直到最优化；再拿下一个影响最大的参数调优</strong>，如此下去，直到所有的参数调整完毕。这个方法的缺点就是可能会调到局部最优而不是全局最优，但是省时间省力，巨大的优势面前，还是试一试吧，后续可以再拿bagging再优化。</p>
<h2 id="2-参数说明"><a href="#2-参数说明" class="headerlink" title="2.参数说明"></a>2.参数说明</h2><p><em>class sklearn.model_selection.<strong>GridSearchCV</strong>(estimator, param_grid, scoring=None, fit_params=None, n_jobs=1, iid=True, refit=True, cv=None, verbose=0, pre_dispatch=‘2*n_jobs’, error_score=’raise’, return_train_score=’warn’)</em></p>
<p><strong>（1）</strong>    <strong><em>estimator\</em></strong></p>
<p>选择使用的分类器，并且传入除需要确定最佳的参数之外的其他参数。每一个分类器都需要一个scoring参数，或者score方法：estimator=RandomForestClassifier(min_samples_split=100,min_samples_leaf=20,max_depth=8,max_features=’sqrt’,random_state=10),</p>
<p><strong>（2）</strong>    <strong><em>param_grid\</em></strong></p>
<p>需要最优化的参数的取值，值为字典或者列表，例如：param_grid =param_test1，param_test1 = {‘n_estimators’:range(10,71,10)}。</p>
<p><strong>（3）</strong>    <strong><em>scoring=None\</em></strong></p>
<p>模型评价标准，默认None,这时需要使用score函数；或者如scoring=’roc_auc’，根据所选模型不同，评价准则不同。字符串（函数名），或是可调用对象，需要其函数签名形如：scorer(estimator, X, y)；如果是None，则使用estimator的误差估计函数。具体值的选取看本篇第三节内容。</p>
<p><strong>（4）</strong>    <strong><em>fit_params=None\</em></strong></p>
<p><strong>（5）</strong>    <strong><em>n_jobs=1\</em></strong></p>
<p>n_jobs: 并行数，int：个数,-1：跟CPU核数一致, 1:默认值</p>
<p><strong>（6）</strong>    <strong><em>iid=True\</em></strong></p>
<p><strong>iid</strong>:默认True,为True时，默认为各个样本fold概率分布一致，误差估计为所有样本之和，而非各个fold的平均。</p>
<p><strong>（7）</strong>    <strong><em>refit=True\</em></strong></p>
<p>默认为True,程序将会以交叉验证训练集得到的最佳参数，重新对所有可用的训练集与开发集进行，作为最终用于性能评估的最佳模型参数。即在搜索参数结束后，用最佳参数结果再次fit一遍全部数据集。</p>
<p><strong>（8）</strong>    <strong><em>cv=None\</em></strong></p>
<p>交叉验证参数，默认None，使用三折交叉验证。指定fold数量，默认为3，也可以是yield训练/测试数据的生成器。</p>
<p><strong>（9）</strong>    <strong><em>verbose=0\</em>, *scoring=None*</strong></p>
<p><strong>verbose</strong>：日志冗长度，int：冗长度，0：不输出训练过程，1：偶尔输出，&gt;1：对每个子模型都输出。</p>
<p><strong>（10）</strong>  <strong><em>pre_dispatch=‘2*n_jobs’\</em></strong></p>
<p>指定总共分发的并行任务数。当n_jobs大于1时，数据将在每个运行点进行复制，这可能导致OOM，而设置pre_dispatch参数，则可以预先划分总共的job数量，使数据最多被复制pre_dispatch次</p>
<p><strong>（11）</strong>  <strong><em>error_score=’raise’\</em></strong></p>
<p><strong>（12）</strong>  <strong><em>return_train_score=’warn’\</em></strong></p>
<p>如果“False”，cv_results_属性将不包括训练分数</p>
<p>回到sklearn里面的GridSearchCV，GridSearchCV用于系统地遍历多种参数组合，通过交叉验证确定最佳效果参数。</p>
<p><strong>打算使用网格搜索对模型进行调优，然后再进行交叉验证！</strong></p>
<h2 id="步骤实现："><a href="#步骤实现：" class="headerlink" title="步骤实现："></a>步骤实现：</h2><ol>
<li>想让树的数目从10到100</li>
</ol>
<p>生成一个10,100的列表</p>
<p>list(range(10,100))</p>
<ol start="2">
<li>构建循环</li>
<li>实现代码</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化模型</span></span><br><span class="line">rfc = RandomForestClassifier()</span><br><span class="line"></span><br><span class="line">tuned_parameter = [&#123; <span class="string">'n_estimators'</span>:list(range(<span class="number">10</span>, <span class="number">100</span>))&#125;]</span><br><span class="line">对模型进行交叉验证，<span class="comment"># 将训练/测试数据集划分10个互斥子集</span></span><br><span class="line"><span class="comment"># kflod = StratifiedKFold(n_splits=10, shuffle = True,random_state=7)</span></span><br><span class="line"><span class="comment"># 将模型进行网格搜索调优</span></span><br><span class="line">clf = GridSearchCV(estimator=rfc,param_grid=tuned_parameter, cv=kflod, n_jobs=<span class="number">1</span>)</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 将模型进行网格搜索调优</span></span><br><span class="line">print(<span class="string">"Best: %f using %s"</span> % (clf.best_score_,clf.best_params_))</span><br><span class="line">out：</span><br><span class="line">	Best: <span class="number">0.912500</span> using &#123;<span class="string">'n_estimators'</span>: <span class="number">28</span>&#125;</span><br></pre></td></tr></table></figure>

<p>没啥必要循环了，每次都在变，选个最高的模型越复杂越好，就选14的倍数，<strong>28</strong></p>
<h2 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a><strong>参考博客</strong></h2><p>参考这篇对模型进行优化，还可以用下这个模型</p>
<p><a href="https://blog.csdn.net/weixin_41988628/article/details/83098130" target="_blank" rel="noopener">https://blog.csdn.net/weixin_41988628/article/details/83098130</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># 数据科学计算工具</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># 数值计算工具</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># 可视化</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns <span class="comment"># matplotlib的高级API</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold <span class="comment">#交叉验证</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV <span class="comment">#网格搜索</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split <span class="comment">#将数据集分开成训练集和测试集</span></span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier                     <span class="comment">#xgboost</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pima = pd.read_csv(<span class="string">"pima_indians-diabetes.csv"</span>)</span><br><span class="line">print(pima.head())</span><br><span class="line"></span><br><span class="line">x = pima.iloc[:,<span class="number">0</span>:<span class="number">8</span>]</span><br><span class="line">y = pima.iloc[:,<span class="number">8</span>]</span><br><span class="line"></span><br><span class="line">seed = <span class="number">7</span> <span class="comment">#重现随机生成的训练</span></span><br><span class="line">test_size = <span class="number">0.33</span> <span class="comment">#33%测试，67%训练</span></span><br><span class="line">X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=test_size, random_state=seed</span><br><span class="line">model = XGBClassifier()               </span><br><span class="line">learning_rate = [<span class="number">0.0001</span>,<span class="number">0.001</span>,<span class="number">0.01</span>,<span class="number">0.1</span>,<span class="number">0.2</span>,<span class="number">0.3</span>] <span class="comment">#学习率</span></span><br><span class="line">gamma = [<span class="number">1</span>, <span class="number">0.1</span>, <span class="number">0.01</span>, <span class="number">0.001</span>]</span><br><span class="line"></span><br><span class="line">param_grid = dict(learning_rate = learning_rate,gamma = gamma)<span class="comment">#转化为字典格式，网络搜索要求</span></span><br><span class="line"></span><br><span class="line">kflod = StratifiedKFold(n_splits=<span class="number">10</span>, shuffle = <span class="literal">True</span>,random_state=<span class="number">7</span>)<span class="comment">#将训练/测试数据集划分10个互斥子集，</span></span><br><span class="line"></span><br><span class="line">grid_search = GridSearchCV(model,param_grid,scoring = <span class="string">'neg_log_loss'</span>,n_jobs = <span class="number">-1</span>,cv = kflod)</span><br><span class="line"><span class="comment">#scoring指定损失函数类型，n_jobs指定全部cpu跑，cv指定交叉验证</span></span><br><span class="line">grid_result = grid_search.fit(X_train, Y_train) <span class="comment">#运行网格搜索</span></span><br><span class="line">print(<span class="string">"Best: %f using %s"</span> % (grid_result.best_score_,grid_search.best_params_))</span><br><span class="line"><span class="comment">#grid_scores_：给出不同参数情况下的评价结果。best_params_：描述了已取得最佳结果的参数的组合</span></span><br><span class="line"><span class="comment">#best_score_：成员提供优化过程期间观察到的最好的评分</span></span><br><span class="line"><span class="comment">#具有键作为列标题和值作为列的dict，可以导入到DataFrame中。</span></span><br><span class="line"><span class="comment">#注意，“params”键用于存储所有参数候选项的参数设置列表。</span></span><br><span class="line">means = grid_result.cv_results_[<span class="string">'mean_test_score'</span>]</span><br><span class="line">params = grid_result.cv_results_[<span class="string">'params'</span>]</span><br><span class="line"><span class="keyword">for</span> mean,param <span class="keyword">in</span> zip(means,params):</span><br><span class="line">    print(<span class="string">"%f  with:   %r"</span> % (mean,param))</span><br></pre></td></tr></table></figure>

<h1 id="忽略警告"><a href="#忽略警告" class="headerlink" title="忽略警告"></a>忽略警告</h1><p>每次都会出现一大堆的红字，看到就不舒服，以后将这个作为第一个</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br></pre></td></tr></table></figure>

<p>在PyCharm中提示shadows name ‘xxxx’ from outer scope，当你在外部有个相同名称的变量在方法内部被重新指定了新的值，也就是说你在外部的相同名称的变量压根就没有任何作用。所以PyCharm就回提示这个信息。这个时候就需要我们去调整具体代码了。</p>
<p>意思就是在pycharm中，函数中的变量最好跟外部的变量不一样，要不然就会警告</p>

            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls" data-autoplay="false">
                <source type="audio/mpeg" src="">
            </audio>
            
                <ul id="audio-list" style="display:none">
                    
                        
                            <li title='0' data-url='https://link.hhtjim.com/163/509313159.mp3'></li>
                        
                    
                        
                            <li title='1' data-url='https://link.hhtjim.com/163/579954.mp3'></li>
                        
                    
                        
                            <li title='2' data-url='https://link.hhtjim.com/163/579648.mp3'></li>
                        
                    
                        
                            <li title='3' data-url='https://link.hhtjim.com/163/40915694.mp3'></li>
                        
                    
                </ul>
            
        </div>
        
    <div id='gitalk-container' class="comment link"
        data-ae='false'
        data-ci=''
        data-cs=''
        data-r=''
        data-o=''
        data-a=''
        data-d='false'
    >查看评论</div>


    </div>
    
</div>


    </div>
</div>
</body>
<script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<script src="//lib.baomitu.com/jquery/1.8.3/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/diaspora.js"></script>
<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">
<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>




</html>