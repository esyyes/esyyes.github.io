<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>ESY</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="esy">
<meta property="og:type" content="website">
<meta property="og:title" content="ESY">
<meta property="og:url" content="https://esyyes.github.io/page/2/index.html">
<meta property="og:site_name" content="ESY">
<meta property="og:description" content="esy">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="esy">
<meta property="article:tag" content="python">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="ESY" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">ESY</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://esyyes.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-各项特征提取" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/09/10/%E5%90%84%E9%A1%B9%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/" class="article-date">
  <time datetime="2020-09-10T01:37:37.000Z" itemprop="datePublished">2020-09-10</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Graduation-work/">Graduation work</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/09/10/%E5%90%84%E9%A1%B9%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/">各项特征提取</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h1><p>关于论文的思维导图见下链接</p>
<p> <a target="_blank" rel="noopener" href="https://www.processon.com/mindmap/5f582d8063768959e2dce54d">https://www.processon.com/mindmap/5f582d8063768959e2dce54d</a> </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://esyyes.github.io/2020/09/10/%E5%90%84%E9%A1%B9%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/" data-id="ckh4h5f7m005yisuegnoh5wo5" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Graduation-work/" rel="tag">Graduation work</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-数据集介绍" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/09/07/%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/" class="article-date">
  <time datetime="2020-09-07T00:52:41.000Z" itemprop="datePublished">2020-09-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Graduation-work/">Graduation work</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/09/07/%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/">数据集介绍</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h2><p>UCDDB和SLPDB，进行介绍下，各个数据经过处理后的阶段表格，和Seff(%)如何计算以及AHI的判定介绍。</p>
<p> MIT-BIH多导睡眠图数据库是睡眠期间多种生理信号记录的集合 </p>
<h2 id="UCDDB"><a href="#UCDDB" class="headerlink" title="UCDDB"></a>UCDDB</h2><p>睡眠阶段由经验丰富的睡眠技术人员根据标准Rechtschaffen和Kales规则（请参见_stage.txt文件）进行评分。这些文件中的注释/含义是：</p>
<ul>
<li>0-唤醒</li>
<li>1-REM</li>
<li>2-阶段1</li>
<li>3-阶段2</li>
<li>4-阶段3</li>
<li>5-阶段4</li>
<li>6- Artifact </li>
<li>7-不确定</li>
</ul>
<table>
<thead>
<tr>
<th>Study</th>
<th><strong>N3</strong></th>
<th><strong>N2</strong></th>
<th><strong>N1</strong></th>
<th><strong>R</strong></th>
<th><strong>W</strong></th>
<th><strong>total</strong></th>
<th>AHI</th>
<th>Seff (%)</th>
</tr>
</thead>
<tbody><tr>
<td>UCDDB002</td>
<td>87</td>
<td>172</td>
<td>213</td>
<td>155</td>
<td>111</td>
<td>738</td>
<td>23</td>
<td>84.96</td>
</tr>
<tr>
<td>UCDDB003</td>
<td>164</td>
<td>254</td>
<td>106</td>
<td>190</td>
<td>157</td>
<td>871</td>
<td>51</td>
<td>81.97</td>
</tr>
<tr>
<td>UCDDB005</td>
<td>52</td>
<td>251</td>
<td>89</td>
<td>125</td>
<td>268</td>
<td>785</td>
<td>13</td>
<td>65.86</td>
</tr>
<tr>
<td>UCDDB006</td>
<td>248</td>
<td>92</td>
<td>171</td>
<td>184</td>
<td>54</td>
<td>749</td>
<td>31</td>
<td>92.79</td>
</tr>
<tr>
<td>UCDDB007</td>
<td>127</td>
<td>414</td>
<td>53</td>
<td>132</td>
<td>76</td>
<td>802</td>
<td>12</td>
<td>90.52</td>
</tr>
<tr>
<td>UCDDB008</td>
<td>81</td>
<td>301</td>
<td>76</td>
<td>33</td>
<td>174</td>
<td>665</td>
<td>5</td>
<td>73.83</td>
</tr>
<tr>
<td>UCDDB009</td>
<td>141</td>
<td>244</td>
<td>261</td>
<td>85</td>
<td>183</td>
<td>914</td>
<td>12</td>
<td>79.98</td>
</tr>
<tr>
<td>UCDDB010</td>
<td>79</td>
<td>464</td>
<td>118</td>
<td>168</td>
<td>67</td>
<td>896</td>
<td>34</td>
<td>92.52</td>
</tr>
<tr>
<td>UCDDB011</td>
<td>118</td>
<td>295</td>
<td>89</td>
<td>42</td>
<td>346</td>
<td>890</td>
<td>8</td>
<td>61.12</td>
</tr>
<tr>
<td>UCDDB012</td>
<td>146</td>
<td>336</td>
<td>58</td>
<td>194</td>
<td>119</td>
<td>853</td>
<td>25</td>
<td>86.05</td>
</tr>
<tr>
<td>UCDDB013</td>
<td>111</td>
<td>173</td>
<td>143</td>
<td>67</td>
<td>306</td>
<td>800</td>
<td>16</td>
<td>61.75</td>
</tr>
<tr>
<td>UCDDB014</td>
<td>0</td>
<td>267</td>
<td>260</td>
<td>82</td>
<td>154</td>
<td>763</td>
<td>36</td>
<td>79.82</td>
</tr>
<tr>
<td>UCDDB015</td>
<td>146</td>
<td>294</td>
<td>200</td>
<td>63</td>
<td>173</td>
<td>876</td>
<td>6</td>
<td>80.25</td>
</tr>
<tr>
<td>UCDDB017</td>
<td>65</td>
<td>392</td>
<td>36</td>
<td>193</td>
<td>92</td>
<td>778</td>
<td>12</td>
<td>88.17</td>
</tr>
<tr>
<td>UCDDB018</td>
<td>137</td>
<td>280</td>
<td>58</td>
<td>19</td>
<td>317</td>
<td>811</td>
<td>2</td>
<td>60.91</td>
</tr>
<tr>
<td>UCDDB019</td>
<td>196</td>
<td>352</td>
<td>45</td>
<td>186</td>
<td>61</td>
<td>840</td>
<td>16</td>
<td>92.74</td>
</tr>
<tr>
<td>UCDDB020</td>
<td>64</td>
<td>155</td>
<td>204</td>
<td>156</td>
<td>162</td>
<td>741</td>
<td>15</td>
<td>78.14</td>
</tr>
<tr>
<td>UCDDB021</td>
<td>127</td>
<td>370</td>
<td>115</td>
<td>128</td>
<td>133</td>
<td>873</td>
<td>13</td>
<td>84.77</td>
</tr>
<tr>
<td>UCDDB022</td>
<td>131</td>
<td>215</td>
<td>70</td>
<td>44</td>
<td>317</td>
<td>777</td>
<td>7</td>
<td>59.20</td>
</tr>
<tr>
<td>UCDDB023</td>
<td>26</td>
<td>179</td>
<td>172</td>
<td>38</td>
<td>212</td>
<td>627</td>
<td>39</td>
<td>66.19</td>
</tr>
<tr>
<td>UCDDB024</td>
<td>137</td>
<td>331</td>
<td>113</td>
<td>168</td>
<td>148</td>
<td>897</td>
<td>24</td>
<td>83.50</td>
</tr>
<tr>
<td>UCDDB025</td>
<td>9</td>
<td>124</td>
<td>367</td>
<td>46</td>
<td>154</td>
<td>700</td>
<td>91</td>
<td>78.00</td>
</tr>
<tr>
<td>UCDDB026</td>
<td>139</td>
<td>241</td>
<td>100</td>
<td>242</td>
<td>105</td>
<td>827</td>
<td>14</td>
<td>87.30</td>
</tr>
<tr>
<td>UCDDB027</td>
<td>35</td>
<td>530</td>
<td>62</td>
<td>139</td>
<td>116</td>
<td>882</td>
<td>55</td>
<td>86.85</td>
</tr>
<tr>
<td>UCDDB028</td>
<td>52</td>
<td>205</td>
<td>139</td>
<td>96</td>
<td>219</td>
<td>711</td>
<td>46</td>
<td>69.20</td>
</tr>
<tr>
<td>total</td>
<td>2663</td>
<td>6982</td>
<td>3393</td>
<td>3005</td>
<td>4496</td>
<td>20539</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h2 id="MIT-BIH多导睡眠图数据库SLPDB"><a href="#MIT-BIH多导睡眠图数据库SLPDB" class="headerlink" title="MIT-BIH多导睡眠图数据库SLPDB"></a>MIT-BIH多导睡眠图数据库SLPDB</h2><p> <a target="_blank" rel="noopener" href="https://www.physionet.org/files/slpdb/1.0.0/slpdb.html">https://www.physionet.org/files/slpdb/1.0.0/slpdb.html</a> </p>
<p>英文全名：MIT-BIH Polysomnographic Database</p>
<p>数据库的阶段判定</p>
<p>每条记录都包含一个头文件（<code>.hea</code>），一个简短的文本文件，其中包含有关信号类型，校准常数，记录长度以及（在文件的最后一行）年龄，性别和体重的信息（以千克为单位）的主题。<strong>在该数据库中，所有16名受试者均为男性，年龄在32至56岁（平均年龄43），体重在89至152千克（平均体重119千克）之间</strong>。记录<code>slp01a</code>和<code>slp01b</code>是一个受试者的多导睡眠图的片段，间隔约一小时。记录 <code>slp02a</code>和<code>slp02b</code>是另一位受试者的多导睡眠图的片段，相隔十分钟。<strong>其余14条记录全都来自不同的主题</strong>。</p>
<p>所有记录均包括ECG信号，侵入性血压信号（使用radial动脉中的导管测量），EEG信号和呼吸信号（在大多数情况下，来自鼻热敏电阻）。六通道和七通道记录还包括通过<strong>电感体积描记法</strong>得出的呼吸努力信号；有些包括EOG信号和EMG信号（来自下巴），其余的包括心搏量信号（请参阅下面的参考文献）和耳垂血氧仪信号。下表总结了每个记录的内容：</p>
<table>
<thead>
<tr>
<th>aux</th>
<th>meaning</th>
</tr>
</thead>
<tbody><tr>
<td>W</td>
<td>subject is awake</td>
</tr>
<tr>
<td>1</td>
<td>sleep stage 1</td>
</tr>
<tr>
<td>2</td>
<td>sleep stage 2</td>
</tr>
<tr>
<td>3</td>
<td>sleep stage 3</td>
</tr>
<tr>
<td>4</td>
<td>sleep stage 4</td>
</tr>
<tr>
<td>R</td>
<td>REM sleep</td>
</tr>
<tr>
<td>H</td>
<td>Hypopnea</td>
</tr>
<tr>
<td>HA</td>
<td>Hypopnea with arousal</td>
</tr>
<tr>
<td>OA</td>
<td>Obstructive apnea</td>
</tr>
<tr>
<td>X</td>
<td>Obstructive apnea with arousal</td>
</tr>
<tr>
<td>CA</td>
<td>Central apnea</td>
</tr>
<tr>
<td>CAA</td>
<td>Central apnea with arousal</td>
</tr>
<tr>
<td>L</td>
<td>Leg movements</td>
</tr>
<tr>
<td>LA</td>
<td>Leg movements with arousal</td>
</tr>
<tr>
<td>A</td>
<td>Unspecified arousal</td>
</tr>
<tr>
<td>MT</td>
<td>Movement time</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>Data</th>
<th>N3</th>
<th>N2</th>
<th>N1</th>
<th>R</th>
<th>W</th>
<th>TOTAL</th>
<th>AHI</th>
<th>Seff(%)</th>
</tr>
</thead>
<tbody><tr>
<td>slp01a</td>
<td>108</td>
<td>103</td>
<td>0</td>
<td>12</td>
<td>5</td>
<td>228</td>
<td>17.0</td>
<td>97.81</td>
</tr>
<tr>
<td>slp01b</td>
<td>0</td>
<td>119</td>
<td>25</td>
<td>25</td>
<td>180</td>
<td>349</td>
<td>22.3</td>
<td>48.42</td>
</tr>
<tr>
<td>slp02a</td>
<td>7</td>
<td>195</td>
<td>18</td>
<td>77</td>
<td>52</td>
<td>349</td>
<td>34.0</td>
<td>85.10</td>
</tr>
<tr>
<td>slp02b</td>
<td>0</td>
<td>114</td>
<td>14</td>
<td>29</td>
<td>102</td>
<td>259</td>
<td>22.2</td>
<td>60.62</td>
</tr>
<tr>
<td>slp03</td>
<td>78</td>
<td>307</td>
<td>105</td>
<td>74</td>
<td>114</td>
<td>678</td>
<td>43.0</td>
<td>83.19</td>
</tr>
<tr>
<td>slp04</td>
<td>33</td>
<td>440</td>
<td>58</td>
<td>23</td>
<td>155</td>
<td>709</td>
<td>59.8</td>
<td>78.14</td>
</tr>
<tr>
<td>slp14</td>
<td>42</td>
<td>126</td>
<td>183</td>
<td>36</td>
<td>316</td>
<td>703</td>
<td>30.7</td>
<td>55.05</td>
</tr>
<tr>
<td>slp16</td>
<td>24</td>
<td>181</td>
<td>107</td>
<td>65</td>
<td>306</td>
<td>683</td>
<td>53.1</td>
<td>55.20</td>
</tr>
<tr>
<td>slp32</td>
<td>60</td>
<td>159</td>
<td>27</td>
<td>0</td>
<td>383</td>
<td>629</td>
<td>22.1</td>
<td>39.11</td>
</tr>
<tr>
<td>slp37</td>
<td>0</td>
<td>586</td>
<td>17</td>
<td>11</td>
<td>73</td>
<td>687</td>
<td>100.8</td>
<td>89.37</td>
</tr>
<tr>
<td>slp41</td>
<td>13</td>
<td>218</td>
<td>230</td>
<td>90</td>
<td>218</td>
<td>769</td>
<td>60 [2]</td>
<td>71.65</td>
</tr>
<tr>
<td>slp45</td>
<td>103</td>
<td>399</td>
<td>54</td>
<td>81</td>
<td>112</td>
<td>749</td>
<td>5 [2]</td>
<td>85.05</td>
</tr>
<tr>
<td>slp48</td>
<td>0</td>
<td>269</td>
<td>238</td>
<td>31</td>
<td>209</td>
<td>747</td>
<td>46.8</td>
<td>72.02</td>
</tr>
<tr>
<td>slp59</td>
<td>80</td>
<td>92</td>
<td>105</td>
<td>35</td>
<td>135</td>
<td>447</td>
<td>55.3</td>
<td>69.80</td>
</tr>
<tr>
<td>slp60</td>
<td>0</td>
<td>49</td>
<td>321</td>
<td>31</td>
<td>276</td>
<td>677</td>
<td>59.2</td>
<td>59.23</td>
</tr>
<tr>
<td>slp61</td>
<td>103</td>
<td>326</td>
<td>88</td>
<td>73</td>
<td>119</td>
<td>709</td>
<td>41.2</td>
<td>83.22</td>
</tr>
<tr>
<td>slp66</td>
<td>5</td>
<td>116</td>
<td>141</td>
<td>0</td>
<td>167</td>
<td>429</td>
<td>65.5</td>
<td>61.07</td>
</tr>
<tr>
<td>slp67x</td>
<td>0</td>
<td>40</td>
<td>37</td>
<td>0</td>
<td>65</td>
<td>142</td>
<td>0.7</td>
<td>54.23</td>
</tr>
<tr>
<td>total</td>
<td>656</td>
<td>3839</td>
<td>1768</td>
<td>693</td>
<td>2987</td>
<td>9943</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p><img src="/images/wuli"></p>
<p><img src="/images/%E5%96%B5%E5%86%85.jpg" alt="喵内"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://esyyes.github.io/2020/09/07/%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/" data-id="ckh4h5f86006wisueh8fh3xyb" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Graduation-work/" rel="tag">Graduation work</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-DATA数据绘制" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/09/03/DATA%E6%95%B0%E6%8D%AE%E7%BB%98%E5%88%B6/" class="article-date">
  <time datetime="2020-09-03T02:42:10.000Z" itemprop="datePublished">2020-09-03</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Graduation-work/">Graduation work</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/09/03/DATA%E6%95%B0%E6%8D%AE%E7%BB%98%E5%88%B6/">DATA数据绘制</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="DATA数据绘制"><a href="#DATA数据绘制" class="headerlink" title="DATA数据绘制"></a>DATA数据绘制</h1><p>提取UCDDB库中的data数据，并绘制ECG信号数据。</p>
<p>提取前面的30s数据来进行绘制。</p>
<p>绘制程序</p>
<h2 id="ECG信号绘制"><a href="#ECG信号绘制" class="headerlink" title="ECG信号绘制"></a>ECG信号绘制</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/9/3</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制ucddb库</span></span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> scio</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> wfdb <span class="keyword">import</span> processing</span><br><span class="line"><span class="keyword">from</span> eliminate_outliers <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取文件名</span></span><br><span class="line">text_name = pd.read_excel(<span class="string">&#x27;F:/st_data/SubjectDetails.xls&#x27;</span>)</span><br><span class="line">study_name = np.array(text_name[<span class="string">&#x27;Study Number&#x27;</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> text <span class="keyword">in</span> study_name[<span class="number">1</span>:<span class="number">2</span>]:</span><br><span class="line">    <span class="comment"># 读取文件对应的数据</span></span><br><span class="line">    dataFile = <span class="string">&#x27;F:/st_data/&#x27;</span> + <span class="string">&#x27;%s&#x27;</span> % text + <span class="string">&#x27;.mat&#x27;</span></span><br><span class="line">    data = scio.loadmat(dataFile)[<span class="string">&#x27;signal&#x27;</span>][<span class="number">0</span>:<span class="number">128</span>*<span class="number">30</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 利用GQRS算法获取R峰值</span></span><br><span class="line">    qrs_inds = processing.gqrs_detect(sig=data[:, <span class="number">0</span>], fs=<span class="number">128</span>)</span><br><span class="line">    <span class="comment"># 去寻找到正确的峰值点坐标</span></span><br><span class="line">    ecg_R_locs = processing.correct_peaks(data[:, <span class="number">0</span>], peak_inds=qrs_inds,</span><br><span class="line">                                          search_radius=<span class="built_in">int</span>(<span class="number">128</span> * <span class="number">60</span> / <span class="number">200</span>), smooth_window_size=<span class="number">100</span>)</span><br><span class="line">    <span class="comment"># ecg_r_locs异常点处理</span></span><br><span class="line">    ecg_r_locs = eliminate(ecg_R_locs)</span><br><span class="line">    <span class="comment"># ecg_r_peaks峰值点获取</span></span><br><span class="line">    ecg_r_peaks = [data[<span class="built_in">int</span>(ecg_r_locs[i])][<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ecg_r_locs))]</span><br><span class="line">    <span class="comment"># 绘制单个的ECG信号，并转换为30s</span></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">7</span>, <span class="number">5</span>))</span><br><span class="line">    x = np.arange(<span class="number">0</span>, <span class="built_in">len</span>(data))</span><br><span class="line">    plt.plot(x/<span class="number">128</span>, data, color=<span class="string">&#x27;#3979f0&#x27;</span>)</span><br><span class="line">    plt.xticks(fontsize=<span class="number">8</span>)</span><br><span class="line">    plt.yticks(fontsize=<span class="number">8</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Time/s&#x27;</span>, color=<span class="string">&#x27;#3979f0&#x27;</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;ECG/mV&#x27;</span>, color=<span class="string">&#x27;#3979f0&#x27;</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    fig.savefig(<span class="string">&#x27;单独的ECG信号绘制.png&#x27;</span>, dpi=<span class="number">1600</span>, bbox_inches=<span class="string">&#x27;tight&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/%E5%8D%95%E7%8B%AC%E7%9A%84ECG%E4%BF%A1%E5%8F%B7%E7%BB%98%E5%88%B6.png" alt="单独的ECG信号绘制"></p>
<h2 id="ECG信号的峰值点标记"><a href="#ECG信号的峰值点标记" class="headerlink" title="ECG信号的峰值点标记"></a>ECG信号的峰值点标记</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/9/3</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制ucddb库</span></span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> scio</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> wfdb <span class="keyword">import</span> processing</span><br><span class="line"><span class="keyword">from</span> eliminate_outliers <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取文件名</span></span><br><span class="line">text_name = pd.read_excel(<span class="string">&#x27;F:/st_data/SubjectDetails.xls&#x27;</span>)</span><br><span class="line">study_name = np.array(text_name[<span class="string">&#x27;Study Number&#x27;</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> text <span class="keyword">in</span> study_name[<span class="number">1</span>:<span class="number">2</span>]:</span><br><span class="line">    <span class="comment"># 读取文件对应的数据</span></span><br><span class="line">    dataFile = <span class="string">&#x27;F:/st_data/&#x27;</span> + <span class="string">&#x27;%s&#x27;</span> % text + <span class="string">&#x27;.mat&#x27;</span></span><br><span class="line">    data = scio.loadmat(dataFile)[<span class="string">&#x27;signal&#x27;</span>][<span class="number">0</span>:<span class="number">128</span>*<span class="number">30</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 利用GQRS算法获取R峰值</span></span><br><span class="line">    qrs_inds = processing.gqrs_detect(sig=data[:, <span class="number">0</span>], fs=<span class="number">128</span>)</span><br><span class="line">    <span class="comment"># 去寻找到正确的峰值点坐标</span></span><br><span class="line">    ecg_R_locs = processing.correct_peaks(data[:, <span class="number">0</span>], peak_inds=qrs_inds,</span><br><span class="line">                                          search_radius=<span class="built_in">int</span>(<span class="number">128</span> * <span class="number">60</span> / <span class="number">200</span>), smooth_window_size=<span class="number">100</span>)</span><br><span class="line">    <span class="comment"># ecg_r_locs异常点处理</span></span><br><span class="line">    ecg_r_locs = eliminate(ecg_R_locs)</span><br><span class="line">    <span class="comment"># ecg_r_peaks峰值点获取</span></span><br><span class="line">    ecg_r_peaks = [data[<span class="built_in">int</span>(ecg_r_locs[i])][<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ecg_r_locs))]</span><br><span class="line">    <span class="comment"># 绘制单个的ECG信号，并转换为30s</span></span><br><span class="line">    <span class="comment"># fig = plt.figure(figsize=(7, 5))</span></span><br><span class="line">    <span class="comment"># x = np.arange(0, len(data))</span></span><br><span class="line">    <span class="comment"># plt.plot(x/128, data, color=&#x27;#3979f0&#x27;)</span></span><br><span class="line">    <span class="comment"># plt.xticks(fontsize=8)</span></span><br><span class="line">    <span class="comment"># plt.yticks(fontsize=8)</span></span><br><span class="line">    <span class="comment"># plt.xlabel(&#x27;Time/s&#x27;, color=&#x27;#3979f0&#x27;, fontsize=10)</span></span><br><span class="line">    <span class="comment"># plt.ylabel(&#x27;ECG/mV&#x27;, color=&#x27;#3979f0&#x27;, fontsize=10)</span></span><br><span class="line">    <span class="comment"># plt.show()</span></span><br><span class="line">    <span class="comment"># fig.savefig(&#x27;单独的ECG信号绘制.png&#x27;, dpi=1600, bbox_inches=&#x27;tight&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制峰值点标记的ECG信号，并转换为30s</span></span><br><span class="line">    <span class="comment"># fig = plt.figure(figsize=(7, 5))</span></span><br><span class="line">    <span class="comment"># plt.plot(np.arange(0, len(data))/128, data, color=&#x27;#3979f0&#x27;)</span></span><br><span class="line">    <span class="comment"># plt.plot(np.array(ecg_r_locs)/128, ecg_r_peaks, &#x27;ro&#x27;, marker=&#x27;o&#x27;, color=&#x27;#8b0000&#x27;, label=&#x27;Peak&#x27;, markersize=4)</span></span><br><span class="line">    <span class="comment"># plt.xticks(fontsize=8)</span></span><br><span class="line">    <span class="comment"># plt.yticks(fontsize=8)</span></span><br><span class="line">    <span class="comment"># plt.xlabel(&#x27;Time/s&#x27;, color=&#x27;#3979f0&#x27;, fontsize=10)</span></span><br><span class="line">    <span class="comment"># plt.ylabel(&#x27;ECG/mV&#x27;, color=&#x27;#3979f0&#x27;, fontsize=10)</span></span><br><span class="line">    <span class="comment"># plt.show()</span></span><br><span class="line">    <span class="comment"># fig.savefig(&#x27;ECG信号绘制峰值点.png&#x27;, dpi=1600, bbox_inches=&#x27;tight&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用分图的形式绘制ECG信号和峰值信号</span></span><br><span class="line">    <span class="comment"># fig = plt.figure(figsize=(7, 5))</span></span><br><span class="line">    <span class="comment"># plt.subplot(211)</span></span><br><span class="line">    <span class="comment"># plt.plot(np.arange(0, len(data))/128, data, color=&#x27;#3979f0&#x27;)</span></span><br><span class="line">    <span class="comment"># plt.xticks(fontsize=8)</span></span><br><span class="line">    <span class="comment"># plt.yticks(fontsize=8)</span></span><br><span class="line">    <span class="comment"># plt.ylabel(&#x27;ECG/mV&#x27;, color=&#x27;#3979f0&#x27;, fontsize=10)</span></span><br><span class="line">    <span class="comment"># plt.title(&#x27;原始ECG信号&#x27;, fontsize=10)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># plt.subplot(212)</span></span><br><span class="line">    <span class="comment"># plt.plot(np.arange(0, len(data))/128, data, color=&#x27;#3979f0&#x27;)</span></span><br><span class="line">    <span class="comment"># plt.plot(np.array(ecg_r_locs)/128, ecg_r_peaks, &#x27;ro&#x27;, marker=&#x27;o&#x27;, color=&#x27;#8b0000&#x27;, label=&#x27;Peak&#x27;, markersize=4)</span></span><br><span class="line">    <span class="comment"># plt.xticks(fontsize=8)</span></span><br><span class="line">    <span class="comment"># plt.yticks(fontsize=8)</span></span><br><span class="line">    <span class="comment"># plt.xlabel(&#x27;Time/s&#x27;, color=&#x27;#3979f0&#x27;, fontsize=10)</span></span><br><span class="line">    <span class="comment"># plt.ylabel(&#x27;ECG/mV&#x27;, color=&#x27;#3979f0&#x27;, fontsize=10)</span></span><br><span class="line">    <span class="comment"># plt.title(&#x27;检测ECG信号峰值点&#x27;, fontsize=10)</span></span><br><span class="line">    <span class="comment"># plt.show()</span></span><br><span class="line">    <span class="comment"># fig.savefig(&#x27;ECG信号峰值和原始图的绘制.png&#x27;, dpi=1600, bbox_inches=&#x27;tight&#x27;)</span></span><br></pre></td></tr></table></figure>

<p><img src="/ECG%E4%BF%A1%E5%8F%B7%E7%BB%98%E5%88%B6%E5%B3%B0%E5%80%BC%E7%82%B9.png" alt="ECG信号绘制峰值点"></p>
<p><img src="/ECG%E4%BF%A1%E5%8F%B7%E5%B3%B0%E5%80%BC%E5%92%8C%E5%8E%9F%E5%A7%8B%E5%9B%BE%E7%9A%84%E7%BB%98%E5%88%B6.png" alt="ECG信号峰值和原始图的绘制"></p>
<h2 id="ECG-R信号"><a href="#ECG-R信号" class="headerlink" title="ECG_R信号"></a>ECG_R信号</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制ECG_R信号</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">7</span>, <span class="number">5</span>))</span><br><span class="line">plt.plot(np.array(ecg_r_locs)/<span class="number">128</span>, ecg_r_peaks, color=<span class="string">&#x27;#3979f0&#x27;</span>)</span><br><span class="line">plt.plot(np.array(ecg_r_locs)/<span class="number">128</span>, ecg_r_peaks, <span class="string">&#x27;ro&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, color=<span class="string">&#x27;#8b0000&#x27;</span>, label=<span class="string">&#x27;Peak&#x27;</span>, markersize=<span class="number">4</span>)</span><br><span class="line">plt.xticks(fontsize=<span class="number">8</span>)</span><br><span class="line">plt.yticks(fontsize=<span class="number">8</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Time/s&#x27;</span>, color=<span class="string">&#x27;#3979f0&#x27;</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;ECG/mV&#x27;</span>, color=<span class="string">&#x27;#3979f0&#x27;</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;ECG_R信号&#x27;</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">plt.show()</span><br><span class="line">fig.savefig(<span class="string">&#x27;ECG_R信号的绘制.png&#x27;</span>, dpi=<span class="number">1600</span>, bbox_inches=<span class="string">&#x27;tight&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/images/ECG_R%E4%BF%A1%E5%8F%B7%E7%9A%84%E7%BB%98%E5%88%B6.png" alt="ECG_R信号的绘制"></p>
<h2 id="HRV信号"><a href="#HRV信号" class="headerlink" title="HRV信号"></a>HRV信号</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">RR = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ecg_R_locs)<span class="number">-1</span>):</span><br><span class="line">    RR.append((ecg_R_locs[i+<span class="number">1</span>] - ecg_R_locs[i]) / <span class="number">128</span> * <span class="number">1000</span>)</span><br><span class="line"><span class="keyword">del</span> ecg_r_locs[<span class="number">0</span>]</span><br><span class="line">plt.plot(np.array(ecg_r_locs)/<span class="number">128</span>, RR, color=<span class="string">&#x27;#3979f0&#x27;</span>)</span><br><span class="line">plt.plot(np.array(ecg_r_locs)/<span class="number">128</span>, RR, <span class="string">&#x27;ro&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, color=<span class="string">&#x27;#8b0000&#x27;</span>, label=<span class="string">&#x27;Peak&#x27;</span>, markersize=<span class="number">4</span>)</span><br><span class="line">plt.xticks(fontsize=<span class="number">8</span>)</span><br><span class="line">plt.yticks(fontsize=<span class="number">8</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Time/s&#x27;</span>, color=<span class="string">&#x27;#3979f0&#x27;</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;HRV/ms&#x27;</span>, color=<span class="string">&#x27;#3979f0&#x27;</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;HRV信号&#x27;</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">plt.show()</span><br><span class="line">fig.savefig(<span class="string">&#x27;HRV信号的绘制.png&#x27;</span>, dpi=<span class="number">1600</span>, bbox_inches=<span class="string">&#x27;tight&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/images/HRV%E4%BF%A1%E5%8F%B7%E7%9A%84%E7%BB%98%E5%88%B6.png" alt="HRV信号的绘制"></p>
<p><img src="./images/timg.jfif"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://esyyes.github.io/2020/09/03/DATA%E6%95%B0%E6%8D%AE%E7%BB%98%E5%88%B6/" data-id="ckh4h5f3y0009isuegbw2fyh8" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Graduation-work/" rel="tag">Graduation work</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-tensorflow2-3版本安装" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/09/02/tensorflow2-3%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85/" class="article-date">
  <time datetime="2020-09-02T07:02:22.000Z" itemprop="datePublished">2020-09-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/work/">work</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/09/02/tensorflow2-3%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85/">tensorflow2.3版本安装</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="tensorflow2-3版本安装"><a href="#tensorflow2-3版本安装" class="headerlink" title="tensorflow2.3版本安装"></a>tensorflow2.3版本安装</h1><p>miniconda搭建python环境？</p>
<p>tensorflow分为GPU和CPU版本。NVIDIA GPU，没有就无法安装</p>
<p>利用豆瓣园进行安装，速度很快，同理清华那个</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pip install tensorflow-gpu==<span class="number">2.3</span><span class="number">.0</span> -i https://pypi.douban.com/simple/</span><br></pre></td></tr></table></figure>

<p>anaconda中的有些与这个不兼容，因此，下载一个miniconda,在这个里面使用tensorflow</p>
<h2 id="miniconda下载"><a href="#miniconda下载" class="headerlink" title="miniconda下载"></a>miniconda下载</h2><p> 官网地址：<a target="_blank" rel="noopener" href="https://docs.conda.io/en/latest/miniconda.html">https://docs.conda.io/en/latest/miniconda.html</a> </p>
<p>清华镜像： <a target="_blank" rel="noopener" href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/</a> </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>] = <span class="string">&#x27;2&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">  tf.keras.layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>2.0版本可以直接运行。想要gpu版本。</p>
<p>需要把环境设置了才能再进行安装</p>
<p>直接就进行2.0吧</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/9/2</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>] = <span class="string">&#x27;2&#x27;</span></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">  tf.keras.layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, epochs=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">model.evaluate(x_test,  y_test, verbose=<span class="number">2</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>GPU版本还需要安装其他的就暂时算了</p>
<p><img src="../../images/u=4060011287,292087049&fm=26&gp=0.jpg"></p>
<p><img src="../../images/timg-1599556642007.jfif"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://esyyes.github.io/2020/09/02/tensorflow2-3%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85/" data-id="ckh4h5f730053isue68npcgka" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/work/" rel="tag">work</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-随机森林超参数优化" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/09/01/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/" class="article-date">
  <time datetime="2020-09-01T06:56:45.000Z" itemprop="datePublished">2020-09-01</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/work/">work</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/09/01/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/">随机森林超参数优化</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="随机森林超参数优化"><a href="#随机森林超参数优化" class="headerlink" title="随机森林超参数优化"></a>随机森林超参数优化</h1><p> <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier</a> </p>
<p> 随机森林是一种元估计量，它适合数据集各个子样本上的许多决策树分类器，并使用平均数来提高预测准确性和控制过度拟合。子样本大小由<code>max_samples</code>参数if <code>bootstrap=True</code>（默认）控制，否则整个数据集用于构建每棵树。 </p>
<p>Parameters</p>
<ul>
<li><p>*<em>n_estimators**</em>int, default=100*</p>
<p>The number of trees in the forest.<em>Changed in version 0.22:</em> The default value of <code>n_estimators</code> changed from 10 to 100 in 0.22.</p>
</li>
<li><p>*<em>criterion**</em>{“gini”, “entropy”}, default=”gini”*</p>
<p>The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain. Note: this parameter is tree-specific.</p>
</li>
<li><p>*<em>max_depth**</em>int, default=None*</p>
<p>The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.</p>
</li>
<li><p>*<em>min_samples_split**</em>int or float, default=2*</p>
<p>The minimum number of samples required to split an internal node:If int, then consider <code>min_samples_split</code> as the minimum number.If float, then <code>min_samples_split</code> is a fraction and <code>ceil(min_samples_split * n_samples)</code> are the minimum number of samples for each split.<em>Changed in version 0.18:</em> Added float values for fractions.</p>
</li>
<li><p>*<em>min_samples_leaf**</em>int or float, default=1*</p>
<p>The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least <code>min_samples_leaf</code> training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.If int, then consider <code>min_samples_leaf</code> as the minimum number.If float, then <code>min_samples_leaf</code> is a fraction and <code>ceil(min_samples_leaf * n_samples)</code> are the minimum number of samples for each node.<em>Changed in version 0.18:</em> Added float values for fractions.</p>
</li>
<li><p>*<em>min_weight_fraction_leaf**</em>float, default=0.0*</p>
<p>The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.</p>
</li>
<li><p>*<em>max_features**</em>{“auto”, “sqrt”, “log2”}, int or float, default=”auto”*</p>
<p>The number of features to consider when looking for the best split:If int, then consider <code>max_features</code> features at each split.If float, then <code>max_features</code> is a fraction and <code>int(max_features * n_features)</code> features are considered at each split.If “auto”, then <code>max_features=sqrt(n_features)</code>.If “sqrt”, then <code>max_features=sqrt(n_features)</code> (same as “auto”).If “log2”, then <code>max_features=log2(n_features)</code>.If None, then <code>max_features=n_features</code>.Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than <code>max_features</code> features.</p>
</li>
<li><p>*<em>max_leaf_nodes**</em>int, default=None*</p>
<p>Grow trees with <code>max_leaf_nodes</code> in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.</p>
</li>
<li><p>*<em>min_impurity_decrease**</em>float, default=0.0*</p>
<p>A node will be split if this split induces a decrease of the impurity greater than or equal to this value.The weighted impurity decrease equation is the following:<code>N_t / N * (impurity - N_t_R / N_t * right_impurity                    - N_t_L / N_t * left_impurity) </code>where <code>N</code> is the total number of samples, <code>N_t</code> is the number of samples at the current node, <code>N_t_L</code> is the number of samples in the left child, and <code>N_t_R</code> is the number of samples in the right child.<code>N</code>, <code>N_t</code>, <code>N_t_R</code> and <code>N_t_L</code> all refer to the weighted sum, if <code>sample_weight</code> is passed.<em>New in version 0.19.</em></p>
</li>
<li><p>*<em>min_impurity_split**</em>float, default=None*</p>
<p>Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.<em>Deprecated since version 0.19:</em> <code>min_impurity_split</code> has been deprecated in favor of <code>min_impurity_decrease</code>in 0.19. The default value of <code>min_impurity_split</code> has changed from 1e-7 to 0 in 0.23 and it will be removed in 0.25. Use <code>min_impurity_decrease</code> instead.</p>
</li>
<li><p>*<em>bootstrap**</em>bool, default=True*</p>
<p>Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.</p>
</li>
<li><p>*<em>oob_score**</em>bool, default=False*</p>
<p>Whether to use out-of-bag samples to estimate the generalization accuracy.</p>
</li>
<li><p>*<em>n_jobs**</em>int, default=None*</p>
<p>The number of jobs to run in parallel. <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.fit"><code>fit</code></a>, <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict"><code>predict</code></a>, <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.decision_path"><code>decision_path</code></a> and <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.apply"><code>apply</code></a> are all parallelized over the trees. <code>None</code> means 1 unless in a <a target="_blank" rel="noopener" href="https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend"><code>joblib.parallel_backend</code></a> context. <code>-1</code> means using all processors. See <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/glossary.html#term-n-jobs">Glossary</a> for more details.</p>
</li>
<li><p>*<em>random_state**</em>int or RandomState, default=None*</p>
<p>Controls both the randomness of the bootstrapping of the samples used when building trees (if <code>bootstrap=True</code>) and the sampling of the features to consider when looking for the best split at each node (if <code>max_features &lt; n_features</code>). See <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/glossary.html#term-random-state">Glossary</a> for details.</p>
</li>
<li><p>*<em>verbose**</em>int, default=0*</p>
<p>Controls the verbosity when fitting and predicting.</p>
</li>
<li><p>*<em>warm_start**</em>bool, default=False*</p>
<p>When set to <code>True</code>, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest. See <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/glossary.html#term-warm-start">the Glossary</a>.</p>
</li>
<li><p>*<em>class_weight**</em>{“balanced”, “balanced_subsample”}, dict or list of dicts, default=None*</p>
<p>Weights associated with classes in the form <code>&#123;class_label: weight&#125;</code>. If not given, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y.Note that for multioutput (including multilabel) weights should be defined for each class of every column in its own dict. For example, for four-class multilabel classification weights should be [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, {4:1}].The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as <code>n_samples / (n_classes * np.bincount(y))</code>The “balanced_subsample” mode is the same as “balanced” except that weights are computed based on the bootstrap sample for every tree grown.For multi-output, the weights of each column of y will be multiplied.Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.</p>
</li>
<li><p>*<em>ccp_alpha**</em>non-negative float, default=0.0*</p>
<p>Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than <code>ccp_alpha</code> will be chosen. By default, no pruning is performed. See <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/tree.html#minimal-cost-complexity-pruning">Minimal Cost-Complexity Pruning</a> for details.<em>New in version 0.22.</em></p>
</li>
<li><p>*<em>max_samples**</em>int or float, default=None*</p>
<p>If bootstrap is True, the number of samples to draw from X to train each base estimator.If None (default), then draw <code>X.shape[0]</code> samples.If int, then draw <code>max_samples</code> samples.If float, then draw <code>max_samples * X.shape[0]</code> samples. Thus, <code>max_samples</code> should be in the interval <code>(0, 1)</code>.<em>New in version 0.22.</em></p>
</li>
</ul>
<p>Attributes</p>
<ul>
<li><p>*<em>base_estimator_**</em>DecisionTreeClassifier*</p>
<p>The child estimator template used to create the collection of fitted sub-estimators.</p>
</li>
<li><p>*<em>estimators_**</em>list of DecisionTreeClassifier*</p>
<p>The collection of fitted sub-estimators.</p>
</li>
<li><p>*<em>classes_**</em>ndarray of shape (n_classes,) or a list of such arrays*</p>
<p>The classes labels (single output problem), or a list of arrays of class labels (multi-output problem).</p>
</li>
<li><p>*<em>n_classes_**</em>int or list*</p>
<p>The number of classes (single output problem), or a list containing the number of classes for each output (multi-output problem).</p>
</li>
<li><p>*<em>n_features_**</em>int*</p>
<p>The number of features when <code>fit</code> is performed.</p>
</li>
<li><p>*<em>n_outputs_**</em>int*</p>
<p>The number of outputs when <code>fit</code> is performed.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.feature_importances_"><code>feature_importances_</code></a><em>ndarray of shape (n_features,)</em></p>
<p>The impurity-based feature importances.</p>
</li>
<li><p>*<em>oob_score_**</em>float*</p>
<p>Score of the training dataset obtained using an out-of-bag estimate. This attribute exists only when <code>oob_score</code>is True.</p>
</li>
<li><p>*<em>oob_decision_function_**</em>ndarray of shape (n_samples, n_classes)*</p>
<p>Decision function computed with out-of-bag estimate on the training set. If n_estimators is small it might be possible that a data point was never left out during the bootstrap. In this case, <code>oob_decision_function_</code> might contain NaN. This attribute exists only when <code>oob_score</code> is True.</p>
</li>
</ul>
<p>控制树（例如<code>max_depth</code>，<code>min_samples_leaf</code>等）大小的参数的默认值会导致树完全生长和未修剪，这在某些数据集上可能非常大。为了减少内存消耗，应通过设置这些参数值来控制树的复杂性和大小。</p>
<p>每次分割时，特征总是随机排列的。因此，即使使用相同的训练数据，最佳找到的分割也可能会有所不同，<code>max_features=n_features</code>并且<code>bootstrap=False</code>，如果在最佳分割的搜索过程中枚举的几个分割的标准改进相同，则最佳分割也可能会有所不同 。为了在拟合过程中获得确定性的行为，<code>random_state</code>必须进行修复。</p>
<h2 id="max-features"><a href="#max-features" class="headerlink" title="max_features"></a><strong>max_features</strong></h2><p>已经筛选出了17个特征，因此不在需要设置该超参数。默认即可。</p>
<h2 id="n-estimators"><a href="#n-estimators" class="headerlink" title="n_estimators"></a><strong>n_estimators</strong></h2><p>默认树的数目：100</p>
<h2 id="criterion"><a href="#criterion" class="headerlink" title="criterion"></a><strong>criterion</strong></h2><p>默认：gini</p>
<p>{“gini”, “entropy”}</p>
<p>考虑这两个参数就可以了，其他是属于特征全部进行使用。</p>
<h2 id="随机森林超参数结果"><a href="#随机森林超参数结果" class="headerlink" title="随机森林超参数结果"></a>随机森林超参数结果</h2><table>
<thead>
<tr>
<th></th>
<th><strong>score</strong></th>
<th><strong>num_tree</strong></th>
<th><strong>score</strong></th>
<th><strong>num_tree</strong></th>
<th><strong>score</strong></th>
<th><strong>num_tree</strong></th>
<th><strong>score</strong></th>
<th><strong>num_tree</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>93.41%</td>
<td>150</td>
<td>88.57%</td>
<td>100</td>
<td>87.21%</td>
<td>150</td>
<td>79.84%</td>
<td>50</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>96.06%</td>
<td>50</td>
<td>93.92%</td>
<td>50</td>
<td>89.16%</td>
<td>200</td>
<td>87.68%</td>
<td>100</td>
</tr>
<tr>
<td><strong>2</strong></td>
<td>91.62%</td>
<td>100</td>
<td>87.25%</td>
<td>150</td>
<td>87.43%</td>
<td>50</td>
<td>79.23%</td>
<td>100</td>
</tr>
<tr>
<td><strong>3</strong></td>
<td>93.51%</td>
<td>150</td>
<td>91.41%</td>
<td>50</td>
<td>87.79%</td>
<td>200</td>
<td>84.54%</td>
<td>150</td>
</tr>
<tr>
<td><strong>4</strong></td>
<td>94.47%</td>
<td>50</td>
<td>91.98%</td>
<td>150</td>
<td>86.81%</td>
<td>50</td>
<td>83.07%</td>
<td>100</td>
</tr>
<tr>
<td><strong>5</strong></td>
<td>92.26%</td>
<td>200</td>
<td>90.11%</td>
<td>150</td>
<td>83.66%</td>
<td>200</td>
<td>78.28%</td>
<td>50</td>
</tr>
<tr>
<td><strong>6</strong></td>
<td>90.45%</td>
<td>100</td>
<td>89.83%</td>
<td>100</td>
<td>86.23%</td>
<td>200</td>
<td>79.66%</td>
<td>150</td>
</tr>
<tr>
<td><strong>7</strong></td>
<td>94.58%</td>
<td>100</td>
<td>91.71%</td>
<td>200</td>
<td>87.88%</td>
<td>150</td>
<td>84.85%</td>
<td>200</td>
</tr>
<tr>
<td><strong>8</strong></td>
<td>92.78%</td>
<td>200</td>
<td>93.42%</td>
<td>150</td>
<td>87.32%</td>
<td>150</td>
<td>87.00%</td>
<td>100</td>
</tr>
<tr>
<td><strong>9</strong></td>
<td>93.47%</td>
<td>100</td>
<td>91.12%</td>
<td>150</td>
<td>88.78%</td>
<td>100</td>
<td>83.58%</td>
<td>200</td>
</tr>
<tr>
<td><strong>10</strong></td>
<td>90.89%</td>
<td>150</td>
<td>91.25%</td>
<td>50</td>
<td>86.96%</td>
<td>200</td>
<td>82.86%</td>
<td>100</td>
</tr>
<tr>
<td><strong>11</strong></td>
<td>90.26%</td>
<td>200</td>
<td>89.70%</td>
<td>100</td>
<td>86.52%</td>
<td>150</td>
<td>80.34%</td>
<td>200</td>
</tr>
<tr>
<td><strong>12</strong></td>
<td>89.07%</td>
<td>150</td>
<td>86.62%</td>
<td>200</td>
<td>82.22%</td>
<td>200</td>
<td>78.14%</td>
<td>50</td>
</tr>
<tr>
<td><strong>13</strong></td>
<td>93.01%</td>
<td>150</td>
<td>93.01%</td>
<td>200</td>
<td>88.42%</td>
<td>100</td>
<td>88.79%</td>
<td>100</td>
</tr>
<tr>
<td><strong>14</strong></td>
<td>96.65%</td>
<td>200</td>
<td>94.89%</td>
<td>50</td>
<td>95.41%</td>
<td>150</td>
<td>92.95%</td>
<td>100</td>
</tr>
<tr>
<td><strong>15</strong></td>
<td>94.73%</td>
<td>50</td>
<td>91.50%</td>
<td>50</td>
<td>88.78%</td>
<td>100</td>
<td>87.24%</td>
<td>100</td>
</tr>
<tr>
<td><strong>16</strong></td>
<td>92.08%</td>
<td>100</td>
<td>88.80%</td>
<td>200</td>
<td>87.84%</td>
<td>200</td>
<td>82.63%</td>
<td>100</td>
</tr>
<tr>
<td><strong>17</strong></td>
<td>94.27%</td>
<td>50</td>
<td>90.34%</td>
<td>200</td>
<td>89.69%</td>
<td>50</td>
<td>88.38%</td>
<td>200</td>
</tr>
<tr>
<td><strong>18</strong></td>
<td>92.27%</td>
<td>200</td>
<td>91.71%</td>
<td>50</td>
<td>91.34%</td>
<td>50</td>
<td>90.06%</td>
<td>150</td>
</tr>
<tr>
<td><strong>19</strong></td>
<td>84.93%</td>
<td>200</td>
<td>83.56%</td>
<td>150</td>
<td>81.28%</td>
<td>50</td>
<td>76.03%</td>
<td>50</td>
</tr>
<tr>
<td><strong>20</strong></td>
<td>94.74%</td>
<td>50</td>
<td>91.07%</td>
<td>100</td>
<td>87.08%</td>
<td>150</td>
<td>82.93%</td>
<td>150</td>
</tr>
<tr>
<td><strong>21</strong></td>
<td>81.63%</td>
<td>200</td>
<td>77.76%</td>
<td>150</td>
<td>79.39%</td>
<td>50</td>
<td>69.18%</td>
<td>100</td>
</tr>
<tr>
<td><strong>22</strong></td>
<td>97.06%</td>
<td>50</td>
<td>93.08%</td>
<td>200</td>
<td>89.79%</td>
<td>150</td>
<td>85.81%</td>
<td>150</td>
</tr>
<tr>
<td><strong>23</strong></td>
<td>95.30%</td>
<td>50</td>
<td>93.84%</td>
<td>200</td>
<td>91.90%</td>
<td>100</td>
<td>88.33%</td>
<td>100</td>
</tr>
<tr>
<td><strong>24</strong></td>
<td>79.28%</td>
<td>100</td>
<td>73.24%</td>
<td>150</td>
<td>66.80%</td>
<td>200</td>
<td>59.56%</td>
<td>200</td>
</tr>
<tr>
<td>均值</td>
<td>91.95%</td>
<td>124</td>
<td>89.59%</td>
<td>132</td>
<td>86.63%</td>
<td>134</td>
<td>82.44%</td>
<td>122</td>
</tr>
</tbody></table>
<p>选取150 </p>
<h2 id="GBDT超参数结果"><a href="#GBDT超参数结果" class="headerlink" title="GBDT超参数结果"></a>GBDT超参数结果</h2><table>
<thead>
<tr>
<th></th>
<th><strong>score</strong></th>
<th><strong>rate</strong></th>
<th><strong>num</strong></th>
<th><strong>score</strong></th>
<th><strong>rate</strong></th>
<th><strong>num</strong></th>
<th><strong>score</strong></th>
<th><strong>rate</strong></th>
<th><strong>num</strong></th>
<th><strong>score</strong></th>
<th><strong>rate</strong></th>
<th><strong>num</strong></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>93%</td>
<td>0.1</td>
<td>200</td>
<td>90%</td>
<td>0.1</td>
<td>200</td>
<td>85%</td>
<td>1</td>
<td>150</td>
<td>79%</td>
<td>0.1</td>
<td>100</td>
<td></td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>96%</td>
<td>0.1</td>
<td>150</td>
<td>94%</td>
<td>0.1</td>
<td>200</td>
<td>90%</td>
<td>0.1</td>
<td>200</td>
<td>85%</td>
<td>0.1</td>
<td>200</td>
<td></td>
</tr>
<tr>
<td><strong>2</strong></td>
<td>90%</td>
<td>0.1</td>
<td>200</td>
<td>88%</td>
<td>0.1</td>
<td>200</td>
<td>84%</td>
<td>0.1</td>
<td>150</td>
<td>77%</td>
<td>0.1</td>
<td>50</td>
<td></td>
</tr>
<tr>
<td><strong>3</strong></td>
<td>95%</td>
<td>0.01</td>
<td>100</td>
<td>90%</td>
<td>0.1</td>
<td>200</td>
<td>86%</td>
<td>1</td>
<td>50</td>
<td>85%</td>
<td>0.1</td>
<td>200</td>
<td></td>
</tr>
<tr>
<td><strong>4</strong></td>
<td>95%</td>
<td>0.01</td>
<td>200</td>
<td>92%</td>
<td>0.1</td>
<td>100</td>
<td>88%</td>
<td>0.1</td>
<td>150</td>
<td>83%</td>
<td>0.1</td>
<td>200</td>
<td></td>
</tr>
<tr>
<td><strong>5</strong></td>
<td>88%</td>
<td>1</td>
<td>150</td>
<td>87%</td>
<td>0.1</td>
<td>150</td>
<td>83%</td>
<td>1</td>
<td>150</td>
<td>75%</td>
<td>0.1</td>
<td>150</td>
<td></td>
</tr>
<tr>
<td><strong>6</strong></td>
<td>89%</td>
<td>0.1</td>
<td>200</td>
<td>90%</td>
<td>1</td>
<td>100</td>
<td>87%</td>
<td>1</td>
<td>50</td>
<td>80%</td>
<td>0.1</td>
<td>200</td>
<td></td>
</tr>
<tr>
<td><strong>7</strong></td>
<td>96%</td>
<td>0.1</td>
<td>50</td>
<td>93%</td>
<td>0.1</td>
<td>100</td>
<td>86%</td>
<td>0.1</td>
<td>200</td>
<td>83%</td>
<td>0.1</td>
<td>200</td>
<td></td>
</tr>
<tr>
<td><strong>8</strong></td>
<td>93%</td>
<td>0.1</td>
<td>100</td>
<td>92%</td>
<td>0.1</td>
<td>100</td>
<td>87%</td>
<td>0.1</td>
<td>50</td>
<td>85%</td>
<td>1</td>
<td>50</td>
<td></td>
</tr>
<tr>
<td><strong>9</strong></td>
<td>94%</td>
<td>0.1</td>
<td>150</td>
<td>91%</td>
<td>0.1</td>
<td>150</td>
<td>88%</td>
<td>0.1</td>
<td>150</td>
<td>82%</td>
<td>0.01</td>
<td>200</td>
<td></td>
</tr>
<tr>
<td><strong>10</strong></td>
<td>90%</td>
<td>0.1</td>
<td>100</td>
<td>88%</td>
<td>1</td>
<td>50</td>
<td>87%</td>
<td>0.1</td>
<td>200</td>
<td>85%</td>
<td>0.1</td>
<td>150</td>
<td></td>
</tr>
<tr>
<td><strong>11</strong></td>
<td>91%</td>
<td>0.1</td>
<td>50</td>
<td>87%</td>
<td>0.1</td>
<td>200</td>
<td>87%</td>
<td>1</td>
<td>50</td>
<td>74%</td>
<td>0.1</td>
<td>150</td>
<td></td>
</tr>
<tr>
<td><strong>12</strong></td>
<td>88%</td>
<td>0.1</td>
<td>200</td>
<td>84%</td>
<td>1</td>
<td>50</td>
<td>82%</td>
<td>0.1</td>
<td>200</td>
<td>80%</td>
<td>0.1</td>
<td>100</td>
<td></td>
</tr>
<tr>
<td><strong>13</strong></td>
<td>94%</td>
<td>0.1</td>
<td>200</td>
<td>92%</td>
<td>1</td>
<td>50</td>
<td>91%</td>
<td>0.1</td>
<td>100</td>
<td>88%</td>
<td>0.1</td>
<td>200</td>
<td></td>
</tr>
<tr>
<td><strong>14</strong></td>
<td>95%</td>
<td>1</td>
<td>150</td>
<td>93%</td>
<td>0.1</td>
<td>100</td>
<td>94%</td>
<td>0.1</td>
<td>200</td>
<td>92%</td>
<td>1</td>
<td>150</td>
<td></td>
</tr>
<tr>
<td><strong>15</strong></td>
<td>94%</td>
<td>0.01</td>
<td>200</td>
<td>93%</td>
<td>0.1</td>
<td>200</td>
<td>88%</td>
<td>0.1</td>
<td>150</td>
<td>84%</td>
<td>0.1</td>
<td>200</td>
<td></td>
</tr>
<tr>
<td><strong>16</strong></td>
<td>91%</td>
<td>0.1</td>
<td>150</td>
<td>88%</td>
<td>0.1</td>
<td>150</td>
<td>88%</td>
<td>0.1</td>
<td>150</td>
<td>83%</td>
<td>0.1</td>
<td>200</td>
<td></td>
</tr>
<tr>
<td><strong>17</strong></td>
<td>95%</td>
<td>0.1</td>
<td>150</td>
<td>93%</td>
<td>0.1</td>
<td>100</td>
<td>90%</td>
<td>0.1</td>
<td>100</td>
<td>87%</td>
<td>0.1</td>
<td>200</td>
<td></td>
</tr>
<tr>
<td><strong>18</strong></td>
<td>92%</td>
<td>1</td>
<td>100</td>
<td>91%</td>
<td>0.1</td>
<td>200</td>
<td>90%</td>
<td>0.1</td>
<td>200</td>
<td>90%</td>
<td>0.1</td>
<td>150</td>
<td></td>
</tr>
<tr>
<td><strong>19</strong></td>
<td>86%</td>
<td>0.1</td>
<td>50</td>
<td>82%</td>
<td>0.1</td>
<td>200</td>
<td>83%</td>
<td>0.1</td>
<td>200</td>
<td>74%</td>
<td>0.1</td>
<td>150</td>
<td></td>
</tr>
<tr>
<td><strong>20</strong></td>
<td>93%</td>
<td>0.1</td>
<td>200</td>
<td>89%</td>
<td>0.1</td>
<td>100</td>
<td>88%</td>
<td>0.1</td>
<td>200</td>
<td>82%</td>
<td>0.1</td>
<td>100</td>
<td></td>
</tr>
<tr>
<td><strong>21</strong></td>
<td>82%</td>
<td>0.1</td>
<td>150</td>
<td>79%</td>
<td>0.01</td>
<td>200</td>
<td>77%</td>
<td>0.01</td>
<td>100</td>
<td>68%</td>
<td>0.1</td>
<td>200</td>
<td></td>
</tr>
<tr>
<td><strong>22</strong></td>
<td>96%</td>
<td>0.1</td>
<td>100</td>
<td>92%</td>
<td>0.1</td>
<td>200</td>
<td>89%</td>
<td>0.1</td>
<td>150</td>
<td>86%</td>
<td>0.1</td>
<td>200</td>
<td></td>
</tr>
<tr>
<td><strong>23</strong></td>
<td>95%</td>
<td>0.1</td>
<td>200</td>
<td>93%</td>
<td>1</td>
<td>200</td>
<td>93%</td>
<td>0.1</td>
<td>100</td>
<td>88%</td>
<td>0.1</td>
<td>200</td>
<td></td>
</tr>
<tr>
<td><strong>24</strong></td>
<td>80%</td>
<td>0.1</td>
<td>50</td>
<td>72%</td>
<td>0.1</td>
<td>50</td>
<td>68%</td>
<td>0.1</td>
<td>50</td>
<td>58%</td>
<td>0.1</td>
<td>100</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>142</td>
<td>0.88</td>
<td></td>
<td>142</td>
<td>0.86</td>
<td></td>
<td>138</td>
<td>0.81</td>
<td></td>
<td>160</td>
<td></td>
</tr>
</tbody></table>
<h2 id="然后分别看GBDT和RF和组合后的优化结果"><a href="#然后分别看GBDT和RF和组合后的优化结果" class="headerlink" title="然后分别看GBDT和RF和组合后的优化结果"></a>然后分别看GBDT和RF和组合后的优化结果</h2><p>还是选择10次10折交叉验证，对训练阶段进行训练</p>
<table>
<thead>
<tr>
<th></th>
<th>stage_2</th>
<th></th>
<th>stage_3</th>
<th></th>
<th>stage_4</th>
<th></th>
<th>stage_5</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td><strong>acr</strong></td>
<td><strong>F1</strong></td>
<td><strong>acr</strong></td>
<td><strong>F1</strong></td>
<td><strong>acr</strong></td>
<td><strong>F1</strong></td>
<td><strong>acr</strong></td>
<td><strong>F1</strong></td>
</tr>
<tr>
<td><strong>Rf</strong></td>
<td>91.67%</td>
<td>84.43%</td>
<td>89.19%</td>
<td>84.19%</td>
<td>86.24%</td>
<td>83.12%</td>
<td>82.04%</td>
<td>78.85%</td>
</tr>
<tr>
<td><strong>gbdt</strong></td>
<td>91.14%</td>
<td>83.90%</td>
<td>88.66%</td>
<td>83.68%</td>
<td>85.61%</td>
<td>82.32%</td>
<td>80.68%</td>
<td>77.19%</td>
</tr>
<tr>
<td><strong>RF-GBDT</strong></td>
<td>91.49%</td>
<td>84.45%</td>
<td>89.12%</td>
<td>84.29%</td>
<td>86.16%</td>
<td>82.87%</td>
<td>81.53%</td>
<td>78.11%</td>
</tr>
</tbody></table>
<p>因此就确认选择RF，超参数N设置为150</p>
<p>原始的RF</p>
<table>
<thead>
<tr>
<th><strong>rf</strong></th>
<th>90.78%</th>
<th>82.73%</th>
<th>87.50%</th>
<th>81.65%</th>
<th>84.35%</th>
<th>80.69%</th>
<th>79.21%</th>
<th>75.46%</th>
</tr>
</thead>
<tbody><tr>
<td><strong>gbdt</strong></td>
<td>91.03%</td>
<td>83.62%</td>
<td>88.30%</td>
<td>82.96%</td>
<td>85.21%</td>
<td>81.73%</td>
<td>80.26%</td>
<td>76.46%</td>
</tr>
</tbody></table>
<p>都有了较大的提高</p>
<p><img src="../images/timg-1599439426477.jfif"></p>
<p><img src="../images/u=2881886025,3356042264&fm=26&gp=0.jpg"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://esyyes.github.io/2020/09/01/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/" data-id="ckh4h5f8t008oisue9lzb53lz" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/work/" rel="tag">work</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-分类模型基于交叉验证进行评估" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/08/31/%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%9F%BA%E4%BA%8E%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E8%BF%9B%E8%A1%8C%E8%AF%84%E4%BC%B0/" class="article-date">
  <time datetime="2020-08-31T10:59:46.000Z" itemprop="datePublished">2020-08-31</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/work/">work</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/08/31/%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%9F%BA%E4%BA%8E%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E8%BF%9B%E8%A1%8C%E8%AF%84%E4%BC%B0/">分类模型基于交叉验证进行评估</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="分类模型基于交叉验证进行评估"><a href="#分类模型基于交叉验证进行评估" class="headerlink" title="分类模型基于交叉验证进行评估"></a>分类模型基于交叉验证进行评估</h1><p>现在只考虑8个分类模型，因为MLP在sklearn中运行速度太慢，就不进行考虑</p>
<p>对模型加入交叉验证后的精准度，标准差，还有准确率都分别进行评估</p>
<h2 id="库函数"><a href="#库函数" class="headerlink" title="库函数"></a>库函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/8/31</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVC, SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier, GradientBoostingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score, recall_score, f1_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score, cross_val_predict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 逻辑回归模型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_lr</span>(<span class="params">train_x, train_y</span>):</span></span><br><span class="line">    clf = LogisticRegression()</span><br><span class="line">    clf.fit(train_x, train_y)</span><br><span class="line">    <span class="comment"># 10折交叉验证,获取准确率的均值和标准差</span></span><br><span class="line">    scores = cross_val_score(clf, train_x, train_y, scoring=<span class="string">&#x27;accuracy&#x27;</span>, cv=<span class="number">10</span>)</span><br><span class="line">    mean_score = np.array(scores).mean()</span><br><span class="line">    std_score = np.array(scores).std()</span><br><span class="line">    <span class="comment"># 10折交叉验证,获取预测类别</span></span><br><span class="line">    pre_train = cross_val_predict(clf, train_x, train_y, cv=<span class="number">10</span>)</span><br><span class="line">    <span class="comment"># 获取精准度，召回率还有F1得分</span></span><br><span class="line">    precision = precision_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    recall = recall_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    F1 = f1_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> [mean_score, std_score, precision, recall, F1]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 线性支持向量机</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_linearsvc</span>(<span class="params">train_x, train_y</span>):</span></span><br><span class="line">    clf = LinearSVC()</span><br><span class="line">    clf.fit(train_x, train_y)</span><br><span class="line">    <span class="comment"># 10折交叉验证,获取准确率的均值和标准差</span></span><br><span class="line">    scores = cross_val_score(clf, train_x, train_y, scoring=<span class="string">&#x27;accuracy&#x27;</span>, cv=<span class="number">10</span>)</span><br><span class="line">    mean_score = np.array(scores).mean()</span><br><span class="line">    std_score = np.array(scores).std()</span><br><span class="line">    <span class="comment"># 10折交叉验证,获取预测类别</span></span><br><span class="line">    pre_train = cross_val_predict(clf, train_x, train_y, cv=<span class="number">10</span>)</span><br><span class="line">    <span class="comment"># 获取精准度，召回率还有F1得分</span></span><br><span class="line">    precision = precision_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    recall = recall_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    F1 = f1_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> [mean_score, std_score, precision, recall, F1]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度下降法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_sgd</span>(<span class="params">train_x, train_y</span>):</span></span><br><span class="line">    clf = SGDClassifier()</span><br><span class="line">    clf.fit(train_x, train_y)</span><br><span class="line">    <span class="comment"># 10折交叉验证,获取准确率的均值和标准差</span></span><br><span class="line">    scores = cross_val_score(clf, train_x, train_y, scoring=<span class="string">&#x27;accuracy&#x27;</span>, cv=<span class="number">10</span>)</span><br><span class="line">    mean_score = np.array(scores).mean()</span><br><span class="line">    std_score = np.array(scores).std()</span><br><span class="line">    <span class="comment"># 10折交叉验证,获取预测类别</span></span><br><span class="line">    pre_train = cross_val_predict(clf, train_x, train_y, cv=<span class="number">10</span>)</span><br><span class="line">    <span class="comment"># 获取精准度，召回率还有F1得分</span></span><br><span class="line">    precision = precision_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    recall = recall_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    F1 = f1_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> [mean_score, std_score, precision, recall, F1]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 非线性的支持向量机</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_svc</span>(<span class="params">train_x, train_y</span>):</span></span><br><span class="line">    clf = SVC()</span><br><span class="line">    clf.fit(train_x, train_y)</span><br><span class="line">    <span class="comment"># 10折交叉验证,获取准确率的均值和标准差</span></span><br><span class="line">    scores = cross_val_score(clf, train_x, train_y, scoring=<span class="string">&#x27;accuracy&#x27;</span>, cv=<span class="number">10</span>)</span><br><span class="line">    mean_score = np.array(scores).mean()</span><br><span class="line">    std_score = np.array(scores).std()</span><br><span class="line">    <span class="comment"># 10折交叉验证,获取预测类别</span></span><br><span class="line">    pre_train = cross_val_predict(clf, train_x, train_y, cv=<span class="number">10</span>)</span><br><span class="line">    <span class="comment"># 获取精准度，召回率还有F1得分</span></span><br><span class="line">    precision = precision_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    recall = recall_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    F1 = f1_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> [mean_score, std_score, precision, recall, F1]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 决策树</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_tree</span>(<span class="params">train_x, train_y</span>):</span></span><br><span class="line">    clf = DecisionTreeClassifier()</span><br><span class="line">    clf.fit(train_x, train_y)</span><br><span class="line">    <span class="comment"># 10折交叉验证,获取准确率的均值和标准差</span></span><br><span class="line">    scores = cross_val_score(clf, train_x, train_y, scoring=<span class="string">&#x27;accuracy&#x27;</span>, cv=<span class="number">10</span>)</span><br><span class="line">    mean_score = np.array(scores).mean()</span><br><span class="line">    std_score = np.array(scores).std()</span><br><span class="line">    <span class="comment"># 10折交叉验证,获取预测类别</span></span><br><span class="line">    pre_train = cross_val_predict(clf, train_x, train_y, cv=<span class="number">10</span>)</span><br><span class="line">    <span class="comment"># 获取精准度，召回率还有F1得分</span></span><br><span class="line">    precision = precision_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    recall = recall_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    F1 = f1_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> [mean_score, std_score, precision, recall, F1]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># KNN</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_knn</span>(<span class="params">train_x, train_y</span>):</span></span><br><span class="line">    clf = KNeighborsClassifier()</span><br><span class="line">    clf.fit(train_x, train_y)</span><br><span class="line">    <span class="comment"># 10折交叉验证,获取准确率的均值和标准差</span></span><br><span class="line">    scores = cross_val_score(clf, train_x, train_y, scoring=<span class="string">&#x27;accuracy&#x27;</span>, cv=<span class="number">10</span>)</span><br><span class="line">    mean_score = np.array(scores).mean()</span><br><span class="line">    std_score = np.array(scores).std()</span><br><span class="line">    <span class="comment"># 10折交叉验证,获取预测类别</span></span><br><span class="line">    pre_train = cross_val_predict(clf, train_x, train_y, cv=<span class="number">10</span>)</span><br><span class="line">    <span class="comment"># 获取精准度，召回率还有F1得分</span></span><br><span class="line">    precision = precision_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    recall = recall_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    F1 = f1_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> [mean_score, std_score, precision, recall, F1]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机森林</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_rf</span>(<span class="params">train_x, train_y</span>):</span></span><br><span class="line">    clf = RandomForestClassifier()</span><br><span class="line">    clf.fit(train_x, train_y)</span><br><span class="line">    <span class="comment"># 10折交叉验证,获取准确率的均值和标准差</span></span><br><span class="line">    scores = cross_val_score(clf, train_x, train_y, scoring=<span class="string">&#x27;accuracy&#x27;</span>, cv=<span class="number">10</span>)</span><br><span class="line">    mean_score = np.array(scores).mean()</span><br><span class="line">    std_score = np.array(scores).std()</span><br><span class="line">    <span class="comment"># 10折交叉验证,获取预测类别</span></span><br><span class="line">    pre_train = cross_val_predict(clf, train_x, train_y, cv=<span class="number">10</span>)</span><br><span class="line">    <span class="comment"># 获取精准度，召回率还有F1得分</span></span><br><span class="line">    precision = precision_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    recall = recall_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    F1 = f1_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> [mean_score, std_score, precision, recall, F1]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度提升树</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_gbdt</span>(<span class="params">train_x, train_y</span>):</span></span><br><span class="line">    clf = GradientBoostingClassifier()</span><br><span class="line">    clf.fit(train_x, train_y)</span><br><span class="line">    <span class="comment"># 10折交叉验证,获取准确率的均值和标准差</span></span><br><span class="line">    scores = cross_val_score(clf, train_x, train_y, scoring=<span class="string">&#x27;accuracy&#x27;</span>, cv=<span class="number">10</span>)</span><br><span class="line">    mean_score = np.array(scores).mean()</span><br><span class="line">    std_score = np.array(scores).std()</span><br><span class="line">    <span class="comment"># 10折交叉验证,获取预测类别</span></span><br><span class="line">    pre_train = cross_val_predict(clf, train_x, train_y, cv=<span class="number">10</span>)</span><br><span class="line">    <span class="comment"># 获取精准度，召回率还有F1得分</span></span><br><span class="line">    precision = precision_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    recall = recall_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    F1 = f1_score(train_y, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> [mean_score, std_score, precision, recall, F1]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_cross</span>(<span class="params">train_x, train_y</span>):</span></span><br><span class="line">    list_lr = run_lr(train_x, train_y)</span><br><span class="line">    list_lsvc = run_linearsvc(train_x, train_y)</span><br><span class="line">    list_sgd = run_sgd(train_x, train_y)</span><br><span class="line">    list_svc = run_svc(train_x, train_y)</span><br><span class="line">    list_tree = run_tree(train_x, train_y)</span><br><span class="line">    list_knn = run_knn(train_x, train_y)</span><br><span class="line">    list_rf = run_rf(train_x, train_y)</span><br><span class="line">    list_gbdt = run_gbdt(train_x, train_y)</span><br><span class="line">    <span class="keyword">return</span> [list_lr, list_lsvc, list_sgd, list_svc, list_tree, list_knn, list_rf, list_gbdt]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="调用函数"><a href="#调用函数" class="headerlink" title="调用函数"></a>调用函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/8/31</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">from</span> data_preprocessing <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> cross_acr_f1 <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取分期为2时的17个特征</span></span><br><span class="line">feature_name = np.array(pd.read_excel(<span class="string">&#x27;F:/st_data/30-17个特征.xlsx&#x27;</span>)[<span class="string">&#x27;stage_2&#x27;</span>])[<span class="number">0</span>:<span class="number">17</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取ucddb库中的名字和AHI/SEFF</span></span><br><span class="line">data = pd.read_excel(<span class="string">&#x27;F:/py/py_sleep stage and apnea/data/&#x27;</span> + <span class="string">&#x27;ucddb&#x27;</span> + <span class="string">&#x27;_sleep_stages.xlsx&#x27;</span>)</span><br><span class="line">study_name = np.array(data[<span class="string">&#x27;data&#x27;</span>])</span><br><span class="line">data_AHI = np.array(data[<span class="string">&#x27;AHI&#x27;</span>])</span><br><span class="line">data_seff = np.array(data[<span class="string">&#x27;Seff&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取ucddb库中的单个数据的全部特征</span></span><br><span class="line"><span class="keyword">for</span> text <span class="keyword">in</span> study_name[<span class="number">0</span>:<span class="number">1</span>]:</span><br><span class="line">    <span class="comment"># 读取ucddb库中的102个特征</span></span><br><span class="line">    features = pd.read_excel(<span class="string">&#x27;E:/MIT data/ucddb_feature/features_&#x27;</span> + <span class="string">&#x27;%s&#x27;</span> % text + <span class="string">&#x27;.xlsx&#x27;</span>)</span><br><span class="line">    <span class="comment"># 将获取的17个特征进行标准化和补缺失值</span></span><br><span class="line">    df = data_pre(pd.get_dummies(features.iloc[:, <span class="number">1</span>:])[feature_name])</span><br><span class="line">    <span class="comment"># 获取标签</span></span><br><span class="line">    labels = pd.read_excel(<span class="string">&#x27;E:/MIT data/ucddb_note/note_&#x27;</span> + <span class="string">&#x27;%s&#x27;</span> % text + <span class="string">&#x27;.xlsx&#x27;</span>)</span><br><span class="line">    tag = pd.get_dummies(labels.iloc[<span class="number">0</span>:<span class="built_in">len</span>(features), <span class="number">1</span>:<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 分层抽样并按照7:3划分为训练集和测试集</span></span><br><span class="line">    class_cross = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        X_train, X_test, y_train, y_test = train_test_split(df, tag, stratify=tag, test_size=<span class="number">0.3</span>)</span><br><span class="line">        class_cross.append(run_cross(X_train, y_train))</span><br><span class="line"></span><br><span class="line">    all_class = []</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>):</span><br><span class="line">        class_1 = []</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">            mean_acr = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">                mean_acr.append(class_cross[i][j][k])</span><br><span class="line">            mean_lr = np.array(mean_acr).mean()</span><br><span class="line">            class_1.append(mean_lr)</span><br><span class="line">        all_class.append(class_1)</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/8/31</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">from</span> data_preprocessing <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> cross_acr_f1 <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取分期为2时的17个特征</span></span><br><span class="line">feature_name = np.array(pd.read_excel(<span class="string">&#x27;F:/st_data/30-17个特征.xlsx&#x27;</span>)[<span class="string">&#x27;stage_2&#x27;</span>])[<span class="number">0</span>:<span class="number">17</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取ucddb库中的名字和AHI/SEFF</span></span><br><span class="line">data = pd.read_excel(<span class="string">&#x27;F:/py/py_sleep stage and apnea/data/&#x27;</span> + <span class="string">&#x27;ucddb&#x27;</span> + <span class="string">&#x27;_sleep_stages.xlsx&#x27;</span>)</span><br><span class="line">study_name = np.array(data[<span class="string">&#x27;data&#x27;</span>])</span><br><span class="line">data_AHI = np.array(data[<span class="string">&#x27;AHI&#x27;</span>])</span><br><span class="line">data_seff = np.array(data[<span class="string">&#x27;Seff&#x27;</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ucddb_class = []</span><br><span class="line"><span class="comment"># 读取ucddb库中的单个数据的全部特征</span></span><br><span class="line"><span class="keyword">for</span> text <span class="keyword">in</span> study_name:</span><br><span class="line">    <span class="comment"># 读取ucddb库中的102个特征</span></span><br><span class="line">    features = pd.read_excel(<span class="string">&#x27;E:/MIT data/ucddb_feature/features_&#x27;</span> + <span class="string">&#x27;%s&#x27;</span> % text + <span class="string">&#x27;.xlsx&#x27;</span>)</span><br><span class="line">    <span class="comment"># 将获取的17个特征进行标准化和补缺失值</span></span><br><span class="line">    df = data_pre(pd.get_dummies(features.iloc[:, <span class="number">1</span>:])[feature_name])</span><br><span class="line">    <span class="comment"># 获取标签</span></span><br><span class="line">    labels = pd.read_excel(<span class="string">&#x27;E:/MIT data/ucddb_note/note_&#x27;</span> + <span class="string">&#x27;%s&#x27;</span> % text + <span class="string">&#x27;.xlsx&#x27;</span>)</span><br><span class="line">    tag = pd.get_dummies(labels.iloc[<span class="number">0</span>:<span class="built_in">len</span>(features), <span class="number">1</span>:<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 分层抽样并按照7:3划分为训练集和测试集</span></span><br><span class="line">    class_cross = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        X_train, X_test, y_train, y_test = train_test_split(df, tag, stratify=tag, test_size=<span class="number">0.3</span>)</span><br><span class="line">        class_cross.append(run_cross(X_train, y_train))</span><br><span class="line">    all_class = [[np.array([class_cross[i][j][k] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]).mean() <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>)] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>)]</span><br><span class="line">    ucddb_class.append(all_class)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>先保存，然后再重新调用，到时看数据的情况。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/9/1</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">6</span>):</span><br><span class="line">    cross = pd.read_excel(<span class="string">&#x27;E:/交叉验证结果/&#x27;</span> + <span class="string">&#x27;%d&#x27;</span> % index + <span class="string">&#x27;期时的交叉验证结果.xlsx&#x27;</span>)</span><br><span class="line">    mean_all = [[np.array([<span class="built_in">eval</span>(cross[i][j])[k] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(cross))]).mean() <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>)] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>)]</span><br><span class="line"></span><br><span class="line">    data = pd.DataFrame(mean_all, index=[<span class="string">&#x27;lr&#x27;</span>, <span class="string">&#x27;lsvc&#x27;</span>, <span class="string">&#x27;sgd&#x27;</span>, <span class="string">&#x27;svc&#x27;</span>, <span class="string">&#x27;tree&#x27;</span>, <span class="string">&#x27;knn&#x27;</span>, <span class="string">&#x27;rf&#x27;</span>, <span class="string">&#x27;gbdt&#x27;</span>],</span><br><span class="line">                        columns=[<span class="string">&#x27;acr&#x27;</span>, <span class="string">&#x27;std&#x27;</span>, <span class="string">&#x27;precision&#x27;</span>, <span class="string">&#x27;recall&#x27;</span>, <span class="string">&#x27;F1&#x27;</span>])</span><br><span class="line">    data.to_excel(<span class="string">&#x27;cross_acr_stage&#x27;</span> + <span class="string">&#x27;%d&#x27;</span> % index + <span class="string">&#x27;.xlsx&#x27;</span>)</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>stage_2</th>
<th><strong>acr</strong></th>
<th><strong>std</strong></th>
<th><strong>precision</strong></th>
<th><strong>recall</strong></th>
<th><strong>F1</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>lr</strong></td>
<td>0.873204</td>
<td>0.03342</td>
<td>0.825375</td>
<td>0.733596</td>
<td>0.759565</td>
</tr>
<tr>
<td><strong>lsvc</strong></td>
<td>0.876835</td>
<td>0.032714</td>
<td>0.838397</td>
<td>0.73677</td>
<td>0.764255</td>
</tr>
<tr>
<td><strong>sgd</strong></td>
<td>0.840779</td>
<td>0.049567</td>
<td>0.747202</td>
<td>0.73014</td>
<td>0.736533</td>
</tr>
<tr>
<td><strong>svc</strong></td>
<td>0.892471</td>
<td>0.029874</td>
<td>0.87406</td>
<td>0.756022</td>
<td>0.786449</td>
</tr>
<tr>
<td><strong>tree</strong></td>
<td>0.879118</td>
<td>0.038455</td>
<td>0.799414</td>
<td>0.79918</td>
<td>0.798938</td>
</tr>
<tr>
<td><strong>knn</strong></td>
<td>0.899159</td>
<td>0.031359</td>
<td>0.8657</td>
<td>0.783775</td>
<td>0.810978</td>
</tr>
<tr>
<td><strong>rf</strong></td>
<td>0.907763</td>
<td>0.030804</td>
<td>0.875697</td>
<td>0.800254</td>
<td>0.827333</td>
</tr>
<tr>
<td><strong>gbdt</strong></td>
<td>0.910328</td>
<td>0.031105</td>
<td>0.867326</td>
<td>0.816129</td>
<td>0.836155</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>stage_3</th>
<th><strong>acr</strong></th>
<th><strong>std</strong></th>
<th><strong>precision</strong></th>
<th><strong>recall</strong></th>
<th><strong>F1</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>lr</strong></td>
<td>0.792084</td>
<td>0.042254</td>
<td>0.728096</td>
<td>0.620623</td>
<td>0.64276</td>
</tr>
<tr>
<td><strong>lsvc</strong></td>
<td>0.802505</td>
<td>0.042456</td>
<td>0.749108</td>
<td>0.644193</td>
<td>0.67019</td>
</tr>
<tr>
<td><strong>sgd</strong></td>
<td>0.764561</td>
<td>0.054607</td>
<td>0.674735</td>
<td>0.637357</td>
<td>0.649782</td>
</tr>
<tr>
<td><strong>svc</strong></td>
<td>0.830053</td>
<td>0.039064</td>
<td>0.805598</td>
<td>0.67005</td>
<td>0.702448</td>
</tr>
<tr>
<td><strong>tree</strong></td>
<td>0.836634</td>
<td>0.044526</td>
<td>0.776706</td>
<td>0.776503</td>
<td>0.775981</td>
</tr>
<tr>
<td><strong>knn</strong></td>
<td>0.853001</td>
<td>0.039173</td>
<td>0.82644</td>
<td>0.749573</td>
<td>0.776256</td>
</tr>
<tr>
<td><strong>rf</strong></td>
<td>0.875021</td>
<td>0.038509</td>
<td>0.857863</td>
<td>0.790371</td>
<td>0.816468</td>
</tr>
<tr>
<td><strong>gbdt</strong></td>
<td>0.883001</td>
<td>0.037505</td>
<td>0.864701</td>
<td>0.806511</td>
<td>0.82958</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>stage_4</th>
<th><strong>acr</strong></th>
<th><strong>std</strong></th>
<th><strong>precision</strong></th>
<th><strong>recall</strong></th>
<th><strong>F1</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>lr</strong></td>
<td>0.721052</td>
<td>0.048301</td>
<td>0.663519</td>
<td>0.571228</td>
<td>0.587809</td>
</tr>
<tr>
<td><strong>lsvc</strong></td>
<td>0.735596</td>
<td>0.046768</td>
<td>0.695477</td>
<td>0.600284</td>
<td>0.621023</td>
</tr>
<tr>
<td><strong>sgd</strong></td>
<td>0.683904</td>
<td>0.059923</td>
<td>0.622163</td>
<td>0.589934</td>
<td>0.599896</td>
</tr>
<tr>
<td><strong>svc</strong></td>
<td>0.77124</td>
<td>0.044369</td>
<td>0.755301</td>
<td>0.628645</td>
<td>0.655689</td>
</tr>
<tr>
<td><strong>tree</strong></td>
<td>0.794947</td>
<td>0.048561</td>
<td>0.759304</td>
<td>0.757206</td>
<td>0.757366</td>
</tr>
<tr>
<td><strong>knn</strong></td>
<td>0.803281</td>
<td>0.046634</td>
<td>0.789236</td>
<td>0.730978</td>
<td>0.750146</td>
</tr>
<tr>
<td><strong>rf</strong></td>
<td>0.843469</td>
<td>0.042679</td>
<td>0.840218</td>
<td>0.785219</td>
<td>0.806853</td>
</tr>
<tr>
<td><strong>gbdt</strong></td>
<td>0.8521</td>
<td>0.04264</td>
<td>0.852484</td>
<td>0.793713</td>
<td>0.817332</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>stage_5</th>
<th><strong>acr</strong></th>
<th><strong>std</strong></th>
<th><strong>precision</strong></th>
<th><strong>recall</strong></th>
<th><strong>F1</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>lr</strong></td>
<td>0.645579</td>
<td>0.049839</td>
<td>0.591382</td>
<td>0.521489</td>
<td>0.525964</td>
</tr>
<tr>
<td><strong>lsvc</strong></td>
<td>0.661358</td>
<td>0.049126</td>
<td>0.612617</td>
<td>0.548897</td>
<td>0.55334</td>
</tr>
<tr>
<td><strong>sgd</strong></td>
<td>0.591087</td>
<td>0.06421</td>
<td>0.539555</td>
<td>0.51574</td>
<td>0.521715</td>
</tr>
<tr>
<td><strong>svc</strong></td>
<td>0.701606</td>
<td>0.048033</td>
<td>0.672929</td>
<td>0.581888</td>
<td>0.595645</td>
</tr>
<tr>
<td><strong>tree</strong></td>
<td>0.739748</td>
<td>0.05237</td>
<td>0.706157</td>
<td>0.705201</td>
<td>0.704886</td>
</tr>
<tr>
<td><strong>knn</strong></td>
<td>0.736938</td>
<td>0.049964</td>
<td>0.716943</td>
<td>0.671462</td>
<td>0.684666</td>
</tr>
<tr>
<td><strong>rf</strong></td>
<td>0.792051</td>
<td>0.046862</td>
<td>0.777754</td>
<td>0.740566</td>
<td>0.754568</td>
</tr>
<tr>
<td><strong>gbdt</strong></td>
<td>0.80258</td>
<td>0.046231</td>
<td>0.793377</td>
<td>0.746552</td>
<td>0.76463</td>
</tr>
</tbody></table>
<p>目的：</p>
<p>标准差为单人标准差下的均值</p>
<p>确定2345期中的最优模型，进行筛选</p>
<p>综合上述4个表格。选择RF和GBDT作为超参数优化。、</p>
<p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1598953428509&di=c0a95868d76a72e79cd00e0d87c33d95&imgtype=0&src=http://pic3.zhimg.com/50/v2-407554e0d45f7331456955554be770b2_hd.gif"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://esyyes.github.io/2020/08/31/%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%9F%BA%E4%BA%8E%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E8%BF%9B%E8%A1%8C%E8%AF%84%E4%BC%B0/" data-id="ckh4h5f7h005lisueekb849ww" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/work/" rel="tag">work</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-分类模型的确定" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/08/31/%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%A1%AE%E5%AE%9A/" class="article-date">
  <time datetime="2020-08-31T05:13:18.000Z" itemprop="datePublished">2020-08-31</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/work/">work</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/08/31/%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%A1%AE%E5%AE%9A/">分类模型的确定</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="分类模型的确定"><a href="#分类模型的确定" class="headerlink" title="分类模型的确定"></a>分类模型的确定</h1><p>按照书中的完善分类器，和重新筛选分类器</p>
<h2 id="选择和训练分类模型"><a href="#选择和训练分类模型" class="headerlink" title="选择和训练分类模型"></a>选择和训练分类模型</h2><p> 分类问题的评价指标是准确率，那么回归算法的评价指标就是MSE，RMSE，MAE、R-Squared ，这几个是回归模型的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error <span class="comment">#均方误差</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error <span class="comment">#平方绝对误差</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score<span class="comment">#R square</span></span><br><span class="line"><span class="comment">#调用</span></span><br><span class="line">mean_squared_error(y_test,y_predict)</span><br><span class="line">mean_absolute_error(y_test,y_predict)</span><br><span class="line">r2_score(y_test,y_predict)</span><br></pre></td></tr></table></figure>

<ul>
<li>训练集（train set） —— 用于模型拟合的数据样本。</li>
<li>验证集（development set）—— 是模型训练过程中单独留出的样本集，它可以用于调整模型的超参数和用于对模型的能力进行初步评估。</li>
</ul>
<p>​         在神经网络中， 我们用验证数据集去寻找最优的网络深度（number of hidden layers)，或者决定反向传播算法的停止点或者<em>在神经网络中选择隐藏层神经元的数量；</em></p>
<p>​        在普通的机器学习中常用的交叉验证（Cross Validation) 就是把训练数据集本身再细分成不同的验证数据集去训练模型。</p>
<ul>
<li>测试集 —— 用来评估模最终模型的泛化能力。但不能作为调参、选择特征等算法相关的选择的依据。</li>
</ul>
<table>
<thead>
<tr>
<th align="left">类别</th>
<th align="left">验证集</th>
<th align="left">测试集</th>
</tr>
</thead>
<tbody><tr>
<td align="left">是否被训练到</td>
<td align="left">否</td>
<td align="left">否</td>
</tr>
<tr>
<td align="left">作用</td>
<td align="left">用于调超参数，监控模型是否发生过拟合（以决定是否停止训练）</td>
<td align="left">为了评估最终模型泛化能力</td>
</tr>
<tr>
<td align="left">使用次数</td>
<td align="left">多次使用，以不断调参</td>
<td align="left">仅仅一次使用</td>
</tr>
<tr>
<td align="left">缺陷</td>
<td align="left">模型在一次次重新手动调参并继续训练后所逼近的验证集，可能只代表一部分非训练集，导致最终训练好的模型泛化性能不够</td>
<td align="left">测试集为了具有泛化代表性，往往数据量比较大，测试一轮要很久，所以往往只取测试集的其中一小部分作为训练过程中的验证集</td>
</tr>
</tbody></table>
<h2 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h2><p>交叉验证算法的具体步骤如下</p>
<ol>
<li><p>随机将训练数据等分成k份，S1, S2, …, Sk。</p>
</li>
<li><p>对于每一个模型Mi，算法执行k次，每次选择一个Sj作为验证集，而其它作为训练集来训练模型Mi，把训练得到的模型在Sj上进行测试，这样一来，每次都会得到一个误差E，最后对k次得到的误差求平均，就可以得到模型Mi的泛化误差。</p>
</li>
<li><p><strong>算法选择具有最小泛化误差的模型作为最终模型，并且在整个训练集上再次训练该模型，从而得到最终的模型。</strong></p>
</li>
</ol>
<p>​        K折交叉验证，其主要 的目的是<strong>为了选择不同的模型类型（比如一次线性模型、非线性模型、）</strong>，而<strong>不是为了选择具体模型的具体参数</strong>。比如在BP神经网络中，其目的主要为了选择模型的层数、神经元的激活函数、每层模型的神经元个数（即所谓的超参数）。每一层网络神经元连接的最终权重是在模型选择（即K折交叉验证）之后，由全部的训练数据重新训练。 </p>
<p>目的在模型选择，而非模型训练调整参数。</p>
<p> <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html">https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html</a> </p>
<p> <a target="_blank" rel="noopener" href="https://github.com/apachecn/hands-on-ml-zh/blob/master/docs/2.%E4%B8%80%E4%B8%AA%E5%AE%8C%E6%95%B4%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE.md">https://github.com/apachecn/hands-on-ml-zh/blob/master/docs/2.%E4%B8%80%E4%B8%AA%E5%AE%8C%E6%95%B4%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE.md</a> </p>
<h2 id="使用交叉验证去评估"><a href="#使用交叉验证去评估" class="headerlink" title="使用交叉验证去评估"></a>使用交叉验证去评估</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">from</span> data_preprocessing <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment"># 均方误差</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score, cross_val_predict, permutation_test_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取分期为2时的17个特征</span></span><br><span class="line">feature_name = np.array(pd.read_excel(<span class="string">&#x27;F:/st_data/30-17个特征.xlsx&#x27;</span>)[<span class="string">&#x27;stage_2&#x27;</span>])[<span class="number">0</span>:<span class="number">17</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取ucddb库中的名字和AHI/SEFF</span></span><br><span class="line">data = pd.read_excel(<span class="string">&#x27;F:/py/py_sleep stage and apnea/data/&#x27;</span> + <span class="string">&#x27;ucddb&#x27;</span> + <span class="string">&#x27;_sleep_stages.xlsx&#x27;</span>)</span><br><span class="line">study_name = np.array(data[<span class="string">&#x27;data&#x27;</span>])</span><br><span class="line">data_AHI = np.array(data[<span class="string">&#x27;AHI&#x27;</span>])</span><br><span class="line">data_seff = np.array(data[<span class="string">&#x27;Seff&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取ucddb库中的单个数据的全部特征</span></span><br><span class="line"><span class="keyword">for</span> text <span class="keyword">in</span> study_name[<span class="number">0</span>:<span class="number">1</span>]:</span><br><span class="line">    <span class="comment"># 读取ucddb库中的102个特征</span></span><br><span class="line">    features = pd.read_excel(<span class="string">&#x27;E:/MIT data/ucddb_feature/features_&#x27;</span> + <span class="string">&#x27;%s&#x27;</span> % text + <span class="string">&#x27;.xlsx&#x27;</span>)</span><br><span class="line">    <span class="comment"># 将获取的17个特征进行标准化和补缺失值</span></span><br><span class="line">    df = data_pre(pd.get_dummies(features.iloc[:, <span class="number">1</span>:])[feature_name])</span><br><span class="line">    <span class="comment"># 获取标签</span></span><br><span class="line">    labels = pd.read_excel(<span class="string">&#x27;E:/MIT data/ucddb_note/note_&#x27;</span> + <span class="string">&#x27;%s&#x27;</span> % text + <span class="string">&#x27;.xlsx&#x27;</span>)</span><br><span class="line">    tag = pd.get_dummies(labels.iloc[<span class="number">0</span>:<span class="built_in">len</span>(features), <span class="number">1</span>:<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 分层抽样并按照7:3划分为训练集和测试集</span></span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(df, tag, stratify=tag, test_size=<span class="number">0.3</span>)</span><br><span class="line">    lin_reg = LinearRegression()</span><br><span class="line">    lin_reg.fit(X_train, y_train)</span><br><span class="line">    pred_y = lin_reg.predict(X_test)</span><br><span class="line">    <span class="comment"># 均方误差</span></span><br><span class="line">    <span class="comment"># print(np.sqrt(mean_squared_error(y_test, pred_y)))</span></span><br><span class="line">    <span class="comment"># MSE均方误差</span></span><br><span class="line">    scores = cross_val_score(lin_reg, X_train, y_train, scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>, cv=<span class="number">10</span>)</span><br><span class="line">    rmse_scores = np.sqrt(-scores)</span><br></pre></td></tr></table></figure>



<p>Target is multiclass but average=’binary’. Please choose another average setting.</p>
<p> <a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_44436677/article/details/105985358">https://blog.csdn.net/weixin_44436677/article/details/105985358</a> </p>
<p>average参数定义了该指标的计算方法，<strong>二分类时average参数默认是binary</strong>；多分类时，可选参数有micro、macro、weighted和samples。</p>
<p><strong>None</strong>：返回每个班级的分数。否则，这将确定对数据执行的平均类型。</p>
<p><strong>binary</strong>：仅报告由指定的类的结果pos_label。仅当targets（y_{true,pred}）是二进制时才适用。</p>
<p><strong>micro</strong>：通过计算总真阳性，假阴性和误报来全球计算指标。也就是把所有的类放在一起算（具体到precision），然后把所有类的TP加和，再除以所有类的TP和FN的加和。因此micro方法下的<strong>precision和recall都等于accuracy。</strong></p>
<p><strong>macro</strong>：计算每个标签的指标，找出它们的未加权平均值。这不会考虑标签不平衡。也就是先分别求出每个类的precision再求其算术平均。</p>
<p><strong>weighted</strong>：计算每个标签的指标，并找到它们的平均值，按支持加权（每个标签的真实实例数）。这会改变“宏观”以解决标签不平衡问题; 它可能导致F分数不在精确度和召回之间。</p>
<p><strong>samples</strong>：计算每个实例的指标，并找出它们的平均值（仅对于不同的多标记分类有意义 accuracy_score）</p>
<p>若选用average=’micro’都等于准确率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">f&#x27;<span class="subst">&#123;confusion_matrix(y_train, pre_train)&#125;</span>&#x27;</span>)</span><br><span class="line">precision = precision_score(y_train, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">recall = recall_score(y_train, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">F1 = f1_score(y_train, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;精准度<span class="subst">&#123;precision&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;召回率<span class="subst">&#123;recall&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;f1_score<span class="subst">&#123;F1&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>现在都是训练，交叉验证什么的都不加入测试集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/8/31</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">from</span> data_preprocessing <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment"># 均方误差</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score, cross_val_predict, permutation_test_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, cohen_kappa_score, precision_score, recall_score, f1_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取分期为2时的17个特征</span></span><br><span class="line">feature_name = np.array(pd.read_excel(<span class="string">&#x27;F:/st_data/30-17个特征.xlsx&#x27;</span>)[<span class="string">&#x27;stage_2&#x27;</span>])[<span class="number">0</span>:<span class="number">17</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取ucddb库中的名字和AHI/SEFF</span></span><br><span class="line">data = pd.read_excel(<span class="string">&#x27;F:/py/py_sleep stage and apnea/data/&#x27;</span> + <span class="string">&#x27;ucddb&#x27;</span> + <span class="string">&#x27;_sleep_stages.xlsx&#x27;</span>)</span><br><span class="line">study_name = np.array(data[<span class="string">&#x27;data&#x27;</span>])</span><br><span class="line">data_AHI = np.array(data[<span class="string">&#x27;AHI&#x27;</span>])</span><br><span class="line">data_seff = np.array(data[<span class="string">&#x27;Seff&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取ucddb库中的单个数据的全部特征</span></span><br><span class="line"><span class="keyword">for</span> text <span class="keyword">in</span> study_name[<span class="number">0</span>:<span class="number">1</span>]:</span><br><span class="line">    <span class="comment"># 读取ucddb库中的102个特征</span></span><br><span class="line">    features = pd.read_excel(<span class="string">&#x27;E:/MIT data/ucddb_feature/features_&#x27;</span> + <span class="string">&#x27;%s&#x27;</span> % text + <span class="string">&#x27;.xlsx&#x27;</span>)</span><br><span class="line">    <span class="comment"># 将获取的17个特征进行标准化和补缺失值</span></span><br><span class="line">    df = data_pre(pd.get_dummies(features.iloc[:, <span class="number">1</span>:])[feature_name])</span><br><span class="line">    <span class="comment"># 获取标签</span></span><br><span class="line">    labels = pd.read_excel(<span class="string">&#x27;E:/MIT data/ucddb_note/note_&#x27;</span> + <span class="string">&#x27;%s&#x27;</span> % text + <span class="string">&#x27;.xlsx&#x27;</span>)</span><br><span class="line">    tag = pd.get_dummies(labels.iloc[<span class="number">0</span>:<span class="built_in">len</span>(features), <span class="number">1</span>:<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 分层抽样并按照7:3划分为训练集和测试集</span></span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(df, tag, stratify=tag, test_size=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">    log_reg = LogisticRegression()</span><br><span class="line">    log_reg.fit(X_train, y_train)</span><br><span class="line">    pred_y = log_reg.predict(X_test)</span><br><span class="line">    <span class="comment"># 均方误差</span></span><br><span class="line">    <span class="comment"># print(np.sqrt(mean_squared_error(y_test, pred_y)))</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">15</span>):</span><br><span class="line">        scores = cross_val_score(log_reg, X_train, y_train, scoring=<span class="string">&#x27;accuracy&#x27;</span>, cv=i)</span><br><span class="line">        print(<span class="string">f&#x27;准率率的平均值<span class="subst">&#123;np.array(scores).mean()&#125;</span>&#x27;</span>)</span><br><span class="line">    print(<span class="string">f&#x27;准率率的标准差<span class="subst">&#123;np.array(scores).std()&#125;</span>&#x27;</span>)</span><br><span class="line">    pre_train = cross_val_predict(log_reg, X_train, y_train, cv=<span class="number">10</span>)</span><br><span class="line">    print(<span class="string">f&#x27;<span class="subst">&#123;confusion_matrix(y_train, pre_train)&#125;</span>&#x27;</span>)</span><br><span class="line">    precision = precision_score(y_train, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    recall = recall_score(y_train, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    F1 = f1_score(y_train, pre_train, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">    print(<span class="string">f&#x27;精准度<span class="subst">&#123;precision&#125;</span>&#x27;</span>)</span><br><span class="line">    print(<span class="string">f&#x27;召回率<span class="subst">&#123;recall&#125;</span>&#x27;</span>)</span><br><span class="line">    print(<span class="string">f&#x27;f1_score<span class="subst">&#123;F1&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>



<p>已经开始了训练，所以下一步就是构建选择分类器。</p>
<p> <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-">https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-</a> </p>
<table>
<thead>
<tr>
<th>Scoring</th>
<th>Function</th>
<th>Comment</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Classification</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>‘accuracy’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score"><code>metrics.accuracy_score</code></a></td>
<td></td>
</tr>
<tr>
<td>‘balanced_accuracy’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score"><code>metrics.balanced_accuracy_score</code></a></td>
<td></td>
</tr>
<tr>
<td>‘average_precision’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score"><code>metrics.average_precision_score</code></a></td>
<td></td>
</tr>
<tr>
<td>‘neg_brier_score’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html#sklearn.metrics.brier_score_loss"><code>metrics.brier_score_loss</code></a></td>
<td></td>
</tr>
<tr>
<td>‘f1’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score"><code>metrics.f1_score</code></a></td>
<td>for binary targets</td>
</tr>
<tr>
<td>‘f1_micro’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score"><code>metrics.f1_score</code></a></td>
<td>micro-averaged</td>
</tr>
<tr>
<td>‘f1_macro’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score"><code>metrics.f1_score</code></a></td>
<td>macro-averaged</td>
</tr>
<tr>
<td>‘f1_weighted’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score"><code>metrics.f1_score</code></a></td>
<td>weighted average</td>
</tr>
<tr>
<td>‘f1_samples’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score"><code>metrics.f1_score</code></a></td>
<td>by multilabel sample</td>
</tr>
<tr>
<td>‘neg_log_loss’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss"><code>metrics.log_loss</code></a></td>
<td>requires <code>predict_proba</code> support</td>
</tr>
<tr>
<td>‘precision’ etc.</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score"><code>metrics.precision_score</code></a></td>
<td>suffixes apply as with ‘f1’</td>
</tr>
<tr>
<td>‘recall’ etc.</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score"><code>metrics.recall_score</code></a></td>
<td>suffixes apply as with ‘f1’</td>
</tr>
<tr>
<td>‘jaccard’ etc.</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.jaccard_score.html#sklearn.metrics.jaccard_score"><code>metrics.jaccard_score</code></a></td>
<td>suffixes apply as with ‘f1’</td>
</tr>
<tr>
<td>‘roc_auc’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score"><code>metrics.roc_auc_score</code></a></td>
<td></td>
</tr>
<tr>
<td>‘roc_auc_ovr’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score"><code>metrics.roc_auc_score</code></a></td>
<td></td>
</tr>
<tr>
<td>‘roc_auc_ovo’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score"><code>metrics.roc_auc_score</code></a></td>
<td></td>
</tr>
<tr>
<td>‘roc_auc_ovr_weighted’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score"><code>metrics.roc_auc_score</code></a></td>
<td></td>
</tr>
<tr>
<td>‘roc_auc_ovo_weighted’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score"><code>metrics.roc_auc_score</code></a></td>
<td></td>
</tr>
<tr>
<td><strong>Clustering</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>‘adjusted_mutual_info_score’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_mutual_info_score.html#sklearn.metrics.adjusted_mutual_info_score"><code>metrics.adjusted_mutual_info_score</code></a></td>
<td></td>
</tr>
<tr>
<td>‘adjusted_rand_score’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html#sklearn.metrics.adjusted_rand_score"><code>metrics.adjusted_rand_score</code></a></td>
<td></td>
</tr>
<tr>
<td>‘completeness_score’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.completeness_score.html#sklearn.metrics.completeness_score"><code>metrics.completeness_score</code></a></td>
<td></td>
</tr>
<tr>
<td>‘fowlkes_mallows_score’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fowlkes_mallows_score.html#sklearn.metrics.fowlkes_mallows_score"><code>metrics.fowlkes_mallows_score</code></a></td>
<td></td>
</tr>
<tr>
<td>‘homogeneity_score’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.homogeneity_score.html#sklearn.metrics.homogeneity_score"><code>metrics.homogeneity_score</code></a></td>
<td></td>
</tr>
<tr>
<td>‘mutual_info_score’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mutual_info_score.html#sklearn.metrics.mutual_info_score"><code>metrics.mutual_info_score</code></a></td>
<td></td>
</tr>
<tr>
<td>‘normalized_mutual_info_score’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.normalized_mutual_info_score.html#sklearn.metrics.normalized_mutual_info_score"><code>metrics.normalized_mutual_info_score</code></a></td>
<td></td>
</tr>
<tr>
<td>‘v_measure_score’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.v_measure_score.html#sklearn.metrics.v_measure_score"><code>metrics.v_measure_score</code></a></td>
<td></td>
</tr>
<tr>
<td><strong>Regression</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>‘explained_variance’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score"><code>metrics.explained_variance_score</code></a></td>
<td></td>
</tr>
<tr>
<td>‘max_error’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.max_error.html#sklearn.metrics.max_error"><code>metrics.max_error</code></a></td>
<td></td>
</tr>
<tr>
<td>‘neg_mean_absolute_error’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error"><code>metrics.mean_absolute_error</code></a></td>
<td></td>
</tr>
<tr>
<td>‘neg_mean_squared_error’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error"><code>metrics.mean_squared_error</code></a></td>
<td></td>
</tr>
<tr>
<td>‘neg_root_mean_squared_error’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error"><code>metrics.mean_squared_error</code></a></td>
<td></td>
</tr>
<tr>
<td>‘neg_mean_squared_log_error’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_log_error.html#sklearn.metrics.mean_squared_log_error"><code>metrics.mean_squared_log_error</code></a></td>
<td></td>
</tr>
<tr>
<td>‘neg_median_absolute_error’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.median_absolute_error.html#sklearn.metrics.median_absolute_error"><code>metrics.median_absolute_error</code></a></td>
<td></td>
</tr>
<tr>
<td>‘r2’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score"><code>metrics.r2_score</code></a></td>
<td></td>
</tr>
<tr>
<td>‘neg_mean_poisson_deviance’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_poisson_deviance.html#sklearn.metrics.mean_poisson_deviance"><code>metrics.mean_poisson_deviance</code></a></td>
<td></td>
</tr>
<tr>
<td>‘neg_mean_gamma_deviance’</td>
<td><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_gamma_deviance.html#sklearn.metrics.mean_gamma_deviance"><code>metrics.mean_gamma_deviance</code></a></td>
<td></td>
</tr>
</tbody></table>
<p> 此实现不适用于大规模数据应用。 特别是 scikit-learn 不支持 GPU。如果想要提高运行速度并使用基于 GPU 的实现以及为构建深度学习架构提供更多灵活性的框架，请参阅 <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/related_projects.html#related-projects">Related Projects</a> 。 </p>
<p><img src="https://pic.rmb.bdstatic.com/c91adf54fa1b5b43a523664167cdc2ab.gif"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://esyyes.github.io/2020/08/31/%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%A1%AE%E5%AE%9A/" data-id="ckh4h5f8r008fisuee5tvbcv8" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/work/" rel="tag">work</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-分层抽样和欠拟合或过拟合" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/08/27/%E5%88%86%E5%B1%82%E6%8A%BD%E6%A0%B7%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88%E6%88%96%E8%BF%87%E6%8B%9F%E5%90%88/" class="article-date">
  <time datetime="2020-08-27T05:04:44.000Z" itemprop="datePublished">2020-08-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/work/">work</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/08/27/%E5%88%86%E5%B1%82%E6%8A%BD%E6%A0%B7%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88%E6%88%96%E8%BF%87%E6%8B%9F%E5%90%88/">分层抽样和欠拟合或过拟合</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="分层抽样和欠拟合或过拟合"><a href="#分层抽样和欠拟合或过拟合" class="headerlink" title="分层抽样和欠拟合或过拟合"></a>分层抽样和欠拟合或过拟合</h1><h2 id="抽样方式"><a href="#抽样方式" class="headerlink" title="抽样方式"></a>抽样方式</h2><h3 id="随机抽样"><a href="#随机抽样" class="headerlink" title="随机抽样"></a>随机抽样</h3><p>总的数据比例</p>
<table>
<thead>
<tr>
<th>slp03</th>
<th>78</th>
<th>307</th>
<th>105</th>
<th>74</th>
<th>114</th>
</tr>
</thead>
<tbody><tr>
<td>总比例</td>
<td>0.11504</td>
<td>0.45280</td>
<td>0.154867</td>
<td>0.109144</td>
<td>0.168141</td>
</tr>
<tr>
<td>测试集随机抽样的比例</td>
<td>0.132352</td>
<td>0.431372</td>
<td>0.127450</td>
<td>0.093137</td>
<td>0.215686</td>
</tr>
<tr>
<td>测试集分层抽样的比例</td>
<td>0.117647</td>
<td>0.450980</td>
<td>0.156862</td>
<td>0.107843</td>
<td>0.166666</td>
</tr>
</tbody></table>
<p>因此采用分层抽样去进行比例的划分</p>
<p>X_train, X_test, y_train, y_test = train_test_split(df, label, <strong>stratify=label,</strong> test_size=0.3)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/8/27</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> data_preprocessing <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_rf</span>(<span class="params">xtrain, xtest, ytrain, ytest</span>):</span></span><br><span class="line">    clf = RandomForestClassifier()</span><br><span class="line">    clf.fit(xtrain, ytrain)</span><br><span class="line">    ypred = clf.predict(xtest)</span><br><span class="line">    sad = accuracy_score(ytest, ypred)</span><br><span class="line">    <span class="keyword">return</span> sad</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据名字</span></span><br><span class="line">text_name = pd.read_excel(<span class="string">&#x27;F:/slpdb_data/mitdata/slpdb_name.xlsx&#x27;</span>)</span><br><span class="line">slpdb_name = np.array(text_name[<span class="string">&#x27;name&#x27;</span>]).tolist()</span><br><span class="line"></span><br><span class="line">se = []</span><br><span class="line"><span class="keyword">for</span> text <span class="keyword">in</span> slpdb_name[<span class="number">4</span>:<span class="number">5</span>]:</span><br><span class="line">    <span class="comment"># 打开对应的特征和对应的集合</span></span><br><span class="line">    feature = pd.read_excel(<span class="string">&#x27;F:/py/py_sleep stage and apnea/data/slpdb_feature/features_&#x27;</span> + <span class="string">&#x27;%s&#x27;</span> % text + <span class="string">&#x27;.xlsx&#x27;</span>)</span><br><span class="line">    data = pd.get_dummies(feature.iloc[<span class="number">0</span>:<span class="built_in">len</span>(feature), <span class="number">1</span>:])</span><br><span class="line">    labels = pd.read_excel(<span class="string">&#x27;F:/py/py_sleep stage and apnea/data/slpdb_note/note_&#x27;</span> + <span class="string">&#x27;%s&#x27;</span> % text + <span class="string">&#x27;.xlsx&#x27;</span>)</span><br><span class="line">    tag = pd.get_dummies(labels.iloc[<span class="number">0</span>:<span class="built_in">len</span>(data), <span class="number">1</span>:])</span><br><span class="line">    <span class="comment"># 均值插补和zscore标准化</span></span><br><span class="line">    df = data_pre(data)</span><br><span class="line">    <span class="comment"># 读取想要分期的标签0-1:5期，1-2：4期，2-3:3期</span></span><br><span class="line">    label = pd.get_dummies(tag.iloc[<span class="number">0</span>:<span class="built_in">len</span>(data), <span class="number">0</span>:<span class="number">1</span>])</span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(df, label, stratify=label, test_size=<span class="number">0.3</span>)</span><br><span class="line">    <span class="comment"># 查看y的分类比例和总体比例</span></span><br><span class="line">    <span class="comment"># 总体比例</span></span><br><span class="line">    list_y_test = np.array(y_test)</span><br><span class="line">    num_3 = <span class="number">0</span></span><br><span class="line">    num_2 = <span class="number">0</span></span><br><span class="line">    num_1 = <span class="number">0</span></span><br><span class="line">    num_r = <span class="number">0</span></span><br><span class="line">    num_w = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(list_y_test)):</span><br><span class="line">        <span class="keyword">if</span> list_y_test[i][<span class="number">0</span>] == <span class="number">1</span>:</span><br><span class="line">            num_3 += <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> list_y_test[i][<span class="number">0</span>] == <span class="number">2</span>:</span><br><span class="line">            num_2 += <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> list_y_test[i][<span class="number">0</span>] == <span class="number">3</span>:</span><br><span class="line">            num_1 += <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> list_y_test[i][<span class="number">0</span>] == <span class="number">4</span>:</span><br><span class="line">            num_r += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            num_w += <span class="number">1</span></span><br><span class="line">    print(num_3/<span class="built_in">len</span>(list_y_test))</span><br><span class="line">    print(num_2/<span class="built_in">len</span>(list_y_test))</span><br><span class="line">    print(num_1/<span class="built_in">len</span>(list_y_test))</span><br><span class="line">    print(num_r/<span class="built_in">len</span>(list_y_test))</span><br><span class="line">    print(num_w/<span class="built_in">len</span>(list_y_test))</span><br></pre></td></tr></table></figure>



<h2 id="过拟合和欠拟合问题"><a href="#过拟合和欠拟合问题" class="headerlink" title="过拟合和欠拟合问题"></a>过拟合和欠拟合问题</h2><p>随机森林一般用更高的偏差去替换低的方差。因此只需要多加点决策树，去满足特征集合就可以，不需要再去考虑这个拟合的问题。</p>
<h2 id="特征的确定"><a href="#特征的确定" class="headerlink" title="特征的确定"></a>特征的确定</h2><ol>
<li>特征集合预处理：均值插补缺省值和zscore 标准化</li>
<li>利用随机森林获取特征重要度</li>
<li>然后筛选出重要度高于平均值的46个特征</li>
<li>再利用46个特征去获取平均重要度和得到这46个特征下特征递归算法，去获取特征的准确率</li>
<li>所以现在就是平均特征重要度确定后，用了一下PCA，重要的就17个啥的就可以了</li>
<li>先看图嘛，然后再去看下结果</li>
</ol>
<h1 id="特征为17个特征"><a href="#特征为17个特征" class="headerlink" title="特征为17个特征"></a>特征为17个特征</h1><p>经过了slpdb和ucddb效果都很好</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">&#x27;HR_mean&#x27;</span>, <span class="string">&#x27;R_mean&#x27;</span>, <span class="string">&#x27;HR_max&#x27;</span>, <span class="string">&#x27;5HR_mean&#x27;</span>, <span class="string">&#x27;5R_mean&#x27;</span>, <span class="string">&#x27;R_median&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;5p_Impulse_factor&#x27;</span>, <span class="string">&#x27;5p_Margin_factor&#x27;</span>, <span class="string">&#x27;5p_max&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;5p_peak_factor&#x27;</span>, <span class="string">&#x27;5p_Peaks&#x27;</span>, <span class="string">&#x27;5p_median&#x27;</span>, <span class="string">&#x27;5csi10&#x27;</span>, <span class="string">&#x27;5p_mean&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;5p_skew&#x27;</span>, <span class="string">&#x27;5apen&#x27;</span>, <span class="string">&#x27;5p_RMS&#x27;</span>], dtype=<span class="built_in">object</span>)</span><br></pre></td></tr></table></figure>

<p>下一步看分类器效果并将分类器写成函数，然后确定一个进行评估，评估完后才是分成两类，然后再去分别优化</p>
<p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1598861004182&di=be372ad9e9bd00bf49d749c80fea3a1b&imgtype=0&src=http://zymsc.bs2cdn.yy.com/d08c16b9-a99c-4f55-b4e8-e4b6ff8f79ea.png"></p>
<p><img src="https://ss1.bdstatic.com/70cFuXSh_Q1YnxGkpoWK1HF6hhy/it/u=2384619687,1414757876&fm=26&gp=0.jpg"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://esyyes.github.io/2020/08/27/%E5%88%86%E5%B1%82%E6%8A%BD%E6%A0%B7%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88%E6%88%96%E8%BF%87%E6%8B%9F%E5%90%88/" data-id="ckh4h5f7g005iisue37874uqa" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/work/" rel="tag">work</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-查看单独数据下的准确率" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/08/24/%E6%9F%A5%E7%9C%8B%E5%8D%95%E7%8B%AC%E6%95%B0%E6%8D%AE%E4%B8%8B%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87/" class="article-date">
  <time datetime="2020-08-24T00:58:44.000Z" itemprop="datePublished">2020-08-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/work/">work</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/08/24/%E6%9F%A5%E7%9C%8B%E5%8D%95%E7%8B%AC%E6%95%B0%E6%8D%AE%E4%B8%8B%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87/">查看单独数据下的准确率</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="查看单独数据下的准确率"><a href="#查看单独数据下的准确率" class="headerlink" title="查看单独数据下的准确率"></a>查看单独数据下的准确率</h1><p>查看每个分期下的特征重要度，并选取均值，然后取18个数据的均值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/8/24</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将2345期的组合放到1个list中</span></span><br><span class="line">slpdb_stage = []</span><br><span class="line">key_word = []</span><br><span class="line"><span class="comment"># 读取2345期的睡眠结果</span></span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">6</span>):</span><br><span class="line">    df = pd.read_excel(<span class="string">&#x27;E:/8-23 feature section and importance/slpdb_feature_mean_stage&#x27;</span> + <span class="string">&#x27;%d&#x27;</span> % index + <span class="string">&#x27;.xlsx&#x27;</span>)</span><br><span class="line">    key_word = df.keys()[<span class="number">1</span>:]</span><br><span class="line">    data = np.array(df)</span><br><span class="line">    all_feature = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">103</span>):</span><br><span class="line">        feature_mean = []</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">18</span>):</span><br><span class="line">            feature_mean.append(data[j][i])</span><br><span class="line">        all_feature.append(np.array(feature_mean).mean())</span><br><span class="line">    slpdb_stage.append(all_feature)</span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/8/24</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将2345期的组合放到1个list中</span></span><br><span class="line">slpdb_stage = []</span><br><span class="line">key_word = []</span><br><span class="line"><span class="comment"># 读取2345期的睡眠结果</span></span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">6</span>):</span><br><span class="line">    df = pd.read_excel(<span class="string">&#x27;E:/8-23 feature section and importance/slpdb_feature_mean_stage&#x27;</span> + <span class="string">&#x27;%d&#x27;</span> % index + <span class="string">&#x27;.xlsx&#x27;</span>)</span><br><span class="line">    key_word = df.keys()[<span class="number">1</span>:]</span><br><span class="line">    data = np.array(df)</span><br><span class="line">    all_feature = [np.array([data[j][i] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">18</span>)]).mean() <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">103</span>)]</span><br><span class="line">    slpdb_stage.append(all_feature)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">feature_name = []</span><br><span class="line"><span class="keyword">for</span> i_x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    dict_data = <span class="built_in">dict</span>(<span class="built_in">zip</span>(key_word, slpdb_stage[i_x]))</span><br><span class="line">    <span class="comment"># 将字典中的值按照降序排序</span></span><br><span class="line">    <span class="comment"># sorted, reverse -- 排序规则，reverse = True 降序 ， reverse = False 升序（默认）,降序排列</span></span><br><span class="line">    sort_score = <span class="built_in">sorted</span>(<span class="built_in">zip</span>(dict_data.values(), dict_data.keys()), reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 得到30个特征的关键词</span></span><br><span class="line">    F1_keys = [sort_score[i][<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">30</span>)]</span><br><span class="line">    feature_name.append(F1_keys)</span><br><span class="line"></span><br><span class="line">feature_names = pd.DataFrame(feature_name, index=[<span class="string">&#x27;stage_2&#x27;</span>, <span class="string">&#x27;stage_3&#x27;</span>, <span class="string">&#x27;stage_4&#x27;</span>, <span class="string">&#x27;stage_5&#x27;</span>], columns=np.arange(<span class="number">1</span>, <span class="number">31</span>)).T</span><br><span class="line">feature_names.to_excel(<span class="string">&#x27;slpdb的特征贡献度特征排序.xlsx&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="查看两个数据库的单人情况"><a href="#查看两个数据库的单人情况" class="headerlink" title="查看两个数据库的单人情况"></a>查看两个数据库的单人情况</h1><p>首先生成对应的特征组合数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取2345期的睡眠结果</span></span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">6</span>):</span><br><span class="line">    df = pd.read_excel(<span class="string">&#x27;E:/8-23 feature section and importance/slpdb_feature_acr_stage&#x27;</span> + <span class="string">&#x27;%d&#x27;</span> % index + <span class="string">&#x27;.xlsx&#x27;</span>).T</span><br><span class="line">    <span class="comment"># 读取18个数据的平均准确率</span></span><br><span class="line">    F_mean = [[np.array([<span class="built_in">eval</span>(df[k][i])[num] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>)]).mean() <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">25</span>)] <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">18</span>)]</span><br><span class="line">    slpdb_singel = pd.DataFrame(F_mean)</span><br><span class="line">    slpdb_singel.to_excel(<span class="string">&#x27;slpdb_stage_&#x27;</span> + <span class="string">&#x27;%d&#x27;</span> % index + <span class="string">&#x27;.xlsx&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>查看生成的4个阶段，在同一个数据库中，差距变化并不大</p>
<p>因此现在选择初始的5个特征作为比较，看每个数据在不同周期下的情况</p>
<table>
<thead>
<tr>
<th></th>
<th><strong>stage_2</strong></th>
<th><strong>stage_3</strong></th>
<th><strong>stage_4</strong></th>
<th><strong>stage_5</strong></th>
<th><strong>AHI</strong></th>
<th><strong>Seff(%)</strong></th>
</tr>
</thead>
<tbody><tr>
<td>slp01a</td>
<td>97.59%</td>
<td>95.80%</td>
<td>83.88%</td>
<td>82.55%</td>
<td>17.0</td>
<td>97.82</td>
</tr>
<tr>
<td>slp01b</td>
<td>86.95%</td>
<td>80.95%</td>
<td>81.58%</td>
<td>76.67%</td>
<td>22.3</td>
<td>48.42</td>
</tr>
<tr>
<td>slp02a</td>
<td>94.27%</td>
<td>89.12%</td>
<td>85.77%</td>
<td>83.47%</td>
<td>34.0</td>
<td>85.10</td>
</tr>
<tr>
<td>slp02b</td>
<td>89.15%</td>
<td>85.10%</td>
<td>85.79%</td>
<td>84.00%</td>
<td>22.2</td>
<td>60.62</td>
</tr>
<tr>
<td>slp03</td>
<td>88.86%</td>
<td>81.59%</td>
<td>77.32%</td>
<td>70.04%</td>
<td>43.0</td>
<td>83.19</td>
</tr>
<tr>
<td>slp04</td>
<td>91.11%</td>
<td>89.93%</td>
<td>85.92%</td>
<td>83.01%</td>
<td>59.8</td>
<td>78.14</td>
</tr>
<tr>
<td>slp14</td>
<td>81.29%</td>
<td>79.86%</td>
<td>79.11%</td>
<td>65.33%</td>
<td>30.7</td>
<td>55.05</td>
</tr>
<tr>
<td>slp16</td>
<td>84.72%</td>
<td>83.80%</td>
<td>82.58%</td>
<td>80.89%</td>
<td>53.1</td>
<td>55.20</td>
</tr>
<tr>
<td>slp32</td>
<td>92.84%</td>
<td>92.63%</td>
<td>81.66%</td>
<td>80.86%</td>
<td>22.1</td>
<td>39.11</td>
</tr>
<tr>
<td>slp37</td>
<td>94.72%</td>
<td>94.23%</td>
<td>94.07%</td>
<td>92.42%</td>
<td>100.8</td>
<td>89.37</td>
</tr>
<tr>
<td>slp41</td>
<td>83.87%</td>
<td>80.64%</td>
<td>80.39%</td>
<td>62.35%</td>
<td>60 [2]</td>
<td>71.65</td>
</tr>
<tr>
<td>slp45</td>
<td>92.92%</td>
<td>88.30%</td>
<td>80.58%</td>
<td>76.06%</td>
<td>5 [2]</td>
<td>85.05</td>
</tr>
<tr>
<td>slp48</td>
<td>90.36%</td>
<td>88.83%</td>
<td>89.14%</td>
<td>66.04%</td>
<td>46.8</td>
<td>72.10</td>
</tr>
<tr>
<td>slp59</td>
<td>86.49%</td>
<td>84.24%</td>
<td>77.87%</td>
<td>72.43%</td>
<td>55.3</td>
<td>69.80</td>
</tr>
<tr>
<td>slp60</td>
<td>87.78%</td>
<td>84.57%</td>
<td>85.07%</td>
<td>78.56%</td>
<td>59.2</td>
<td>59.23</td>
</tr>
<tr>
<td>slp61</td>
<td>89.54%</td>
<td>87.57%</td>
<td>80.29%</td>
<td>73.15%</td>
<td>41.2</td>
<td>83.22</td>
</tr>
<tr>
<td>slp66</td>
<td>87.94%</td>
<td>88.20%</td>
<td>87.04%</td>
<td>73.16%</td>
<td>65.5</td>
<td>61.07</td>
</tr>
<tr>
<td><strong>slp67x</strong></td>
<td><strong>79.95%</strong></td>
<td><strong>79.44%</strong></td>
<td><strong>80.09%</strong></td>
<td><strong>69.72%</strong></td>
<td>0.7</td>
<td>54.55</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th></th>
<th><strong>stage_2</strong></th>
<th><strong>stage_3</strong></th>
<th><strong>stage_4</strong></th>
<th><strong>stage_5</strong></th>
<th>PSG AHI</th>
<th>Seff (%)</th>
</tr>
</thead>
<tbody><tr>
<td>UCDDB002</td>
<td>90.15%</td>
<td>84.77%</td>
<td>76.27%</td>
<td>66.92%</td>
<td>23</td>
<td>84.96</td>
</tr>
<tr>
<td>UCDDB003</td>
<td>95.50%</td>
<td>91.20%</td>
<td>85.08%</td>
<td>80.12%</td>
<td>51</td>
<td>81.97</td>
</tr>
<tr>
<td>UCDDB005</td>
<td>87.31%</td>
<td>82.83%</td>
<td>81.25%</td>
<td>73.46%</td>
<td>13</td>
<td>65.86</td>
</tr>
<tr>
<td>UCDDB006</td>
<td>95.00%</td>
<td>90.21%</td>
<td>82.68%</td>
<td>77.42%</td>
<td>31</td>
<td>92.79</td>
</tr>
<tr>
<td>UCDDB007</td>
<td>92.66%</td>
<td>87.80%</td>
<td>81.70%</td>
<td>76.85%</td>
<td>12</td>
<td>90.52</td>
</tr>
<tr>
<td>UCDDB008</td>
<td>88.47%</td>
<td>85.11%</td>
<td>80.01%</td>
<td>71.42%</td>
<td>5</td>
<td>73.83</td>
</tr>
<tr>
<td>UCDDB009</td>
<td>86.84%</td>
<td>86.61%</td>
<td>76.91%</td>
<td>70.63%</td>
<td>12</td>
<td>79.98</td>
</tr>
<tr>
<td>UCDDB010</td>
<td>93.61%</td>
<td>86.52%</td>
<td>82.15%</td>
<td>76.10%</td>
<td>34</td>
<td>92.52</td>
</tr>
<tr>
<td>UCDDB011</td>
<td>91.37%</td>
<td>88.07%</td>
<td>80.90%</td>
<td>78.05%</td>
<td>8</td>
<td>61.12</td>
</tr>
<tr>
<td>UCDDB012</td>
<td>91.60%</td>
<td>84.68%</td>
<td>80.43%</td>
<td>75.52%</td>
<td>25</td>
<td>86.05</td>
</tr>
<tr>
<td>UCDDB013</td>
<td>88.38%</td>
<td>85.77%</td>
<td>84.61%</td>
<td>81.25%</td>
<td>16</td>
<td>61.75</td>
</tr>
<tr>
<td>UCDDB014</td>
<td>87.39%</td>
<td>84.66%</td>
<td>85.00%</td>
<td>74.87%</td>
<td>36</td>
<td>79.82</td>
</tr>
<tr>
<td>UCDDB015</td>
<td>83.48%</td>
<td>79.19%</td>
<td>78.02%</td>
<td>70.76%</td>
<td>6</td>
<td>80.25</td>
</tr>
<tr>
<td>UCDDB017</td>
<td>93.46%</td>
<td>88.16%</td>
<td>81.74%</td>
<td>80.11%</td>
<td>12</td>
<td>88.17</td>
</tr>
<tr>
<td><strong>UCDDB018</strong></td>
<td><strong>92.25%</strong></td>
<td><strong>89.76%</strong></td>
<td><strong>90.24%</strong></td>
<td><strong>87.82%</strong></td>
<td>2</td>
<td>60.91</td>
</tr>
<tr>
<td>UCDDB019</td>
<td>94.89%</td>
<td>84.90%</td>
<td>82.22%</td>
<td>80.19%</td>
<td>16</td>
<td>92.74</td>
</tr>
<tr>
<td>UCDDB020</td>
<td>84.75%</td>
<td>82.27%</td>
<td>80.90%</td>
<td>75.78%</td>
<td>15</td>
<td>78.14</td>
</tr>
<tr>
<td>UCDDB021</td>
<td>91.93%</td>
<td>87.16%</td>
<td>83.76%</td>
<td>79.42%</td>
<td>13</td>
<td>84.77</td>
</tr>
<tr>
<td>UCDDB022</td>
<td>87.14%</td>
<td>86.52%</td>
<td>85.84%</td>
<td>84.08%</td>
<td>7</td>
<td>59.20</td>
</tr>
<tr>
<td>UCDDB023</td>
<td>81.09%</td>
<td>79.60%</td>
<td>76.65%</td>
<td>64.41%</td>
<td>39</td>
<td>66.19</td>
</tr>
<tr>
<td>UCDDB024</td>
<td>91.32%</td>
<td>86.76%</td>
<td>83.42%</td>
<td>79.03%</td>
<td>24</td>
<td>83.50</td>
</tr>
<tr>
<td>UCDDB025</td>
<td>78.15%</td>
<td>75.19%</td>
<td>74.87%</td>
<td>58.10%</td>
<td>91</td>
<td>78.00</td>
</tr>
<tr>
<td>UCDDB026</td>
<td>95.52%</td>
<td>85.37%</td>
<td>79.05%</td>
<td>74.18%</td>
<td>14</td>
<td>87.30</td>
</tr>
<tr>
<td>UCDDB027</td>
<td>92.88%</td>
<td>85.71%</td>
<td>86.15%</td>
<td>80.86%</td>
<td>55</td>
<td>86.85</td>
</tr>
<tr>
<td>UCDDB028</td>
<td>73.49%</td>
<td>64.52%</td>
<td>62.79%</td>
<td>55.63%</td>
<td>46</td>
<td>69.20</td>
</tr>
</tbody></table>
<p>利用AHI和SEFF进行分类别，看下平均的</p>
<p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1598265807368&di=de5fc4ce35b04ffbc8ea8699648516a7&imgtype=0&src=http://i0.hdslb.com/bfs/article/f19c090f678c8e472ad62affb63457d976163339.jpg"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://esyyes.github.io/2020/08/24/%E6%9F%A5%E7%9C%8B%E5%8D%95%E7%8B%AC%E6%95%B0%E6%8D%AE%E4%B8%8B%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87/" data-id="ckh4h5f87006zisuehoj8639d" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/work/" rel="tag">work</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-绘制特征选择结果图" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/08/23/%E7%BB%98%E5%88%B6%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E7%BB%93%E6%9E%9C%E5%9B%BE/" class="article-date">
  <time datetime="2020-08-23T08:39:46.000Z" itemprop="datePublished">2020-08-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/work/">work</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/08/23/%E7%BB%98%E5%88%B6%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E7%BB%93%E6%9E%9C%E5%9B%BE/">绘制特征选择结果图</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="绘制特征选择结果图"><a href="#绘制特征选择结果图" class="headerlink" title="绘制特征选择结果图"></a>绘制特征选择结果图</h1><ol>
<li>利用RFE-RF生成的数据特征准确率数据去判定最佳的特征数目</li>
<li>比较不同组合下的特征之间的数目和区别</li>
</ol>
<h2 id="slpdb库中的全部数据下的特征选择结果图"><a href="#slpdb库中的全部数据下的特征选择结果图" class="headerlink" title="slpdb库中的全部数据下的特征选择结果图"></a>slpdb库中的全部数据下的特征选择结果图</h2><p>先读取出slpdb中2期的分期准确率结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取2345期的睡眠结果</span></span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">3</span>):</span><br><span class="line">    data = pd.read_excel(<span class="string">&#x27;E:/8-23 feature section and importance/slpdb_feature_acr_stage&#x27;</span> + <span class="string">&#x27;%d&#x27;</span> % index + <span class="string">&#x27;.xlsx&#x27;</span>)</span><br><span class="line">    df = data.T</span><br><span class="line">    <span class="comment"># 读取18个数据的平均准确率</span></span><br><span class="line">    F_mean = []</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">18</span>):</span><br><span class="line">        <span class="comment"># 读取25个特征子集组合的特征平均准确率</span></span><br><span class="line">        feature_num_mean = []</span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">25</span>):</span><br><span class="line">            <span class="comment"># 读取第一个数据的前面准确率结果</span></span><br><span class="line">            <span class="comment"># 特征对应的准确率</span></span><br><span class="line">            feature_acr = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line">                feature_acr.append(<span class="built_in">eval</span>(df[k][i])[num])</span><br><span class="line">            <span class="comment"># 将50准确率求平均值</span></span><br><span class="line">            feature_mean = np.array(feature_acr).mean()</span><br><span class="line">            feature_num_mean.append(feature_mean)</span><br><span class="line">        F_mean.append(feature_num_mean)</span><br></pre></td></tr></table></figure>

<p>进行化简，F_mean暂时留着吧，也没啥用，到时直接读取数据的量就行了去针对性的读取，还是留着吧</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取2345期的睡眠结果</span></span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">3</span>):</span><br><span class="line">    df = pd.read_excel(<span class="string">&#x27;E:/8-23 feature section and importance/slpdb_feature_acr_stage&#x27;</span> + <span class="string">&#x27;%d&#x27;</span> % index + <span class="string">&#x27;.xlsx&#x27;</span>).T</span><br><span class="line">    <span class="comment"># 读取18个数据的平均准确率</span></span><br><span class="line">    F_mean = [[np.array([<span class="built_in">eval</span>(df[k][i])[num] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>)]).mean() <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">25</span>)] <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">18</span>)]</span><br><span class="line">    <span class="comment"># 对应特征求一个平均准确率，先用整体的来计算</span></span><br><span class="line">    <span class="comment"># 总共有25个特征组合</span></span><br><span class="line">    feature_total = []</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">25</span>):</span><br><span class="line">        acr = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(F_mean)):</span><br><span class="line">            acr.append(F_mean[i][j])</span><br><span class="line">        <span class="comment"># 转换为百分数，乘以100</span></span><br><span class="line">        all_mean = np.array(acr).mean()*<span class="number">100</span></span><br><span class="line">        feature_total.append(all_mean)</span><br></pre></td></tr></table></figure>

<p>这儿对应的25个特征组合，在18个数据下的平均准确率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2020/8/23</span></span><br><span class="line"><span class="comment"># @Author   : esy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将2345期的组合放到1个list中</span></span><br><span class="line">slpdb_stage = []</span><br><span class="line"><span class="comment"># 读取2345期的睡眠结果</span></span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">6</span>):</span><br><span class="line">    df = pd.read_excel(<span class="string">&#x27;E:/8-23 feature section and importance/slpdb_feature_acr_stage&#x27;</span> + <span class="string">&#x27;%d&#x27;</span> % index + <span class="string">&#x27;.xlsx&#x27;</span>).T</span><br><span class="line">    <span class="comment"># 读取18个数据的平均准确率</span></span><br><span class="line">    F_mean = [[np.array([<span class="built_in">eval</span>(df[k][i])[num] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>)]).mean() <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">25</span>)] <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">18</span>)]</span><br><span class="line">    <span class="comment"># 总共有25个特征组合</span></span><br><span class="line">    feature_total = [np.array([F_mean[i][j] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(F_mean))]).mean()*<span class="number">100</span> <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">25</span>)]</span><br><span class="line">    slpdb_stage.append(feature_total)</span><br></pre></td></tr></table></figure>

<h2 id="slpdb全部数据的绘制"><a href="#slpdb全部数据的绘制" class="headerlink" title="slpdb全部数据的绘制"></a>slpdb全部数据的绘制</h2><p>将其进行绘制</p>
<p> <a target="_blank" rel="noopener" href="https://blog.csdn.net/Poul_henry/article/details/82590392?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~all~first_rank_v2~rank_v25-1-82590392.nonecase&utm_term=python%E6%94%B9%E6%A8%AA%E5%9D%90%E6%A0%87">https://blog.csdn.net/Poul_henry/article/details/82590392?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2<del>all</del>first_rank_v2~rank_v25-1-82590392.nonecase&amp;utm_term=python%E6%94%B9%E6%A8%AA%E5%9D%90%E6%A0%87</a> </p>
<p>横纵坐标的更改</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将2345期的组合放到1个list中</span></span><br><span class="line">slpdb_stage = []</span><br><span class="line"><span class="comment"># 读取2345期的睡眠结果</span></span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">6</span>):</span><br><span class="line">    df = pd.read_excel(<span class="string">&#x27;E:/8-23 feature section and importance/slpdb_feature_acr_stage&#x27;</span> + <span class="string">&#x27;%d&#x27;</span> % index + <span class="string">&#x27;.xlsx&#x27;</span>).T</span><br><span class="line">    <span class="comment"># 读取18个数据的平均准确率</span></span><br><span class="line">    F_mean = [[np.array([<span class="built_in">eval</span>(df[k][i])[num] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>)]).mean() <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">25</span>)] <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">18</span>)]</span><br><span class="line">    <span class="comment"># 总共有25个特征组合</span></span><br><span class="line">    feature_total = [np.array([F_mean[i][j] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(F_mean))]).mean()*<span class="number">100</span> <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">25</span>)]</span><br><span class="line">    slpdb_stage.append(feature_total)</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">1</span>, <span class="number">26</span>)</span><br><span class="line">x1 = np.arange(<span class="number">5</span>, <span class="number">31</span>)</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">10</span>, <span class="number">8</span>))</span><br><span class="line"><span class="comment"># 显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line"><span class="comment"># x轴重命名</span></span><br><span class="line">plt.xticks(x, x1)</span><br><span class="line">plt.plot(x, slpdb_stage[<span class="number">0</span>], <span class="string">&quot;k*--&quot;</span>, linewidth=<span class="number">1</span>, label=<span class="string">&#x27;class_2&#x27;</span>)</span><br><span class="line">plt.plot(x, slpdb_stage[<span class="number">1</span>], <span class="string">&quot;b*--&quot;</span>, linewidth=<span class="number">1</span>, label=<span class="string">&#x27;class_3&#x27;</span>)</span><br><span class="line">plt.plot(x, slpdb_stage[<span class="number">2</span>], <span class="string">&quot;r*--&quot;</span>, linewidth=<span class="number">1</span>, label=<span class="string">&#x27;class_4&#x27;</span>)</span><br><span class="line">plt.plot(x, slpdb_stage[<span class="number">3</span>], <span class="string">&quot;y*--&quot;</span>, linewidth=<span class="number">1</span>, label=<span class="string">&#x27;class_4&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">4</span>):</span><br><span class="line">    plt.scatter(x[slpdb_stage[i].index(<span class="built_in">max</span>(slpdb_stage[i]))], <span class="built_in">max</span>(slpdb_stage[i]), s=<span class="number">80</span>, color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">&quot;Number of Features&quot;</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">plt.xticks(fontsize=<span class="number">8</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Average Accuracy of RF/%&quot;</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">plt.yticks(fontsize=<span class="number">8</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line"><span class="comment"># 隐藏左边和上边的边框</span></span><br><span class="line">ax = plt.gca()</span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">fig.savefig(<span class="string">&#x27;slpdb所有数据的一起绘制图.png&#x27;</span>, dpi=<span class="number">1600</span>, bbox_inches=<span class="string">&#x27;tight&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="H:\myboke\mybike\source\images\slpdb所有数据的一起绘制图.png"></p>
<p>太模糊了将其绘制成子图的形式</p>
<h2 id="子图形式的绘制"><a href="#子图形式的绘制" class="headerlink" title="子图形式的绘制"></a>子图形式的绘制</h2><p><img src="H:\myboke\mybike\source\images\slpdb数据的子图绘制.png"></p>
<h2 id="特征数目表"><a href="#特征数目表" class="headerlink" title="特征数目表"></a>特征数目表</h2><table>
<thead>
<tr>
<th>特征数</th>
<th><strong>stage_2</strong></th>
<th><strong>stage_3</strong></th>
<th><strong>stage_4</strong></th>
<th><strong>stage_5</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>5</strong></td>
<td>88.91</td>
<td>86.38</td>
<td>83.23</td>
<td>76.15</td>
</tr>
<tr>
<td><strong>6</strong></td>
<td>89.21</td>
<td>86.99</td>
<td>83.86</td>
<td>76.82</td>
</tr>
<tr>
<td><strong>7</strong></td>
<td>89.55</td>
<td>87.23</td>
<td>84.21</td>
<td>77.23</td>
</tr>
<tr>
<td><strong>8</strong></td>
<td>89.82</td>
<td>87.62</td>
<td>84.49</td>
<td>77.76</td>
</tr>
<tr>
<td><strong>9</strong></td>
<td>90.06</td>
<td>87.93</td>
<td>85.03</td>
<td>77.96</td>
</tr>
<tr>
<td><strong>10</strong></td>
<td>90.04</td>
<td>88.19</td>
<td>85.22</td>
<td>78.14</td>
</tr>
<tr>
<td><strong>11</strong></td>
<td>90.12</td>
<td>88.27</td>
<td>85.36</td>
<td>78.23</td>
</tr>
<tr>
<td><strong>12</strong></td>
<td>90.29</td>
<td>88.29</td>
<td>85.59</td>
<td>78.77</td>
</tr>
<tr>
<td><strong>13</strong></td>
<td>90.42</td>
<td>88.55</td>
<td>85.62</td>
<td>78.68</td>
</tr>
<tr>
<td><strong>14</strong></td>
<td>90.46</td>
<td>88.57</td>
<td>85.75</td>
<td>78.81</td>
</tr>
<tr>
<td><strong>15</strong></td>
<td>90.53</td>
<td>88.64</td>
<td>85.86</td>
<td>78.91</td>
</tr>
<tr>
<td><strong>16</strong></td>
<td>90.64</td>
<td>88.70</td>
<td>85.95</td>
<td>78.99</td>
</tr>
<tr>
<td><strong>17</strong></td>
<td>90.59</td>
<td>88.74</td>
<td>86.06</td>
<td>79.11</td>
</tr>
<tr>
<td><strong>18</strong></td>
<td>90.63</td>
<td>88.80</td>
<td>86.07</td>
<td>79.16</td>
</tr>
<tr>
<td><strong>19</strong></td>
<td>90.68</td>
<td>88.86</td>
<td>86.07</td>
<td>79.15</td>
</tr>
<tr>
<td><strong>20</strong></td>
<td>90.59</td>
<td>88.79</td>
<td>86.09</td>
<td>79.32</td>
</tr>
<tr>
<td><strong>21</strong></td>
<td>90.71</td>
<td>88.91</td>
<td>86.13</td>
<td>79.39</td>
</tr>
<tr>
<td><strong>22</strong></td>
<td>90.76</td>
<td>88.87</td>
<td>86.12</td>
<td>79.26</td>
</tr>
<tr>
<td><strong>23</strong></td>
<td>90.70</td>
<td>88.92</td>
<td>86.31</td>
<td>79.30</td>
</tr>
<tr>
<td><strong>24</strong></td>
<td>90.76</td>
<td>88.88</td>
<td>86.26</td>
<td>79.39</td>
</tr>
<tr>
<td><strong>25</strong></td>
<td>90.72</td>
<td>89.00</td>
<td>86.26</td>
<td>79.54</td>
</tr>
<tr>
<td><strong>26</strong></td>
<td>90.73</td>
<td>88.93</td>
<td>86.18</td>
<td>79.41</td>
</tr>
<tr>
<td><strong>27</strong></td>
<td>90.73</td>
<td>88.96</td>
<td>86.24</td>
<td>79.44</td>
</tr>
<tr>
<td><strong>28</strong></td>
<td>90.73</td>
<td>89.05</td>
<td>86.27</td>
<td>79.54</td>
</tr>
<tr>
<td><strong>29</strong></td>
<td>90.67</td>
<td>88.95</td>
<td>86.28</td>
<td>79.65</td>
</tr>
</tbody></table>
<h2 id="ucddb库中的全部数据的绘制结果"><a href="#ucddb库中的全部数据的绘制结果" class="headerlink" title="ucddb库中的全部数据的绘制结果"></a>ucddb库中的全部数据的绘制结果</h2><p><img src="H:\myboke\mybike\source\images\ucddb所有数据的一起绘制图.png"></p>
<h2 id="子图形式的绘制-1"><a href="#子图形式的绘制-1" class="headerlink" title="子图形式的绘制"></a>子图形式的绘制</h2><p><img src="H:\myboke\mybike\source\images\ucddb数据的子图绘制.png"></p>
<h2 id="特征数目表-1"><a href="#特征数目表-1" class="headerlink" title="特征数目表"></a>特征数目表</h2><table>
<thead>
<tr>
<th align="center"></th>
<th align="center"><strong>stage_2</strong></th>
<th align="center"><strong>stage_3</strong></th>
<th align="center"><strong>stage_4</strong></th>
<th align="center"><strong>stage_5</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>5</strong></td>
<td align="center">90.50</td>
<td align="center">86.09</td>
<td align="center">81.88</td>
<td align="center">76.48</td>
</tr>
<tr>
<td align="center"><strong>6</strong></td>
<td align="center">90.79</td>
<td align="center">86.86</td>
<td align="center">82.98</td>
<td align="center">77.87</td>
</tr>
<tr>
<td align="center"><strong>7</strong></td>
<td align="center">91.10</td>
<td align="center">87.34</td>
<td align="center">83.64</td>
<td align="center">78.77</td>
</tr>
<tr>
<td align="center"><strong>8</strong></td>
<td align="center">91.27</td>
<td align="center">87.73</td>
<td align="center">84.16</td>
<td align="center">79.43</td>
</tr>
<tr>
<td align="center"><strong>9</strong></td>
<td align="center">91.52</td>
<td align="center">88.12</td>
<td align="center">84.54</td>
<td align="center">80.06</td>
</tr>
<tr>
<td align="center"><strong>10</strong></td>
<td align="center">91.68</td>
<td align="center">88.39</td>
<td align="center">84.81</td>
<td align="center">80.40</td>
</tr>
<tr>
<td align="center"><strong>11</strong></td>
<td align="center">91.79</td>
<td align="center">88.59</td>
<td align="center">85.08</td>
<td align="center">80.67</td>
</tr>
<tr>
<td align="center"><strong>12</strong></td>
<td align="center">91.80</td>
<td align="center">88.76</td>
<td align="center">85.30</td>
<td align="center">81.05</td>
</tr>
<tr>
<td align="center"><strong>13</strong></td>
<td align="center">91.90</td>
<td align="center">88.96</td>
<td align="center">85.45</td>
<td align="center">81.24</td>
</tr>
<tr>
<td align="center"><strong>14</strong></td>
<td align="center">91.94</td>
<td align="center">89.06</td>
<td align="center">85.62</td>
<td align="center">81.41</td>
</tr>
<tr>
<td align="center"><strong>15</strong></td>
<td align="center">91.97</td>
<td align="center">89.14</td>
<td align="center">85.79</td>
<td align="center">81.53</td>
</tr>
<tr>
<td align="center"><strong>16</strong></td>
<td align="center">92.06</td>
<td align="center">89.30</td>
<td align="center">85.84</td>
<td align="center">81.69</td>
</tr>
<tr>
<td align="center"><strong>17</strong></td>
<td align="center">92.12</td>
<td align="center">89.39</td>
<td align="center">86.02</td>
<td align="center">81.89</td>
</tr>
<tr>
<td align="center"><strong>18</strong></td>
<td align="center">92.10</td>
<td align="center">89.48</td>
<td align="center">86.03</td>
<td align="center">82.10</td>
</tr>
<tr>
<td align="center"><strong>19</strong></td>
<td align="center">92.18</td>
<td align="center">89.45</td>
<td align="center">86.10</td>
<td align="center">82.01</td>
</tr>
<tr>
<td align="center"><strong>20</strong></td>
<td align="center">92.15</td>
<td align="center">89.46</td>
<td align="center">86.13</td>
<td align="center">82.16</td>
</tr>
<tr>
<td align="center"><strong>21</strong></td>
<td align="center">92.20</td>
<td align="center">89.62</td>
<td align="center">86.26</td>
<td align="center">82.20</td>
</tr>
<tr>
<td align="center"><strong>22</strong></td>
<td align="center">92.16</td>
<td align="center">89.59</td>
<td align="center">86.27</td>
<td align="center">82.16</td>
</tr>
<tr>
<td align="center"><strong>23</strong></td>
<td align="center">92.22</td>
<td align="center">89.62</td>
<td align="center">86.29</td>
<td align="center">82.36</td>
</tr>
<tr>
<td align="center"><strong>24</strong></td>
<td align="center">92.22</td>
<td align="center">89.58</td>
<td align="center">86.30</td>
<td align="center">82.36</td>
</tr>
<tr>
<td align="center"><strong>25</strong></td>
<td align="center">92.24</td>
<td align="center">89.76</td>
<td align="center">86.42</td>
<td align="center">82.43</td>
</tr>
<tr>
<td align="center"><strong>26</strong></td>
<td align="center">92.20</td>
<td align="center">89.67</td>
<td align="center">86.35</td>
<td align="center">82.38</td>
</tr>
<tr>
<td align="center"><strong>27</strong></td>
<td align="center">92.21</td>
<td align="center">89.70</td>
<td align="center">86.38</td>
<td align="center">82.48</td>
</tr>
<tr>
<td align="center"><strong>28</strong></td>
<td align="center">92.28</td>
<td align="center">89.71</td>
<td align="center">86.35</td>
<td align="center">82.51</td>
</tr>
<tr>
<td align="center"><strong>29</strong></td>
<td align="center">92.25</td>
<td align="center">89.76</td>
<td align="center">86.40</td>
<td align="center">82.44</td>
</tr>
</tbody></table>
<p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1598175163552&di=6293d942b394e03ebcfd0ccd5e931831&imgtype=0&src=http://c.hiphotos.baidu.com/zhidao/pic/item/d31b0ef41bd5ad6eaf4a33b383cb39dbb6fd3c33.jpg"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://esyyes.github.io/2020/08/23/%E7%BB%98%E5%88%B6%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E7%BB%93%E6%9E%9C%E5%9B%BE/" data-id="ckh4h5f8d007misuedpqj3ff3" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/work/" rel="tag">work</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/">&amp;laquo; 上一页</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><a class="extend next" rel="next" href="/page/3/">下一页 &amp;raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/hexo%E5%AE%8C%E5%96%84/">-hexo完善</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/matlab-%E5%B7%A5%E4%BD%9C/">-matlab -工作</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python%E5%9F%BA%E7%A1%80/">-python基础</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%8D%87%E7%BA%A7conda/">-升级conda</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E4%BD%9C/">-工作</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E4%BD%9C-matlab/">-工作 -matlab</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Graduation-work/">Graduation work</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/mathematical-modeling/">mathematical modeling</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/matlab/">matlab</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/nlp/">nlp</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/py-study/">py_study</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python%E5%9F%BA%E7%A1%80/">python基础</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/work/">work</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B8%B8%E6%88%8F%E4%BA%BA%E7%94%9F/">游戏人生</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%9A%8F%E7%AC%94/">随笔</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/malab-%E6%AF%95%E4%B8%9A/" rel="tag">-malab -毕业</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">-python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" rel="tag">-python -人工智能</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/" rel="tag">-个人博客搭建</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Graduation-work/" rel="tag">Graduation work</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/" rel="tag">hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mathematical-modeling/" rel="tag">mathematical modeling</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nlp/" rel="tag">nlp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/py-study/" rel="tag">py_study</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/work/" rel="tag">work</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/malab-%E6%AF%95%E4%B8%9A/" style="font-size: 12px;">-malab -毕业</a> <a href="/tags/python/" style="font-size: 10px;">-python</a> <a href="/tags/python-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" style="font-size: 10px;">-python -人工智能</a> <a href="/tags/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/" style="font-size: 10px;">-个人博客搭建</a> <a href="/tags/Graduation-work/" style="font-size: 14px;">Graduation work</a> <a href="/tags/hexo/" style="font-size: 12px;">hexo</a> <a href="/tags/mathematical-modeling/" style="font-size: 16px;">mathematical modeling</a> <a href="/tags/nlp/" style="font-size: 12px;">nlp</a> <a href="/tags/py-study/" style="font-size: 10px;">py_study</a> <a href="/tags/python/" style="font-size: 18px;">python</a> <a href="/tags/work/" style="font-size: 20px;">work</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">十一月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">十月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">九月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">八月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">七月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">六月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">五月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">四月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">三月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">一月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">十二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/11/04/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2020/11/03/%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/">分类模型的评估指标</a>
          </li>
        
          <li>
            <a href="/2020/10/21/10-21-%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/">10-21 爬虫基础</a>
          </li>
        
          <li>
            <a href="/2020/09/25/CRF%E7%9A%84%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B%E7%BB%93%E6%9E%9C/">CRF的整体流程结果</a>
          </li>
        
          <li>
            <a href="/2020/09/25/nlp-crf%E6%A8%A1%E5%9E%8B/">nlp_crf模型</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 esy<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>